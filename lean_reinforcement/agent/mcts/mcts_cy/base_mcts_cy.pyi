from typing import List, Optional, Dict, Any, Tuple
import torch
from lean_dojo import TacticState, ProofFinished, LeanError, ProofGivenUp
from lean_reinforcement.utilities.gym import LeanDojoEnv
from lean_reinforcement.agent.transformer import TransformerProtocol

class Edge:
    action: str
    prior: float
    child: Node
    visit_count: int
    def __init__(self, action: str, prior: float, child: Node) -> None: ...

class Node:
    state: Any
    parents: List[
        Tuple[Node, Optional[str]]
    ]  # DAG structure: list of (parent, action) tuples
    action: Optional[str]
    prior_p: float
    children: List[Node]
    visit_count: int
    max_value: float
    is_terminal: bool
    untried_actions: Optional[List[str]]
    encoder_features: Optional[torch.Tensor]

    @property
    def parent(self) -> Optional[Node]: ...  # Backward compatibility property
    def __init__(
        self, state: Union[TacticState, ProofFinished, LeanError, ProofGivenUp]
    ) -> None: ...
    def value(self) -> float: ...
    def is_fully_expanded(self) -> bool: ...
    def add_parent(self, parent: Node, action: Optional[str] = ...) -> None: ...
    def get_parent(self) -> Optional[Node]: ...

class BaseMCTS:
    env: LeanDojoEnv
    transformer: TransformerProtocol
    exploration_weight: float
    max_tree_nodes: int
    batch_size: int
    num_tactics_to_expand: int
    max_rollout_depth: int
    max_time: float
    node_count: int
    virtual_losses: Dict[Node, int]
    seen_states: Dict[str, Node]
    theorem: Any
    theorem_pos: Any
    root: Node

    def __init__(
        self,
        env: LeanDojoEnv,
        transformer: TransformerProtocol,
        exploration_weight: float = ...,
        max_tree_nodes: int = ...,
        batch_size: int = ...,
        num_tactics_to_expand: int = ...,
        max_rollout_depth: int = ...,
        max_time: float = ...,
    ) -> None: ...
    def _get_or_create_node(self, state: Any) -> Node: ...
    def _get_virtual_loss(self, node: Node) -> int: ...
    def _add_virtual_loss(self, node: Node, loss: int = ...) -> None: ...
    def _remove_virtual_loss(self, node: Node, loss: int = ...) -> None: ...
    def _get_state_key(self, state: Any) -> Optional[str]: ...
    def _log_gpu_memory(self) -> None: ...
    def _get_reachable_nodes(self, root: Node) -> set: ...
    def _prune_unreachable_nodes(self, new_root: Node) -> int: ...
    def search(self, num_iterations: int, batch_size: Optional[int] = ...) -> None: ...
    def _select(self, node: Node) -> Tuple[Node, List[Tuple[Node, Optional[Edge]]]]: ...
    def _get_best_child(self, node: Node) -> Node: ...
    def _expand(self, node: Node) -> Tuple[Node, Optional[Edge]]: ...
    def _expand_batch(self, nodes: List[Node]) -> List[Tuple[Node, Optional[Edge]]]: ...
    def _simulate(self, node: Node) -> float: ...
    def _simulate_batch(self, nodes: List[Node]) -> List[float]: ...
    def _backpropagate(
        self, path: List[Tuple[Node, Optional[Edge]]], reward: float
    ) -> None: ...
    def get_best_action(self) -> Optional[str]: ...
    def move_root(self, action: str) -> None: ...
    def _count_nodes(self, node: Node) -> int: ...
    def _rebuild_seen_states(self, node: Node) -> None: ...
