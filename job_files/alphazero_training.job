#!/bin/bash

#SBATCH --partition=gpu_a100
#SBATCH --gpus=1
#SBATCH --job-name=alphazero_training
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=18
#SBATCH --time=12:00:00
#SBATCH --output=logs/alphazero_training_%A.out

module purge
module load 2024
module load Anaconda3/2024.06-1
module load CUDA/12.6.0

# Set CUDA_HOME environment variable
export CUDA_HOME=$CUDA_ROOT
export CUDA_PATH=$CUDA_ROOT

source activate lean-reinforcement

# Source environment variables
set -a
source $HOME/lean_reinforcement/.env
set +a

cd $HOME/lean_reinforcement

# Build Cython extensions
echo "Building Cython extensions..."
python3 setup.py build_ext --inplace

echo "Starting training run with distributed environment..."
srun python3 -m lean_reinforcement.training.train \
    --data-type novel_premises \
    --indexed-corpus-path $CORPUS_DIR/indexed_corpus.pkl \
    --num-epochs 128 \
    --num-theorems 100 \
    --num-iterations 200 \
    --batch-size 16 \
    --num-tactics-to-expand 16 \
    --num-workers 12 \
    --env-timeout 72 \
    --max-time 40 \
    --proof-timeout 300.0 \
    --mcts-type alpha_zero \
    --train-epochs 3 \
    --train-value-head \
    --use-final-reward \
    --save-training-data \
    --save-checkpoints \
    --resume \
    --use-wandb
