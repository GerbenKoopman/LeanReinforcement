#!/bin/bash

#SBATCH --partition=gpu_a100
#SBATCH --gpus=1
#SBATCH --job-name=guided_rollout_training
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=18
#SBATCH --time=36:00:00
#SBATCH --output=logs/guided_rollout_training_%A.out

module purge
module load 2024
module load Anaconda3/2024.06-1
module load CUDA/12.6.0

# Set CUDA_HOME environment variable
export CUDA_HOME=$CUDA_ROOT
export CUDA_PATH=$CUDA_ROOT

source activate lean-reinforcement

# Source environment variables
set -a
source $HOME/lean_reinforcement/.env
set +a

cd $HOME/lean_reinforcement

# Build Cython extensions
echo "Building Cython extensions..."
python3 setup.py build_ext --inplace

echo "Starting training run with distributed environment..."
srun python3 -m lean_reinforcement.training.train \
    --data-type novel_premises \
    --indexed-corpus-path $CORPUS_DIR/indexed_corpus.pkl \
    --num-epochs 128 \
    --num-theorems 32 \
    --num-iterations 1000 \
    --batch-size 64 \
    --num-tactics-to-expand 64 \
    --num-workers 16 \
    --mcts-type guided_rollout \
    --train-epochs 4 \
    --train-value-head \
    --use-final-reward \
    --save-training-data \
    --save-checkpoints \
    --resume \
    --use-wandb
