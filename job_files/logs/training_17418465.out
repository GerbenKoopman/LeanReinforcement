============================================================================================== 
Warning! Mixing Conda and module environments may lead to corruption of the
user environment. 
We do not recommend users mixing those two environments unless absolutely
necessary. Note that 
SURF does not provide any support for Conda environment.
For more information, please refer to our software policy page:
https://servicedesk.surf.nl/wiki/display/WIKI/Software+policy+Snellius#SoftwarepolicySnellius-UseofAnacondaandMinicondaenvironmentsonSnellius 

Remember that many packages have already been installed on the system and can
be loaded using 
the 'module load <package__name>' command. If you are uncertain if a package is
already available 
on the system, please use 'module avail' or 'module spider' to search for it.
============================================================================================== 
Starting training run with distributed environment...
wandb: Currently logged in as: gerbennkoopman to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: setting up run j8zb7k31
wandb: Tracking run with wandb version 0.22.3
wandb: Run data is saved locally in /gpfs/home1/gkoopman/lean_reinforcement/wandb/run-20251210_121559-j8zb7k31
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-cosmos-25
wandb: ‚≠êÔ∏è View project at https://wandb.ai/gerbennkoopman-university-of-amsterdam/lean-reinforcement
wandb: üöÄ View run at https://wandb.ai/gerbennkoopman-university-of-amsterdam/lean-reinforcement/runs/j8zb7k31
2025-12-10 12:16:01.483 | INFO     | __main__:main:184 - Using checkpoint directory: /gpfs/scratch1/shared/lean-reinforcement/checkpoints
2025-12-10 12:16:04.486 | INFO     | lean_reinforcement.agent.value_head:load_checkpoint:192 - Checkpoint loaded from /gpfs/scratch1/shared/lean-reinforcement/checkpoints/value_head_latest.pth
2025-12-10 12:16:04.487 | INFO     | __main__:main:197 - Resuming training from epoch 3
2025-12-10 12:16:04.488 | INFO     | __main__:log_gpu_memory:168 - After model initialization - GPU Memory: 1.12GB allocated, 1.23GB reserved
2025-12-10 12:16:04.488 | INFO     | __main__:main:202 - Loading data from 'leandojo_benchmark_4/novel_premises'
2025-12-10 12:16:04.488 | INFO     | ReProver.common:__init__:201 - Building the corpus from leandojo_benchmark_4/corpus.jsonl
2025-12-10 12:16:51.800 | INFO     | lean_dojo.data_extraction.trace:trace:248 - Loading the traced repo from /gpfs/scratch1/shared/lean-reinforcement/datasets/lean_dojo_cache/leanprover-community-mathlib4-29dcec074de168ac2bf835a77ef68bbe069194c5/mathlib4
2025-12-10 12:17:23,110	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
  0%|          | 0/5674 [00:00<?, ?it/s]  0%|          | 1/5674 [00:01<2:41:13,  1.71s/it]  0%|          | 2/5674 [00:06<5:09:07,  3.27s/it]  0%|          | 8/5674 [00:06<53:24,  1.77it/s]    0%|          | 10/5674 [00:06<39:36,  2.38it/s]  0%|          | 15/5674 [00:06<20:40,  4.56it/s]  0%|          | 18/5674 [00:06<15:24,  6.12it/s]  0%|          | 24/5674 [00:06<09:06, 10.33it/s]  1%|          | 31/5674 [00:11<32:09,  2.92it/s]  1%|          | 35/5674 [00:11<24:25,  3.85it/s]  1%|          | 40/5674 [00:11<17:25,  5.39it/s]  1%|          | 44/5674 [00:11<13:33,  6.92it/s]  1%|          | 50/5674 [00:11<09:11, 10.19it/s]  1%|          | 54/5674 [00:11<07:28, 12.53it/s]  1%|          | 58/5674 [00:12<06:20, 14.76it/s]  1%|          | 62/5674 [00:17<40:30,  2.31it/s]  1%|          | 65/5674 [00:17<32:20,  2.89it/s]  1%|          | 68/5674 [00:17<25:34,  3.65it/s]  1%|‚ñè         | 72/5674 [00:17<18:08,  5.15it/s]  1%|‚ñè         | 79/5674 [00:18<10:51,  8.59it/s]  1%|‚ñè         | 83/5674 [00:18<08:43, 10.69it/s]  2%|‚ñè         | 88/5674 [00:18<06:32, 14.25it/s]  2%|‚ñè         | 94/5674 [00:18<04:50, 19.21it/s]  2%|‚ñè         | 99/5674 [00:24<37:06,  2.50it/s]  2%|‚ñè         | 102/5674 [00:24<30:58,  3.00it/s]  2%|‚ñè         | 105/5674 [00:25<25:53,  3.59it/s]  2%|‚ñè         | 109/5674 [00:25<19:32,  4.75it/s]  2%|‚ñè         | 113/5674 [00:32<1:00:48,  1.52it/s]  2%|‚ñè         | 116/5674 [00:32<46:49,  1.98it/s]    2%|‚ñè         | 124/5674 [00:32<25:03,  3.69it/s]  2%|‚ñè         | 131/5674 [00:32<16:15,  5.68it/s]  2%|‚ñè         | 135/5674 [00:32<13:19,  6.93it/s]  2%|‚ñè         | 139/5674 [00:32<11:15,  8.20it/s]  3%|‚ñé         | 142/5674 [00:33<10:10,  9.06it/s]  3%|‚ñé         | 146/5674 [00:33<07:57, 11.59it/s]  3%|‚ñé         | 149/5674 [00:33<07:39, 12.03it/s]  3%|‚ñé         | 152/5674 [00:40<1:03:23,  1.45it/s]  3%|‚ñé         | 156/5674 [00:40<44:01,  2.09it/s]    3%|‚ñé         | 160/5674 [00:41<31:07,  2.95it/s]  3%|‚ñé         | 167/5674 [00:41<17:59,  5.10it/s]  3%|‚ñé         | 172/5674 [00:41<13:05,  7.00it/s]  3%|‚ñé         | 179/5674 [00:41<08:36, 10.65it/s]  3%|‚ñé         | 184/5674 [00:41<06:57, 13.14it/s]  3%|‚ñé         | 189/5674 [00:41<05:43, 15.98it/s]  3%|‚ñé         | 195/5674 [00:41<04:22, 20.88it/s]  4%|‚ñé         | 200/5674 [00:42<04:04, 22.39it/s]  4%|‚ñé         | 204/5674 [00:42<03:53, 23.43it/s]  4%|‚ñé         | 209/5674 [00:42<03:22, 26.98it/s]  4%|‚ñç         | 218/5674 [00:50<40:21,  2.25it/s]  4%|‚ñç         | 233/5674 [00:51<20:02,  4.52it/s]  4%|‚ñç         | 242/5674 [00:51<14:23,  6.29it/s]  4%|‚ñç         | 248/5674 [00:51<11:33,  7.82it/s]  4%|‚ñç         | 254/5674 [00:51<09:33,  9.44it/s]  5%|‚ñç         | 259/5674 [00:51<07:53, 11.44it/s]  5%|‚ñç         | 264/5674 [00:51<07:03, 12.77it/s]  5%|‚ñç         | 270/5674 [00:52<05:30, 16.36it/s]  5%|‚ñç         | 275/5674 [00:52<04:51, 18.50it/s]  5%|‚ñç         | 282/5674 [00:52<03:38, 24.62it/s]  5%|‚ñå         | 287/5674 [00:52<03:19, 26.95it/s]  5%|‚ñå         | 292/5674 [00:52<03:26, 26.07it/s]  5%|‚ñå         | 296/5674 [00:52<03:31, 25.46it/s]  5%|‚ñå         | 300/5674 [00:52<03:19, 26.92it/s]  5%|‚ñå         | 300/5674 [01:03<03:19, 26.92it/s]  5%|‚ñå         | 302/5674 [01:03<1:13:15,  1.22it/s]  5%|‚ñå         | 306/5674 [01:03<52:06,  1.72it/s]    5%|‚ñå         | 310/5674 [01:03<37:29,  2.38it/s]  6%|‚ñå         | 314/5674 [01:03<26:50,  3.33it/s]  6%|‚ñå         | 319/5674 [01:03<18:03,  4.94it/s]  6%|‚ñå         | 329/5674 [01:03<09:29,  9.38it/s]  6%|‚ñå         | 340/5674 [01:04<05:39, 15.70it/s]  6%|‚ñå         | 350/5674 [01:04<03:56, 22.55it/s]  6%|‚ñã         | 360/5674 [01:04<02:56, 30.17it/s]  7%|‚ñã         | 369/5674 [01:04<02:20, 37.80it/s]  7%|‚ñã         | 378/5674 [01:04<01:57, 44.98it/s]  7%|‚ñã         | 387/5674 [01:04<01:46, 49.87it/s]  7%|‚ñã         | 400/5674 [01:04<01:20, 65.33it/s]  7%|‚ñã         | 410/5674 [01:04<01:13, 71.86it/s]  8%|‚ñä         | 428/5674 [01:04<00:54, 97.09it/s]  8%|‚ñä         | 442/5674 [01:05<00:50, 104.01it/s]  8%|‚ñä         | 455/5674 [01:05<00:49, 106.23it/s]  8%|‚ñä         | 467/5674 [01:05<01:00, 86.59it/s]   8%|‚ñä         | 478/5674 [01:05<01:10, 73.66it/s]  8%|‚ñä         | 478/5674 [01:17<01:10, 73.66it/s]  9%|‚ñä         | 486/5674 [01:17<28:53,  2.99it/s]  9%|‚ñä         | 489/5674 [01:17<26:13,  3.30it/s]  9%|‚ñä         | 496/5674 [01:17<19:47,  4.36it/s]  9%|‚ñâ         | 503/5674 [01:17<14:57,  5.76it/s]  9%|‚ñâ         | 509/5674 [01:18<12:07,  7.10it/s]  9%|‚ñâ         | 517/5674 [01:18<08:34, 10.01it/s]  9%|‚ñâ         | 523/5674 [01:18<06:58, 12.30it/s]  9%|‚ñâ         | 531/5674 [01:18<05:02, 17.00it/s] 10%|‚ñâ         | 541/5674 [01:18<03:35, 23.87it/s] 10%|‚ñâ         | 548/5674 [01:18<03:05, 27.60it/s] 10%|‚ñâ         | 558/5674 [01:18<02:17, 37.13it/s] 10%|‚ñâ         | 566/5674 [01:18<02:03, 41.24it/s] 10%|‚ñà         | 576/5674 [01:19<01:54, 44.36it/s] 10%|‚ñà         | 584/5674 [01:19<01:41, 50.15it/s] 10%|‚ñà         | 595/5674 [01:19<01:21, 62.12it/s] 11%|‚ñà         | 603/5674 [01:19<01:21, 62.17it/s] 11%|‚ñà         | 611/5674 [01:19<01:18, 64.84it/s] 11%|‚ñà         | 619/5674 [01:19<01:26, 58.69it/s] 11%|‚ñà         | 626/5674 [01:19<01:26, 58.04it/s] 11%|‚ñà         | 633/5674 [01:19<01:24, 59.38it/s] 11%|‚ñà‚ñè        | 640/5674 [01:20<01:30, 55.41it/s] 11%|‚ñà‚ñè        | 649/5674 [01:20<01:19, 63.31it/s] 11%|‚ñà‚ñè        | 649/5674 [01:33<01:19, 63.31it/s] 12%|‚ñà‚ñè        | 658/5674 [01:33<42:08,  1.98it/s] 12%|‚ñà‚ñè        | 664/5674 [01:33<32:36,  2.56it/s] 12%|‚ñà‚ñè        | 672/5674 [01:34<22:45,  3.66it/s] 12%|‚ñà‚ñè        | 679/5674 [01:34<16:54,  4.92it/s] 12%|‚ñà‚ñè        | 685/5674 [01:34<13:01,  6.39it/s] 12%|‚ñà‚ñè        | 691/5674 [01:34<10:16,  8.08it/s] 12%|‚ñà‚ñè        | 698/5674 [01:34<07:31, 11.02it/s] 12%|‚ñà‚ñè        | 709/5674 [01:34<04:48, 17.21it/s] 13%|‚ñà‚ñé        | 716/5674 [01:34<04:01, 20.49it/s] 13%|‚ñà‚ñé        | 722/5674 [01:35<03:28, 23.73it/s] 13%|‚ñà‚ñé        | 728/5674 [01:35<03:01, 27.21it/s] 13%|‚ñà‚ñé        | 734/5674 [01:35<03:07, 26.36it/s] 13%|‚ñà‚ñé        | 739/5674 [01:35<02:56, 27.96it/s] 13%|‚ñà‚ñé        | 746/5674 [01:35<02:22, 34.54it/s] 13%|‚ñà‚ñé        | 752/5674 [01:35<02:13, 36.81it/s] 13%|‚ñà‚ñé        | 757/5674 [01:35<02:11, 37.39it/s] 13%|‚ñà‚ñé        | 762/5674 [01:36<02:17, 35.71it/s] 14%|‚ñà‚ñé        | 767/5674 [01:36<02:34, 31.82it/s] 14%|‚ñà‚ñé        | 771/5674 [01:36<02:34, 31.77it/s] 14%|‚ñà‚ñé        | 776/5674 [01:36<02:19, 35.06it/s] 14%|‚ñà‚ñç        | 785/5674 [01:36<01:44, 46.76it/s] 14%|‚ñà‚ñç        | 791/5674 [01:36<01:47, 45.35it/s] 14%|‚ñà‚ñç        | 799/5674 [01:36<01:32, 52.84it/s] 14%|‚ñà‚ñç        | 805/5674 [01:37<01:31, 53.37it/s] 14%|‚ñà‚ñç        | 811/5674 [01:37<01:37, 49.92it/s] 14%|‚ñà‚ñç        | 817/5674 [01:37<01:36, 50.39it/s] 14%|‚ñà‚ñç        | 817/5674 [01:54<01:36, 50.39it/s] 14%|‚ñà‚ñç        | 821/5674 [01:54<1:14:23,  1.09it/s] 15%|‚ñà‚ñç        | 824/5674 [01:54<1:00:58,  1.33it/s] 15%|‚ñà‚ñç        | 829/5674 [01:54<43:02,  1.88it/s]   15%|‚ñà‚ñç        | 833/5674 [01:54<32:37,  2.47it/s] 15%|‚ñà‚ñç        | 840/5674 [01:54<20:23,  3.95it/s] 15%|‚ñà‚ñç        | 847/5674 [01:54<13:27,  5.98it/s] 15%|‚ñà‚ñå        | 853/5674 [01:54<09:54,  8.11it/s] 15%|‚ñà‚ñå        | 859/5674 [01:55<07:27, 10.75it/s] 15%|‚ñà‚ñå        | 865/5674 [01:55<05:36, 14.28it/s] 15%|‚ñà‚ñå        | 871/5674 [01:55<04:31, 17.66it/s] 15%|‚ñà‚ñå        | 876/5674 [01:55<04:25, 18.08it/s] 16%|‚ñà‚ñå        | 880/5674 [01:55<03:53, 20.57it/s] 16%|‚ñà‚ñå        | 885/5674 [01:55<03:24, 23.41it/s] 16%|‚ñà‚ñå        | 891/5674 [01:55<02:42, 29.39it/s] 16%|‚ñà‚ñå        | 896/5674 [01:56<02:33, 31.05it/s] 16%|‚ñà‚ñå        | 901/5674 [01:56<02:36, 30.43it/s] 16%|‚ñà‚ñå        | 905/5674 [01:56<02:35, 30.59it/s] 16%|‚ñà‚ñå        | 910/5674 [01:56<02:19, 34.27it/s] 16%|‚ñà‚ñå        | 918/5674 [01:56<01:48, 43.65it/s] 16%|‚ñà‚ñã        | 923/5674 [01:56<01:47, 44.07it/s] 16%|‚ñà‚ñã        | 930/5674 [01:56<01:47, 44.22it/s] 16%|‚ñà‚ñã        | 936/5674 [01:56<01:43, 45.80it/s] 17%|‚ñà‚ñã        | 941/5674 [01:57<02:22, 33.11it/s] 17%|‚ñà‚ñã        | 948/5674 [01:57<01:58, 39.73it/s] 17%|‚ñà‚ñã        | 953/5674 [01:57<01:55, 40.81it/s] 17%|‚ñà‚ñã        | 958/5674 [01:57<01:58, 39.87it/s] 17%|‚ñà‚ñã        | 963/5674 [01:57<02:17, 34.26it/s] 17%|‚ñà‚ñã        | 971/5674 [01:57<01:56, 40.45it/s] 17%|‚ñà‚ñã        | 978/5674 [01:58<01:43, 45.59it/s] 17%|‚ñà‚ñã        | 983/5674 [01:58<01:41, 46.15it/s] 17%|‚ñà‚ñã        | 989/5674 [01:58<01:44, 44.75it/s] 18%|‚ñà‚ñä        | 997/5674 [01:58<01:28, 52.99it/s] 18%|‚ñà‚ñä        | 997/5674 [02:18<01:28, 52.99it/s] 18%|‚ñà‚ñä        | 1003/5674 [02:18<1:13:30,  1.06it/s] 18%|‚ñà‚ñä        | 1010/5674 [02:18<50:27,  1.54it/s]   18%|‚ñà‚ñä        | 1016/5674 [02:18<36:56,  2.10it/s] 18%|‚ñà‚ñä        | 1021/5674 [02:18<28:42,  2.70it/s] 18%|‚ñà‚ñä        | 1025/5674 [02:19<23:22,  3.31it/s] 18%|‚ñà‚ñä        | 1030/5674 [02:19<17:14,  4.49it/s] 18%|‚ñà‚ñä        | 1037/5674 [02:19<11:26,  6.76it/s] 18%|‚ñà‚ñä        | 1044/5674 [02:19<07:56,  9.72it/s] 19%|‚ñà‚ñä        | 1050/5674 [02:19<06:00, 12.83it/s] 19%|‚ñà‚ñä        | 1056/5674 [02:19<04:47, 16.06it/s] 19%|‚ñà‚ñâ        | 1067/5674 [02:19<03:01, 25.39it/s] 19%|‚ñà‚ñâ        | 1074/5674 [02:19<02:28, 30.97it/s] 19%|‚ñà‚ñâ        | 1081/5674 [02:20<02:06, 36.40it/s] 19%|‚ñà‚ñâ        | 1088/5674 [02:20<01:48, 42.12it/s] 19%|‚ñà‚ñâ        | 1095/5674 [02:20<01:55, 39.69it/s] 19%|‚ñà‚ñâ        | 1101/5674 [02:20<01:57, 38.93it/s] 20%|‚ñà‚ñâ        | 1107/5674 [02:20<01:52, 40.59it/s] 20%|‚ñà‚ñâ        | 1112/5674 [02:20<01:53, 40.32it/s] 20%|‚ñà‚ñâ        | 1117/5674 [02:20<01:58, 38.58it/s] 20%|‚ñà‚ñâ        | 1125/5674 [02:21<01:43, 43.97it/s] 20%|‚ñà‚ñâ        | 1134/5674 [02:21<01:28, 51.22it/s] 20%|‚ñà‚ñà        | 1141/5674 [02:21<01:21, 55.57it/s] 20%|‚ñà‚ñà        | 1149/5674 [02:21<01:16, 58.84it/s] 20%|‚ñà‚ñà        | 1163/5674 [02:21<00:59, 76.01it/s] 21%|‚ñà‚ñà        | 1181/5674 [02:21<00:44, 100.85it/s] 21%|‚ñà‚ñà        | 1195/5674 [02:21<00:43, 103.93it/s] 21%|‚ñà‚ñà‚ñè       | 1208/5674 [02:21<00:41, 108.50it/s] 22%|‚ñà‚ñà‚ñè       | 1225/5674 [02:22<00:35, 124.48it/s] 22%|‚ñà‚ñà‚ñè       | 1239/5674 [02:22<00:35, 126.43it/s] 22%|‚ñà‚ñà‚ñè       | 1258/5674 [02:22<00:32, 136.19it/s] 22%|‚ñà‚ñà‚ñè       | 1272/5674 [02:22<00:33, 131.69it/s] 23%|‚ñà‚ñà‚ñé       | 1286/5674 [02:22<00:48, 91.29it/s]  23%|‚ñà‚ñà‚ñé       | 1302/5674 [02:22<00:41, 105.69it/s] 23%|‚ñà‚ñà‚ñé       | 1315/5674 [02:22<00:45, 96.12it/s]  23%|‚ñà‚ñà‚ñé       | 1326/5674 [02:22<00:43, 99.18it/s] 24%|‚ñà‚ñà‚ñé       | 1337/5674 [02:23<00:43, 98.77it/s] 24%|‚ñà‚ñà‚ñç       | 1348/5674 [02:23<00:42, 101.18it/s] 24%|‚ñà‚ñà‚ñç       | 1361/5674 [02:23<00:39, 107.89it/s] 24%|‚ñà‚ñà‚ñç       | 1373/5674 [02:23<01:03, 68.27it/s]  24%|‚ñà‚ñà‚ñç       | 1382/5674 [02:23<01:02, 68.50it/s] 24%|‚ñà‚ñà‚ñç       | 1382/5674 [02:48<01:02, 68.50it/s] 24%|‚ñà‚ñà‚ñç       | 1387/5674 [02:48<56:01,  1.28it/s] 25%|‚ñà‚ñà‚ñç       | 1393/5674 [02:48<44:15,  1.61it/s] 25%|‚ñà‚ñà‚ñç       | 1401/5674 [02:48<31:59,  2.23it/s] 25%|‚ñà‚ñà‚ñç       | 1408/5674 [02:48<24:01,  2.96it/s] 25%|‚ñà‚ñà‚ñç       | 1414/5674 [02:48<18:22,  3.86it/s] 25%|‚ñà‚ñà‚ñå       | 1420/5674 [02:48<14:05,  5.03it/s] 25%|‚ñà‚ñà‚ñå       | 1429/5674 [02:48<09:20,  7.57it/s] 25%|‚ñà‚ñà‚ñå       | 1435/5674 [02:49<07:23,  9.55it/s] 25%|‚ñà‚ñà‚ñå       | 1441/5674 [02:49<05:52, 12.02it/s] 26%|‚ñà‚ñà‚ñå       | 1450/5674 [02:49<04:01, 17.50it/s] 26%|‚ñà‚ñà‚ñå       | 1459/5674 [02:49<02:55, 24.08it/s] 26%|‚ñà‚ñà‚ñå       | 1466/5674 [02:49<02:32, 27.65it/s] 26%|‚ñà‚ñà‚ñå       | 1474/5674 [02:49<02:03, 34.04it/s] 26%|‚ñà‚ñà‚ñå       | 1481/5674 [02:49<01:59, 35.03it/s] 26%|‚ñà‚ñà‚ñå       | 1487/5674 [02:50<01:51, 37.51it/s] 26%|‚ñà‚ñà‚ñã       | 1493/5674 [02:50<01:40, 41.65it/s] 26%|‚ñà‚ñà‚ñã       | 1499/5674 [02:50<02:13, 31.31it/s] 27%|‚ñà‚ñà‚ñã       | 1504/5674 [02:50<02:15, 30.70it/s] 27%|‚ñà‚ñà‚ñã       | 1508/5674 [02:50<02:21, 29.46it/s] 27%|‚ñà‚ñà‚ñã       | 1513/5674 [02:50<02:07, 32.53it/s] 27%|‚ñà‚ñà‚ñã       | 1517/5674 [02:51<02:23, 29.04it/s] 27%|‚ñà‚ñà‚ñã       | 1521/5674 [02:51<02:32, 27.29it/s] 27%|‚ñà‚ñà‚ñã       | 1525/5674 [02:51<02:46, 24.98it/s] 27%|‚ñà‚ñà‚ñã       | 1530/5674 [02:51<02:21, 29.36it/s] 27%|‚ñà‚ñà‚ñã       | 1541/5674 [02:51<01:28, 46.58it/s] 27%|‚ñà‚ñà‚ñã       | 1547/5674 [02:51<01:39, 41.39it/s] 27%|‚ñà‚ñà‚ñã       | 1552/5674 [02:51<01:42, 40.04it/s] 27%|‚ñà‚ñà‚ñã       | 1557/5674 [02:52<02:00, 34.22it/s] 28%|‚ñà‚ñà‚ñä       | 1562/5674 [02:52<01:52, 36.70it/s] 28%|‚ñà‚ñà‚ñä       | 1567/5674 [02:52<01:45, 38.93it/s] 28%|‚ñà‚ñà‚ñä       | 1572/5674 [02:52<02:15, 30.28it/s] 28%|‚ñà‚ñà‚ñä       | 1576/5674 [02:52<02:38, 25.86it/s] 28%|‚ñà‚ñà‚ñä       | 1580/5674 [02:53<03:34, 19.10it/s] 28%|‚ñà‚ñà‚ñä       | 1583/5674 [02:53<03:45, 18.15it/s] 28%|‚ñà‚ñà‚ñä       | 1586/5674 [02:53<03:29, 19.49it/s] 28%|‚ñà‚ñà‚ñä       | 1591/5674 [02:53<02:50, 23.93it/s] 28%|‚ñà‚ñà‚ñä       | 1596/5674 [02:53<02:28, 27.50it/s] 28%|‚ñà‚ñà‚ñä       | 1604/5674 [02:53<01:55, 35.09it/s] 28%|‚ñà‚ñà‚ñä       | 1611/5674 [02:54<01:51, 36.42it/s] 28%|‚ñà‚ñà‚ñä       | 1615/5674 [02:54<01:51, 36.46it/s] 29%|‚ñà‚ñà‚ñä       | 1621/5674 [02:54<01:43, 39.25it/s] 29%|‚ñà‚ñà‚ñä       | 1621/5674 [03:24<01:43, 39.25it/s] 29%|‚ñà‚ñà‚ñä       | 1625/5674 [03:24<2:01:28,  1.80s/it] 29%|‚ñà‚ñà‚ñä       | 1629/5674 [03:24<1:31:18,  1.35s/it] 29%|‚ñà‚ñà‚ñâ       | 1638/5674 [03:24<50:39,  1.33it/s]   29%|‚ñà‚ñà‚ñâ       | 1644/5674 [03:24<35:56,  1.87it/s] 29%|‚ñà‚ñà‚ñâ       | 1649/5674 [03:25<26:56,  2.49it/s] 29%|‚ñà‚ñà‚ñâ       | 1654/5674 [03:25<19:56,  3.36it/s] 29%|‚ñà‚ñà‚ñâ       | 1662/5674 [03:25<12:40,  5.27it/s] 29%|‚ñà‚ñà‚ñâ       | 1668/5674 [03:25<09:29,  7.04it/s] 30%|‚ñà‚ñà‚ñâ       | 1675/5674 [03:25<06:42,  9.93it/s] 30%|‚ñà‚ñà‚ñâ       | 1681/5674 [03:25<05:34, 11.95it/s] 30%|‚ñà‚ñà‚ñâ       | 1686/5674 [03:25<04:29, 14.77it/s] 30%|‚ñà‚ñà‚ñâ       | 1692/5674 [03:26<03:28, 19.14it/s] 30%|‚ñà‚ñà‚ñâ       | 1697/5674 [03:26<03:09, 20.99it/s] 30%|‚ñà‚ñà‚ñâ       | 1702/5674 [03:26<02:57, 22.34it/s] 30%|‚ñà‚ñà‚ñà       | 1709/5674 [03:26<02:15, 29.27it/s] 30%|‚ñà‚ñà‚ñà       | 1714/5674 [03:26<02:13, 29.71it/s] 30%|‚ñà‚ñà‚ñà       | 1722/5674 [03:26<02:08, 30.84it/s] 31%|‚ñà‚ñà‚ñà       | 1731/5674 [03:26<01:36, 40.79it/s] 31%|‚ñà‚ñà‚ñà       | 1739/5674 [03:27<01:22, 47.70it/s] 31%|‚ñà‚ñà‚ñà       | 1747/5674 [03:27<01:13, 53.57it/s] 31%|‚ñà‚ñà‚ñà       | 1754/5674 [03:27<01:08, 57.25it/s] 31%|‚ñà‚ñà‚ñà       | 1761/5674 [03:27<01:14, 52.47it/s] 31%|‚ñà‚ñà‚ñà       | 1772/5674 [03:27<00:59, 65.40it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1783/5674 [03:27<00:51, 76.21it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1792/5674 [03:27<00:53, 73.01it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1800/5674 [03:27<00:51, 74.51it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1808/5674 [03:28<01:00, 63.79it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1815/5674 [03:28<01:07, 57.50it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1823/5674 [03:28<01:03, 60.74it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1833/5674 [03:28<00:57, 66.58it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1840/5674 [03:28<00:57, 66.45it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1847/5674 [03:28<01:09, 55.23it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1856/5674 [03:28<01:00, 62.85it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1865/5674 [03:28<00:54, 69.51it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1874/5674 [03:29<00:52, 72.61it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1882/5674 [03:29<01:02, 61.09it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1891/5674 [03:29<00:57, 65.80it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1899/5674 [03:29<00:55, 67.52it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1907/5674 [03:29<00:59, 63.20it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1915/5674 [03:29<00:59, 63.70it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1922/5674 [03:29<00:58, 63.96it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1929/5674 [03:29<01:02, 60.11it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1939/5674 [03:30<00:53, 70.02it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1947/5674 [03:30<00:57, 64.37it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1959/5674 [03:30<00:48, 77.13it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1968/5674 [03:30<00:50, 73.25it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1979/5674 [03:30<00:46, 79.69it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1988/5674 [03:30<00:45, 80.30it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1998/5674 [03:30<00:43, 84.24it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 2007/5674 [03:30<00:44, 81.73it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 2016/5674 [03:31<00:47, 77.20it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 2027/5674 [03:31<00:42, 85.30it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 2036/5674 [03:31<00:49, 73.02it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 2044/5674 [03:31<00:57, 62.79it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 2051/5674 [03:31<01:00, 60.27it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 2060/5674 [03:31<00:55, 64.65it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 2070/5674 [03:31<00:51, 69.47it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 2078/5674 [03:32<00:54, 66.37it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 2085/5674 [03:32<01:10, 50.58it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 2091/5674 [03:32<01:13, 48.63it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 2098/5674 [03:32<01:11, 50.36it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 2098/5674 [04:07<01:11, 50.36it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 2100/5674 [04:07<1:48:04,  1.81s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 2105/5674 [04:07<1:19:03,  1.33s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 2111/5674 [04:07<54:43,  1.09it/s]   37%|‚ñà‚ñà‚ñà‚ñã      | 2116/5674 [04:07<40:07,  1.48it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 2124/5674 [04:07<24:55,  2.37it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 2131/5674 [04:07<17:03,  3.46it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 2140/5674 [04:07<10:56,  5.38it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 2147/5674 [04:08<08:01,  7.33it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 2157/5674 [04:08<05:22, 10.92it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 2167/5674 [04:08<03:41, 15.83it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 2175/5674 [04:08<02:57, 19.76it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 2182/5674 [04:08<02:25, 23.93it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 2189/5674 [04:08<02:01, 28.73it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 2196/5674 [04:08<01:44, 33.42it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 2203/5674 [04:08<01:30, 38.45it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 2210/5674 [04:09<01:30, 38.09it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 2216/5674 [04:09<01:34, 36.60it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 2222/5674 [04:09<01:25, 40.21it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 2227/5674 [04:09<01:32, 37.29it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 2234/5674 [04:09<01:20, 42.89it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 2240/5674 [04:09<01:24, 40.83it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 2245/5674 [04:10<01:31, 37.47it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 2251/5674 [04:10<01:30, 37.95it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 2256/5674 [04:10<01:53, 30.15it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 2264/5674 [04:10<01:39, 34.18it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 2271/5674 [04:10<01:41, 33.66it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 2275/5674 [04:10<01:37, 34.69it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 2284/5674 [04:11<01:15, 45.07it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 2290/5674 [04:11<01:15, 44.85it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 2296/5674 [04:11<01:10, 47.94it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 2304/5674 [04:11<01:02, 54.12it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 2310/5674 [04:11<01:21, 41.42it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 2319/5674 [04:11<01:07, 49.95it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 2325/5674 [04:11<01:07, 49.58it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 2331/5674 [04:11<01:07, 49.33it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 2337/5674 [04:12<01:06, 50.25it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2343/5674 [04:12<01:15, 43.84it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2349/5674 [04:12<01:11, 46.38it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2357/5674 [04:12<01:10, 46.82it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2362/5674 [04:12<01:39, 33.45it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2368/5674 [04:12<01:26, 38.01it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2375/5674 [04:13<01:15, 43.62it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2384/5674 [04:13<01:02, 52.76it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2392/5674 [04:13<00:57, 56.65it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2399/5674 [04:13<00:54, 59.63it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2409/5674 [04:13<00:47, 69.43it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2417/5674 [04:13<00:58, 55.82it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2424/5674 [04:13<01:01, 53.27it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2430/5674 [04:14<01:11, 45.62it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2436/5674 [04:14<01:33, 34.58it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2445/5674 [04:14<01:13, 43.90it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2451/5674 [04:14<01:23, 38.39it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2456/5674 [04:14<01:28, 36.55it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2464/5674 [04:15<01:26, 36.91it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2473/5674 [04:15<01:09, 46.28it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2480/5674 [04:15<01:02, 51.05it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2486/5674 [04:15<01:04, 49.48it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2494/5674 [04:15<00:59, 53.07it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2500/5674 [04:15<00:59, 53.31it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2506/5674 [04:15<00:59, 53.26it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2512/5674 [04:15<01:04, 49.05it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2518/5674 [04:16<01:10, 44.60it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2524/5674 [04:16<01:06, 47.41it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2529/5674 [04:16<01:06, 47.28it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2534/5674 [04:16<01:11, 44.16it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2541/5674 [04:16<01:04, 48.25it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2546/5674 [04:16<01:08, 45.99it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2546/5674 [05:00<01:08, 45.99it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2547/5674 [05:00<2:40:58,  3.09s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2552/5674 [05:00<1:47:39,  2.07s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2557/5674 [05:00<1:13:25,  1.41s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2563/5674 [05:00<47:33,  1.09it/s]   45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2569/5674 [05:01<31:46,  1.63it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2574/5674 [05:01<23:02,  2.24it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2579/5674 [05:01<16:42,  3.09it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2584/5674 [05:01<12:13,  4.22it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2589/5674 [05:01<09:10,  5.61it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2593/5674 [05:01<07:16,  7.06it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2597/5674 [05:01<05:48,  8.83it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2601/5674 [05:02<04:38, 11.02it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2608/5674 [05:02<03:05, 16.51it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2614/5674 [05:02<02:21, 21.70it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2619/5674 [05:02<02:14, 22.70it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2626/5674 [05:02<01:43, 29.39it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2631/5674 [05:02<01:34, 32.07it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2636/5674 [05:02<01:26, 35.26it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2646/5674 [05:02<01:02, 48.40it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2655/5674 [05:03<00:52, 57.46it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2664/5674 [05:03<00:50, 59.47it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2671/5674 [05:03<00:53, 56.61it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2678/5674 [05:03<00:51, 58.23it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2685/5674 [05:03<01:10, 42.50it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2691/5674 [05:03<01:07, 44.07it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2697/5674 [05:03<01:03, 46.89it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2704/5674 [05:04<01:00, 48.92it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2710/5674 [05:04<01:02, 47.39it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2717/5674 [05:04<01:07, 43.93it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2724/5674 [05:04<01:02, 46.98it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2729/5674 [05:04<01:08, 42.81it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2735/5674 [05:04<01:03, 45.97it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2740/5674 [05:04<01:04, 45.50it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2746/5674 [05:04<01:00, 48.16it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2754/5674 [05:05<00:52, 55.85it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2761/5674 [05:05<00:56, 51.83it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2767/5674 [05:05<01:02, 46.72it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2773/5674 [05:05<00:58, 49.53it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2779/5674 [05:05<01:13, 39.38it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2788/5674 [05:05<00:59, 48.18it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2794/5674 [05:05<00:59, 48.67it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2800/5674 [05:06<01:08, 42.23it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2805/5674 [05:06<01:18, 36.49it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2813/5674 [05:06<01:03, 45.26it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2819/5674 [05:06<01:09, 41.13it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2824/5674 [05:06<01:08, 41.42it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2831/5674 [05:06<01:00, 46.70it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2837/5674 [05:06<00:58, 48.71it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2844/5674 [05:07<00:54, 51.49it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2856/5674 [05:07<00:41, 67.59it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2867/5674 [05:07<00:36, 75.96it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2877/5674 [05:07<00:36, 76.83it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2885/5674 [05:07<00:41, 67.01it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2892/5674 [05:07<00:47, 58.95it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2899/5674 [05:08<01:02, 44.51it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2905/5674 [05:08<01:06, 41.93it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2912/5674 [05:08<01:05, 42.32it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2917/5674 [05:08<01:06, 41.49it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2923/5674 [05:08<01:02, 43.86it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2930/5674 [05:08<00:55, 49.09it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2936/5674 [05:08<01:11, 38.43it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2943/5674 [05:09<01:05, 41.98it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2948/5674 [05:09<01:15, 35.97it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2956/5674 [05:09<01:04, 42.41it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2961/5674 [05:09<01:10, 38.65it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2966/5674 [05:09<01:15, 35.80it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2973/5674 [05:09<01:06, 40.46it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2978/5674 [05:10<01:11, 37.46it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2984/5674 [05:10<01:03, 42.28it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2989/5674 [05:10<01:01, 44.01it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2995/5674 [05:10<00:57, 46.65it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3000/5674 [05:10<00:59, 44.85it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3010/5674 [05:10<00:48, 54.57it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3016/5674 [05:10<00:59, 44.59it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3021/5674 [05:11<01:12, 36.55it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3028/5674 [05:11<01:01, 42.70it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3033/5674 [05:11<01:02, 42.55it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3039/5674 [05:11<00:59, 44.40it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3044/5674 [05:11<01:02, 42.00it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3050/5674 [05:11<01:02, 42.01it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3056/5674 [05:11<01:01, 42.74it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3064/5674 [05:11<00:53, 48.51it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3070/5674 [05:12<00:50, 51.16it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3078/5674 [05:12<00:47, 54.67it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3085/5674 [05:12<00:50, 51.55it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3085/5674 [06:05<00:50, 51.55it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3086/5674 [06:05<2:15:56,  3.15s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3090/5674 [06:05<1:42:00,  2.37s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3095/5674 [06:06<1:10:35,  1.64s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3100/5674 [06:06<49:17,  1.15s/it]   55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3105/5674 [06:06<34:42,  1.23it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3114/5674 [06:06<19:39,  2.17it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3122/5674 [06:06<12:46,  3.33it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3129/5674 [06:06<09:02,  4.69it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3137/5674 [06:06<06:10,  6.84it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3144/5674 [06:06<04:33,  9.26it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3151/5674 [06:07<03:26, 12.21it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3157/5674 [06:07<02:45, 15.22it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3163/5674 [06:07<02:14, 18.61it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3169/5674 [06:07<01:50, 22.77it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3175/5674 [06:07<01:35, 26.05it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3184/5674 [06:07<01:10, 35.44it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3190/5674 [06:07<01:03, 38.94it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3199/5674 [06:07<00:50, 48.65it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3207/5674 [06:08<00:45, 53.66it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3214/5674 [06:08<00:43, 56.70it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3221/5674 [06:08<00:46, 53.18it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3231/5674 [06:08<00:38, 63.19it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3239/5674 [06:08<00:36, 66.97it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3251/5674 [06:08<00:30, 80.24it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3260/5674 [06:08<00:43, 55.26it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3267/5674 [06:09<00:43, 55.62it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3274/5674 [06:09<00:45, 52.73it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3284/5674 [06:09<00:38, 62.58it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3292/5674 [06:09<00:44, 53.45it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3300/5674 [06:09<00:48, 48.75it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3306/5674 [06:09<00:47, 50.29it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3315/5674 [06:09<00:40, 58.81it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3322/5674 [06:10<00:52, 44.97it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3328/5674 [06:10<01:03, 36.96it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3333/5674 [06:10<01:17, 30.33it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3342/5674 [06:10<01:00, 38.48it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3348/5674 [06:10<01:02, 37.37it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3357/5674 [06:11<00:49, 46.87it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3363/5674 [06:11<00:47, 48.95it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3369/5674 [06:11<00:51, 44.39it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3378/5674 [06:11<00:43, 52.66it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3384/5674 [06:11<00:46, 49.65it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3390/5674 [06:11<01:02, 36.29it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3395/5674 [06:12<01:09, 32.66it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3399/5674 [06:12<01:07, 33.89it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3403/5674 [06:12<01:09, 32.64it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3409/5674 [06:12<01:00, 37.20it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3419/5674 [06:12<00:47, 47.84it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3426/5674 [06:12<00:52, 43.09it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3433/5674 [06:12<00:57, 38.94it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3438/5674 [06:13<00:54, 40.88it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3443/5674 [06:13<01:07, 32.89it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3451/5674 [06:13<01:00, 36.64it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3458/5674 [06:13<00:55, 39.90it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3466/5674 [06:13<00:46, 47.71it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3476/5674 [06:13<00:38, 57.17it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3490/5674 [06:13<00:28, 76.07it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3499/5674 [06:14<00:29, 73.21it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3507/5674 [06:14<00:51, 41.93it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3514/5674 [06:14<00:53, 40.36it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3521/5674 [06:14<00:51, 41.49it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3527/5674 [06:15<00:54, 39.50it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3533/5674 [06:15<00:55, 38.80it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3542/5674 [06:15<00:44, 47.83it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3548/5674 [06:15<00:51, 41.08it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3553/5674 [06:15<00:57, 36.74it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3566/5674 [06:15<00:39, 53.76it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3573/5674 [06:15<00:38, 54.63it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3580/5674 [06:16<00:40, 51.84it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3590/5674 [06:16<00:41, 50.71it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3596/5674 [06:16<00:41, 50.68it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3602/5674 [06:16<00:40, 51.30it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3608/5674 [06:16<00:40, 51.05it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3614/5674 [06:16<00:43, 47.20it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3620/5674 [06:17<00:54, 37.68it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3625/5674 [06:17<00:56, 35.95it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3631/5674 [06:17<00:50, 40.38it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3637/5674 [06:17<00:47, 42.59it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3642/5674 [06:17<00:51, 39.29it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3650/5674 [06:17<00:43, 46.57it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3656/5674 [06:17<00:41, 48.67it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3664/5674 [06:17<00:35, 55.93it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3673/5674 [06:18<00:31, 64.13it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3680/5674 [06:18<00:34, 57.47it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3687/5674 [06:18<00:43, 45.92it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3693/5674 [06:18<00:44, 44.31it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3698/5674 [06:18<00:43, 45.53it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3704/5674 [06:18<00:42, 46.72it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3709/5674 [06:18<00:41, 47.38it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3716/5674 [06:18<00:38, 51.42it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3722/5674 [06:19<00:44, 43.82it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3732/5674 [06:19<00:38, 50.52it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3738/5674 [06:19<00:38, 50.83it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3744/5674 [06:19<00:46, 41.26it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3744/5674 [07:23<00:46, 41.26it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3748/5674 [07:23<1:45:55,  3.30s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3754/5674 [07:23<1:13:29,  2.30s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3764/5674 [07:23<42:28,  1.33s/it]   67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3774/5674 [07:23<26:30,  1.19it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3783/5674 [07:24<17:54,  1.76it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3795/5674 [07:24<11:06,  2.82it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3804/5674 [07:24<08:01,  3.89it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3812/5674 [07:24<05:57,  5.20it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3820/5674 [07:24<04:24,  7.02it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3834/5674 [07:24<02:40, 11.44it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3844/5674 [07:24<01:59, 15.37it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3856/5674 [07:24<01:24, 21.54it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3866/5674 [07:25<01:06, 27.13it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3875/5674 [07:25<00:54, 32.88it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3884/5674 [07:25<00:48, 36.78it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3893/5674 [07:25<00:41, 42.72it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3901/5674 [07:25<00:38, 45.51it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3908/5674 [07:25<00:37, 47.64it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3918/5674 [07:25<00:30, 57.82it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3926/5674 [07:25<00:31, 55.13it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3935/5674 [07:26<00:28, 61.37it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3943/5674 [07:26<00:31, 55.00it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3950/5674 [07:26<00:41, 41.95it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3956/5674 [07:26<00:42, 40.71it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3962/5674 [07:26<00:39, 43.68it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3967/5674 [07:26<00:39, 43.59it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 3972/5674 [07:27<00:39, 43.59it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 3985/5674 [07:27<00:26, 63.72it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 3993/5674 [07:27<00:28, 58.17it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 4000/5674 [07:27<00:30, 54.31it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 4007/5674 [07:27<00:29, 57.47it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 4014/5674 [07:27<00:38, 42.83it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 4025/5674 [07:27<00:29, 55.98it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 4032/5674 [07:28<00:36, 45.20it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 4039/5674 [07:28<00:32, 49.70it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4045/5674 [07:28<00:32, 49.74it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4057/5674 [07:28<00:25, 62.74it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4064/5674 [07:28<00:27, 57.78it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4072/5674 [07:28<00:26, 61.39it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4080/5674 [07:28<00:27, 58.40it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4087/5674 [07:29<00:28, 55.58it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4097/5674 [07:29<00:26, 58.44it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4104/5674 [07:29<00:25, 60.51it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4112/5674 [07:29<00:24, 64.48it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4121/5674 [07:29<00:23, 67.47it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4128/5674 [07:29<00:24, 63.17it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4140/5674 [07:29<00:20, 75.27it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4149/5674 [07:29<00:20, 74.90it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4160/5674 [07:30<00:18, 81.86it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4169/5674 [07:30<00:21, 70.03it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4177/5674 [07:30<00:28, 52.49it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4184/5674 [07:30<00:28, 51.67it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4191/5674 [07:30<00:27, 54.70it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4197/5674 [07:30<00:29, 50.77it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4203/5674 [07:30<00:27, 52.55it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4214/5674 [07:31<00:22, 65.72it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4225/5674 [07:31<00:19, 73.94it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4233/5674 [07:31<00:20, 71.11it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4241/5674 [07:31<00:32, 44.02it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4247/5674 [07:31<00:31, 45.76it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4253/5674 [07:32<00:40, 34.86it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4258/5674 [07:32<00:39, 35.53it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4263/5674 [07:32<00:39, 35.96it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4268/5674 [07:32<00:38, 36.93it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4273/5674 [07:32<00:38, 36.28it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4279/5674 [07:32<00:33, 41.47it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4284/5674 [07:32<00:33, 41.79it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4289/5674 [07:32<00:35, 38.68it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4296/5674 [07:33<00:34, 40.10it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4302/5674 [07:33<00:30, 44.55it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4307/5674 [07:33<00:30, 44.48it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4313/5674 [07:33<00:29, 45.91it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4318/5674 [07:33<00:29, 45.75it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4324/5674 [07:33<00:28, 47.92it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4334/5674 [07:33<00:21, 61.57it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4343/5674 [07:33<00:19, 67.56it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4350/5674 [07:34<00:19, 67.13it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4357/5674 [07:34<00:21, 62.17it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4378/5674 [07:34<00:12, 99.84it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4389/5674 [07:34<00:14, 91.22it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4399/5674 [07:34<00:16, 76.89it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4408/5674 [07:34<00:15, 79.49it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4417/5674 [07:34<00:21, 59.09it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4424/5674 [07:35<00:21, 58.48it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4431/5674 [07:35<00:22, 54.92it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4437/5674 [07:35<00:22, 55.96it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4447/5674 [07:35<00:19, 63.94it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4462/5674 [07:35<00:15, 78.01it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4474/5674 [07:35<00:13, 87.94it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4492/5674 [07:35<00:10, 110.27it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4504/5674 [07:35<00:11, 100.35it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4524/5674 [07:36<00:11, 96.08it/s]  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4546/5674 [07:36<00:09, 121.58it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4570/5674 [07:36<00:07, 148.78it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4587/5674 [07:36<00:07, 152.16it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4604/5674 [07:36<00:07, 151.99it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4620/5674 [07:36<00:07, 144.02it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4635/5674 [07:36<00:07, 131.73it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4658/5674 [07:36<00:06, 147.18it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4674/5674 [07:37<00:07, 134.55it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4688/5674 [07:37<00:08, 122.30it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4701/5674 [07:37<00:13, 71.32it/s]  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4711/5674 [07:38<00:18, 51.02it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4719/5674 [07:38<00:19, 50.05it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4727/5674 [07:38<00:17, 54.16it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4736/5674 [07:38<00:16, 55.47it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4754/5674 [07:38<00:11, 77.43it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4767/5674 [07:38<00:11, 80.48it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4783/5674 [07:38<00:09, 95.00it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4794/5674 [07:38<00:09, 95.84it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4805/5674 [07:39<00:13, 65.04it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4820/5674 [07:39<00:11, 71.44it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4829/5674 [07:39<00:11, 71.94it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4842/5674 [07:39<00:10, 83.12it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4852/5674 [07:39<00:09, 82.22it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4872/5674 [07:39<00:07, 108.90it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4887/5674 [07:40<00:06, 117.27it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 4906/5674 [07:40<00:05, 133.06it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 4921/5674 [07:40<00:06, 118.08it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 4939/5674 [07:40<00:05, 132.22it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 4958/5674 [07:40<00:04, 144.16it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 4974/5674 [07:40<00:05, 137.02it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 4989/5674 [07:40<00:05, 131.86it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 4989/5674 [09:01<00:05, 131.86it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 4995/5674 [09:01<20:51,  1.84s/it]  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 5006/5674 [09:01<15:08,  1.36s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 5019/5674 [09:01<10:18,  1.06it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 5031/5674 [09:01<07:13,  1.48it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5042/5674 [09:01<05:11,  2.03it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5052/5674 [09:02<03:49,  2.72it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5061/5674 [09:02<02:50,  3.59it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5072/5674 [09:02<01:58,  5.08it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5083/5674 [09:02<01:22,  7.16it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5095/5674 [09:02<00:56, 10.26it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5106/5674 [09:02<00:40, 14.00it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 5123/5674 [09:02<00:25, 21.73it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 5138/5674 [09:02<00:17, 29.96it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 5150/5674 [09:03<00:14, 36.25it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 5161/5674 [09:03<00:12, 42.01it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 5171/5674 [09:03<00:10, 48.31it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5181/5674 [09:03<00:09, 54.51it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5192/5674 [09:03<00:07, 62.97it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5202/5674 [09:03<00:06, 69.19it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5212/5674 [09:03<00:06, 72.89it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5222/5674 [09:03<00:06, 73.16it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5231/5674 [09:04<00:06, 68.95it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5242/5674 [09:04<00:05, 77.93it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5254/5674 [09:04<00:04, 86.48it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5265/5674 [09:04<00:04, 84.35it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5274/5674 [09:04<00:05, 76.48it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5288/5674 [09:04<00:04, 91.66it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5298/5674 [09:04<00:04, 80.77it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5308/5674 [09:04<00:04, 83.52it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5317/5674 [09:05<00:04, 78.44it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5328/5674 [09:05<00:04, 83.44it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5337/5674 [09:05<00:04, 79.25it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5347/5674 [09:05<00:03, 82.66it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5361/5674 [09:05<00:03, 90.83it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5372/5674 [09:05<00:03, 92.65it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5384/5674 [09:05<00:02, 98.29it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5398/5674 [09:05<00:02, 107.47it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5412/5674 [09:05<00:02, 107.79it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5425/5674 [09:06<00:02, 108.27it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5440/5674 [09:06<00:01, 117.73it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5452/5674 [09:06<00:02, 104.76it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5463/5674 [09:06<00:02, 104.83it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5476/5674 [09:06<00:01, 99.34it/s]  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5487/5674 [09:06<00:02, 72.84it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5499/5674 [09:06<00:02, 81.45it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5514/5674 [09:07<00:01, 96.61it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5536/5674 [09:07<00:01, 126.36it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5557/5674 [09:07<00:00, 145.67it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5574/5674 [09:07<00:00, 150.28it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5591/5674 [09:07<00:00, 120.19it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5605/5674 [09:07<00:00, 114.25it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5618/5674 [09:07<00:00, 116.53it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5636/5674 [09:07<00:00, 131.78it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5651/5674 [09:08<00:00, 119.19it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5664/5674 [09:08<00:00, 82.98it/s] 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5674/5674 [09:08<00:00, 10.34it/s]
2025-12-10 12:39:08.059 | INFO     | __main__:main:278 - Starting Epoch 4/10
2025-12-10 12:39:08.153 | INFO     | __main__:main:294 - Processing 128 theorems with 16 workers.
2025-12-10 12:39:20.375 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: MonoidHom.cancel_left
2025-12-10 12:39:21.024 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: List.formPerm_apply_lt_get
2025-12-10 12:39:21.207 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Rat.inv_intCast_num
2025-12-10 12:39:21.775 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: List.perm_permutations'_iff
2025-12-10 12:39:23.707 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: induced_generateFrom_eq
2025-12-10 12:39:23.800 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: CategoryTheory.Limits.kernelSubobject_factors_iff
2025-12-10 12:39:24.216 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Homeomorph.coe_toHomotopyEquiv
2025-12-10 12:39:25.906 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Submodule.mem_sup
2025-12-10 12:39:27.516 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-10 12:39:29.113 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-10 12:39:29.306 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-10 12:39:29.369 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: LSeries_sub
2025-12-10 12:39:29.517 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-10 12:39:31.429 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-10 12:39:31.563 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-10 12:39:31.591 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: LucasLehmer.norm_num_ext.testFalseHelper
2025-12-10 12:39:31.621 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-10 12:39:31.628 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: ExteriorAlgebra.liftAlternating_one
2025-12-10 12:39:32.433 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-10 12:39:35.369 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-10 12:39:36.851 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-10 12:39:36.967 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-10 12:39:37.445 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Zsqrtd.not_sqLe_succ
2025-12-10 12:39:37.558 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: MeasureTheory.Adapted.measurable_upcrossings
2025-12-10 12:39:39.835 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: linearIndependent_of_ne_zero_of_inner_eq_zero
2025-12-10 12:39:42.525 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: MeasureTheory.L1.SimpleFunc.norm_Integral_le_one
2025-12-10 12:39:42.985 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-10 12:39:43.051 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-10 12:39:44.822 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-10 12:39:46.949 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: MeasureTheory.IsSetAlgebra.generateSetAlgebra_subset_self
2025-12-10 12:39:47.151 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-10 12:39:51.673 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-10 12:40:29.886 | WARNING  | lean_reinforcement.training.inference_server:_run_transformer_batch:119 - OOM encountered. Reducing max safe batch size to 120
2025-12-10 12:40:50.328 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: rw [‚Üê MonoidHom.comp_assoc, ‚Üê MonoidHom.comp_assoc, ‚Üê MonoidHom.comp_assoc,
  MonoidHom.comp_id, ‚Üê MonoidHom.comp_id, ‚Üê MonoidHom.comp_id, ‚Üê MonoidHom.comp_id,
  ‚Üê MonoidHom.comp_id, ‚Üê MonoidHom.comp_id, ‚Üê MonoidHom.comp_id, ‚Üê MonoidHom.comp_id,
  ‚Üê MonoidHom.comp_id, ‚Üê MonoidHom.comp_id, ‚Üê MonoidHom.comp_id, ‚Üê MonoidHom.comp_id,
  ‚Üê MonoidHom.comp_id, ‚Üê MonoidHom.comp_id, ‚Üê MonoidHom.comp_id, ‚Üê MonoidHom.comp_id,
  ‚Üê MonoidHom.comp_id, ‚Üê MonoidHom.comp_id, ‚Üê MonoidHom.comp_id, ‚Üê MonoidHom.comp_id,
  ‚Üê MonoidHom.comp_id, ‚Üê MonoidHom.comp_id, ‚Üê MonoidHom.comp_id, ‚Üê MonoidHom.comp_id,
  ‚Üê MonoidHom.comp_id, ‚Üê MonoidHom.comp_id, ‚Üê MonoidHom.comp_id, ‚Üê MonoidHom.comp_id,
  ‚Üê MonoidHom.comp_id, ‚Üê MonoidHom.comp_id, ‚Üê MonoidHom.comp_id, ‚Üê MonoidHom.comp_id,
  ‚Üê MonoidHom.comp_id, ‚Üê MonoidHom.comp_id, ‚Üê MonoidHom.comp_id, ‚Üê MonoidHom.comp_id,
  ‚Üê MonoidHom.comp_id, ‚Üê MonoidHom.comp_id, ‚Üê MonoidHom.comp_id, ‚Üê MonoidHom.comp_id,
  ‚Üê
2025-12-10 12:40:50.394 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error='<stdin>:12:3: unexpected end of input')
2025-12-10 12:40:50.394 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 90.02s.
2025-12-10 12:40:50.394 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error='<stdin>:12:3: unexpected end of input')
2025-12-10 12:40:50.536 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-10 12:41:00.324 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: IsSelfAdjoint.star_add_self
2025-12-10 12:41:04.965 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-10 12:42:16.916 | WARNING  | lean_reinforcement.training.inference_server:_run_transformer_batch:119 - OOM encountered. Reducing max safe batch size to 60
2025-12-10 12:43:50.491 | WARNING  | lean_reinforcement.training.inference_server:_run_transformer_batch:119 - OOM encountered. Reducing max safe batch size to 30
2025-12-10 12:45:25.426 | WARNING  | lean_reinforcement.training.inference_server:_run_transformer_batch:119 - OOM encountered. Reducing max safe batch size to 15
2025-12-10 12:46:58.753 | WARNING  | lean_reinforcement.training.inference_server:_run_transformer_batch:119 - OOM encountered. Reducing max safe batch size to 7
2025-12-10 12:48:33.505 | WARNING  | lean_reinforcement.training.inference_server:_run_transformer_batch:119 - OOM encountered. Reducing max safe batch size to 3
2025-12-10 12:50:08.544 | WARNING  | lean_reinforcement.training.inference_server:_run_transformer_batch:119 - OOM encountered. Reducing max safe batch size to 1
2025-12-10 12:51:42.872 | ERROR    | __main__:main:402 - Training crashed: OOM even with single sample! n=16
2025-12-10 12:51:42.873 | INFO     | __main__:main:405 - Shutting down workers...
Traceback (most recent call last):
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 111, in _run_transformer_batch
    return method(states, n=n, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/agent/transformer.py", line 149, in generate_tactics_with_probs_batch
    outputs = self.model.generate(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 2564, in generate
    result = decoding_method(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 3265, in _beam_search
    model_outputs = self(**model_inputs, return_dict=True)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 1764, in forward
    decoder_outputs = self.decoder(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 1100, in forward
    layer_outputs = layer_module(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 711, in forward
    cross_attention_outputs = self.layer[1](
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 640, in forward
    attention_output = self.EncDecAttention(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 521, in forward
    key_states, value_states = curr_past_key_value.update(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/cache_utils.py", line 776, in update
    keys, values = self.layers[layer_idx].update(key_states, value_states, cache_kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/cache_utils.py", line 119, in update
    self.keys = torch.cat([self.keys, key_states], dim=-2)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacity of 39.49 GiB of which 2.29 GiB is free. Including non-PyTorch memory, this process has 37.19 GiB memory in use. Of the allocated memory 34.57 GiB is allocated by PyTorch, and 2.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 111, in _run_transformer_batch
    return method(states, n=n, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/agent/transformer.py", line 149, in generate_tactics_with_probs_batch
    outputs = self.model.generate(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    model_kwargs = self._prepare_encoder_decoder_kwargs_for_generation(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 861, in _prepare_encoder_decoder_kwargs_for_generation
    model_kwargs["encoder_outputs"]: ModelOutput = encoder(**encoder_kwargs)  # type: ignore
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 1100, in forward
    layer_outputs = layer_module(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 737, in forward
    hidden_states = self.layer[-1](hidden_states)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 343, in forward
    forwarded_states = self.DenseReluDense(forwarded_states)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 311, in forward
    hidden_gelu = self.act(self.wi_0(hidden_states))
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/activations.py", line 62, in forward
    return 0.5 * input * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (input + 0.044715 * torch.pow(input, 3.0))))
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 778.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 334.75 MiB is free. Including non-PyTorch memory, this process has 39.16 GiB memory in use. Of the allocated memory 36.86 GiB is allocated by PyTorch, and 1.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 111, in _run_transformer_batch
    return method(states, n=n, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/agent/transformer.py", line 149, in generate_tactics_with_probs_batch
    outputs = self.model.generate(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 2482, in generate
    input_ids, model_kwargs = self._expand_inputs_for_generation(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 955, in _expand_inputs_for_generation
    model_kwargs["encoder_outputs"] = _expand_dict_for_generation(model_kwargs["encoder_outputs"])
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 944, in _expand_dict_for_generation
    dict_to_expand[key] = dict_to_expand[key].repeat_interleave(expand_size, dim=0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.13 GiB. GPU 0 has a total capacity of 39.49 GiB of which 334.75 MiB is free. Including non-PyTorch memory, this process has 39.16 GiB memory in use. Of the allocated memory 36.94 GiB is allocated by PyTorch, and 1.73 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 111, in _run_transformer_batch
    return method(states, n=n, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/agent/transformer.py", line 149, in generate_tactics_with_probs_batch
    outputs = self.model.generate(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 2564, in generate
    result = decoding_method(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 3265, in _beam_search
    model_outputs = self(**model_inputs, return_dict=True)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 1764, in forward
    decoder_outputs = self.decoder(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 1100, in forward
    layer_outputs = layer_module(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 711, in forward
    cross_attention_outputs = self.layer[1](
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 640, in forward
    attention_output = self.EncDecAttention(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 521, in forward
    key_states, value_states = curr_past_key_value.update(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/cache_utils.py", line 776, in update
    keys, values = self.layers[layer_idx].update(key_states, value_states, cache_kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/cache_utils.py", line 119, in update
    self.keys = torch.cat([self.keys, key_states], dim=-2)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 52.75 MiB is free. Including non-PyTorch memory, this process has 39.43 GiB memory in use. Of the allocated memory 38.53 GiB is allocated by PyTorch, and 416.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 111, in _run_transformer_batch
    return method(states, n=n, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/agent/transformer.py", line 149, in generate_tactics_with_probs_batch
    outputs = self.model.generate(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 2482, in generate
    input_ids, model_kwargs = self._expand_inputs_for_generation(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 955, in _expand_inputs_for_generation
    model_kwargs["encoder_outputs"] = _expand_dict_for_generation(model_kwargs["encoder_outputs"])
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 944, in _expand_dict_for_generation
    dict_to_expand[key] = dict_to_expand[key].repeat_interleave(expand_size, dim=0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 260.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 52.75 MiB is free. Including non-PyTorch memory, this process has 39.43 GiB memory in use. Of the allocated memory 38.55 GiB is allocated by PyTorch, and 399.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 111, in _run_transformer_batch
    return method(states, n=n, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/agent/transformer.py", line 149, in generate_tactics_with_probs_batch
    outputs = self.model.generate(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 2482, in generate
    input_ids, model_kwargs = self._expand_inputs_for_generation(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 955, in _expand_inputs_for_generation
    model_kwargs["encoder_outputs"] = _expand_dict_for_generation(model_kwargs["encoder_outputs"])
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 944, in _expand_dict_for_generation
    dict_to_expand[key] = dict_to_expand[key].repeat_interleave(expand_size, dim=0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 52.75 MiB is free. Including non-PyTorch memory, this process has 39.43 GiB memory in use. Of the allocated memory 38.56 GiB is allocated by PyTorch, and 391.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 111, in _run_transformer_batch
    return method(states, n=n, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/agent/transformer.py", line 149, in generate_tactics_with_probs_batch
    outputs = self.model.generate(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 2564, in generate
    result = decoding_method(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 3377, in _beam_search
    model_kwargs["past_key_values"].reorder_cache(beam_idx)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/cache_utils.py", line 1309, in reorder_cache
    self.cross_attention_cache.reorder_cache(beam_idx)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/cache_utils.py", line 832, in reorder_cache
    self.layers[layer_idx].reorder_cache(beam_idx)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/cache_utils.py", line 80, in reorder_cache
    self.keys = self.keys.index_select(0, beam_idx.to(self.keys.device))
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 12.75 MiB is free. Including non-PyTorch memory, this process has 39.47 GiB memory in use. Of the allocated memory 38.79 GiB is allocated by PyTorch, and 191.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 111, in _run_transformer_batch
    return method(states, n=n, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/agent/transformer.py", line 149, in generate_tactics_with_probs_batch
    outputs = self.model.generate(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 2482, in generate
    input_ids, model_kwargs = self._expand_inputs_for_generation(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 955, in _expand_inputs_for_generation
    model_kwargs["encoder_outputs"] = _expand_dict_for_generation(model_kwargs["encoder_outputs"])
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 944, in _expand_dict_for_generation
    dict_to_expand[key] = dict_to_expand[key].repeat_interleave(expand_size, dim=0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 12.75 MiB is free. Including non-PyTorch memory, this process has 39.47 GiB memory in use. Of the allocated memory 38.79 GiB is allocated by PyTorch, and 190.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/train.py", line 414, in <module>
    main(args)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/train.py", line 403, in main
    raise e
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/train.py", line 303, in main
    processed_batch = inference_server.process_requests()
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 54, in process_requests
    self._process_batch(batch_requests)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 101, in _process_batch
    self._execute_batch(current_type, current_batch, current_indices)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 182, in _execute_batch
    all_results = self._run_transformer_batch(
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 127, in _run_transformer_batch
    left = self._run_transformer_batch(method, states[:mid], n, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 127, in _run_transformer_batch
    left = self._run_transformer_batch(method, states[:mid], n, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 127, in _run_transformer_batch
    left = self._run_transformer_batch(method, states[:mid], n, **kwargs)
  [Previous line repeated 4 more times]
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 115, in _run_transformer_batch
    raise RuntimeError(f"OOM even with single sample! n={n}")
RuntimeError: OOM even with single sample! n=16
Traceback (most recent call last):
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 111, in _run_transformer_batch
    return method(states, n=n, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/agent/transformer.py", line 149, in generate_tactics_with_probs_batch
    outputs = self.model.generate(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 2564, in generate
    result = decoding_method(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 3265, in _beam_search
    model_outputs = self(**model_inputs, return_dict=True)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 1764, in forward
    decoder_outputs = self.decoder(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 1100, in forward
    layer_outputs = layer_module(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 711, in forward
    cross_attention_outputs = self.layer[1](
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 640, in forward
    attention_output = self.EncDecAttention(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 521, in forward
    key_states, value_states = curr_past_key_value.update(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/cache_utils.py", line 776, in update
    keys, values = self.layers[layer_idx].update(key_states, value_states, cache_kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/cache_utils.py", line 119, in update
    self.keys = torch.cat([self.keys, key_states], dim=-2)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacity of 39.49 GiB of which 2.29 GiB is free. Including non-PyTorch memory, this process has 37.19 GiB memory in use. Of the allocated memory 34.57 GiB is allocated by PyTorch, and 2.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 111, in _run_transformer_batch
    return method(states, n=n, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/agent/transformer.py", line 149, in generate_tactics_with_probs_batch
    outputs = self.model.generate(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    model_kwargs = self._prepare_encoder_decoder_kwargs_for_generation(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 861, in _prepare_encoder_decoder_kwargs_for_generation
    model_kwargs["encoder_outputs"]: ModelOutput = encoder(**encoder_kwargs)  # type: ignore
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 1100, in forward
    layer_outputs = layer_module(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 737, in forward
    hidden_states = self.layer[-1](hidden_states)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 343, in forward
    forwarded_states = self.DenseReluDense(forwarded_states)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 311, in forward
    hidden_gelu = self.act(self.wi_0(hidden_states))
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/activations.py", line 62, in forward
    return 0.5 * input * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (input + 0.044715 * torch.pow(input, 3.0))))
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 778.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 334.75 MiB is free. Including non-PyTorch memory, this process has 39.16 GiB memory in use. Of the allocated memory 36.86 GiB is allocated by PyTorch, and 1.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 111, in _run_transformer_batch
    return method(states, n=n, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/agent/transformer.py", line 149, in generate_tactics_with_probs_batch
    outputs = self.model.generate(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 2482, in generate
    input_ids, model_kwargs = self._expand_inputs_for_generation(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 955, in _expand_inputs_for_generation
    model_kwargs["encoder_outputs"] = _expand_dict_for_generation(model_kwargs["encoder_outputs"])
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 944, in _expand_dict_for_generation
    dict_to_expand[key] = dict_to_expand[key].repeat_interleave(expand_size, dim=0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.13 GiB. GPU 0 has a total capacity of 39.49 GiB of which 334.75 MiB is free. Including non-PyTorch memory, this process has 39.16 GiB memory in use. Of the allocated memory 36.94 GiB is allocated by PyTorch, and 1.73 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 111, in _run_transformer_batch
    return method(states, n=n, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/agent/transformer.py", line 149, in generate_tactics_with_probs_batch
    outputs = self.model.generate(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 2564, in generate
    result = decoding_method(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 3265, in _beam_search
    model_outputs = self(**model_inputs, return_dict=True)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 1764, in forward
    decoder_outputs = self.decoder(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 1100, in forward
    layer_outputs = layer_module(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 711, in forward
    cross_attention_outputs = self.layer[1](
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 640, in forward
    attention_output = self.EncDecAttention(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 521, in forward
    key_states, value_states = curr_past_key_value.update(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/cache_utils.py", line 776, in update
    keys, values = self.layers[layer_idx].update(key_states, value_states, cache_kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/cache_utils.py", line 119, in update
    self.keys = torch.cat([self.keys, key_states], dim=-2)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 52.75 MiB is free. Including non-PyTorch memory, this process has 39.43 GiB memory in use. Of the allocated memory 38.53 GiB is allocated by PyTorch, and 416.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 111, in _run_transformer_batch
    return method(states, n=n, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/agent/transformer.py", line 149, in generate_tactics_with_probs_batch
    outputs = self.model.generate(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 2482, in generate
    input_ids, model_kwargs = self._expand_inputs_for_generation(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 955, in _expand_inputs_for_generation
    model_kwargs["encoder_outputs"] = _expand_dict_for_generation(model_kwargs["encoder_outputs"])
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 944, in _expand_dict_for_generation
    dict_to_expand[key] = dict_to_expand[key].repeat_interleave(expand_size, dim=0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 260.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 52.75 MiB is free. Including non-PyTorch memory, this process has 39.43 GiB memory in use. Of the allocated memory 38.55 GiB is allocated by PyTorch, and 399.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 111, in _run_transformer_batch
    return method(states, n=n, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/agent/transformer.py", line 149, in generate_tactics_with_probs_batch
    outputs = self.model.generate(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 2482, in generate
    input_ids, model_kwargs = self._expand_inputs_for_generation(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 955, in _expand_inputs_for_generation
    model_kwargs["encoder_outputs"] = _expand_dict_for_generation(model_kwargs["encoder_outputs"])
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 944, in _expand_dict_for_generation
    dict_to_expand[key] = dict_to_expand[key].repeat_interleave(expand_size, dim=0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 52.75 MiB is free. Including non-PyTorch memory, this process has 39.43 GiB memory in use. Of the allocated memory 38.56 GiB is allocated by PyTorch, and 391.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 111, in _run_transformer_batch
    return method(states, n=n, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/agent/transformer.py", line 149, in generate_tactics_with_probs_batch
    outputs = self.model.generate(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 2564, in generate
    result = decoding_method(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 3377, in _beam_search
    model_kwargs["past_key_values"].reorder_cache(beam_idx)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/cache_utils.py", line 1309, in reorder_cache
    self.cross_attention_cache.reorder_cache(beam_idx)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/cache_utils.py", line 832, in reorder_cache
    self.layers[layer_idx].reorder_cache(beam_idx)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/cache_utils.py", line 80, in reorder_cache
    self.keys = self.keys.index_select(0, beam_idx.to(self.keys.device))
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 12.75 MiB is free. Including non-PyTorch memory, this process has 39.47 GiB memory in use. Of the allocated memory 38.79 GiB is allocated by PyTorch, and 191.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 111, in _run_transformer_batch
    return method(states, n=n, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/agent/transformer.py", line 149, in generate_tactics_with_probs_batch
    outputs = self.model.generate(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 2482, in generate
    input_ids, model_kwargs = self._expand_inputs_for_generation(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 955, in _expand_inputs_for_generation
    model_kwargs["encoder_outputs"] = _expand_dict_for_generation(model_kwargs["encoder_outputs"])
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 944, in _expand_dict_for_generation
    dict_to_expand[key] = dict_to_expand[key].repeat_interleave(expand_size, dim=0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 12.75 MiB is free. Including non-PyTorch memory, this process has 39.47 GiB memory in use. Of the allocated memory 38.79 GiB is allocated by PyTorch, and 190.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/train.py", line 414, in <module>
    main(args)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/train.py", line 403, in main
    raise e
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/train.py", line 303, in main
    processed_batch = inference_server.process_requests()
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 54, in process_requests
    self._process_batch(batch_requests)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 101, in _process_batch
    self._execute_batch(current_type, current_batch, current_indices)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 182, in _execute_batch
    all_results = self._run_transformer_batch(
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 127, in _run_transformer_batch
    left = self._run_transformer_batch(method, states[:mid], n, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 127, in _run_transformer_batch
    left = self._run_transformer_batch(method, states[:mid], n, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 127, in _run_transformer_batch
    left = self._run_transformer_batch(method, states[:mid], n, **kwargs)
  [Previous line repeated 4 more times]
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 115, in _run_transformer_batch
    raise RuntimeError(f"OOM even with single sample! n={n}")
RuntimeError: OOM even with single sample! n=16
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mzany-cosmos-25[0m at: [34mhttps://wandb.ai/gerbennkoopman-university-of-amsterdam/lean-reinforcement/runs/j8zb7k31[0m
[1;34mwandb[0m: Find logs at: [1;35m../../../gpfs/home1/gkoopman/lean_reinforcement/wandb/run-20251210_121559-j8zb7k31/logs[0m
[2025-12-10T12:53:40.027] error: *** JOB 17418465 ON gcn28 CANCELLED AT 2025-12-10T12:53:40 DUE to SIGNAL Terminated ***
[2025-12-10T12:53:40.030] error: *** STEP 17418465.0 ON gcn28 CANCELLED AT 2025-12-10T12:53:40 DUE to SIGNAL Terminated ***
