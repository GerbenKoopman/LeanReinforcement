============================================================================================== 
Warning! Mixing Conda and module environments may lead to corruption of the
user environment. 
We do not recommend users mixing those two environments unless absolutely
necessary. Note that 
SURF does not provide any support for Conda environment.
For more information, please refer to our software policy page:
https://servicedesk.surf.nl/wiki/display/WIKI/Software+policy+Snellius#SoftwarepolicySnellius-UseofAnacondaandMinicondaenvironmentsonSnellius 

Remember that many packages have already been installed on the system and can
be loaded using 
the 'module load <package__name>' command. If you are uncertain if a package is
already available 
on the system, please use 'module avail' or 'module spider' to search for it.
============================================================================================== 
Starting training run with distributed environment...
wandb: Currently logged in as: gerbennkoopman to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: setting up run ry9k60r1
wandb: Tracking run with wandb version 0.22.3
wandb: Run data is saved locally in /gpfs/home1/gkoopman/lean_reinforcement/wandb/run-20251210_132612-ry9k60r1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-waterfall-26
wandb: ‚≠êÔ∏è View project at https://wandb.ai/gerbennkoopman-university-of-amsterdam/lean-reinforcement
wandb: üöÄ View run at https://wandb.ai/gerbennkoopman-university-of-amsterdam/lean-reinforcement/runs/ry9k60r1
2025-12-10 13:26:13.844 | INFO     | __main__:main:184 - Using checkpoint directory: /gpfs/scratch1/shared/lean-reinforcement/checkpoints
2025-12-10 13:26:16.866 | INFO     | lean_reinforcement.agent.value_head:load_checkpoint:192 - Checkpoint loaded from /gpfs/scratch1/shared/lean-reinforcement/checkpoints/value_head_latest.pth
2025-12-10 13:26:16.867 | INFO     | __main__:main:197 - Resuming training from epoch 3
2025-12-10 13:26:16.868 | INFO     | __main__:log_gpu_memory:168 - After model initialization - GPU Memory: 1.12GB allocated, 1.23GB reserved
2025-12-10 13:26:16.868 | INFO     | __main__:main:202 - Loading data from 'leandojo_benchmark_4/novel_premises'
2025-12-10 13:26:16.868 | INFO     | ReProver.common:__init__:201 - Building the corpus from leandojo_benchmark_4/corpus.jsonl
2025-12-10 13:27:02.188 | INFO     | lean_dojo.data_extraction.trace:trace:248 - Loading the traced repo from /gpfs/scratch1/shared/lean-reinforcement/datasets/lean_dojo_cache/leanprover-community-mathlib4-29dcec074de168ac2bf835a77ef68bbe069194c5/mathlib4
2025-12-10 13:27:14,759	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
  0%|          | 0/5674 [00:00<?, ?it/s]  0%|          | 1/5674 [00:05<9:24:03,  5.97s/it]  0%|          | 7/5674 [00:06<1:00:19,  1.57it/s]  0%|          | 11/5674 [00:06<33:54,  2.78it/s]   0%|          | 15/5674 [00:06<22:14,  4.24it/s]  0%|          | 19/5674 [00:06<15:09,  6.22it/s]  0%|          | 25/5674 [00:06<09:19, 10.10it/s]  1%|          | 29/5674 [00:11<38:17,  2.46it/s]  1%|          | 34/5674 [00:11<25:45,  3.65it/s]  1%|          | 41/5674 [00:11<15:49,  5.93it/s]  1%|          | 46/5674 [00:11<11:44,  7.99it/s]  1%|          | 51/5674 [00:11<08:50, 10.59it/s]  1%|          | 56/5674 [00:11<07:01, 13.33it/s]  1%|          | 61/5674 [00:11<05:54, 15.83it/s]  1%|          | 65/5674 [00:16<34:01,  2.75it/s]  1%|          | 69/5674 [00:17<25:48,  3.62it/s]  1%|‚ñè         | 75/5674 [00:17<17:23,  5.37it/s]  1%|‚ñè         | 79/5674 [00:17<13:32,  6.89it/s]  2%|‚ñè         | 87/5674 [00:17<08:18, 11.21it/s]  2%|‚ñè         | 93/5674 [00:17<06:27, 14.40it/s]  2%|‚ñè         | 98/5674 [00:23<34:52,  2.66it/s]  2%|‚ñè         | 102/5674 [00:23<27:33,  3.37it/s]  2%|‚ñè         | 105/5674 [00:23<22:59,  4.04it/s]  2%|‚ñè         | 108/5674 [00:24<18:51,  4.92it/s]  2%|‚ñè         | 112/5674 [00:24<14:14,  6.51it/s]  2%|‚ñè         | 115/5674 [00:24<11:54,  7.79it/s]  2%|‚ñè         | 118/5674 [00:24<10:39,  8.69it/s]  2%|‚ñè         | 121/5674 [00:31<1:02:33,  1.48it/s]  2%|‚ñè         | 125/5674 [00:31<42:36,  2.17it/s]    2%|‚ñè         | 128/5674 [00:31<32:30,  2.84it/s]  2%|‚ñè         | 131/5674 [00:31<24:42,  3.74it/s]  2%|‚ñè         | 134/5674 [00:31<18:48,  4.91it/s]  2%|‚ñè         | 137/5674 [00:31<14:37,  6.31it/s]  3%|‚ñé         | 142/5674 [00:32<09:47,  9.41it/s]  3%|‚ñé         | 148/5674 [00:32<06:30, 14.15it/s]  3%|‚ñé         | 152/5674 [00:32<06:02, 15.22it/s]  3%|‚ñé         | 155/5674 [00:39<56:26,  1.63it/s]  3%|‚ñé         | 158/5674 [00:39<43:29,  2.11it/s]  3%|‚ñé         | 162/5674 [00:40<31:01,  2.96it/s]  3%|‚ñé         | 164/5674 [00:40<26:10,  3.51it/s]  3%|‚ñé         | 167/5674 [00:40<19:51,  4.62it/s]  3%|‚ñé         | 170/5674 [00:40<15:31,  5.91it/s]  3%|‚ñé         | 177/5674 [00:40<08:34, 10.67it/s]  3%|‚ñé         | 181/5674 [00:40<06:47, 13.48it/s]  3%|‚ñé         | 189/5674 [00:40<04:15, 21.43it/s]  3%|‚ñé         | 194/5674 [00:40<03:37, 25.21it/s]  4%|‚ñé         | 200/5674 [00:41<02:59, 30.56it/s]  4%|‚ñé         | 205/5674 [00:41<02:48, 32.55it/s]  4%|‚ñé         | 211/5674 [00:41<02:33, 35.55it/s]  4%|‚ñç         | 219/5674 [00:41<02:05, 43.50it/s]  4%|‚ñç         | 225/5674 [00:49<37:45,  2.41it/s]  4%|‚ñç         | 234/5674 [00:49<23:44,  3.82it/s]  4%|‚ñç         | 239/5674 [00:49<19:01,  4.76it/s]  4%|‚ñç         | 246/5674 [00:50<13:23,  6.76it/s]  4%|‚ñç         | 251/5674 [00:50<11:04,  8.16it/s]  5%|‚ñç         | 256/5674 [00:50<08:41, 10.39it/s]  5%|‚ñç         | 261/5674 [00:50<06:58, 12.93it/s]  5%|‚ñç         | 266/5674 [00:50<05:56, 15.17it/s]  5%|‚ñç         | 270/5674 [00:50<05:15, 17.11it/s]  5%|‚ñç         | 274/5674 [00:50<04:36, 19.54it/s]  5%|‚ñç         | 283/5674 [00:51<03:02, 29.49it/s]  5%|‚ñå         | 289/5674 [00:51<02:37, 34.29it/s]  5%|‚ñå         | 294/5674 [00:51<02:47, 32.05it/s]  5%|‚ñå         | 299/5674 [00:51<02:45, 32.44it/s]  5%|‚ñå         | 304/5674 [00:51<02:30, 35.59it/s]  5%|‚ñå         | 309/5674 [01:01<51:36,  1.73it/s]  6%|‚ñå         | 314/5674 [01:01<37:06,  2.41it/s]  6%|‚ñå         | 318/5674 [01:01<28:33,  3.12it/s]  6%|‚ñå         | 324/5674 [01:01<19:25,  4.59it/s]  6%|‚ñå         | 333/5674 [01:01<11:32,  7.71it/s]  6%|‚ñå         | 345/5674 [01:02<06:53, 12.90it/s]  6%|‚ñå         | 351/5674 [01:02<05:40, 15.62it/s]  6%|‚ñã         | 358/5674 [01:02<04:24, 20.11it/s]  6%|‚ñã         | 366/5674 [01:02<03:20, 26.41it/s]  7%|‚ñã         | 373/5674 [01:02<02:47, 31.66it/s]  7%|‚ñã         | 382/5674 [01:02<02:13, 39.61it/s]  7%|‚ñã         | 392/5674 [01:02<01:45, 50.24it/s]  7%|‚ñã         | 408/5674 [01:02<01:13, 71.61it/s]  8%|‚ñä         | 434/5674 [01:02<00:50, 104.28it/s]  8%|‚ñä         | 453/5674 [01:03<00:42, 121.86it/s]  8%|‚ñä         | 468/5674 [01:03<00:52, 99.38it/s]   8%|‚ñä         | 480/5674 [01:03<01:05, 79.07it/s]  9%|‚ñä         | 490/5674 [01:03<01:19, 65.04it/s]  9%|‚ñä         | 490/5674 [01:15<01:19, 65.04it/s]  9%|‚ñä         | 494/5674 [01:15<28:58,  2.98it/s]  9%|‚ñä         | 496/5674 [01:15<27:11,  3.17it/s]  9%|‚ñâ         | 504/5674 [01:15<19:35,  4.40it/s]  9%|‚ñâ         | 510/5674 [01:15<15:22,  5.60it/s]  9%|‚ñâ         | 516/5674 [01:15<11:58,  7.18it/s]  9%|‚ñâ         | 521/5674 [01:15<09:39,  8.90it/s]  9%|‚ñâ         | 533/5674 [01:15<05:39, 15.16it/s] 10%|‚ñâ         | 540/5674 [01:16<04:35, 18.63it/s] 10%|‚ñâ         | 547/5674 [01:16<03:47, 22.53it/s] 10%|‚ñâ         | 555/5674 [01:16<02:56, 28.96it/s] 10%|‚ñâ         | 563/5674 [01:16<02:26, 35.00it/s] 10%|‚ñà         | 573/5674 [01:16<01:56, 43.73it/s] 10%|‚ñà         | 580/5674 [01:16<01:59, 42.61it/s] 10%|‚ñà         | 587/5674 [01:16<02:15, 37.49it/s] 11%|‚ñà         | 598/5674 [01:17<01:42, 49.63it/s] 11%|‚ñà         | 607/5674 [01:17<01:29, 56.41it/s] 11%|‚ñà         | 615/5674 [01:17<01:23, 60.75it/s] 11%|‚ñà         | 623/5674 [01:17<01:32, 54.51it/s] 11%|‚ñà         | 630/5674 [01:17<01:34, 53.19it/s] 11%|‚ñà         | 636/5674 [01:17<01:34, 53.10it/s] 11%|‚ñà‚ñè        | 642/5674 [01:17<01:43, 48.46it/s] 11%|‚ñà‚ñè        | 648/5674 [01:18<01:50, 45.31it/s] 11%|‚ñà‚ñè        | 648/5674 [01:31<01:50, 45.31it/s] 11%|‚ñà‚ñè        | 650/5674 [01:31<1:07:13,  1.25it/s] 12%|‚ñà‚ñè        | 657/5674 [01:31<43:21,  1.93it/s]   12%|‚ñà‚ñè        | 666/5674 [01:32<26:23,  3.16it/s] 12%|‚ñà‚ñè        | 672/5674 [01:32<19:41,  4.23it/s] 12%|‚ñà‚ñè        | 680/5674 [01:32<13:20,  6.24it/s] 12%|‚ñà‚ñè        | 687/5674 [01:32<09:42,  8.56it/s] 12%|‚ñà‚ñè        | 697/5674 [01:32<06:28, 12.80it/s] 12%|‚ñà‚ñè        | 706/5674 [01:32<04:42, 17.56it/s] 13%|‚ñà‚ñé        | 713/5674 [01:32<03:56, 20.97it/s] 13%|‚ñà‚ñé        | 719/5674 [01:32<03:19, 24.79it/s] 13%|‚ñà‚ñé        | 725/5674 [01:33<03:15, 25.33it/s] 13%|‚ñà‚ñé        | 730/5674 [01:33<03:04, 26.74it/s] 13%|‚ñà‚ñé        | 735/5674 [01:33<02:46, 29.72it/s] 13%|‚ñà‚ñé        | 743/5674 [01:33<02:14, 36.68it/s] 13%|‚ñà‚ñé        | 748/5674 [01:33<02:10, 37.87it/s] 13%|‚ñà‚ñé        | 753/5674 [01:33<02:35, 31.67it/s] 13%|‚ñà‚ñé        | 759/5674 [01:34<02:26, 33.54it/s] 13%|‚ñà‚ñé        | 764/5674 [01:34<02:22, 34.44it/s] 14%|‚ñà‚ñé        | 768/5674 [01:34<02:44, 29.86it/s] 14%|‚ñà‚ñé        | 775/5674 [01:34<02:41, 30.40it/s] 14%|‚ñà‚ñç        | 782/5674 [01:34<02:14, 36.46it/s] 14%|‚ñà‚ñç        | 788/5674 [01:34<02:04, 39.23it/s] 14%|‚ñà‚ñç        | 797/5674 [01:35<01:38, 49.64it/s] 14%|‚ñà‚ñç        | 803/5674 [01:35<01:53, 42.90it/s] 14%|‚ñà‚ñç        | 811/5674 [01:35<01:45, 46.14it/s] 14%|‚ñà‚ñç        | 817/5674 [01:35<01:39, 48.67it/s] 14%|‚ñà‚ñç        | 817/5674 [01:51<01:39, 48.67it/s] 14%|‚ñà‚ñç        | 819/5674 [01:51<1:16:46,  1.05it/s] 14%|‚ñà‚ñç        | 822/5674 [01:52<1:02:21,  1.30it/s] 15%|‚ñà‚ñç        | 827/5674 [01:52<43:07,  1.87it/s]   15%|‚ñà‚ñç        | 832/5674 [01:52<30:43,  2.63it/s] 15%|‚ñà‚ñç        | 839/5674 [01:52<19:22,  4.16it/s] 15%|‚ñà‚ñç        | 846/5674 [01:52<12:58,  6.21it/s] 15%|‚ñà‚ñå        | 852/5674 [01:52<09:37,  8.35it/s] 15%|‚ñà‚ñå        | 857/5674 [01:52<07:48, 10.27it/s] 15%|‚ñà‚ñå        | 862/5674 [01:53<06:16, 12.77it/s] 15%|‚ñà‚ñå        | 870/5674 [01:53<04:31, 17.69it/s] 15%|‚ñà‚ñå        | 875/5674 [01:53<04:03, 19.68it/s] 16%|‚ñà‚ñå        | 880/5674 [01:53<03:25, 23.37it/s] 16%|‚ñà‚ñå        | 885/5674 [01:53<03:03, 26.04it/s] 16%|‚ñà‚ñå        | 890/5674 [01:53<02:45, 28.94it/s] 16%|‚ñà‚ñå        | 895/5674 [01:53<02:46, 28.78it/s] 16%|‚ñà‚ñå        | 901/5674 [01:54<02:22, 33.43it/s] 16%|‚ñà‚ñå        | 906/5674 [01:54<02:09, 36.72it/s] 16%|‚ñà‚ñå        | 911/5674 [01:54<02:18, 34.46it/s] 16%|‚ñà‚ñå        | 918/5674 [01:54<02:08, 36.89it/s] 16%|‚ñà‚ñã        | 926/5674 [01:54<01:44, 45.33it/s] 16%|‚ñà‚ñã        | 934/5674 [01:54<01:41, 46.61it/s] 17%|‚ñà‚ñã        | 942/5674 [01:55<01:49, 43.03it/s] 17%|‚ñà‚ñã        | 949/5674 [01:55<01:38, 47.87it/s] 17%|‚ñà‚ñã        | 955/5674 [01:55<01:40, 47.02it/s] 17%|‚ñà‚ñã        | 960/5674 [01:55<01:48, 43.57it/s] 17%|‚ñà‚ñã        | 965/5674 [01:55<02:06, 37.20it/s] 17%|‚ñà‚ñã        | 971/5674 [01:55<01:52, 41.89it/s] 17%|‚ñà‚ñã        | 977/5674 [01:55<01:48, 43.42it/s] 17%|‚ñà‚ñã        | 982/5674 [01:56<02:24, 32.51it/s] 17%|‚ñà‚ñã        | 986/5674 [01:56<02:33, 30.57it/s] 17%|‚ñà‚ñã        | 990/5674 [01:56<03:07, 25.01it/s] 17%|‚ñà‚ñã        | 990/5674 [02:16<03:07, 25.01it/s] 18%|‚ñà‚ñä        | 993/5674 [02:16<1:53:53,  1.46s/it] 18%|‚ñà‚ñä        | 996/5674 [02:17<1:28:52,  1.14s/it] 18%|‚ñà‚ñä        | 1003/5674 [02:17<51:08,  1.52it/s]  18%|‚ñà‚ñä        | 1008/5674 [02:17<35:52,  2.17it/s] 18%|‚ñà‚ñä        | 1013/5674 [02:17<25:31,  3.04it/s] 18%|‚ñà‚ñä        | 1017/5674 [02:17<19:34,  3.96it/s] 18%|‚ñà‚ñä        | 1024/5674 [02:17<12:29,  6.20it/s] 18%|‚ñà‚ñä        | 1034/5674 [02:17<07:16, 10.63it/s] 18%|‚ñà‚ñä        | 1042/5674 [02:17<05:09, 14.99it/s] 19%|‚ñà‚ñä        | 1051/5674 [02:18<03:38, 21.11it/s] 19%|‚ñà‚ñä        | 1058/5674 [02:18<03:02, 25.35it/s] 19%|‚ñà‚ñâ        | 1065/5674 [02:18<02:51, 26.94it/s] 19%|‚ñà‚ñâ        | 1071/5674 [02:18<02:27, 31.18it/s] 19%|‚ñà‚ñâ        | 1077/5674 [02:18<02:31, 30.30it/s] 19%|‚ñà‚ñâ        | 1084/5674 [02:18<02:05, 36.51it/s] 19%|‚ñà‚ñâ        | 1093/5674 [02:18<01:42, 44.57it/s] 19%|‚ñà‚ñâ        | 1102/5674 [02:19<01:26, 52.74it/s] 20%|‚ñà‚ñâ        | 1109/5674 [02:19<01:33, 49.08it/s] 20%|‚ñà‚ñâ        | 1115/5674 [02:19<01:34, 48.34it/s] 20%|‚ñà‚ñâ        | 1123/5674 [02:19<01:35, 47.75it/s] 20%|‚ñà‚ñâ        | 1130/5674 [02:19<01:29, 50.94it/s] 20%|‚ñà‚ñà        | 1137/5674 [02:19<01:33, 48.68it/s] 20%|‚ñà‚ñà        | 1143/5674 [02:19<01:38, 45.80it/s] 20%|‚ñà‚ñà        | 1149/5674 [02:20<01:33, 48.29it/s] 20%|‚ñà‚ñà        | 1158/5674 [02:20<01:24, 53.14it/s] 21%|‚ñà‚ñà        | 1176/5674 [02:20<00:55, 81.57it/s] 21%|‚ñà‚ñà        | 1195/5674 [02:20<00:42, 104.68it/s] 21%|‚ñà‚ñà‚ñè       | 1214/5674 [02:20<00:35, 125.92it/s] 22%|‚ñà‚ñà‚ñè       | 1229/5674 [02:20<00:35, 126.43it/s] 22%|‚ñà‚ñà‚ñè       | 1248/5674 [02:20<00:31, 141.20it/s] 22%|‚ñà‚ñà‚ñè       | 1265/5674 [02:20<00:30, 144.44it/s] 23%|‚ñà‚ñà‚ñé       | 1280/5674 [02:21<00:33, 130.30it/s] 23%|‚ñà‚ñà‚ñé       | 1294/5674 [02:21<00:33, 131.38it/s] 23%|‚ñà‚ñà‚ñé       | 1312/5674 [02:21<00:31, 139.72it/s] 23%|‚ñà‚ñà‚ñé       | 1327/5674 [02:21<00:33, 128.25it/s] 24%|‚ñà‚ñà‚ñé       | 1341/5674 [02:21<00:38, 113.36it/s] 24%|‚ñà‚ñà‚ñç       | 1353/5674 [02:21<00:52, 81.85it/s]  24%|‚ñà‚ñà‚ñç       | 1363/5674 [02:21<00:52, 82.06it/s] 24%|‚ñà‚ñà‚ñç       | 1373/5674 [02:22<00:55, 78.05it/s] 24%|‚ñà‚ñà‚ñç       | 1382/5674 [02:22<01:03, 67.54it/s] 24%|‚ñà‚ñà‚ñç       | 1382/5674 [02:45<01:03, 67.54it/s] 24%|‚ñà‚ñà‚ñç       | 1385/5674 [02:45<58:47,  1.22it/s] 24%|‚ñà‚ñà‚ñç       | 1390/5674 [02:45<47:35,  1.50it/s] 25%|‚ñà‚ñà‚ñç       | 1397/5674 [02:46<34:38,  2.06it/s] 25%|‚ñà‚ñà‚ñç       | 1405/5674 [02:46<23:58,  2.97it/s] 25%|‚ñà‚ñà‚ñç       | 1411/5674 [02:46<18:17,  3.89it/s] 25%|‚ñà‚ñà‚ñç       | 1417/5674 [02:46<13:53,  5.11it/s] 25%|‚ñà‚ñà‚ñå       | 1425/5674 [02:46<09:34,  7.40it/s] 25%|‚ñà‚ñà‚ñå       | 1431/5674 [02:46<07:26,  9.51it/s] 25%|‚ñà‚ñà‚ñå       | 1437/5674 [02:46<05:59, 11.77it/s] 25%|‚ñà‚ñà‚ñå       | 1443/5674 [02:47<04:39, 15.15it/s] 26%|‚ñà‚ñà‚ñå       | 1448/5674 [02:47<03:52, 18.18it/s] 26%|‚ñà‚ñà‚ñå       | 1456/5674 [02:47<02:49, 24.92it/s] 26%|‚ñà‚ñà‚ñå       | 1464/5674 [02:47<02:10, 32.25it/s] 26%|‚ñà‚ñà‚ñå       | 1473/5674 [02:47<01:41, 41.53it/s] 26%|‚ñà‚ñà‚ñå       | 1482/5674 [02:47<01:24, 49.48it/s] 26%|‚ñà‚ñà‚ñã       | 1490/5674 [02:48<02:12, 31.47it/s] 26%|‚ñà‚ñà‚ñã       | 1496/5674 [02:48<01:59, 35.07it/s] 26%|‚ñà‚ñà‚ñã       | 1502/5674 [02:48<01:48, 38.33it/s] 27%|‚ñà‚ñà‚ñã       | 1508/5674 [02:48<01:53, 36.79it/s] 27%|‚ñà‚ñà‚ñã       | 1514/5674 [02:48<01:54, 36.25it/s] 27%|‚ñà‚ñà‚ñã       | 1519/5674 [02:48<02:07, 32.66it/s] 27%|‚ñà‚ñà‚ñã       | 1527/5674 [02:49<01:43, 40.09it/s] 27%|‚ñà‚ñà‚ñã       | 1534/5674 [02:49<01:48, 38.32it/s] 27%|‚ñà‚ñà‚ñã       | 1539/5674 [02:49<01:45, 39.06it/s] 27%|‚ñà‚ñà‚ñã       | 1544/5674 [02:49<01:47, 38.41it/s] 27%|‚ñà‚ñà‚ñã       | 1549/5674 [02:49<01:46, 38.76it/s] 27%|‚ñà‚ñà‚ñã       | 1554/5674 [02:49<01:48, 37.83it/s] 27%|‚ñà‚ñà‚ñã       | 1559/5674 [02:49<01:45, 38.94it/s] 28%|‚ñà‚ñà‚ñä       | 1564/5674 [02:49<01:45, 38.83it/s] 28%|‚ñà‚ñà‚ñä       | 1568/5674 [02:50<03:07, 21.85it/s] 28%|‚ñà‚ñà‚ñä       | 1574/5674 [02:50<02:37, 26.05it/s] 28%|‚ñà‚ñà‚ñä       | 1578/5674 [02:50<02:30, 27.29it/s] 28%|‚ñà‚ñà‚ñä       | 1582/5674 [02:50<02:26, 27.91it/s] 28%|‚ñà‚ñà‚ñä       | 1586/5674 [02:50<02:33, 26.57it/s] 28%|‚ñà‚ñà‚ñä       | 1589/5674 [02:51<02:37, 25.99it/s] 28%|‚ñà‚ñà‚ñä       | 1593/5674 [02:51<02:31, 26.88it/s] 28%|‚ñà‚ñà‚ñä       | 1596/5674 [02:51<02:29, 27.28it/s] 28%|‚ñà‚ñà‚ñä       | 1601/5674 [02:51<02:11, 31.00it/s] 28%|‚ñà‚ñà‚ñä       | 1605/5674 [02:51<02:02, 33.14it/s] 28%|‚ñà‚ñà‚ñä       | 1610/5674 [02:51<01:51, 36.34it/s] 28%|‚ñà‚ñà‚ñä       | 1614/5674 [02:51<02:23, 28.32it/s] 29%|‚ñà‚ñà‚ñä       | 1624/5674 [02:52<01:32, 43.60it/s] 29%|‚ñà‚ñà‚ñä       | 1630/5674 [02:52<01:41, 39.90it/s] 29%|‚ñà‚ñà‚ñä       | 1630/5674 [03:21<01:41, 39.90it/s] 29%|‚ñà‚ñà‚ñâ       | 1633/5674 [03:21<1:57:28,  1.74s/it] 29%|‚ñà‚ñà‚ñâ       | 1636/5674 [03:21<1:34:12,  1.40s/it] 29%|‚ñà‚ñà‚ñâ       | 1640/5674 [03:21<1:08:58,  1.03s/it] 29%|‚ñà‚ñà‚ñâ       | 1645/5674 [03:21<46:36,  1.44it/s]   29%|‚ñà‚ñà‚ñâ       | 1651/5674 [03:21<30:10,  2.22it/s] 29%|‚ñà‚ñà‚ñâ       | 1655/5674 [03:22<23:02,  2.91it/s] 29%|‚ñà‚ñà‚ñâ       | 1663/5674 [03:22<13:38,  4.90it/s] 29%|‚ñà‚ñà‚ñâ       | 1668/5674 [03:22<10:16,  6.50it/s] 29%|‚ñà‚ñà‚ñâ       | 1673/5674 [03:22<07:47,  8.55it/s] 30%|‚ñà‚ñà‚ñâ       | 1678/5674 [03:22<06:03, 10.98it/s] 30%|‚ñà‚ñà‚ñâ       | 1684/5674 [03:22<04:28, 14.83it/s] 30%|‚ñà‚ñà‚ñâ       | 1689/5674 [03:22<03:42, 17.91it/s] 30%|‚ñà‚ñà‚ñâ       | 1697/5674 [03:22<02:44, 24.13it/s] 30%|‚ñà‚ñà‚ñà       | 1706/5674 [03:23<01:59, 33.27it/s] 30%|‚ñà‚ñà‚ñà       | 1712/5674 [03:23<02:17, 28.78it/s] 30%|‚ñà‚ñà‚ñà       | 1721/5674 [03:23<01:43, 38.24it/s] 30%|‚ñà‚ñà‚ñà       | 1727/5674 [03:23<01:49, 35.99it/s] 31%|‚ñà‚ñà‚ñà       | 1733/5674 [03:23<01:37, 40.27it/s] 31%|‚ñà‚ñà‚ñà       | 1741/5674 [03:23<01:22, 47.66it/s] 31%|‚ñà‚ñà‚ñà       | 1747/5674 [03:24<01:51, 35.32it/s] 31%|‚ñà‚ñà‚ñà       | 1752/5674 [03:24<01:46, 36.97it/s] 31%|‚ñà‚ñà‚ñà       | 1757/5674 [03:24<01:39, 39.31it/s] 31%|‚ñà‚ñà‚ñà       | 1767/5674 [03:24<01:15, 51.93it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1774/5674 [03:24<01:21, 47.60it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1785/5674 [03:24<01:03, 61.14it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1796/5674 [03:24<00:54, 70.77it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1807/5674 [03:25<00:48, 80.13it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1816/5674 [03:25<00:51, 75.46it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1825/5674 [03:25<01:00, 63.83it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1833/5674 [03:25<01:01, 62.91it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1841/5674 [03:25<00:57, 66.22it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1849/5674 [03:25<00:58, 65.11it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1859/5674 [03:25<00:56, 67.65it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1867/5674 [03:25<00:54, 69.53it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1875/5674 [03:26<00:52, 72.04it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1886/5674 [03:26<00:46, 81.21it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1895/5674 [03:26<01:04, 59.02it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1904/5674 [03:26<00:58, 64.25it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1915/5674 [03:26<00:52, 71.81it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1923/5674 [03:26<00:56, 66.10it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1931/5674 [03:26<01:01, 60.75it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1941/5674 [03:27<00:53, 69.26it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1949/5674 [03:27<00:52, 70.75it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1958/5674 [03:27<00:49, 75.57it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1966/5674 [03:27<00:53, 68.98it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1974/5674 [03:27<00:52, 71.05it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1986/5674 [03:27<00:44, 81.96it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1998/5674 [03:27<00:39, 91.97it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 2008/5674 [03:27<00:41, 89.16it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 2018/5674 [03:27<00:47, 77.38it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 2027/5674 [03:28<00:52, 68.87it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 2036/5674 [03:28<00:49, 72.86it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 2044/5674 [03:28<00:51, 70.62it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 2052/5674 [03:28<01:00, 59.90it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 2059/5674 [03:28<01:00, 59.32it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 2066/5674 [03:28<01:04, 56.15it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 2073/5674 [03:28<01:00, 59.21it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 2080/5674 [03:29<01:08, 52.74it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 2086/5674 [03:29<01:06, 54.08it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 2092/5674 [03:29<01:11, 50.24it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 2098/5674 [03:29<01:09, 51.55it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 2098/5674 [04:04<01:09, 51.55it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 2099/5674 [04:04<2:09:14,  2.17s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 2112/5674 [04:04<1:00:07,  1.01s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 2120/5674 [04:04<41:16,  1.44it/s]   37%|‚ñà‚ñà‚ñà‚ñã      | 2127/5674 [04:04<29:45,  1.99it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 2133/5674 [04:04<22:17,  2.65it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 2143/5674 [04:04<14:02,  4.19it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 2153/5674 [04:05<09:26,  6.22it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 2162/5674 [04:05<06:44,  8.69it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 2169/5674 [04:05<05:15, 11.10it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 2176/5674 [04:05<04:19, 13.47it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 2182/5674 [04:05<03:41, 15.76it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 2187/5674 [04:05<03:10, 18.31it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 2192/5674 [04:05<02:41, 21.56it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 2199/5674 [04:06<02:06, 27.42it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 2205/5674 [04:06<01:51, 31.09it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 2210/5674 [04:06<01:50, 31.28it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 2216/5674 [04:06<01:49, 31.64it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 2221/5674 [04:06<01:46, 32.50it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 2228/5674 [04:06<01:29, 38.31it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 2235/5674 [04:06<01:24, 40.86it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 2242/5674 [04:07<01:14, 46.36it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 2248/5674 [04:07<01:19, 43.08it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 2253/5674 [04:07<01:26, 39.42it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 2258/5674 [04:07<01:22, 41.64it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 2263/5674 [04:07<01:24, 40.35it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 2270/5674 [04:07<01:34, 36.20it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 2277/5674 [04:07<01:26, 39.11it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 2282/5674 [04:08<01:43, 32.76it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 2289/5674 [04:08<01:30, 37.48it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 2297/5674 [04:08<01:14, 45.03it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 2302/5674 [04:08<01:34, 35.61it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 2310/5674 [04:08<01:16, 44.25it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 2316/5674 [04:08<01:17, 43.37it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 2321/5674 [04:09<01:14, 44.79it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 2326/5674 [04:09<01:13, 45.41it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 2332/5674 [04:09<01:10, 47.10it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 2339/5674 [04:09<01:13, 45.45it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2344/5674 [04:09<01:12, 46.08it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2349/5674 [04:09<01:10, 46.98it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2355/5674 [04:09<01:06, 50.25it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2361/5674 [04:09<01:15, 43.82it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2371/5674 [04:10<01:02, 53.02it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2381/5674 [04:10<00:51, 63.93it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2389/5674 [04:10<00:50, 65.07it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2398/5674 [04:10<00:46, 70.63it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2406/5674 [04:10<01:06, 48.83it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2414/5674 [04:10<00:59, 54.68it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2421/5674 [04:10<01:09, 46.51it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2428/5674 [04:11<01:04, 50.30it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2436/5674 [04:11<00:57, 56.66it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2447/5674 [04:11<00:57, 56.03it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2456/5674 [04:11<00:51, 62.11it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2467/5674 [04:11<00:44, 72.19it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2475/5674 [04:11<00:58, 54.92it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2482/5674 [04:11<00:58, 54.94it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2489/5674 [04:12<01:09, 46.07it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2495/5674 [04:12<01:09, 45.97it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2502/5674 [04:12<01:04, 49.55it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2508/5674 [04:12<01:25, 37.20it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2513/5674 [04:12<01:45, 29.99it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2518/5674 [04:13<01:35, 33.21it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2524/5674 [04:13<01:31, 34.60it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2529/5674 [04:13<01:27, 35.81it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2534/5674 [04:13<01:21, 38.68it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2539/5674 [04:13<01:18, 39.71it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2545/5674 [04:13<01:10, 44.24it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2545/5674 [04:57<01:10, 44.24it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2551/5674 [04:57<2:01:35,  2.34s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2555/5674 [04:57<1:33:33,  1.80s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2562/5674 [04:57<59:26,  1.15s/it]   45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2567/5674 [04:57<43:28,  1.19it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2572/5674 [04:58<31:37,  1.63it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2577/5674 [04:58<23:26,  2.20it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2582/5674 [04:58<17:02,  3.02it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2586/5674 [04:58<13:07,  3.92it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2590/5674 [04:58<10:07,  5.08it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2594/5674 [04:58<08:04,  6.35it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2598/5674 [04:59<06:10,  8.29it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2607/5674 [04:59<03:30, 14.55it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2612/5674 [04:59<02:53, 17.68it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2618/5674 [04:59<02:16, 22.43it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2625/5674 [04:59<01:46, 28.62it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2631/5674 [04:59<01:38, 30.87it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2637/5674 [04:59<01:25, 35.72it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2648/5674 [04:59<00:59, 50.62it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2655/5674 [04:59<00:59, 50.95it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2664/5674 [05:00<00:51, 58.23it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2671/5674 [05:00<00:55, 54.11it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2678/5674 [05:00<00:52, 57.27it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2685/5674 [05:00<00:52, 56.61it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2692/5674 [05:00<00:56, 52.72it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2698/5674 [05:00<00:56, 52.74it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2704/5674 [05:00<01:00, 49.07it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2710/5674 [05:01<01:05, 44.97it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2717/5674 [05:01<01:13, 40.34it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2725/5674 [05:01<01:01, 47.98it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2732/5674 [05:01<00:55, 52.81it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2738/5674 [05:01<01:10, 41.66it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2743/5674 [05:01<01:11, 40.93it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2748/5674 [05:01<01:12, 40.33it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2753/5674 [05:02<01:24, 34.49it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2758/5674 [05:02<01:22, 35.24it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2763/5674 [05:02<01:27, 33.19it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2768/5674 [05:02<01:20, 36.25it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2773/5674 [05:02<01:14, 38.88it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2783/5674 [05:02<00:55, 52.05it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2791/5674 [05:02<00:49, 58.64it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2798/5674 [05:02<00:48, 59.35it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2805/5674 [05:03<00:50, 57.24it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2811/5674 [05:03<00:49, 57.82it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2817/5674 [05:03<00:51, 55.00it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2823/5674 [05:03<01:06, 42.66it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2831/5674 [05:03<01:00, 47.28it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2837/5674 [05:03<01:06, 42.90it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2844/5674 [05:03<00:58, 48.04it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2851/5674 [05:04<00:53, 53.15it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2857/5674 [05:04<00:52, 53.28it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2863/5674 [05:04<00:54, 51.73it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2869/5674 [05:04<00:52, 53.18it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2875/5674 [05:04<00:54, 51.74it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2884/5674 [05:04<00:46, 60.08it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2891/5674 [05:04<00:47, 58.55it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2897/5674 [05:04<00:51, 54.40it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2903/5674 [05:05<00:51, 53.48it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2909/5674 [05:05<00:57, 48.32it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2914/5674 [05:05<01:01, 44.84it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2921/5674 [05:05<00:54, 50.97it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2929/5674 [05:05<00:48, 56.76it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2935/5674 [05:05<00:49, 55.37it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2942/5674 [05:05<00:51, 52.80it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2948/5674 [05:05<00:57, 47.41it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2953/5674 [05:06<01:10, 38.82it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2958/5674 [05:06<01:14, 36.68it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2963/5674 [05:06<01:08, 39.32it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2968/5674 [05:06<01:08, 39.59it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2973/5674 [05:06<01:08, 39.51it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2978/5674 [05:06<01:10, 38.30it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2985/5674 [05:06<00:59, 45.02it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2990/5674 [05:07<01:08, 39.47it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2995/5674 [05:07<01:07, 39.48it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3000/5674 [05:07<01:04, 41.66it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3005/5674 [05:07<01:04, 41.49it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3012/5674 [05:07<00:55, 47.75it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3018/5674 [05:07<00:55, 48.01it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3023/5674 [05:07<00:56, 46.81it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3028/5674 [05:07<00:58, 45.27it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3033/5674 [05:08<00:57, 45.99it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3038/5674 [05:08<01:11, 36.74it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3044/5674 [05:08<01:08, 38.36it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3050/5674 [05:08<01:02, 41.84it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3056/5674 [05:08<00:58, 45.10it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3062/5674 [05:08<00:55, 47.06it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3068/5674 [05:08<00:56, 46.35it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3074/5674 [05:08<00:54, 47.67it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3081/5674 [05:09<00:51, 50.47it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3087/5674 [05:09<00:52, 49.55it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3087/5674 [06:02<00:52, 49.55it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3089/5674 [06:02<2:20:58,  3.27s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3093/5674 [06:02<1:44:37,  2.43s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3099/5674 [06:02<1:07:25,  1.57s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3105/5674 [06:02<44:51,  1.05s/it]   55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3111/5674 [06:03<30:34,  1.40it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3116/5674 [06:03<22:18,  1.91it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3121/5674 [06:03<16:10,  2.63it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3126/5674 [06:03<11:49,  3.59it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3131/5674 [06:03<08:36,  4.93it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3139/5674 [06:03<05:25,  7.79it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3144/5674 [06:03<04:16,  9.87it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3149/5674 [06:03<03:22, 12.49it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3160/5674 [06:03<02:00, 20.94it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3167/5674 [06:04<01:37, 25.67it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3174/5674 [06:04<01:21, 30.50it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3181/5674 [06:04<01:09, 36.08it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3188/5674 [06:04<01:02, 39.88it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3197/5674 [06:04<00:50, 48.70it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3206/5674 [06:04<00:45, 54.43it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3213/5674 [06:04<00:50, 48.85it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3219/5674 [06:05<00:51, 47.83it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3229/5674 [06:05<00:42, 57.64it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3239/5674 [06:05<00:36, 67.20it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3247/5674 [06:05<00:35, 69.28it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3259/5674 [06:05<00:31, 76.87it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3268/5674 [06:05<00:38, 62.55it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3275/5674 [06:05<00:47, 50.86it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3287/5674 [06:06<00:39, 59.97it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3296/5674 [06:06<00:43, 54.98it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3303/5674 [06:06<00:41, 56.53it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3310/5674 [06:06<00:48, 49.12it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3316/5674 [06:06<00:46, 50.80it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3322/5674 [06:06<00:57, 41.16it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3329/5674 [06:07<00:53, 43.77it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3334/5674 [06:07<01:00, 38.42it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3339/5674 [06:07<01:10, 32.90it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3343/5674 [06:07<01:24, 27.72it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3348/5674 [06:07<01:15, 30.92it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3357/5674 [06:07<00:55, 42.10it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3366/5674 [06:07<00:46, 50.13it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3372/5674 [06:08<00:44, 51.65it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3383/5674 [06:08<00:34, 65.82it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3391/5674 [06:08<00:42, 54.28it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3398/5674 [06:08<00:53, 42.69it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3404/5674 [06:08<00:54, 41.66it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3409/5674 [06:08<00:52, 42.93it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3414/5674 [06:09<01:00, 37.51it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3419/5674 [06:09<00:59, 37.71it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3424/5674 [06:09<01:02, 36.11it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3428/5674 [06:09<01:08, 32.79it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3433/5674 [06:09<01:03, 35.43it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3438/5674 [06:09<01:02, 35.75it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3444/5674 [06:09<00:54, 41.20it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3449/5674 [06:10<00:57, 38.86it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3454/5674 [06:10<00:56, 39.41it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3461/5674 [06:10<00:58, 37.60it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3465/5674 [06:10<01:23, 26.42it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3478/5674 [06:10<00:49, 43.96it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3488/5674 [06:10<00:40, 53.45it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3495/5674 [06:11<00:38, 56.40it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3502/5674 [06:11<00:41, 52.58it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3508/5674 [06:11<00:44, 49.07it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3514/5674 [06:11<01:03, 34.14it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3520/5674 [06:11<00:59, 36.00it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3525/5674 [06:11<01:02, 34.20it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3532/5674 [06:12<00:53, 39.91it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3538/5674 [06:12<00:48, 43.84it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3551/5674 [06:12<00:34, 62.38it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3562/5674 [06:12<00:29, 70.91it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3571/5674 [06:12<00:28, 73.94it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3580/5674 [06:12<00:27, 76.85it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3589/5674 [06:12<00:31, 66.84it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3597/5674 [06:13<00:37, 54.93it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3604/5674 [06:13<00:35, 57.99it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3611/5674 [06:13<00:36, 57.02it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3622/5674 [06:13<00:29, 69.24it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3630/5674 [06:13<00:44, 46.06it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3636/5674 [06:13<00:48, 41.77it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3642/5674 [06:14<00:52, 38.40it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3647/5674 [06:14<01:02, 32.47it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3651/5674 [06:14<01:01, 32.78it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3658/5674 [06:14<00:50, 39.77it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3663/5674 [06:14<00:49, 40.35it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3671/5674 [06:14<00:43, 45.84it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3676/5674 [06:14<00:42, 46.51it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3682/5674 [06:14<00:40, 49.22it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3688/5674 [06:15<00:49, 39.90it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3694/5674 [06:15<00:44, 44.22it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3700/5674 [06:15<00:41, 47.92it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3706/5674 [06:15<00:41, 47.35it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3712/5674 [06:15<00:40, 48.28it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3718/5674 [06:15<00:40, 48.78it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3724/5674 [06:15<00:42, 45.74it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3730/5674 [06:16<00:52, 37.32it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3738/5674 [06:16<00:42, 45.40it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3744/5674 [06:16<00:43, 44.40it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3749/5674 [06:16<00:46, 41.49it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3749/5674 [07:20<00:46, 41.49it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3750/5674 [07:20<2:16:46,  4.27s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3764/5674 [07:20<58:17,  1.83s/it]   66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3772/5674 [07:20<39:43,  1.25s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3780/5674 [07:20<27:26,  1.15it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3789/5674 [07:20<18:20,  1.71it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3796/5674 [07:20<13:27,  2.33it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3803/5674 [07:20<09:50,  3.17it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3819/5674 [07:21<05:12,  5.94it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3832/5674 [07:21<03:25,  8.98it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3846/5674 [07:21<02:16, 13.41it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3857/5674 [07:21<01:42, 17.66it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3868/5674 [07:21<01:23, 21.66it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3877/5674 [07:21<01:07, 26.72it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3888/5674 [07:21<00:51, 34.68it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3898/5674 [07:21<00:46, 38.42it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3907/5674 [07:22<00:40, 43.47it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3916/5674 [07:22<00:36, 48.57it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3926/5674 [07:22<00:30, 56.91it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3935/5674 [07:22<00:35, 48.66it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3943/5674 [07:22<00:34, 50.86it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3950/5674 [07:22<00:40, 42.10it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3956/5674 [07:23<00:38, 44.55it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3962/5674 [07:23<00:45, 37.73it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3969/5674 [07:23<00:40, 42.21it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 3977/5674 [07:23<00:36, 46.75it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 3985/5674 [07:23<00:31, 53.10it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 3991/5674 [07:23<00:37, 45.13it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 3997/5674 [07:24<00:36, 46.28it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 4003/5674 [07:24<00:45, 37.00it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 4009/5674 [07:24<00:41, 40.02it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 4016/5674 [07:24<00:37, 44.81it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 4021/5674 [07:24<00:43, 38.39it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 4028/5674 [07:24<00:38, 43.26it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 4041/5674 [07:24<00:30, 53.77it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4054/5674 [07:25<00:23, 69.74it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4062/5674 [07:25<00:25, 63.68it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4071/5674 [07:25<00:23, 69.65it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4079/5674 [07:25<00:25, 63.43it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4087/5674 [07:25<00:23, 67.05it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4095/5674 [07:25<00:27, 56.43it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4102/5674 [07:25<00:29, 52.66it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4110/5674 [07:26<00:26, 58.55it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4118/5674 [07:26<00:24, 63.15it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4125/5674 [07:26<00:25, 60.28it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4135/5674 [07:26<00:22, 68.90it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4147/5674 [07:26<00:18, 80.50it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4156/5674 [07:26<00:20, 72.62it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4164/5674 [07:26<00:29, 51.50it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4171/5674 [07:27<00:33, 45.30it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4179/5674 [07:27<00:29, 51.15it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4185/5674 [07:27<00:29, 50.91it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4200/5674 [07:27<00:20, 71.22it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4209/5674 [07:27<00:19, 74.25it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4218/5674 [07:27<00:24, 60.23it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4225/5674 [07:27<00:26, 55.03it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4232/5674 [07:28<00:26, 53.41it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4238/5674 [07:28<00:28, 50.10it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4244/5674 [07:28<00:42, 33.45it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4251/5674 [07:28<00:36, 39.33it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4258/5674 [07:28<00:35, 40.19it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4263/5674 [07:29<00:36, 39.07it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4268/5674 [07:29<00:34, 41.08it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4274/5674 [07:29<00:33, 41.70it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4279/5674 [07:29<00:35, 39.27it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4287/5674 [07:29<00:29, 47.63it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4294/5674 [07:29<00:30, 45.39it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4301/5674 [07:29<00:27, 49.96it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4307/5674 [07:29<00:29, 46.13it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4314/5674 [07:30<00:29, 46.18it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4320/5674 [07:30<00:27, 48.60it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4327/5674 [07:30<00:26, 49.98it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4335/5674 [07:30<00:23, 57.03it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4346/5674 [07:30<00:20, 65.90it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4357/5674 [07:30<00:17, 73.67it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4372/5674 [07:30<00:14, 91.66it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4384/5674 [07:30<00:13, 94.67it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4394/5674 [07:31<00:14, 85.82it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4403/5674 [07:31<00:17, 74.25it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4411/5674 [07:31<00:22, 56.85it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4418/5674 [07:31<00:21, 57.67it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4425/5674 [07:31<00:21, 59.12it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4432/5674 [07:31<00:20, 61.35it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4444/5674 [07:31<00:16, 74.43it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4457/5674 [07:32<00:13, 87.03it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4467/5674 [07:32<00:14, 85.63it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4476/5674 [07:32<00:16, 73.06it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4487/5674 [07:32<00:14, 81.63it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4500/5674 [07:32<00:13, 87.02it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4516/5674 [07:32<00:10, 105.34it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4530/5674 [07:32<00:13, 87.88it/s]  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4554/5674 [07:32<00:09, 120.12it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4575/5674 [07:33<00:07, 141.40it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4591/5674 [07:33<00:07, 143.90it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4609/5674 [07:33<00:07, 151.80it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4626/5674 [07:33<00:07, 139.24it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4641/5674 [07:33<00:07, 137.36it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4664/5674 [07:33<00:06, 158.24it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4681/5674 [07:33<00:07, 126.64it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4695/5674 [07:34<00:12, 76.32it/s]  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4706/5674 [07:34<00:14, 67.19it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4715/5674 [07:34<00:13, 70.40it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4724/5674 [07:34<00:12, 73.89it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4733/5674 [07:34<00:14, 65.00it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4741/5674 [07:35<00:17, 52.69it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4756/5674 [07:35<00:13, 69.72it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4765/5674 [07:35<00:14, 61.66it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4778/5674 [07:35<00:13, 67.72it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4794/5674 [07:35<00:10, 86.06it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4805/5674 [07:35<00:10, 84.36it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4815/5674 [07:36<00:13, 63.93it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4829/5674 [07:36<00:11, 70.46it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4845/5674 [07:36<00:09, 87.39it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4859/5674 [07:36<00:08, 97.70it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4871/5674 [07:36<00:08, 89.99it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4886/5674 [07:36<00:07, 103.38it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 4898/5674 [07:36<00:07, 103.31it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 4913/5674 [07:36<00:06, 113.96it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 4929/5674 [07:37<00:05, 125.82it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 4950/5674 [07:37<00:05, 120.76it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 4963/5674 [07:37<00:06, 109.24it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 4975/5674 [07:37<00:06, 106.47it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 4975/5674 [08:56<00:06, 106.47it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 4976/5674 [08:56<26:48,  2.30s/it]  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 4982/5674 [08:56<21:19,  1.85s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 4992/5674 [08:56<14:18,  1.26s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 5008/5674 [08:56<08:04,  1.37it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 5023/5674 [08:57<05:04,  2.14it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5036/5674 [08:57<03:27,  3.07it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5048/5674 [08:57<02:26,  4.27it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5060/5674 [08:57<01:43,  5.94it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5072/5674 [08:57<01:13,  8.16it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5085/5674 [08:57<00:51, 11.52it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5096/5674 [08:58<00:40, 14.12it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5106/5674 [08:58<00:31, 18.15it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 5115/5674 [08:58<00:26, 21.41it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 5127/5674 [08:58<00:18, 29.01it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 5140/5674 [08:58<00:13, 39.08it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 5151/5674 [08:58<00:11, 46.94it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 5166/5674 [08:58<00:08, 61.76it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5178/5674 [08:58<00:06, 71.34it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5190/5674 [08:58<00:06, 79.85it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5202/5674 [08:59<00:05, 81.44it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5213/5674 [08:59<00:06, 74.69it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5223/5674 [08:59<00:06, 68.64it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5233/5674 [08:59<00:05, 74.71it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5244/5674 [08:59<00:05, 81.65it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5254/5674 [08:59<00:05, 75.05it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5263/5674 [08:59<00:05, 70.46it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5273/5674 [09:00<00:05, 70.05it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5289/5674 [09:00<00:04, 86.05it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5299/5674 [09:00<00:04, 86.13it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5308/5674 [09:00<00:04, 79.36it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5317/5674 [09:00<00:04, 80.43it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5327/5674 [09:00<00:04, 81.16it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5341/5674 [09:00<00:03, 95.45it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5356/5674 [09:00<00:02, 109.38it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5368/5674 [09:01<00:02, 112.22it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5380/5674 [09:01<00:02, 107.41it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5396/5674 [09:01<00:02, 118.31it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5409/5674 [09:01<00:02, 120.09it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5424/5674 [09:01<00:01, 127.26it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5437/5674 [09:01<00:01, 120.64it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5450/5674 [09:01<00:01, 120.36it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5463/5674 [09:01<00:01, 118.39it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5475/5674 [09:02<00:02, 99.00it/s]  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5488/5674 [09:02<00:01, 105.05it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5504/5674 [09:02<00:01, 119.04it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5522/5674 [09:02<00:01, 134.46it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5540/5674 [09:02<00:00, 144.23it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5565/5674 [09:02<00:00, 170.60it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5583/5674 [09:02<00:00, 133.01it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5598/5674 [09:02<00:00, 135.99it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5613/5674 [09:03<00:00, 91.11it/s]  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5637/5674 [09:03<00:00, 114.14it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5652/5674 [09:03<00:00, 79.22it/s] 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5664/5674 [09:04<00:00, 59.09it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5673/5674 [09:04<00:00, 54.82it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5674/5674 [09:04<00:00, 10.42it/s]
2025-12-10 13:48:04.152 | INFO     | __main__:main:278 - Starting Epoch 4/10
2025-12-10 13:48:04.244 | INFO     | __main__:main:294 - Processing 128 theorems with 16 workers.
2025-12-10 13:48:14.199 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: mul_le_mul_of_nonpos_right
2025-12-10 13:48:14.700 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: List.mem_diff_of_mem
2025-12-10 13:48:17.395 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Ordinal.opow_principal_add_of_principal_add
2025-12-10 13:48:19.035 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Matroid.Basis'.subset
2025-12-10 13:48:19.322 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-10 13:48:19.564 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: NonUnitalSubsemiring.coe_bot
2025-12-10 13:48:20.313 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-10 13:48:22.081 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Real.logb_div
2025-12-10 13:48:23.474 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-10 13:48:23.602 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Asymptotics.SuperpolynomialDecay.inv_param_mul
2025-12-10 13:48:24.060 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: ContinuousLinearMap.hasDerivAt_of_bilinear
2025-12-10 13:48:24.140 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Matrix.nonsing_inv_mul_cancel_right
2025-12-10 13:48:24.767 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Hyperreal.abs_lt_real_iff_infinitesimal
2025-12-10 13:48:25.399 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-10 13:48:26.362 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-10 13:48:26.675 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: PadicInt.norm_int_le_pow_iff_dvd
2025-12-10 13:48:27.569 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Polynomial.X_pow_mul_C
2025-12-10 13:48:29.073 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-10 13:48:30.801 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-10 13:48:31.548 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-10 13:48:31.773 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-10 13:48:32.022 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-10 13:48:32.953 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: CategoryTheory.Limits.IsColimit.OfNatIso.homOfCocone_cooneOfHom
2025-12-10 13:48:33.227 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-10 13:48:33.501 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-10 13:48:37.385 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-10 13:48:38.433 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: parallelogram_law_with_nnnorm
2025-12-10 13:48:39.321 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: IsIntegralClosure.mk'_mul
2025-12-10 13:48:43.111 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-10 13:48:43.918 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-10 13:48:47.342 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: simp (config := { unfoldPartialApp := true })
2025-12-10 13:48:47.420 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error='simp made no progress')
2025-12-10 13:48:47.420 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 32.72s.
2025-12-10 13:48:47.420 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error='simp made no progress')
2025-12-10 13:48:47.561 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-10 13:48:47.718 | WARNING  | lean_reinforcement.training.inference_server:_run_transformer_batch:149 - OOM encountered. Reducing max safe batch size to 24
2025-12-10 13:48:48.213 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: obtain ‚ü®d, rfl‚ü© := exists_add_of_le hc
2025-12-10 13:48:48.336 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="tactic 'subst' failed, invalid equality proof, it is not of the form (x = t) or (t = x)\n  0 = c + d\ncase intro\nŒ± : Type u\nŒ≤ : Type u_1\ninst‚úù¬≤ : OrderedSemiring Œ±\na b c d‚úù : Œ±\ninst‚úù¬π : ExistsAddOfLE Œ±\ninst‚úù : ContravariantClass Œ± Œ± (Function.swap fun x x_1 => x + x_1) fun x x_1 => x ‚â§ x_1\nh : b ‚â§ a\nhc : c ‚â§ 0\nd : Œ±\nh‚úù : 0 = c + d\n‚ä¢ a * c ‚â§ b * c")
2025-12-10 13:48:48.336 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 34.14s.
2025-12-10 13:48:48.336 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="tactic 'subst' failed, invalid equality proof, it is not of the form (x = t) or (t = x)\n  0 = c + d\ncase intro\nŒ± : Type u\nŒ≤ : Type u_1\ninst‚úù¬≤ : OrderedSemiring Œ±\na b c d‚úù : Œ±\ninst‚úù¬π : ExistsAddOfLE Œ±\ninst‚úù : ContravariantClass Œ± Œ± (Function.swap fun x x_1 => x + x_1) fun x x_1 => x ‚â§ x_1\nh : b ‚â§ a\nhc : c ‚â§ 0\nd : Œ±\nh‚úù : 0 = c + d\n‚ä¢ a * c ‚â§ b * c")
2025-12-10 13:48:48.478 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-10 13:48:55.021 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Orientation.two_zsmul_oangle_smul_left_of_ne_zero
2025-12-10 13:48:56.686 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Urysohns.CU.bddAbove_range_approx
2025-12-10 13:49:00.050 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-10 13:49:00.222 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Dioph.const_dioph
2025-12-10 13:49:01.127 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-10 13:49:05.159 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-10 13:50:51.788 | WARNING  | lean_reinforcement.training.inference_server:_run_transformer_batch:149 - OOM encountered. Reducing max safe batch size to 12
2025-12-10 13:52:29.433 | WARNING  | lean_reinforcement.training.inference_server:_run_transformer_batch:149 - OOM encountered. Reducing max safe batch size to 6
2025-12-10 13:54:04.631 | WARNING  | lean_reinforcement.training.inference_server:_run_transformer_batch:149 - OOM encountered. Reducing max safe batch size to 3
2025-12-10 13:55:41.242 | WARNING  | lean_reinforcement.training.inference_server:_run_transformer_batch:149 - OOM encountered. Reducing max safe batch size to 1
2025-12-10 13:58:53.053 | ERROR    | __main__:main:402 - Training crashed: OOM even with single sample! n=16
2025-12-10 13:58:53.053 | INFO     | __main__:main:405 - Shutting down workers...
Traceback (most recent call last):
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 136, in _run_transformer_batch
    return method(states, n=n, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/agent/transformer.py", line 149, in generate_tactics_with_probs_batch
    outputs = self.model.generate(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 2564, in generate
    result = decoding_method(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 3265, in _beam_search
    model_outputs = self(**model_inputs, return_dict=True)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 1764, in forward
    decoder_outputs = self.decoder(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 1100, in forward
    layer_outputs = layer_module(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 687, in forward
    self_attention_outputs = self.layer[0](
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 603, in forward
    attention_output = self.SelfAttention(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 521, in forward
    key_states, value_states = curr_past_key_value.update(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/cache_utils.py", line 776, in update
    keys, values = self.layers[layer_idx].update(key_states, value_states, cache_kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/cache_utils.py", line 120, in update
    self.values = torch.cat([self.values, value_states], dim=-2)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 482.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 452.75 MiB is free. Including non-PyTorch memory, this process has 39.04 GiB memory in use. Of the allocated memory 7.97 GiB is allocated by PyTorch, and 30.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 136, in _run_transformer_batch
    return method(states, n=n, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/agent/transformer.py", line 149, in generate_tactics_with_probs_batch
    outputs = self.model.generate(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 2564, in generate
    result = decoding_method(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 3265, in _beam_search
    model_outputs = self(**model_inputs, return_dict=True)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 1764, in forward
    decoder_outputs = self.decoder(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 1100, in forward
    layer_outputs = layer_module(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 687, in forward
    self_attention_outputs = self.layer[0](
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 603, in forward
    attention_output = self.SelfAttention(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 514, in forward
    value_states = self.v(current_states)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 768.00 KiB is free. Including non-PyTorch memory, this process has 39.48 GiB memory in use. Of the allocated memory 12.55 GiB is allocated by PyTorch, and 26.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 136, in _run_transformer_batch
    return method(states, n=n, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/agent/transformer.py", line 149, in generate_tactics_with_probs_batch
    outputs = self.model.generate(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    model_kwargs = self._prepare_encoder_decoder_kwargs_for_generation(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 861, in _prepare_encoder_decoder_kwargs_for_generation
    model_kwargs["encoder_outputs"]: ModelOutput = encoder(**encoder_kwargs)  # type: ignore
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 1100, in forward
    layer_outputs = layer_module(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 687, in forward
    self_attention_outputs = self.layer[0](
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 603, in forward
    attention_output = self.SelfAttention(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 542, in forward
    position_bias = self.compute_bias(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 464, in compute_bias
    values = self.relative_attention_bias(relative_position_bucket)  # shape (query_length, key_length, num_heads)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/sparse.py", line 192, in forward
    return F.embedding(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/functional.py", line 2546, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 768.00 KiB is free. Including non-PyTorch memory, this process has 39.48 GiB memory in use. Of the allocated memory 12.60 GiB is allocated by PyTorch, and 26.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 136, in _run_transformer_batch
    return method(states, n=n, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/agent/transformer.py", line 149, in generate_tactics_with_probs_batch
    outputs = self.model.generate(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    model_kwargs = self._prepare_encoder_decoder_kwargs_for_generation(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 861, in _prepare_encoder_decoder_kwargs_for_generation
    model_kwargs["encoder_outputs"]: ModelOutput = encoder(**encoder_kwargs)  # type: ignore
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 1100, in forward
    layer_outputs = layer_module(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 687, in forward
    self_attention_outputs = self.layer[0](
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 603, in forward
    attention_output = self.SelfAttention(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 492, in forward
    query_states = self.q(hidden_states)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 768.00 KiB is free. Including non-PyTorch memory, this process has 39.48 GiB memory in use. Of the allocated memory 12.60 GiB is allocated by PyTorch, and 26.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 136, in _run_transformer_batch
    return method(states, n=n, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/agent/transformer.py", line 149, in generate_tactics_with_probs_batch
    outputs = self.model.generate(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    model_kwargs = self._prepare_encoder_decoder_kwargs_for_generation(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 861, in _prepare_encoder_decoder_kwargs_for_generation
    model_kwargs["encoder_outputs"]: ModelOutput = encoder(**encoder_kwargs)  # type: ignore
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 1100, in forward
    layer_outputs = layer_module(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 687, in forward
    self_attention_outputs = self.layer[0](
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 603, in forward
    attention_output = self.SelfAttention(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 513, in forward
    key_states = self.k(current_states)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 768.00 KiB is free. Including non-PyTorch memory, this process has 39.48 GiB memory in use. Of the allocated memory 12.60 GiB is allocated by PyTorch, and 26.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 136, in _run_transformer_batch
    return method(states, n=n, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/agent/transformer.py", line 149, in generate_tactics_with_probs_batch
    outputs = self.model.generate(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    model_kwargs = self._prepare_encoder_decoder_kwargs_for_generation(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 861, in _prepare_encoder_decoder_kwargs_for_generation
    model_kwargs["encoder_outputs"]: ModelOutput = encoder(**encoder_kwargs)  # type: ignore
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 1003, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/sparse.py", line 192, in forward
    return F.embedding(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/functional.py", line 2546, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 768.00 KiB is free. Including non-PyTorch memory, this process has 39.48 GiB memory in use. Of the allocated memory 12.60 GiB is allocated by PyTorch, and 26.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 143, in _run_transformer_batch
    return method(states, n=n, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/agent/transformer.py", line 149, in generate_tactics_with_probs_batch
    outputs = self.model.generate(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    model_kwargs = self._prepare_encoder_decoder_kwargs_for_generation(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 861, in _prepare_encoder_decoder_kwargs_for_generation
    model_kwargs["encoder_outputs"]: ModelOutput = encoder(**encoder_kwargs)  # type: ignore
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 1003, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/sparse.py", line 192, in forward
    return F.embedding(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/functional.py", line 2546, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 768.00 KiB is free. Including non-PyTorch memory, this process has 39.48 GiB memory in use. Of the allocated memory 12.60 GiB is allocated by PyTorch, and 26.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/train.py", line 414, in <module>
    main(args)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/train.py", line 403, in main
    raise e
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/train.py", line 303, in main
    processed_batch = inference_server.process_requests()
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 54, in process_requests
    self._process_batch(batch_requests)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 126, in _process_batch
    self._execute_batch(current_type, current_batch, current_indices)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 212, in _execute_batch
    all_results = self._run_transformer_batch(
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 158, in _run_transformer_batch
    right = self._run_transformer_batch(method, states[mid:], n, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 157, in _run_transformer_batch
    left = self._run_transformer_batch(method, states[:mid], n, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 157, in _run_transformer_batch
    left = self._run_transformer_batch(method, states[:mid], n, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 157, in _run_transformer_batch
    left = self._run_transformer_batch(method, states[:mid], n, **kwargs)
  [Previous line repeated 1 more time]
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 145, in _run_transformer_batch
    raise RuntimeError(f"OOM even with single sample! n={n}")
RuntimeError: OOM even with single sample! n=16
Traceback (most recent call last):
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 136, in _run_transformer_batch
    return method(states, n=n, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/agent/transformer.py", line 149, in generate_tactics_with_probs_batch
    outputs = self.model.generate(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 2564, in generate
    result = decoding_method(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 3265, in _beam_search
    model_outputs = self(**model_inputs, return_dict=True)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 1764, in forward
    decoder_outputs = self.decoder(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 1100, in forward
    layer_outputs = layer_module(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 687, in forward
    self_attention_outputs = self.layer[0](
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 603, in forward
    attention_output = self.SelfAttention(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 521, in forward
    key_states, value_states = curr_past_key_value.update(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/cache_utils.py", line 776, in update
    keys, values = self.layers[layer_idx].update(key_states, value_states, cache_kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/cache_utils.py", line 120, in update
    self.values = torch.cat([self.values, value_states], dim=-2)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 482.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 452.75 MiB is free. Including non-PyTorch memory, this process has 39.04 GiB memory in use. Of the allocated memory 7.97 GiB is allocated by PyTorch, and 30.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 136, in _run_transformer_batch
    return method(states, n=n, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/agent/transformer.py", line 149, in generate_tactics_with_probs_batch
    outputs = self.model.generate(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 2564, in generate
    result = decoding_method(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 3265, in _beam_search
    model_outputs = self(**model_inputs, return_dict=True)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 1764, in forward
    decoder_outputs = self.decoder(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 1100, in forward
    layer_outputs = layer_module(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 687, in forward
    self_attention_outputs = self.layer[0](
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 603, in forward
    attention_output = self.SelfAttention(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 514, in forward
    value_states = self.v(current_states)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 768.00 KiB is free. Including non-PyTorch memory, this process has 39.48 GiB memory in use. Of the allocated memory 12.55 GiB is allocated by PyTorch, and 26.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 136, in _run_transformer_batch
    return method(states, n=n, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/agent/transformer.py", line 149, in generate_tactics_with_probs_batch
    outputs = self.model.generate(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    model_kwargs = self._prepare_encoder_decoder_kwargs_for_generation(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 861, in _prepare_encoder_decoder_kwargs_for_generation
    model_kwargs["encoder_outputs"]: ModelOutput = encoder(**encoder_kwargs)  # type: ignore
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 1100, in forward
    layer_outputs = layer_module(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 687, in forward
    self_attention_outputs = self.layer[0](
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 603, in forward
    attention_output = self.SelfAttention(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 542, in forward
    position_bias = self.compute_bias(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 464, in compute_bias
    values = self.relative_attention_bias(relative_position_bucket)  # shape (query_length, key_length, num_heads)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/sparse.py", line 192, in forward
    return F.embedding(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/functional.py", line 2546, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 768.00 KiB is free. Including non-PyTorch memory, this process has 39.48 GiB memory in use. Of the allocated memory 12.60 GiB is allocated by PyTorch, and 26.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 136, in _run_transformer_batch
    return method(states, n=n, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/agent/transformer.py", line 149, in generate_tactics_with_probs_batch
    outputs = self.model.generate(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    model_kwargs = self._prepare_encoder_decoder_kwargs_for_generation(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 861, in _prepare_encoder_decoder_kwargs_for_generation
    model_kwargs["encoder_outputs"]: ModelOutput = encoder(**encoder_kwargs)  # type: ignore
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 1100, in forward
    layer_outputs = layer_module(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 687, in forward
    self_attention_outputs = self.layer[0](
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 603, in forward
    attention_output = self.SelfAttention(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 492, in forward
    query_states = self.q(hidden_states)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 768.00 KiB is free. Including non-PyTorch memory, this process has 39.48 GiB memory in use. Of the allocated memory 12.60 GiB is allocated by PyTorch, and 26.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 136, in _run_transformer_batch
    return method(states, n=n, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/agent/transformer.py", line 149, in generate_tactics_with_probs_batch
    outputs = self.model.generate(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    model_kwargs = self._prepare_encoder_decoder_kwargs_for_generation(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 861, in _prepare_encoder_decoder_kwargs_for_generation
    model_kwargs["encoder_outputs"]: ModelOutput = encoder(**encoder_kwargs)  # type: ignore
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 1100, in forward
    layer_outputs = layer_module(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 687, in forward
    self_attention_outputs = self.layer[0](
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 603, in forward
    attention_output = self.SelfAttention(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 513, in forward
    key_states = self.k(current_states)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 768.00 KiB is free. Including non-PyTorch memory, this process has 39.48 GiB memory in use. Of the allocated memory 12.60 GiB is allocated by PyTorch, and 26.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 136, in _run_transformer_batch
    return method(states, n=n, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/agent/transformer.py", line 149, in generate_tactics_with_probs_batch
    outputs = self.model.generate(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    model_kwargs = self._prepare_encoder_decoder_kwargs_for_generation(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 861, in _prepare_encoder_decoder_kwargs_for_generation
    model_kwargs["encoder_outputs"]: ModelOutput = encoder(**encoder_kwargs)  # type: ignore
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 1003, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/sparse.py", line 192, in forward
    return F.embedding(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/functional.py", line 2546, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 768.00 KiB is free. Including non-PyTorch memory, this process has 39.48 GiB memory in use. Of the allocated memory 12.60 GiB is allocated by PyTorch, and 26.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 143, in _run_transformer_batch
    return method(states, n=n, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/agent/transformer.py", line 149, in generate_tactics_with_probs_batch
    outputs = self.model.generate(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 2465, in generate
    model_kwargs = self._prepare_encoder_decoder_kwargs_for_generation(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 861, in _prepare_encoder_decoder_kwargs_for_generation
    model_kwargs["encoder_outputs"]: ModelOutput = encoder(**encoder_kwargs)  # type: ignore
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 1003, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/sparse.py", line 192, in forward
    return F.embedding(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/functional.py", line 2546, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 768.00 KiB is free. Including non-PyTorch memory, this process has 39.48 GiB memory in use. Of the allocated memory 12.60 GiB is allocated by PyTorch, and 26.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/train.py", line 414, in <module>
    main(args)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/train.py", line 403, in main
    raise e
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/train.py", line 303, in main
    processed_batch = inference_server.process_requests()
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 54, in process_requests
    self._process_batch(batch_requests)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 126, in _process_batch
    self._execute_batch(current_type, current_batch, current_indices)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 212, in _execute_batch
    all_results = self._run_transformer_batch(
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 158, in _run_transformer_batch
    right = self._run_transformer_batch(method, states[mid:], n, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 157, in _run_transformer_batch
    left = self._run_transformer_batch(method, states[:mid], n, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 157, in _run_transformer_batch
    left = self._run_transformer_batch(method, states[:mid], n, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 157, in _run_transformer_batch
    left = self._run_transformer_batch(method, states[:mid], n, **kwargs)
  [Previous line repeated 1 more time]
  File "/gpfs/home1/gkoopman/lean_reinforcement/lean_reinforcement/training/inference_server.py", line 145, in _run_transformer_batch
    raise RuntimeError(f"OOM even with single sample! n={n}")
RuntimeError: OOM even with single sample! n=16
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mefficient-waterfall-26[0m at: [34mhttps://wandb.ai/gerbennkoopman-university-of-amsterdam/lean-reinforcement/runs/ry9k60r1[0m
[1;34mwandb[0m: Find logs at: [1;35m../../../gpfs/home1/gkoopman/lean_reinforcement/wandb/run-20251210_132612-ry9k60r1/logs[0m
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
[2025-12-10T16:23:54.279] error: *** JOB 17422202 ON gcn30 CANCELLED AT 2025-12-10T16:23:54 DUE to SIGNAL Terminated ***
[2025-12-10T16:23:54.280] error: *** STEP 17422202.0 ON gcn30 CANCELLED AT 2025-12-10T16:23:54 DUE to SIGNAL Terminated ***
