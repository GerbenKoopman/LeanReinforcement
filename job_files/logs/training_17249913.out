============================================================================================== 
Warning! Mixing Conda and module environments may lead to corruption of the
user environment. 
We do not recommend users mixing those two environments unless absolutely
necessary. Note that 
SURF does not provide any support for Conda environment.
For more information, please refer to our software policy page:
https://servicedesk.surf.nl/wiki/display/WIKI/Software+policy+Snellius#SoftwarepolicySnellius-UseofAnacondaandMinicondaenvironmentsonSnellius 

Remember that many packages have already been installed on the system and can
be loaded using 
the 'module load <package__name>' command. If you are uncertain if a package is
already available 
on the system, please use 'module avail' or 'module spider' to search for it.
============================================================================================== 
Starting training run with distributed environment...
wandb: Currently logged in as: gerbennkoopman to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: setting up run 4su8gy0s
wandb: Tracking run with wandb version 0.22.3
wandb: Run data is saved locally in /gpfs/home1/gkoopman/lean_reinforcement/wandb/run-20251205_170157-4su8gy0s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-dew-23
wandb: ‚≠êÔ∏è View project at https://wandb.ai/gerbennkoopman-university-of-amsterdam/lean-reinforcement
wandb: üöÄ View run at https://wandb.ai/gerbennkoopman-university-of-amsterdam/lean-reinforcement/runs/4su8gy0s
2025-12-05 17:01:58.399 | INFO     | __main__:main:160 - Using checkpoint directory: /gpfs/scratch1/shared/lean-reinforcement/checkpoints
2025-12-05 17:02:01.361 | INFO     | src.agent.value_head:load_checkpoint:192 - Checkpoint loaded from /gpfs/scratch1/shared/lean-reinforcement/checkpoints/value_head_latest.pth
2025-12-05 17:02:01.361 | INFO     | __main__:main:173 - Resuming training from epoch 3
2025-12-05 17:02:01.362 | INFO     | __main__:log_gpu_memory:144 - After model initialization - GPU Memory: 1.12GB allocated, 1.23GB reserved
2025-12-05 17:02:01.362 | INFO     | __main__:main:178 - Loading data from 'leandojo_benchmark_4/novel_premises'
2025-12-05 17:02:01.362 | INFO     | ReProver.common:__init__:201 - Building the corpus from leandojo_benchmark_4/corpus.jsonl
2025-12-05 17:02:49.533 | INFO     | lean_dojo.data_extraction.trace:trace:248 - Loading the traced repo from /gpfs/scratch1/shared/lean-reinforcement/datasets/lean_dojo_cache/leanprover-community-mathlib4-29dcec074de168ac2bf835a77ef68bbe069194c5/mathlib4
2025-12-05 17:03:02,539	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
  0%|          | 0/5674 [00:00<?, ?it/s]  0%|          | 1/5674 [00:06<9:53:07,  6.27s/it]  0%|          | 9/5674 [00:06<49:07,  1.92it/s]    0%|          | 13/5674 [00:06<31:00,  3.04it/s]  0%|          | 17/5674 [00:06<21:04,  4.47it/s]  0%|          | 22/5674 [00:06<13:48,  6.82it/s]  0%|          | 27/5674 [00:11<40:37,  2.32it/s]  1%|          | 33/5674 [00:11<25:51,  3.64it/s]  1%|          | 38/5674 [00:11<18:38,  5.04it/s]  1%|          | 43/5674 [00:11<13:28,  6.96it/s]  1%|          | 51/5674 [00:12<08:26, 11.11it/s]  1%|          | 56/5674 [00:12<06:40, 14.04it/s]  1%|          | 61/5674 [00:17<32:55,  2.84it/s]  1%|          | 66/5674 [00:17<24:27,  3.82it/s]  1%|          | 70/5674 [00:17<19:37,  4.76it/s]  1%|‚ñè         | 77/5674 [00:18<12:42,  7.34it/s]  1%|‚ñè         | 81/5674 [00:18<10:22,  8.99it/s]  2%|‚ñè         | 87/5674 [00:18<07:26, 12.52it/s]  2%|‚ñè         | 92/5674 [00:18<06:00, 15.48it/s]  2%|‚ñè         | 97/5674 [00:24<36:03,  2.58it/s]  2%|‚ñè         | 100/5674 [00:24<29:49,  3.11it/s]  2%|‚ñè         | 103/5674 [00:24<24:02,  3.86it/s]  2%|‚ñè         | 106/5674 [00:24<19:31,  4.75it/s]  2%|‚ñè         | 109/5674 [00:24<16:02,  5.78it/s]  2%|‚ñè         | 112/5674 [00:25<13:42,  6.77it/s]  2%|‚ñè         | 115/5674 [00:25<10:59,  8.43it/s]  2%|‚ñè         | 118/5674 [00:32<1:07:19,  1.38it/s]  2%|‚ñè         | 120/5674 [00:32<54:13,  1.71it/s]    2%|‚ñè         | 124/5674 [00:32<35:29,  2.61it/s]  2%|‚ñè         | 126/5674 [00:32<29:19,  3.15it/s]  2%|‚ñè         | 130/5674 [00:32<19:42,  4.69it/s]  2%|‚ñè         | 135/5674 [00:32<12:35,  7.34it/s]  2%|‚ñè         | 138/5674 [00:32<10:16,  8.98it/s]  3%|‚ñé         | 143/5674 [00:33<07:46, 11.86it/s]  3%|‚ñé         | 147/5674 [00:33<06:20, 14.54it/s]  3%|‚ñé         | 151/5674 [00:40<57:32,  1.60it/s]  3%|‚ñé         | 156/5674 [00:41<38:00,  2.42it/s]  3%|‚ñé         | 159/5674 [00:41<30:16,  3.04it/s]  3%|‚ñé         | 163/5674 [00:41<22:27,  4.09it/s]  3%|‚ñé         | 167/5674 [00:41<16:42,  5.49it/s]  3%|‚ñé         | 175/5674 [00:41<09:44,  9.40it/s]  3%|‚ñé         | 179/5674 [00:41<08:04, 11.34it/s]  3%|‚ñé         | 183/5674 [00:41<06:43, 13.60it/s]  3%|‚ñé         | 188/5674 [00:42<05:15, 17.41it/s]  3%|‚ñé         | 192/5674 [00:42<04:37, 19.76it/s]  3%|‚ñé         | 196/5674 [00:42<04:11, 21.79it/s]  4%|‚ñé         | 201/5674 [00:42<03:48, 23.96it/s]  4%|‚ñé         | 208/5674 [00:51<46:54,  1.94it/s]  4%|‚ñç         | 213/5674 [00:51<33:51,  2.69it/s]  4%|‚ñç         | 231/5674 [00:51<13:58,  6.49it/s]  4%|‚ñç         | 239/5674 [00:51<10:26,  8.67it/s]  4%|‚ñç         | 246/5674 [00:51<08:30, 10.63it/s]  4%|‚ñç         | 252/5674 [00:51<06:59, 12.93it/s]  5%|‚ñç         | 259/5674 [00:51<05:23, 16.72it/s]  5%|‚ñç         | 265/5674 [00:52<05:00, 18.02it/s]  5%|‚ñç         | 270/5674 [00:52<04:27, 20.21it/s]  5%|‚ñç         | 276/5674 [00:52<03:38, 24.74it/s]  5%|‚ñç         | 281/5674 [00:52<03:11, 28.21it/s]  5%|‚ñå         | 288/5674 [00:52<02:43, 32.99it/s]  5%|‚ñå         | 293/5674 [00:52<02:37, 34.14it/s]  5%|‚ñå         | 298/5674 [00:52<02:38, 33.85it/s]  5%|‚ñå         | 304/5674 [00:53<02:17, 38.93it/s]  5%|‚ñå         | 309/5674 [01:03<49:59,  1.79it/s]  6%|‚ñå         | 315/5674 [01:03<34:31,  2.59it/s]  6%|‚ñå         | 320/5674 [01:03<25:32,  3.49it/s]  6%|‚ñå         | 325/5674 [01:03<18:54,  4.72it/s]  6%|‚ñå         | 332/5674 [01:03<12:46,  6.97it/s]  6%|‚ñå         | 340/5674 [01:03<08:40, 10.26it/s]  6%|‚ñå         | 347/5674 [01:03<06:26, 13.79it/s]  6%|‚ñå         | 353/5674 [01:03<05:04, 17.47it/s]  6%|‚ñã         | 363/5674 [01:03<03:25, 25.85it/s]  7%|‚ñã         | 374/5674 [01:04<02:25, 36.34it/s]  7%|‚ñã         | 382/5674 [01:04<02:10, 40.65it/s]  7%|‚ñã         | 390/5674 [01:04<01:53, 46.62it/s]  7%|‚ñã         | 399/5674 [01:04<01:43, 51.11it/s]  7%|‚ñã         | 414/5674 [01:04<01:16, 68.40it/s]  8%|‚ñä         | 436/5674 [01:04<00:51, 101.44it/s]  8%|‚ñä         | 456/5674 [01:04<00:43, 119.17it/s]  8%|‚ñä         | 470/5674 [01:05<00:49, 105.33it/s]  9%|‚ñä         | 483/5674 [01:05<00:56, 91.77it/s]   9%|‚ñä         | 494/5674 [01:05<01:04, 80.23it/s]  9%|‚ñä         | 494/5674 [01:17<01:04, 80.23it/s]  9%|‚ñä         | 495/5674 [01:17<32:43,  2.64it/s]  9%|‚ñâ         | 498/5674 [01:17<29:16,  2.95it/s]  9%|‚ñâ         | 506/5674 [01:17<21:05,  4.09it/s]  9%|‚ñâ         | 512/5674 [01:17<16:34,  5.19it/s]  9%|‚ñâ         | 518/5674 [01:18<13:14,  6.49it/s]  9%|‚ñâ         | 523/5674 [01:18<10:29,  8.18it/s]  9%|‚ñâ         | 532/5674 [01:18<06:51, 12.48it/s] 10%|‚ñâ         | 541/5674 [01:18<04:47, 17.88it/s] 10%|‚ñâ         | 548/5674 [01:18<03:55, 21.80it/s] 10%|‚ñâ         | 559/5674 [01:18<02:43, 31.28it/s] 10%|‚ñâ         | 567/5674 [01:18<02:24, 35.44it/s] 10%|‚ñà         | 574/5674 [01:18<02:07, 40.15it/s] 10%|‚ñà         | 581/5674 [01:19<01:54, 44.30it/s] 10%|‚ñà         | 594/5674 [01:19<01:23, 60.69it/s] 11%|‚ñà         | 603/5674 [01:19<01:38, 51.41it/s] 11%|‚ñà         | 610/5674 [01:19<01:47, 47.31it/s] 11%|‚ñà         | 616/5674 [01:19<02:08, 39.32it/s] 11%|‚ñà         | 626/5674 [01:19<01:41, 49.77it/s] 11%|‚ñà         | 633/5674 [01:20<01:34, 53.27it/s] 11%|‚ñà‚ñè        | 640/5674 [01:20<01:32, 54.60it/s] 11%|‚ñà‚ñè        | 647/5674 [01:20<01:33, 54.00it/s] 11%|‚ñà‚ñè        | 647/5674 [01:34<01:33, 54.00it/s] 11%|‚ñà‚ñè        | 648/5674 [01:34<1:04:42,  1.29it/s] 12%|‚ñà‚ñè        | 653/5674 [01:34<47:08,  1.78it/s]   12%|‚ñà‚ñè        | 659/5674 [01:34<32:26,  2.58it/s] 12%|‚ñà‚ñè        | 665/5674 [01:34<22:48,  3.66it/s] 12%|‚ñà‚ñè        | 673/5674 [01:34<14:37,  5.70it/s] 12%|‚ñà‚ñè        | 679/5674 [01:34<10:54,  7.63it/s] 12%|‚ñà‚ñè        | 688/5674 [01:34<07:10, 11.58it/s] 12%|‚ñà‚ñè        | 695/5674 [01:35<05:23, 15.37it/s] 12%|‚ñà‚ñè        | 707/5674 [01:35<03:26, 24.08it/s] 13%|‚ñà‚ñé        | 715/5674 [01:35<02:49, 29.28it/s] 13%|‚ñà‚ñé        | 723/5674 [01:35<02:29, 33.02it/s] 13%|‚ñà‚ñé        | 730/5674 [01:35<02:23, 34.51it/s] 13%|‚ñà‚ñé        | 736/5674 [01:35<02:27, 33.54it/s] 13%|‚ñà‚ñé        | 742/5674 [01:36<02:16, 36.17it/s] 13%|‚ñà‚ñé        | 747/5674 [01:36<02:22, 34.46it/s] 13%|‚ñà‚ñé        | 753/5674 [01:36<02:10, 37.79it/s] 13%|‚ñà‚ñé        | 760/5674 [01:36<01:50, 44.29it/s] 14%|‚ñà‚ñé        | 766/5674 [01:36<01:46, 46.26it/s] 14%|‚ñà‚ñé        | 772/5674 [01:36<02:06, 38.87it/s] 14%|‚ñà‚ñé        | 778/5674 [01:36<01:56, 42.00it/s] 14%|‚ñà‚ñç        | 784/5674 [01:36<01:59, 40.91it/s] 14%|‚ñà‚ñç        | 791/5674 [01:37<01:44, 46.55it/s] 14%|‚ñà‚ñç        | 797/5674 [01:37<02:03, 39.35it/s] 14%|‚ñà‚ñç        | 802/5674 [01:37<02:09, 37.74it/s] 14%|‚ñà‚ñç        | 807/5674 [01:37<02:28, 32.73it/s] 14%|‚ñà‚ñç        | 813/5674 [01:37<02:11, 37.00it/s] 14%|‚ñà‚ñç        | 819/5674 [01:37<02:02, 39.74it/s] 14%|‚ñà‚ñç        | 819/5674 [01:54<02:02, 39.74it/s] 14%|‚ñà‚ñç        | 821/5674 [01:54<1:28:15,  1.09s/it] 15%|‚ñà‚ñç        | 823/5674 [01:54<1:15:15,  1.07it/s] 15%|‚ñà‚ñç        | 827/5674 [01:54<52:53,  1.53it/s]   15%|‚ñà‚ñç        | 831/5674 [01:54<37:45,  2.14it/s] 15%|‚ñà‚ñç        | 835/5674 [01:55<27:02,  2.98it/s] 15%|‚ñà‚ñç        | 840/5674 [01:55<18:13,  4.42it/s] 15%|‚ñà‚ñç        | 845/5674 [01:55<12:42,  6.33it/s] 15%|‚ñà‚ñç        | 851/5674 [01:55<08:38,  9.30it/s] 15%|‚ñà‚ñå        | 856/5674 [01:55<06:55, 11.59it/s] 15%|‚ñà‚ñå        | 860/5674 [01:55<05:49, 13.78it/s] 15%|‚ñà‚ñå        | 866/5674 [01:55<04:15, 18.80it/s] 15%|‚ñà‚ñå        | 873/5674 [01:55<03:11, 25.07it/s] 15%|‚ñà‚ñå        | 879/5674 [01:56<02:49, 28.30it/s] 16%|‚ñà‚ñå        | 884/5674 [01:56<02:43, 29.24it/s] 16%|‚ñà‚ñå        | 889/5674 [01:56<02:33, 31.09it/s] 16%|‚ñà‚ñå        | 894/5674 [01:56<02:23, 33.32it/s] 16%|‚ñà‚ñå        | 899/5674 [01:56<02:19, 34.12it/s] 16%|‚ñà‚ñå        | 909/5674 [01:56<01:38, 48.15it/s] 16%|‚ñà‚ñå        | 915/5674 [01:56<01:39, 47.76it/s] 16%|‚ñà‚ñå        | 921/5674 [01:57<01:36, 49.02it/s] 16%|‚ñà‚ñã        | 929/5674 [01:57<01:24, 56.19it/s] 16%|‚ñà‚ñã        | 936/5674 [01:57<01:28, 53.52it/s] 17%|‚ñà‚ñã        | 943/5674 [01:57<01:33, 50.45it/s] 17%|‚ñà‚ñã        | 949/5674 [01:57<02:03, 38.22it/s] 17%|‚ñà‚ñã        | 955/5674 [01:57<01:53, 41.67it/s] 17%|‚ñà‚ñã        | 960/5674 [01:57<01:50, 42.65it/s] 17%|‚ñà‚ñã        | 966/5674 [01:58<01:45, 44.76it/s] 17%|‚ñà‚ñã        | 971/5674 [01:58<01:47, 43.93it/s] 17%|‚ñà‚ñã        | 976/5674 [01:58<02:19, 33.79it/s] 17%|‚ñà‚ñã        | 980/5674 [01:58<02:20, 33.42it/s] 17%|‚ñà‚ñã        | 988/5674 [01:58<02:12, 35.41it/s] 17%|‚ñà‚ñã        | 992/5674 [01:58<02:11, 35.72it/s] 18%|‚ñà‚ñä        | 999/5674 [01:58<01:48, 43.19it/s] 18%|‚ñà‚ñä        | 999/5674 [02:18<01:48, 43.19it/s] 18%|‚ñà‚ñä        | 1005/5674 [02:18<1:20:05,  1.03s/it] 18%|‚ñà‚ñä        | 1009/5674 [02:18<1:02:29,  1.24it/s] 18%|‚ñà‚ñä        | 1014/5674 [02:19<45:00,  1.73it/s]   18%|‚ñà‚ñä        | 1019/5674 [02:19<32:58,  2.35it/s] 18%|‚ñà‚ñä        | 1023/5674 [02:19<25:31,  3.04it/s] 18%|‚ñà‚ñä        | 1027/5674 [02:19<19:54,  3.89it/s] 18%|‚ñà‚ñä        | 1033/5674 [02:19<13:13,  5.85it/s] 18%|‚ñà‚ñä        | 1040/5674 [02:19<08:47,  8.79it/s] 18%|‚ñà‚ñä        | 1047/5674 [02:20<06:24, 12.05it/s] 19%|‚ñà‚ñä        | 1053/5674 [02:20<04:59, 15.44it/s] 19%|‚ñà‚ñä        | 1058/5674 [02:20<04:08, 18.56it/s] 19%|‚ñà‚ñâ        | 1067/5674 [02:20<02:53, 26.55it/s] 19%|‚ñà‚ñâ        | 1074/5674 [02:20<02:47, 27.41it/s] 19%|‚ñà‚ñâ        | 1079/5674 [02:20<02:31, 30.23it/s] 19%|‚ñà‚ñâ        | 1084/5674 [02:20<02:19, 32.97it/s] 19%|‚ñà‚ñâ        | 1089/5674 [02:21<02:15, 33.80it/s] 19%|‚ñà‚ñâ        | 1094/5674 [02:21<02:03, 37.09it/s] 19%|‚ñà‚ñâ        | 1101/5674 [02:21<01:43, 44.16it/s] 20%|‚ñà‚ñâ        | 1107/5674 [02:21<01:36, 47.32it/s] 20%|‚ñà‚ñâ        | 1115/5674 [02:21<01:23, 54.82it/s] 20%|‚ñà‚ñâ        | 1121/5674 [02:21<01:31, 49.82it/s] 20%|‚ñà‚ñâ        | 1133/5674 [02:21<01:10, 63.96it/s] 20%|‚ñà‚ñà        | 1140/5674 [02:21<01:22, 54.71it/s] 20%|‚ñà‚ñà        | 1151/5674 [02:22<01:12, 62.26it/s] 21%|‚ñà‚ñà        | 1164/5674 [02:22<00:57, 77.83it/s] 21%|‚ñà‚ñà        | 1173/5674 [02:22<00:57, 77.87it/s] 21%|‚ñà‚ñà        | 1183/5674 [02:22<00:56, 79.33it/s] 21%|‚ñà‚ñà        | 1198/5674 [02:22<00:46, 97.05it/s] 21%|‚ñà‚ñà‚ñè       | 1216/5674 [02:22<00:39, 114.08it/s] 22%|‚ñà‚ñà‚ñè       | 1236/5674 [02:22<00:32, 136.92it/s] 22%|‚ñà‚ñà‚ñè       | 1251/5674 [02:22<00:34, 127.59it/s] 22%|‚ñà‚ñà‚ñè       | 1268/5674 [02:22<00:33, 129.63it/s] 23%|‚ñà‚ñà‚ñé       | 1282/5674 [02:23<00:36, 119.37it/s] 23%|‚ñà‚ñà‚ñé       | 1297/5674 [02:23<00:34, 126.66it/s] 23%|‚ñà‚ñà‚ñé       | 1314/5674 [02:23<00:33, 130.47it/s] 23%|‚ñà‚ñà‚ñé       | 1328/5674 [02:23<00:39, 111.40it/s] 24%|‚ñà‚ñà‚ñé       | 1341/5674 [02:23<00:37, 115.40it/s] 24%|‚ñà‚ñà‚ñç       | 1354/5674 [02:23<00:38, 112.49it/s] 24%|‚ñà‚ñà‚ñç       | 1366/5674 [02:23<00:42, 102.14it/s] 24%|‚ñà‚ñà‚ñç       | 1377/5674 [02:24<00:57, 74.33it/s]  24%|‚ñà‚ñà‚ñç       | 1386/5674 [02:24<00:59, 72.45it/s] 24%|‚ñà‚ñà‚ñç       | 1386/5674 [02:47<00:59, 72.45it/s] 25%|‚ñà‚ñà‚ñç       | 1391/5674 [02:47<53:29,  1.33it/s] 25%|‚ñà‚ñà‚ñç       | 1394/5674 [02:48<47:26,  1.50it/s] 25%|‚ñà‚ñà‚ñç       | 1401/5674 [02:48<34:53,  2.04it/s] 25%|‚ñà‚ñà‚ñç       | 1407/5674 [02:48<26:33,  2.68it/s] 25%|‚ñà‚ñà‚ñç       | 1412/5674 [02:48<20:52,  3.40it/s] 25%|‚ñà‚ñà‚ñç       | 1418/5674 [02:48<15:13,  4.66it/s] 25%|‚ñà‚ñà‚ñå       | 1427/5674 [02:48<09:45,  7.25it/s] 25%|‚ñà‚ñà‚ñå       | 1433/5674 [02:49<07:32,  9.38it/s] 25%|‚ñà‚ñà‚ñå       | 1439/5674 [02:49<05:57, 11.86it/s] 26%|‚ñà‚ñà‚ñå       | 1448/5674 [02:49<04:03, 17.33it/s] 26%|‚ñà‚ñà‚ñå       | 1456/5674 [02:49<03:02, 23.06it/s] 26%|‚ñà‚ñà‚ñå       | 1463/5674 [02:49<03:06, 22.53it/s] 26%|‚ñà‚ñà‚ñå       | 1469/5674 [02:49<02:46, 25.21it/s] 26%|‚ñà‚ñà‚ñå       | 1476/5674 [02:50<02:30, 27.84it/s] 26%|‚ñà‚ñà‚ñå       | 1485/5674 [02:50<01:55, 36.17it/s] 26%|‚ñà‚ñà‚ñã       | 1491/5674 [02:50<01:48, 38.49it/s] 26%|‚ñà‚ñà‚ñã       | 1497/5674 [02:50<02:30, 27.82it/s] 26%|‚ñà‚ñà‚ñã       | 1503/5674 [02:50<02:10, 32.08it/s] 27%|‚ñà‚ñà‚ñã       | 1508/5674 [02:50<01:58, 35.18it/s] 27%|‚ñà‚ñà‚ñã       | 1513/5674 [02:51<02:10, 31.88it/s] 27%|‚ñà‚ñà‚ñã       | 1518/5674 [02:51<02:01, 34.31it/s] 27%|‚ñà‚ñà‚ñã       | 1526/5674 [02:51<01:34, 43.87it/s] 27%|‚ñà‚ñà‚ñã       | 1532/5674 [02:51<01:37, 42.38it/s] 27%|‚ñà‚ñà‚ñã       | 1539/5674 [02:51<01:32, 44.47it/s] 27%|‚ñà‚ñà‚ñã       | 1544/5674 [02:51<01:32, 44.67it/s] 27%|‚ñà‚ñà‚ñã       | 1549/5674 [02:51<01:39, 41.62it/s] 27%|‚ñà‚ñà‚ñã       | 1554/5674 [02:52<01:35, 43.12it/s] 27%|‚ñà‚ñà‚ñã       | 1559/5674 [02:52<01:48, 37.76it/s] 28%|‚ñà‚ñà‚ñä       | 1564/5674 [02:52<01:57, 35.02it/s] 28%|‚ñà‚ñà‚ñä       | 1569/5674 [02:52<01:59, 34.30it/s] 28%|‚ñà‚ñà‚ñä       | 1573/5674 [02:52<02:01, 33.87it/s] 28%|‚ñà‚ñà‚ñä       | 1577/5674 [02:52<02:15, 30.35it/s] 28%|‚ñà‚ñà‚ñä       | 1583/5674 [02:52<01:51, 36.83it/s] 28%|‚ñà‚ñà‚ñä       | 1587/5674 [02:53<02:04, 32.82it/s] 28%|‚ñà‚ñà‚ñä       | 1591/5674 [02:53<02:04, 32.67it/s] 28%|‚ñà‚ñà‚ñä       | 1595/5674 [02:53<02:07, 32.05it/s] 28%|‚ñà‚ñà‚ñä       | 1602/5674 [02:53<01:43, 39.19it/s] 28%|‚ñà‚ñà‚ñä       | 1608/5674 [02:53<01:31, 44.30it/s] 28%|‚ñà‚ñà‚ñä       | 1613/5674 [02:53<01:42, 39.65it/s] 29%|‚ñà‚ñà‚ñä       | 1618/5674 [02:53<01:57, 34.66it/s] 29%|‚ñà‚ñà‚ñä       | 1622/5674 [02:54<02:00, 33.69it/s] 29%|‚ñà‚ñà‚ñä       | 1626/5674 [02:54<02:23, 28.27it/s] 29%|‚ñà‚ñà‚ñâ       | 1632/5674 [02:54<02:01, 33.31it/s] 29%|‚ñà‚ñà‚ñâ       | 1638/5674 [02:54<01:46, 37.76it/s] 29%|‚ñà‚ñà‚ñâ       | 1638/5674 [03:23<01:46, 37.76it/s] 29%|‚ñà‚ñà‚ñâ       | 1640/5674 [03:23<2:17:08,  2.04s/it] 29%|‚ñà‚ñà‚ñâ       | 1643/5674 [03:23<1:46:13,  1.58s/it] 29%|‚ñà‚ñà‚ñâ       | 1647/5674 [03:23<1:14:23,  1.11s/it] 29%|‚ñà‚ñà‚ñâ       | 1651/5674 [03:23<52:26,  1.28it/s]   29%|‚ñà‚ñà‚ñâ       | 1658/5674 [03:24<30:22,  2.20it/s] 29%|‚ñà‚ñà‚ñâ       | 1667/5674 [03:24<18:00,  3.71it/s] 30%|‚ñà‚ñà‚ñâ       | 1674/5674 [03:24<12:23,  5.38it/s] 30%|‚ñà‚ñà‚ñâ       | 1679/5674 [03:24<09:38,  6.91it/s] 30%|‚ñà‚ñà‚ñâ       | 1684/5674 [03:24<07:28,  8.89it/s] 30%|‚ñà‚ñà‚ñâ       | 1690/5674 [03:24<05:39, 11.74it/s] 30%|‚ñà‚ñà‚ñâ       | 1695/5674 [03:24<04:43, 14.02it/s] 30%|‚ñà‚ñà‚ñâ       | 1699/5674 [03:25<04:20, 15.25it/s] 30%|‚ñà‚ñà‚ñà       | 1706/5674 [03:25<03:05, 21.40it/s] 30%|‚ñà‚ñà‚ñà       | 1711/5674 [03:25<02:56, 22.45it/s] 30%|‚ñà‚ñà‚ñà       | 1717/5674 [03:25<02:24, 27.34it/s] 30%|‚ñà‚ñà‚ñà       | 1725/5674 [03:25<01:48, 36.33it/s] 31%|‚ñà‚ñà‚ñà       | 1731/5674 [03:25<01:43, 38.20it/s] 31%|‚ñà‚ñà‚ñà       | 1737/5674 [03:25<01:36, 40.60it/s] 31%|‚ñà‚ñà‚ñà       | 1742/5674 [03:26<01:50, 35.73it/s] 31%|‚ñà‚ñà‚ñà       | 1747/5674 [03:26<01:41, 38.51it/s] 31%|‚ñà‚ñà‚ñà       | 1756/5674 [03:26<01:19, 49.26it/s] 31%|‚ñà‚ñà‚ñà       | 1762/5674 [03:26<01:16, 51.03it/s] 31%|‚ñà‚ñà‚ñà       | 1768/5674 [03:26<01:30, 43.29it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1779/5674 [03:26<01:06, 58.44it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1791/5674 [03:26<00:53, 73.01it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1801/5674 [03:26<00:48, 79.60it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1810/5674 [03:27<00:54, 71.08it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1818/5674 [03:27<00:57, 67.25it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1826/5674 [03:27<00:58, 66.17it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1834/5674 [03:27<00:55, 69.04it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1842/5674 [03:27<01:01, 62.19it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1852/5674 [03:27<00:54, 70.67it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1863/5674 [03:27<00:49, 77.77it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1874/5674 [03:27<00:44, 86.07it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1885/5674 [03:28<00:42, 89.83it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1895/5674 [03:28<00:49, 76.32it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1904/5674 [03:28<00:52, 71.26it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1912/5674 [03:28<00:58, 64.68it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1919/5674 [03:28<01:05, 57.27it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1927/5674 [03:28<01:01, 61.33it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1937/5674 [03:28<00:53, 70.51it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1945/5674 [03:29<01:04, 57.80it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1952/5674 [03:29<01:05, 56.85it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1959/5674 [03:29<01:02, 59.43it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1968/5674 [03:29<01:00, 61.30it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1982/5674 [03:29<00:46, 79.10it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1994/5674 [03:29<00:43, 85.14it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 2003/5674 [03:29<00:44, 83.13it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 2012/5674 [03:30<00:49, 73.40it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 2020/5674 [03:30<01:01, 59.87it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 2027/5674 [03:30<01:04, 56.92it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 2038/5674 [03:30<00:53, 67.51it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 2046/5674 [03:30<00:53, 67.78it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 2054/5674 [03:30<00:58, 62.25it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 2064/5674 [03:30<00:55, 64.83it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 2071/5674 [03:31<00:58, 61.85it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 2079/5674 [03:31<00:57, 62.04it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 2086/5674 [03:31<00:57, 61.91it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 2093/5674 [03:31<01:07, 52.84it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 2093/5674 [04:06<01:07, 52.84it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 2098/5674 [04:06<1:31:54,  1.54s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 2102/5674 [04:06<1:13:48,  1.24s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 2107/5674 [04:06<54:37,  1.09it/s]   37%|‚ñà‚ñà‚ñà‚ñã      | 2113/5674 [04:06<38:08,  1.56it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 2123/5674 [04:06<22:12,  2.67it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 2129/5674 [04:07<16:43,  3.53it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 2137/5674 [04:07<11:27,  5.15it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 2142/5674 [04:07<09:04,  6.49it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 2154/5674 [04:07<05:15, 11.16it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 2162/5674 [04:07<04:00, 14.63it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 2169/5674 [04:07<03:18, 17.65it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 2175/5674 [04:07<02:44, 21.29it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 2183/5674 [04:07<02:05, 27.81it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 2190/5674 [04:08<01:52, 30.98it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 2196/5674 [04:08<01:40, 34.60it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 2203/5674 [04:08<01:31, 37.88it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 2209/5674 [04:08<01:25, 40.33it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 2216/5674 [04:08<01:17, 44.62it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 2222/5674 [04:08<01:25, 40.55it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 2227/5674 [04:09<01:46, 32.34it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 2234/5674 [04:09<01:31, 37.54it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 2243/5674 [04:09<01:11, 47.71it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 2250/5674 [04:09<01:09, 49.06it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 2256/5674 [04:09<01:28, 38.84it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 2261/5674 [04:09<01:28, 38.53it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 2266/5674 [04:09<01:47, 31.73it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 2274/5674 [04:10<01:25, 39.79it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 2280/5674 [04:10<01:22, 41.09it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 2287/5674 [04:10<01:17, 43.57it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 2294/5674 [04:10<01:08, 49.15it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 2302/5674 [04:10<01:09, 48.37it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 2308/5674 [04:10<01:18, 43.08it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 2313/5674 [04:10<01:23, 40.48it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 2320/5674 [04:11<01:28, 37.79it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 2326/5674 [04:11<01:21, 41.14it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 2331/5674 [04:11<01:18, 42.66it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 2336/5674 [04:11<01:19, 42.19it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2341/5674 [04:11<01:20, 41.30it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2347/5674 [04:11<01:22, 40.22it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2352/5674 [04:11<01:18, 42.18it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2358/5674 [04:12<01:12, 45.52it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2368/5674 [04:12<00:55, 59.43it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2376/5674 [04:12<00:50, 64.67it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2383/5674 [04:12<00:50, 65.78it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2390/5674 [04:12<00:49, 66.67it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2397/5674 [04:12<00:58, 55.95it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2406/5674 [04:12<00:52, 62.49it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2413/5674 [04:12<00:54, 59.83it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2422/5674 [04:12<00:48, 66.43it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2429/5674 [04:13<01:09, 46.74it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2435/5674 [04:13<01:11, 45.53it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2441/5674 [04:13<01:17, 41.64it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2446/5674 [04:13<01:31, 35.36it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2450/5674 [04:13<01:36, 33.30it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2458/5674 [04:14<01:17, 41.68it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2464/5674 [04:14<01:23, 38.24it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2470/5674 [04:14<01:16, 41.68it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2476/5674 [04:14<01:12, 44.07it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2484/5674 [04:14<01:02, 51.35it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2491/5674 [04:14<00:57, 55.45it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2497/5674 [04:14<00:57, 55.55it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2503/5674 [04:14<00:56, 56.33it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2509/5674 [04:15<01:06, 47.81it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2515/5674 [04:15<01:10, 44.93it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2520/5674 [04:15<01:10, 44.96it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2525/5674 [04:15<01:15, 41.76it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2530/5674 [04:15<01:13, 42.73it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2538/5674 [04:15<01:05, 47.95it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2544/5674 [04:15<01:03, 49.14it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2544/5674 [04:58<01:03, 49.14it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2551/5674 [04:58<1:44:46,  2.01s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2554/5674 [04:58<1:27:28,  1.68s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2560/5674 [04:58<59:21,  1.14s/it]   45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2565/5674 [04:58<43:16,  1.20it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2570/5674 [04:58<31:17,  1.65it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2575/5674 [04:59<22:47,  2.27it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2581/5674 [04:59<15:37,  3.30it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2585/5674 [04:59<12:19,  4.18it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2590/5674 [04:59<09:00,  5.71it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2594/5674 [04:59<07:04,  7.25it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2602/5674 [04:59<04:23, 11.66it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2608/5674 [04:59<03:19, 15.37it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2615/5674 [04:59<02:26, 20.81it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2621/5674 [05:00<02:10, 23.46it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2626/5674 [05:00<01:53, 26.79it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2631/5674 [05:00<01:43, 29.52it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2637/5674 [05:00<01:31, 33.31it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2643/5674 [05:00<01:31, 33.02it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2649/5674 [05:00<01:21, 37.24it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2656/5674 [05:00<01:08, 43.81it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2664/5674 [05:01<01:01, 48.64it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2672/5674 [05:01<00:55, 54.04it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2678/5674 [05:01<00:57, 51.76it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2685/5674 [05:01<00:54, 54.75it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2693/5674 [05:01<00:49, 60.45it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2700/5674 [05:01<01:01, 48.41it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2706/5674 [05:01<01:07, 43.66it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2711/5674 [05:02<01:09, 42.78it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2716/5674 [05:02<01:07, 43.80it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2724/5674 [05:02<00:57, 51.75it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2730/5674 [05:02<01:20, 36.42it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2735/5674 [05:02<01:16, 38.22it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2740/5674 [05:02<01:15, 38.70it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2746/5674 [05:02<01:20, 36.33it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2751/5674 [05:03<01:15, 38.46it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2758/5674 [05:03<01:18, 37.10it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2762/5674 [05:03<01:33, 31.25it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2770/5674 [05:03<01:11, 40.38it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2775/5674 [05:03<01:11, 40.45it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2785/5674 [05:03<00:54, 53.34it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2792/5674 [05:03<00:52, 54.58it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2798/5674 [05:04<00:54, 53.18it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2804/5674 [05:04<00:53, 53.49it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2810/5674 [05:04<01:04, 44.59it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2815/5674 [05:04<01:03, 44.97it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2820/5674 [05:04<01:10, 40.31it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2825/5674 [05:04<01:08, 41.41it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2834/5674 [05:04<00:53, 53.18it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2844/5674 [05:04<00:43, 64.70it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2855/5674 [05:05<00:37, 75.42it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2863/5674 [05:05<00:43, 64.21it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2872/5674 [05:05<00:40, 69.93it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2880/5674 [05:05<00:39, 70.02it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2888/5674 [05:05<00:42, 66.03it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2895/5674 [05:05<00:48, 57.62it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2902/5674 [05:05<00:50, 54.36it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2908/5674 [05:06<00:57, 48.33it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2914/5674 [05:06<00:57, 48.14it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2919/5674 [05:06<01:00, 45.23it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2924/5674 [05:06<01:05, 42.30it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2930/5674 [05:06<01:00, 45.04it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2936/5674 [05:06<00:56, 48.06it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2944/5674 [05:06<00:51, 52.80it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2950/5674 [05:06<00:51, 52.99it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2956/5674 [05:07<01:17, 35.28it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2961/5674 [05:07<01:14, 36.33it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2966/5674 [05:07<01:13, 36.91it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2973/5674 [05:07<01:02, 43.26it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2978/5674 [05:07<01:13, 36.54it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2987/5674 [05:07<00:56, 47.42it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2993/5674 [05:07<00:53, 50.33it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2999/5674 [05:08<00:52, 50.51it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3005/5674 [05:08<01:00, 43.97it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3010/5674 [05:08<01:01, 43.63it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3015/5674 [05:08<01:26, 30.68it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3020/5674 [05:08<01:18, 33.85it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3025/5674 [05:08<01:11, 36.81it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3030/5674 [05:09<01:10, 37.69it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3039/5674 [05:09<00:55, 47.23it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3045/5674 [05:09<00:57, 45.96it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3051/5674 [05:09<00:54, 48.05it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3058/5674 [05:09<00:50, 51.51it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3065/5674 [05:09<00:51, 51.06it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3071/5674 [05:09<00:52, 49.20it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3077/5674 [05:09<00:57, 44.93it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3082/5674 [05:10<01:04, 40.42it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3082/5674 [06:01<01:04, 40.42it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3085/5674 [06:01<2:13:38,  3.10s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3089/5674 [06:01<1:39:52,  2.32s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3093/5674 [06:01<1:13:29,  1.71s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3098/5674 [06:02<50:02,  1.17s/it]   55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3104/5674 [06:02<32:26,  1.32it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3109/5674 [06:02<23:06,  1.85it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3114/5674 [06:02<16:27,  2.59it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3122/5674 [06:02<09:58,  4.26it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3128/5674 [06:02<07:14,  5.86it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3134/5674 [06:02<05:15,  8.04it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3140/5674 [06:02<03:55, 10.78it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3147/5674 [06:03<02:49, 14.87it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3154/5674 [06:03<02:10, 19.24it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3160/5674 [06:03<01:46, 23.51it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3166/5674 [06:03<01:34, 26.54it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3171/5674 [06:03<01:25, 29.26it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3178/5674 [06:03<01:11, 34.92it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3184/5674 [06:03<01:03, 39.44it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3191/5674 [06:03<01:02, 39.80it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3200/5674 [06:04<00:53, 46.32it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3210/5674 [06:04<00:42, 57.53it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3219/5674 [06:04<00:40, 60.93it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3228/5674 [06:04<00:38, 62.79it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3235/5674 [06:04<00:40, 60.13it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3246/5674 [06:04<00:33, 71.75it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3254/5674 [06:04<00:35, 69.13it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3262/5674 [06:04<00:34, 69.63it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3270/5674 [06:05<00:35, 68.10it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3277/5674 [06:05<00:38, 62.57it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3287/5674 [06:05<00:35, 67.23it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3296/5674 [06:05<00:32, 72.55it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3305/5674 [06:05<00:30, 76.42it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3314/5674 [06:05<00:36, 63.79it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3321/5674 [06:05<00:48, 48.78it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3330/5674 [06:06<00:58, 40.32it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3335/5674 [06:06<01:04, 36.27it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3341/5674 [06:06<00:59, 39.26it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3348/5674 [06:06<00:51, 45.10it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3354/5674 [06:06<00:55, 42.09it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3360/5674 [06:06<00:51, 45.32it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3365/5674 [06:07<00:51, 45.14it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3373/5674 [06:07<00:50, 45.38it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3378/5674 [06:07<00:55, 41.49it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3383/5674 [06:07<00:55, 41.32it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3391/5674 [06:07<00:46, 49.24it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3397/5674 [06:07<00:49, 45.59it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3402/5674 [06:08<01:02, 36.35it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3411/5674 [06:08<01:00, 37.20it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3415/5674 [06:08<01:03, 35.44it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3419/5674 [06:08<01:20, 28.10it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3425/5674 [06:08<01:15, 29.94it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3433/5674 [06:08<00:58, 38.47it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3438/5674 [06:09<01:01, 36.40it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3443/5674 [06:09<01:03, 35.27it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3450/5674 [06:09<00:52, 42.15it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3458/5674 [06:09<01:05, 33.59it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3464/5674 [06:09<00:58, 37.88it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3473/5674 [06:09<00:47, 46.51it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3483/5674 [06:10<00:48, 45.02it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3489/5674 [06:10<00:49, 44.39it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3494/5674 [06:10<00:50, 43.16it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3500/5674 [06:10<00:46, 46.43it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3506/5674 [06:10<00:46, 46.91it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3511/5674 [06:10<00:46, 46.86it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3518/5674 [06:10<00:41, 52.03it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3524/5674 [06:10<00:43, 49.17it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3531/5674 [06:11<00:40, 52.49it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3537/5674 [06:11<00:52, 40.81it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3549/5674 [06:11<00:43, 48.88it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3559/5674 [06:11<00:35, 59.17it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3570/5674 [06:11<00:29, 70.25it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3578/5674 [06:11<00:39, 52.78it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3589/5674 [06:12<00:35, 58.32it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3596/5674 [06:12<00:43, 48.08it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3603/5674 [06:12<00:39, 51.95it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3610/5674 [06:12<00:37, 54.44it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3622/5674 [06:12<00:29, 69.18it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3630/5674 [06:12<00:43, 46.49it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3637/5674 [06:13<01:10, 28.81it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3643/5674 [06:13<01:02, 32.45it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3649/5674 [06:13<01:01, 33.11it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3654/5674 [06:13<01:02, 32.49it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3663/5674 [06:14<00:47, 42.40it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3669/5674 [06:14<00:45, 44.18it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3675/5674 [06:14<00:44, 44.48it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3681/5674 [06:14<00:43, 45.52it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3687/5674 [06:14<00:45, 43.35it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3693/5674 [06:14<00:46, 42.91it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3698/5674 [06:14<00:45, 43.88it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3704/5674 [06:14<00:43, 45.03it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3711/5674 [06:15<00:51, 38.25it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3717/5674 [06:15<00:47, 41.53it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3722/5674 [06:15<00:52, 37.01it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3726/5674 [06:15<00:53, 36.24it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3732/5674 [06:15<00:50, 38.79it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3744/5674 [06:15<00:34, 55.65it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3744/5674 [07:19<00:34, 55.65it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3747/5674 [07:19<1:40:49,  3.14s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3755/5674 [07:19<1:04:34,  2.02s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3763/5674 [07:19<42:38,  1.34s/it]   66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3770/5674 [07:19<29:58,  1.06it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3783/5674 [07:19<16:44,  1.88it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3792/5674 [07:20<11:49,  2.65it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3803/5674 [07:20<07:50,  3.97it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3814/5674 [07:20<05:19,  5.83it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3824/5674 [07:20<03:48,  8.09it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3834/5674 [07:20<02:45, 11.15it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3844/5674 [07:20<02:00, 15.19it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3853/5674 [07:20<01:38, 18.50it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3864/5674 [07:21<01:11, 25.17it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3873/5674 [07:21<00:57, 31.06it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3882/5674 [07:21<00:49, 36.11it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3891/5674 [07:21<00:41, 43.31it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3901/5674 [07:21<00:33, 52.34it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3910/5674 [07:21<00:34, 51.04it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3918/5674 [07:21<00:39, 44.06it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3925/5674 [07:22<00:40, 42.90it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3931/5674 [07:22<00:38, 45.46it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3938/5674 [07:22<00:34, 50.08it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3944/5674 [07:22<00:39, 43.69it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3950/5674 [07:22<00:37, 46.56it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3956/5674 [07:22<00:34, 49.50it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3963/5674 [07:22<00:32, 51.98it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3969/5674 [07:23<00:32, 52.67it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 3976/5674 [07:23<00:30, 55.82it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 3982/5674 [07:23<00:32, 51.68it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 3992/5674 [07:23<00:27, 61.78it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 4000/5674 [07:23<00:28, 59.61it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 4007/5674 [07:23<00:28, 57.63it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 4014/5674 [07:23<00:27, 60.38it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 4024/5674 [07:23<00:23, 70.70it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 4032/5674 [07:24<00:32, 50.71it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4046/5674 [07:24<00:24, 65.51it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4056/5674 [07:24<00:30, 53.34it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4063/5674 [07:24<00:31, 50.85it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4071/5674 [07:24<00:29, 55.05it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4082/5674 [07:24<00:24, 65.10it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4090/5674 [07:25<00:25, 63.27it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4097/5674 [07:25<00:28, 54.44it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4105/5674 [07:25<00:26, 58.29it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4112/5674 [07:25<00:29, 53.11it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4118/5674 [07:25<00:30, 50.68it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4124/5674 [07:25<00:29, 51.74it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4135/5674 [07:25<00:27, 55.35it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4146/5674 [07:26<00:23, 66.31it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4153/5674 [07:26<00:24, 61.89it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4165/5674 [07:26<00:20, 72.50it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4173/5674 [07:26<00:24, 60.78it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4180/5674 [07:26<00:26, 56.02it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4187/5674 [07:26<00:25, 58.98it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4198/5674 [07:26<00:20, 70.93it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4207/5674 [07:26<00:20, 70.71it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4215/5674 [07:27<00:20, 70.16it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4223/5674 [07:27<00:23, 61.54it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4230/5674 [07:27<00:29, 48.96it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4236/5674 [07:27<00:41, 34.53it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4242/5674 [07:27<00:37, 38.17it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4247/5674 [07:28<00:42, 33.30it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4251/5674 [07:28<00:42, 33.30it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4259/5674 [07:28<00:34, 41.54it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4264/5674 [07:28<00:34, 41.31it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4269/5674 [07:28<00:37, 37.89it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4274/5674 [07:28<00:37, 37.00it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4280/5674 [07:28<00:33, 41.07it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4287/5674 [07:28<00:29, 47.40it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4293/5674 [07:29<00:28, 48.82it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4299/5674 [07:29<00:26, 51.12it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4306/5674 [07:29<00:26, 52.12it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4313/5674 [07:29<00:24, 55.41it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4319/5674 [07:29<00:24, 56.17it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4325/5674 [07:29<00:25, 53.61it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4333/5674 [07:29<00:23, 58.28it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4342/5674 [07:29<00:21, 63.28it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4349/5674 [07:30<00:21, 62.51it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4356/5674 [07:30<00:21, 61.76it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4372/5674 [07:30<00:15, 84.16it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4386/5674 [07:30<00:13, 92.79it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4396/5674 [07:30<00:14, 91.23it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4406/5674 [07:30<00:14, 85.42it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4415/5674 [07:30<00:17, 72.96it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4428/5674 [07:31<00:20, 59.48it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4435/5674 [07:31<00:21, 56.40it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4445/5674 [07:31<00:19, 63.61it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4463/5674 [07:31<00:13, 88.58it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4474/5674 [07:31<00:13, 89.90it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4489/5674 [07:31<00:11, 101.31it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4502/5674 [07:31<00:10, 106.89it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4514/5674 [07:31<00:12, 96.42it/s]  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4529/5674 [07:32<00:10, 106.68it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4545/5674 [07:32<00:09, 119.54it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4566/5674 [07:32<00:09, 111.06it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4581/5674 [07:32<00:09, 119.73it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4599/5674 [07:32<00:08, 133.16it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4614/5674 [07:32<00:07, 134.10it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4628/5674 [07:32<00:08, 124.12it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4641/5674 [07:32<00:08, 121.03it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4654/5674 [07:33<00:11, 90.64it/s]  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4665/5674 [07:33<00:11, 90.91it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4675/5674 [07:33<00:11, 89.62it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4685/5674 [07:33<00:11, 83.26it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4696/5674 [07:33<00:11, 88.69it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4706/5674 [07:33<00:12, 78.77it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4716/5674 [07:33<00:11, 82.58it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4725/5674 [07:34<00:13, 72.92it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4736/5674 [07:34<00:15, 61.06it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4752/5674 [07:34<00:11, 78.44it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4765/5674 [07:34<00:10, 89.61it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4779/5674 [07:34<00:09, 90.35it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4789/5674 [07:34<00:09, 90.33it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4799/5674 [07:35<00:12, 72.89it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4808/5674 [07:35<00:13, 65.38it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4824/5674 [07:35<00:10, 84.90it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4834/5674 [07:35<00:14, 59.20it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4848/5674 [07:35<00:11, 70.90it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4860/5674 [07:35<00:10, 80.08it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4876/5674 [07:35<00:08, 96.61it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4888/5674 [07:36<00:08, 90.57it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 4899/5674 [07:36<00:08, 90.26it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 4914/5674 [07:36<00:07, 103.76it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 4934/5674 [07:36<00:05, 125.14it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 4949/5674 [07:36<00:05, 128.49it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 4965/5674 [07:36<00:05, 136.43it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 4965/5674 [08:55<00:05, 136.43it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 4978/5674 [08:55<18:47,  1.62s/it]  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 4990/5674 [08:55<13:42,  1.20s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 5003/5674 [08:56<09:39,  1.16it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 5016/5674 [08:56<06:44,  1.63it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 5027/5674 [08:56<04:57,  2.18it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5037/5674 [08:56<03:40,  2.89it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5048/5674 [08:56<02:36,  3.99it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5063/5674 [08:56<01:40,  6.08it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5074/5674 [08:56<01:15,  7.97it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5083/5674 [08:57<00:58, 10.13it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5092/5674 [08:57<00:44, 12.96it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5104/5674 [08:57<00:31, 18.22it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 5123/5674 [08:57<00:18, 29.57it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 5139/5674 [08:57<00:13, 38.98it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 5151/5674 [08:57<00:11, 43.82it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 5162/5674 [08:57<00:10, 47.83it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 5171/5674 [08:58<00:09, 52.74it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5182/5674 [08:58<00:08, 60.52it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5191/5674 [08:58<00:07, 65.50it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5205/5674 [08:58<00:05, 79.35it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5215/5674 [08:58<00:06, 70.51it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5224/5674 [08:58<00:06, 72.07it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5238/5674 [08:58<00:05, 85.98it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5248/5674 [08:58<00:05, 79.55it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5260/5674 [08:59<00:04, 88.24it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5270/5674 [08:59<00:04, 89.18it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5287/5674 [08:59<00:03, 106.78it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5299/5674 [08:59<00:03, 109.68it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5311/5674 [08:59<00:03, 105.91it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5322/5674 [08:59<00:03, 95.61it/s]  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5332/5674 [08:59<00:04, 80.46it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5341/5674 [08:59<00:04, 80.13it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5355/5674 [08:59<00:03, 94.19it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5366/5674 [09:00<00:03, 89.33it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5377/5674 [09:00<00:03, 91.60it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5387/5674 [09:00<00:03, 83.67it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5409/5674 [09:00<00:02, 117.34it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5422/5674 [09:00<00:02, 114.48it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5435/5674 [09:00<00:02, 105.78it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5447/5674 [09:00<00:02, 107.54it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5459/5674 [09:00<00:02, 105.62it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5470/5674 [09:01<00:02, 95.72it/s]  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5482/5674 [09:01<00:01, 100.78it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5494/5674 [09:01<00:01, 101.68it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5511/5674 [09:01<00:01, 119.21it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5529/5674 [09:01<00:01, 133.21it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5555/5674 [09:01<00:00, 162.38it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5572/5674 [09:01<00:00, 157.58it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5588/5674 [09:01<00:00, 150.68it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5604/5674 [09:02<00:00, 108.36it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5617/5674 [09:02<00:00, 102.73it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5629/5674 [09:02<00:00, 77.29it/s] 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5646/5674 [09:02<00:00, 83.01it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5656/5674 [09:02<00:00, 80.04it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5665/5674 [09:03<00:00, 57.44it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5672/5674 [09:03<00:00, 49.85it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5674/5674 [09:03<00:00, 10.44it/s]
2025-12-05 17:24:31.029 | INFO     | __main__:main:250 - Starting Epoch 4/10
2025-12-05 17:24:31.120 | INFO     | __main__:main:266 - Processing 128 theorems with 16 workers.
2025-12-05 17:24:46.410 | INFO     | src.agent.runner:run:83 - Starting proof search for: sup_le_inf
2025-12-05 17:24:50.383 | INFO     | src.agent.runner:run:83 - Starting proof search for: Down.card_compression
2025-12-05 17:24:50.841 | INFO     | src.agent.runner:run:114 - Step 1: Running MCTS search for 200 iterations...
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
2025-12-05 17:24:54.228 | INFO     | src.agent.runner:run:83 - Starting proof search for: SubMulAction.orbitRel_of_subMul
2025-12-05 17:24:54.856 | INFO     | src.agent.runner:run:83 - Starting proof search for: Finset.map_subtype_embedding_Ioo
2025-12-05 17:24:54.939 | INFO     | src.agent.runner:run:114 - Step 1: Running MCTS search for 200 iterations...
2025-12-05 17:24:55.937 | INFO     | src.agent.runner:run:83 - Starting proof search for: Finset.image_sdiff_product
2025-12-05 17:24:59.042 | INFO     | src.agent.runner:run:114 - Step 1: Running MCTS search for 200 iterations...
2025-12-05 17:24:59.595 | INFO     | src.agent.runner:run:114 - Step 1: Running MCTS search for 200 iterations...
2025-12-05 17:25:00.576 | INFO     | src.agent.runner:run:114 - Step 1: Running MCTS search for 200 iterations...
2025-12-05 17:25:00.773 | INFO     | src.agent.runner:run:83 - Starting proof search for: CategoryTheory.Functor.IsCoverDense.iso_of_restrict_iso
2025-12-05 17:25:01.896 | INFO     | src.agent.runner:run:83 - Starting proof search for: Complex.IsExpCmpFilter.of_boundedUnder_im
2025-12-05 17:25:03.754 | INFO     | src.agent.runner:run:83 - Starting proof search for: Filter.eventually_atTop_curry
2025-12-05 17:25:05.393 | INFO     | src.agent.runner:run:114 - Step 1: Running MCTS search for 200 iterations...
2025-12-05 17:25:05.729 | INFO     | src.agent.runner:run:83 - Starting proof search for: MeasureTheory.unifIntegrable_congr_ae
2025-12-05 17:25:06.875 | INFO     | src.agent.runner:run:83 - Starting proof search for: Measurable.lintegral_kernel_prod_right
2025-12-05 17:25:07.053 | INFO     | src.agent.runner:run:114 - Step 1: Running MCTS search for 200 iterations...
2025-12-05 17:25:08.074 | INFO     | src.agent.runner:run:83 - Starting proof search for: ProbabilityTheory.iIndepFun.cgf_sum
2025-12-05 17:25:08.509 | INFO     | src.agent.runner:run:83 - Starting proof search for: ProbabilityTheory.measure_le_le_exp_cgf
2025-12-05 17:25:09.259 | INFO     | src.agent.runner:run:114 - Step 1: Running MCTS search for 200 iterations...
2025-12-05 17:25:10.698 | INFO     | src.agent.runner:run:83 - Starting proof search for: WeierstrassCurve.map_Œî
2025-12-05 17:25:11.504 | INFO     | src.agent.runner:run:114 - Step 1: Running MCTS search for 200 iterations...
2025-12-05 17:25:12.792 | INFO     | src.agent.runner:run:114 - Step 1: Running MCTS search for 200 iterations...
2025-12-05 17:25:13.629 | INFO     | src.agent.runner:run:83 - Starting proof search for: SeminormFamily.withSeminorms_iff_uniformSpace_eq_iInf
2025-12-05 17:25:13.987 | INFO     | src.agent.runner:run:83 - Starting proof search for: ne_neg_of_mem_unit_sphere
2025-12-05 17:25:14.106 | INFO     | src.agent.runner:run:114 - Step 1: Running MCTS search for 200 iterations...
2025-12-05 17:25:14.168 | INFO     | src.agent.runner:run:114 - Step 1: Running MCTS search for 200 iterations...
2025-12-05 17:25:16.144 | INFO     | src.agent.runner:run:114 - Step 1: Running MCTS search for 200 iterations...
2025-12-05 17:25:18.916 | INFO     | src.agent.runner:run:114 - Step 1: Running MCTS search for 200 iterations...
2025-12-05 17:25:19.012 | INFO     | src.agent.runner:run:114 - Step 1: Running MCTS search for 200 iterations...
2025-12-05 17:25:23.150 | INFO     | src.agent.runner:run:83 - Starting proof search for: BoxIntegral.HasIntegral.mcShane_of_forall_isLittleO
2025-12-05 17:25:28.033 | INFO     | src.agent.runner:run:114 - Step 1: Running MCTS search for 200 iterations...
2025-12-05 17:31:33.835 | INFO     | src.agent.runner:run:177 - Step 1: Applying best tactic: exact isExpCmpFilter_of_tendsto_atTop hre him_le him_ge
2025-12-05 17:31:33.903 | WARNING  | src.agent.runner:run:186 - Tactic resulted in error: LeanError(error="unknown identifier 'isExpCmpFilter_of_tendsto_atTop'")
2025-12-05 17:31:33.903 | ERROR    | src.agent.runner:run:230 - Proof failed after 1 steps and 392.01s.
2025-12-05 17:31:33.904 | WARNING  | src.agent.runner:run:234 - Final state: LeanError(error="unknown identifier 'isExpCmpFilter_of_tendsto_atTop'")
2025-12-05 17:31:34.052 | INFO     | src.utilities.gym:close:89 - Environment closed.
2025-12-05 17:31:34.143 | INFO     | src.agent.runner:run:177 - Step 1: Applying best tactic: rw [‚Üê MulAction.orbitRel_eq_comap, ‚Üê MulAction.orbitRel_eq_comap,
  MulAction.orbitRel_eq_comap_comap, MulAction.orbitRel_eq_comap_comap,
  MulAction.orbitRel_eq_comap_comap, MulAction.orbitRel_eq_comap_comap,
  MulAction.orbitRel_eq_comap_comap, MulAction.orbitRel_eq_comap_comap,
  MulAction.orbitRel_eq_comap_comap, MulAction.orbitRel_eq_comap_comap,
  MulAction.orbitRel_eq_comap_comap, MulAction.orbitRel_eq_comap_comap,
  MulAction.orbitRel_eq_comap_comap, MulAction.orbitRel_eq_comap_comap,
  MulAction.orbitRel_eq_comap_comap, MulAction.orbitRel_eq_comap_comap,
  MulAction.orbitRel_eq_comap_comap, MulAction.orbitRel_eq_comap_comap,
  MulAction.orbitRel_eq_comap_comap, MulAction.orbitRel_eq_comap_comap,
  MulAction.orbitRel_eq_comap_comap, MulAction.orbitRel_eq_comap_comap,
  MulAction.orbitRel_eq_comap_comap, MulAction.orbitRel_eq_comap_comap,
  MulAction.orbitRel_eq_comap_comap, MulAction.orbitRel_eq_comap_comap, MulAction.orbit_eq_comap,
  MulAction.orbitRel_eq_comap_comap, MulAction.orbitRel_eq_coma
2025-12-05 17:31:34.211 | WARNING  | src.agent.runner:run:186 - Tactic resulted in error: LeanError(error="<stdin>:14:63: unexpected end of input; expected ']'")
2025-12-05 17:31:34.211 | ERROR    | src.agent.runner:run:230 - Proof failed after 1 steps and 399.98s.
2025-12-05 17:31:34.211 | WARNING  | src.agent.runner:run:234 - Final state: LeanError(error="<stdin>:14:63: unexpected end of input; expected ']'")
2025-12-05 17:31:34.360 | INFO     | src.utilities.gym:close:89 - Environment closed.
2025-12-05 17:31:34.442 | INFO     | src.agent.runner:run:177 - Step 1: Applying best tactic: rw [‚Üê image_sdiff, image_uncurry_prod]
2025-12-05 17:31:34.574 | WARNING  | src.agent.runner:run:186 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  Finset.image ?m.160000 ?s \\ Finset.image ?m.160000 ?t\nF : Type u_1\nŒ± : Type u_2\nŒ≤ : Type u_3\ninst‚úù¬≤ : DecidableEq Œ±\ninst‚úù¬π : DecidableEq Œ≤\ninst‚úù : GeneralizedBooleanAlgebra Œ±\ns‚úù s‚ÇÅ s‚ÇÇ t‚úù t‚ÇÅ t‚ÇÇ u v : Finset Œ±\na b c : Œ±\ns t : Finset Œ±\n‚ä¢ Finset.image (Function.uncurry fun x x_1 => x \\ x_1) (s √óÀ¢ t) = s \\\\ t")
2025-12-05 17:31:34.574 | ERROR    | src.agent.runner:run:230 - Proof failed after 1 steps and 398.64s.
2025-12-05 17:31:34.574 | WARNING  | src.agent.runner:run:234 - Final state: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  Finset.image ?m.160000 ?s \\ Finset.image ?m.160000 ?t\nF : Type u_1\nŒ± : Type u_2\nŒ≤ : Type u_3\ninst‚úù¬≤ : DecidableEq Œ±\ninst‚úù¬π : DecidableEq Œ≤\ninst‚úù : GeneralizedBooleanAlgebra Œ±\ns‚úù s‚ÇÅ s‚ÇÇ t‚úù t‚ÇÅ t‚ÇÇ u v : Finset Œ±\na b c : Œ±\ns t : Finset Œ±\n‚ä¢ Finset.image (Function.uncurry fun x x_1 => x \\ x_1) (s √óÀ¢ t) = s \\\\ t")
2025-12-05 17:31:34.593 | INFO     | src.agent.runner:run:177 - Step 1: Applying best tactic: have : IsIso (whiskerLeft G.op Œ±.val) := by
  apply isIso_of_fully_faithful (whiskerLeft G.op Œ±.val)
  all_goals
  apply isIso_of_fully_faithful (whiskerLeft G.op Œ±.val)
  all_goals
  apply isIso_of_fully_faithful (whiskerLeft G.op Œ±.val)
  all_goals
  apply isIso_of_fully_faithful (whiskerLeft G.op Œ±.val)
  all_goals
  apply isIso_of_fully_faithful (whiskerLeft G.op Œ±.val)
  all_goals
  apply isIso_of_fully_faithful (whiskerLeft G.op Œ±.val) (whiskerLeft G.op Œ±.val)
  all_goals
  apply isIso_of_fully_faithful (whiskerLeft G.op Œ±.val) (whiskerLeft G.op Œ±.val)
  all_goals
  apply isIso_of_fully_faithful (whiskerLeft G.op Œ±.val) (whiskerLeft G.op Œ±.val)
  all_goals
  apply isIso_of_fully_faithful (whiskerLeft G.op Œ±.val) (whiskerLeft G.op Œ±.val)
  all_goals
  apply isIso_of_fully_faithful (whiskerLeft G.op Œ±.val) (whiskerLeft G.op Œ±.val)
  all_goals
  apply isIso_of_fully_faithful (whiskerLeft G.op Œ±.val) (whiskerLeft G.op Œ±.val)
  all_goals
  apply isIso_of_fully_faithful (whiskerLeft G.op Œ±
2025-12-05 17:31:34.611 | INFO     | src.agent.runner:run:177 - Step 1: Applying best tactic: rw [subtype_Ioo_eq_self_iff_of_injective, map_injective_of_injective_injective_injective_injective_injective_injective_injective_injective_injective_injective_injective_injective_injective_injective_injective_injective_injective_injective_injective_injective_injective_injective_injective_injective_injective_injective_injective_injective_injective_injective_injective_injective_injective_injective_injective_injective_injective,
  injective_injective_injective_injective_injective_injective_injective_injective_injective_injective_injective,
  injective_injective_injective_injective_injective_injective_injective_injective_injective_injective_injective_injective_injective]
2025-12-05 17:31:34.665 | WARNING  | src.agent.runner:run:186 - Tactic resulted in error: LeanError(error="<stdin>:24:51: unexpected end of input; expected ')', ',' or ':'")
2025-12-05 17:31:34.665 | ERROR    | src.agent.runner:run:230 - Proof failed after 1 steps and 393.89s.
2025-12-05 17:31:34.665 | WARNING  | src.agent.runner:run:234 - Final state: LeanError(error="<stdin>:24:51: unexpected end of input; expected ')', ',' or ':'")
2025-12-05 17:31:34.725 | INFO     | src.utilities.gym:close:89 - Environment closed.
2025-12-05 17:31:34.730 | WARNING  | src.agent.runner:run:186 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.95490\nŒ± : Type u_1\nŒ≤ : Type u_2\ninst‚úù¬≤ : Preorder Œ±\np : Œ± ‚Üí Prop\ninst‚úù¬π : DecidablePred p\ninst‚úù : LocallyFiniteOrder Œ±\na b : Subtype p\nhp : ‚àÄ ‚¶Éa b x : Œ±‚¶Ñ, a ‚â§ x ‚Üí x ‚â§ b ‚Üí p a ‚Üí p b ‚Üí p x\n‚ä¢ Finset.map (Function.Embedding.subtype p) (Finset.Ioo a b) = Finset.Ioo ‚Üëa ‚Üëb")
2025-12-05 17:31:34.730 | ERROR    | src.agent.runner:run:230 - Proof failed after 1 steps and 399.87s.
2025-12-05 17:31:34.730 | WARNING  | src.agent.runner:run:234 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.95490\nŒ± : Type u_1\nŒ≤ : Type u_2\ninst‚úù¬≤ : Preorder Œ±\np : Œ± ‚Üí Prop\ninst‚úù¬π : DecidablePred p\ninst‚úù : LocallyFiniteOrder Œ±\na b : Subtype p\nhp : ‚àÄ ‚¶Éa b x : Œ±‚¶Ñ, a ‚â§ x ‚Üí x ‚â§ b ‚Üí p a ‚Üí p b ‚Üí p x\n‚ä¢ Finset.map (Function.Embedding.subtype p) (Finset.Ioo a b) = Finset.Ioo ‚Üëa ‚Üëb")
2025-12-05 17:31:34.815 | INFO     | src.utilities.gym:close:89 - Environment closed.
2025-12-05 17:31:34.880 | INFO     | src.utilities.gym:close:89 - Environment closed.
2025-12-05 17:31:47.939 | INFO     | src.agent.runner:run:83 - Starting proof search for: inv_mul_eq_one‚ÇÄ
2025-12-05 17:31:50.615 | INFO     | src.agent.runner:run:83 - Starting proof search for: Multiset.length_sort
2025-12-05 17:31:51.007 | INFO     | src.agent.runner:run:83 - Starting proof search for: Prod.mk_wcovBy_mk_iff
2025-12-05 17:31:52.403 | INFO     | src.agent.runner:run:114 - Step 1: Running MCTS search for 200 iterations...
2025-12-05 17:31:55.220 | INFO     | src.agent.runner:run:114 - Step 1: Running MCTS search for 200 iterations...
2025-12-05 17:31:55.497 | INFO     | src.agent.runner:run:114 - Step 1: Running MCTS search for 200 iterations...
2025-12-05 17:31:56.194 | INFO     | src.agent.runner:run:83 - Starting proof search for: CategoryTheory.Functor.isLeftKanExtension_iff_postcomp‚ÇÅ
2025-12-05 17:32:00.683 | INFO     | src.agent.runner:run:114 - Step 1: Running MCTS search for 200 iterations...
2025-12-05 17:32:06.242 | WARNING  | src.training.inference_server:_run_transformer_batch:111 - OOM encountered. Reducing max safe batch size to 72
2025-12-05 17:32:07.105 | WARNING  | src.training.inference_server:_run_transformer_batch:111 - OOM encountered. Reducing max safe batch size to 36
2025-12-05 17:32:09.370 | INFO     | src.agent.runner:run:83 - Starting proof search for: Finset.smul_singleton
2025-12-05 17:32:13.792 | INFO     | src.agent.runner:run:114 - Step 1: Running MCTS search for 200 iterations...
2025-12-05 17:32:20.809 | WARNING  | src.training.inference_server:_run_transformer_batch:111 - OOM encountered. Reducing max safe batch size to 18
2025-12-05 17:32:20.843 | WARNING  | src.training.inference_server:_run_transformer_batch:111 - OOM encountered. Reducing max safe batch size to 9
2025-12-05 17:32:21.136 | WARNING  | src.training.inference_server:_run_transformer_batch:111 - OOM encountered. Reducing max safe batch size to 4
2025-12-05 17:32:40.903 | WARNING  | src.training.inference_server:_run_transformer_batch:111 - OOM encountered. Reducing max safe batch size to 2
2025-12-05 17:32:48.316 | WARNING  | src.training.inference_server:_run_transformer_batch:111 - OOM encountered. Reducing max safe batch size to 1
2025-12-05 17:32:55.081 | ERROR    | __main__:main:370 - Training crashed: OOM even with single sample! n=16
2025-12-05 17:32:55.081 | INFO     | __main__:main:373 - Shutting down workers...
Traceback (most recent call last):
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/training/inference_server.py", line 103, in _run_transformer_batch
    return method(states, n=n, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/agent/transformer.py", line 92, in generate_tactics_batch
    tactics_ids = self.model.generate(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 2564, in generate
    result = decoding_method(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 3377, in _beam_search
    model_kwargs["past_key_values"].reorder_cache(beam_idx)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/cache_utils.py", line 1309, in reorder_cache
    self.cross_attention_cache.reorder_cache(beam_idx)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/cache_utils.py", line 832, in reorder_cache
    self.layers[layer_idx].reorder_cache(beam_idx)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/cache_utils.py", line 80, in reorder_cache
    self.keys = self.keys.index_select(0, beam_idx.to(self.keys.device))
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 39.49 GiB of which 494.75 MiB is free. Including non-PyTorch memory, this process has 39.00 GiB memory in use. Of the allocated memory 31.62 GiB is allocated by PyTorch, and 6.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/training/inference_server.py", line 103, in _run_transformer_batch
    return method(states, n=n, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/agent/transformer.py", line 92, in generate_tactics_batch
    tactics_ids = self.model.generate(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 2482, in generate
    input_ids, model_kwargs = self._expand_inputs_for_generation(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 955, in _expand_inputs_for_generation
    model_kwargs["encoder_outputs"] = _expand_dict_for_generation(model_kwargs["encoder_outputs"])
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 944, in _expand_dict_for_generation
    dict_to_expand[key] = dict_to_expand[key].repeat_interleave(expand_size, dim=0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacity of 39.49 GiB of which 492.75 MiB is free. Including non-PyTorch memory, this process has 39.00 GiB memory in use. Of the allocated memory 31.78 GiB is allocated by PyTorch, and 6.73 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/training/inference_server.py", line 103, in _run_transformer_batch
    return method(states, n=n, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/agent/transformer.py", line 92, in generate_tactics_batch
    tactics_ids = self.model.generate(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 2564, in generate
    result = decoding_method(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 3265, in _beam_search
    model_outputs = self(**model_inputs, return_dict=True)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 1764, in forward
    decoder_outputs = self.decoder(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 1100, in forward
    layer_outputs = layer_module(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 687, in forward
    self_attention_outputs = self.layer[0](
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 603, in forward
    attention_output = self.SelfAttention(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 521, in forward
    key_states, value_states = curr_past_key_value.update(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/cache_utils.py", line 776, in update
    keys, values = self.layers[layer_idx].update(key_states, value_states, cache_kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/cache_utils.py", line 120, in update
    self.values = torch.cat([self.values, value_states], dim=-2)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 158.75 MiB is free. Including non-PyTorch memory, this process has 39.33 GiB memory in use. Of the allocated memory 36.86 GiB is allocated by PyTorch, and 1.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/training/inference_server.py", line 103, in _run_transformer_batch
    return method(states, n=n, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/agent/transformer.py", line 92, in generate_tactics_batch
    tactics_ids = self.model.generate(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 2564, in generate
    result = decoding_method(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 3377, in _beam_search
    model_kwargs["past_key_values"].reorder_cache(beam_idx)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/cache_utils.py", line 1308, in reorder_cache
    self.self_attention_cache.reorder_cache(beam_idx)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/cache_utils.py", line 832, in reorder_cache
    self.layers[layer_idx].reorder_cache(beam_idx)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/cache_utils.py", line 80, in reorder_cache
    self.keys = self.keys.index_select(0, beam_idx.to(self.keys.device))
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 66.75 MiB is free. Including non-PyTorch memory, this process has 39.42 GiB memory in use. Of the allocated memory 37.96 GiB is allocated by PyTorch, and 991.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/training/inference_server.py", line 103, in _run_transformer_batch
    return method(states, n=n, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/agent/transformer.py", line 92, in generate_tactics_batch
    tactics_ids = self.model.generate(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 2564, in generate
    result = decoding_method(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 3265, in _beam_search
    model_outputs = self(**model_inputs, return_dict=True)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 1764, in forward
    decoder_outputs = self.decoder(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 1100, in forward
    layer_outputs = layer_module(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 687, in forward
    self_attention_outputs = self.layer[0](
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 603, in forward
    attention_output = self.SelfAttention(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 521, in forward
    key_states, value_states = curr_past_key_value.update(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/cache_utils.py", line 776, in update
    keys, values = self.layers[layer_idx].update(key_states, value_states, cache_kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/cache_utils.py", line 119, in update
    self.keys = torch.cat([self.keys, key_states], dim=-2)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 20.75 MiB is free. Including non-PyTorch memory, this process has 39.46 GiB memory in use. Of the allocated memory 38.51 GiB is allocated by PyTorch, and 475.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/training/inference_server.py", line 103, in _run_transformer_batch
    return method(states, n=n, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/agent/transformer.py", line 92, in generate_tactics_batch
    tactics_ids = self.model.generate(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 2564, in generate
    result = decoding_method(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 3377, in _beam_search
    model_kwargs["past_key_values"].reorder_cache(beam_idx)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/cache_utils.py", line 1308, in reorder_cache
    self.self_attention_cache.reorder_cache(beam_idx)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/cache_utils.py", line 832, in reorder_cache
    self.layers[layer_idx].reorder_cache(beam_idx)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/cache_utils.py", line 80, in reorder_cache
    self.keys = self.keys.index_select(0, beam_idx.to(self.keys.device))
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 2.75 MiB is free. Including non-PyTorch memory, this process has 39.48 GiB memory in use. Of the allocated memory 38.72 GiB is allocated by PyTorch, and 277.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/training/train.py", line 382, in <module>
    main(args)
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/training/train.py", line 371, in main
    raise e
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/training/train.py", line 279, in main
    processed_batch = inference_server.process_requests()
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/training/inference_server.py", line 46, in process_requests
    self._process_batch(batch_requests)
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/training/inference_server.py", line 93, in _process_batch
    self._execute_batch(current_type, current_batch, current_indices)
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/training/inference_server.py", line 150, in _execute_batch
    all_results = self._run_transformer_batch(
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/training/inference_server.py", line 118, in _run_transformer_batch
    left = self._run_transformer_batch(method, states[:mid], n, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/training/inference_server.py", line 119, in _run_transformer_batch
    right = self._run_transformer_batch(method, states[mid:], n, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/training/inference_server.py", line 119, in _run_transformer_batch
    right = self._run_transformer_batch(method, states[mid:], n, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/training/inference_server.py", line 99, in _run_transformer_batch
    right = self._run_transformer_batch(method, states[mid:], n, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/training/inference_server.py", line 98, in _run_transformer_batch
    left = self._run_transformer_batch(method, states[:mid], n, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/training/inference_server.py", line 118, in _run_transformer_batch
    left = self._run_transformer_batch(method, states[:mid], n, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/training/inference_server.py", line 119, in _run_transformer_batch
    right = self._run_transformer_batch(method, states[mid:], n, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/training/inference_server.py", line 107, in _run_transformer_batch
    raise RuntimeError(f"OOM even with single sample! n={n}")
RuntimeError: OOM even with single sample! n=16
Traceback (most recent call last):
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/training/inference_server.py", line 103, in _run_transformer_batch
    return method(states, n=n, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/agent/transformer.py", line 92, in generate_tactics_batch
    tactics_ids = self.model.generate(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 2564, in generate
    result = decoding_method(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 3377, in _beam_search
    model_kwargs["past_key_values"].reorder_cache(beam_idx)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/cache_utils.py", line 1309, in reorder_cache
    self.cross_attention_cache.reorder_cache(beam_idx)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/cache_utils.py", line 832, in reorder_cache
    self.layers[layer_idx].reorder_cache(beam_idx)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/cache_utils.py", line 80, in reorder_cache
    self.keys = self.keys.index_select(0, beam_idx.to(self.keys.device))
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacity of 39.49 GiB of which 494.75 MiB is free. Including non-PyTorch memory, this process has 39.00 GiB memory in use. Of the allocated memory 31.62 GiB is allocated by PyTorch, and 6.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/training/inference_server.py", line 103, in _run_transformer_batch
    return method(states, n=n, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/agent/transformer.py", line 92, in generate_tactics_batch
    tactics_ids = self.model.generate(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 2482, in generate
    input_ids, model_kwargs = self._expand_inputs_for_generation(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 955, in _expand_inputs_for_generation
    model_kwargs["encoder_outputs"] = _expand_dict_for_generation(model_kwargs["encoder_outputs"])
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 944, in _expand_dict_for_generation
    dict_to_expand[key] = dict_to_expand[key].repeat_interleave(expand_size, dim=0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.45 GiB. GPU 0 has a total capacity of 39.49 GiB of which 492.75 MiB is free. Including non-PyTorch memory, this process has 39.00 GiB memory in use. Of the allocated memory 31.78 GiB is allocated by PyTorch, and 6.73 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/training/inference_server.py", line 103, in _run_transformer_batch
    return method(states, n=n, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/agent/transformer.py", line 92, in generate_tactics_batch
    tactics_ids = self.model.generate(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 2564, in generate
    result = decoding_method(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 3265, in _beam_search
    model_outputs = self(**model_inputs, return_dict=True)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 1764, in forward
    decoder_outputs = self.decoder(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 1100, in forward
    layer_outputs = layer_module(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 687, in forward
    self_attention_outputs = self.layer[0](
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 603, in forward
    attention_output = self.SelfAttention(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 521, in forward
    key_states, value_states = curr_past_key_value.update(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/cache_utils.py", line 776, in update
    keys, values = self.layers[layer_idx].update(key_states, value_states, cache_kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/cache_utils.py", line 120, in update
    self.values = torch.cat([self.values, value_states], dim=-2)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 158.75 MiB is free. Including non-PyTorch memory, this process has 39.33 GiB memory in use. Of the allocated memory 36.86 GiB is allocated by PyTorch, and 1.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/training/inference_server.py", line 103, in _run_transformer_batch
    return method(states, n=n, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/agent/transformer.py", line 92, in generate_tactics_batch
    tactics_ids = self.model.generate(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 2564, in generate
    result = decoding_method(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 3377, in _beam_search
    model_kwargs["past_key_values"].reorder_cache(beam_idx)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/cache_utils.py", line 1308, in reorder_cache
    self.self_attention_cache.reorder_cache(beam_idx)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/cache_utils.py", line 832, in reorder_cache
    self.layers[layer_idx].reorder_cache(beam_idx)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/cache_utils.py", line 80, in reorder_cache
    self.keys = self.keys.index_select(0, beam_idx.to(self.keys.device))
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 66.75 MiB is free. Including non-PyTorch memory, this process has 39.42 GiB memory in use. Of the allocated memory 37.96 GiB is allocated by PyTorch, and 991.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/training/inference_server.py", line 103, in _run_transformer_batch
    return method(states, n=n, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/agent/transformer.py", line 92, in generate_tactics_batch
    tactics_ids = self.model.generate(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 2564, in generate
    result = decoding_method(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 3265, in _beam_search
    model_outputs = self(**model_inputs, return_dict=True)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 1764, in forward
    decoder_outputs = self.decoder(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 1100, in forward
    layer_outputs = layer_module(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 687, in forward
    self_attention_outputs = self.layer[0](
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 603, in forward
    attention_output = self.SelfAttention(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py", line 521, in forward
    key_states, value_states = curr_past_key_value.update(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/cache_utils.py", line 776, in update
    keys, values = self.layers[layer_idx].update(key_states, value_states, cache_kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/cache_utils.py", line 119, in update
    self.keys = torch.cat([self.keys, key_states], dim=-2)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 20.75 MiB is free. Including non-PyTorch memory, this process has 39.46 GiB memory in use. Of the allocated memory 38.51 GiB is allocated by PyTorch, and 475.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/training/inference_server.py", line 103, in _run_transformer_batch
    return method(states, n=n, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/agent/transformer.py", line 92, in generate_tactics_batch
    tactics_ids = self.model.generate(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 2564, in generate
    result = decoding_method(
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/generation/utils.py", line 3377, in _beam_search
    model_kwargs["past_key_values"].reorder_cache(beam_idx)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/cache_utils.py", line 1308, in reorder_cache
    self.self_attention_cache.reorder_cache(beam_idx)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/cache_utils.py", line 832, in reorder_cache
    self.layers[layer_idx].reorder_cache(beam_idx)
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/transformers/cache_utils.py", line 80, in reorder_cache
    self.keys = self.keys.index_select(0, beam_idx.to(self.keys.device))
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 2.75 MiB is free. Including non-PyTorch memory, this process has 39.48 GiB memory in use. Of the allocated memory 38.72 GiB is allocated by PyTorch, and 277.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/training/train.py", line 382, in <module>
    main(args)
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/training/train.py", line 371, in main
    raise e
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/training/train.py", line 279, in main
    processed_batch = inference_server.process_requests()
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/training/inference_server.py", line 46, in process_requests
    self._process_batch(batch_requests)
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/training/inference_server.py", line 93, in _process_batch
    self._execute_batch(current_type, current_batch, current_indices)
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/training/inference_server.py", line 150, in _execute_batch
    all_results = self._run_transformer_batch(
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/training/inference_server.py", line 118, in _run_transformer_batch
    left = self._run_transformer_batch(method, states[:mid], n, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/training/inference_server.py", line 119, in _run_transformer_batch
    right = self._run_transformer_batch(method, states[mid:], n, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/training/inference_server.py", line 119, in _run_transformer_batch
    right = self._run_transformer_batch(method, states[mid:], n, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/training/inference_server.py", line 99, in _run_transformer_batch
    right = self._run_transformer_batch(method, states[mid:], n, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/training/inference_server.py", line 98, in _run_transformer_batch
    left = self._run_transformer_batch(method, states[:mid], n, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/training/inference_server.py", line 118, in _run_transformer_batch
    left = self._run_transformer_batch(method, states[:mid], n, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/training/inference_server.py", line 119, in _run_transformer_batch
    right = self._run_transformer_batch(method, states[mid:], n, **kwargs)
  File "/gpfs/home1/gkoopman/lean_reinforcement/src/training/inference_server.py", line 107, in _run_transformer_batch
    raise RuntimeError(f"OOM even with single sample! n={n}")
RuntimeError: OOM even with single sample! n=16
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
[2025-12-05T17:34:53.312] error: *** JOB 17249913 ON gcn31 CANCELLED AT 2025-12-05T17:34:53 DUE to SIGNAL Terminated ***
[2025-12-05T17:34:53.312] error: *** STEP 17249913.0 ON gcn31 CANCELLED AT 2025-12-05T17:34:53 DUE to SIGNAL Terminated ***
