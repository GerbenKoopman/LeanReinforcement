============================================================================================== 
Warning! Mixing Conda and module environments may lead to corruption of the
user environment. 
We do not recommend users mixing those two environments unless absolutely
necessary. Note that 
SURF does not provide any support for Conda environment.
For more information, please refer to our software policy page:
https://servicedesk.surf.nl/wiki/display/WIKI/Software+policy+Snellius#SoftwarepolicySnellius-UseofAnacondaandMinicondaenvironmentsonSnellius 

Remember that many packages have already been installed on the system and can
be loaded using 
the 'module load <package__name>' command. If you are uncertain if a package is
already available 
on the system, please use 'module avail' or 'module spider' to search for it.
============================================================================================== 
Starting training run with distributed environment...
wandb: Currently logged in as: gerbennkoopman to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: setting up run e8kh6nim
wandb: Tracking run with wandb version 0.22.3
wandb: Run data is saved locally in /gpfs/home1/gkoopman/lean_reinforcement/wandb/run-20251215_105731-e8kh6nim
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-cherry-30
wandb: ‚≠êÔ∏è View project at https://wandb.ai/gerbennkoopman-university-of-amsterdam/lean-reinforcement
wandb: üöÄ View run at https://wandb.ai/gerbennkoopman-university-of-amsterdam/lean-reinforcement/runs/e8kh6nim
2025-12-15 10:57:33.187 | INFO     | __main__:main:186 - Using checkpoint directory: /gpfs/scratch1/shared/lean-reinforcement/checkpoints
2025-12-15 10:57:36.535 | INFO     | lean_reinforcement.agent.value_head:load_checkpoint:192 - Checkpoint loaded from /gpfs/scratch1/shared/lean-reinforcement/checkpoints/value_head_latest.pth
2025-12-15 10:57:36.535 | INFO     | __main__:main:199 - Resuming training from epoch 3
2025-12-15 10:57:36.536 | INFO     | __main__:log_gpu_memory:170 - After model initialization - GPU Memory: 1.12GB allocated, 1.23GB reserved
2025-12-15 10:57:36.536 | INFO     | __main__:main:204 - Loading data from 'leandojo_benchmark_4/novel_premises'
2025-12-15 10:57:36.536 | INFO     | ReProver.common:__init__:201 - Building the corpus from leandojo_benchmark_4/corpus.jsonl
2025-12-15 10:58:21.926 | INFO     | lean_dojo.data_extraction.trace:trace:248 - Loading the traced repo from /gpfs/scratch1/shared/lean-reinforcement/datasets/lean_dojo_cache/leanprover-community-mathlib4-29dcec074de168ac2bf835a77ef68bbe069194c5/mathlib4
2025-12-15 10:58:48,727	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
  0%|          | 0/5674 [00:00<?, ?it/s]  0%|          | 1/5674 [00:05<9:06:11,  5.78s/it]  0%|          | 9/5674 [00:05<45:12,  2.09it/s]    0%|          | 13/5674 [00:06<28:28,  3.31it/s]  0%|          | 19/5674 [00:06<16:14,  5.81it/s]  0%|          | 24/5674 [00:06<11:43,  8.03it/s]  1%|          | 35/5674 [00:10<25:20,  3.71it/s]  1%|          | 38/5674 [00:10<21:34,  4.35it/s]  1%|          | 43/5674 [00:10<15:53,  5.90it/s]  1%|          | 48/5674 [00:11<11:53,  7.88it/s]  1%|          | 52/5674 [00:11<10:00,  9.36it/s]  1%|          | 56/5674 [00:11<08:07, 11.52it/s]  1%|          | 60/5674 [00:16<38:23,  2.44it/s]  1%|          | 63/5674 [00:16<31:00,  3.02it/s]  1%|          | 67/5674 [00:16<22:48,  4.10it/s]  1%|          | 70/5674 [00:16<18:16,  5.11it/s]  1%|‚ñè         | 75/5674 [00:17<12:28,  7.48it/s]  1%|‚ñè         | 79/5674 [00:17<09:42,  9.60it/s]  2%|‚ñè         | 86/5674 [00:17<06:11, 15.05it/s]  2%|‚ñè         | 93/5674 [00:22<31:37,  2.94it/s]  2%|‚ñè         | 97/5674 [00:22<24:47,  3.75it/s]  2%|‚ñè         | 100/5674 [00:23<20:58,  4.43it/s]  2%|‚ñè         | 103/5674 [00:23<18:00,  5.16it/s]  2%|‚ñè         | 106/5674 [00:23<14:44,  6.30it/s]  2%|‚ñè         | 109/5674 [00:23<11:54,  7.79it/s]  2%|‚ñè         | 114/5674 [00:23<08:06, 11.43it/s]  2%|‚ñè         | 119/5674 [00:23<06:26, 14.37it/s]  2%|‚ñè         | 122/5674 [00:30<52:52,  1.75it/s]  2%|‚ñè         | 125/5674 [00:30<41:31,  2.23it/s]  2%|‚ñè         | 130/5674 [00:31<26:49,  3.44it/s]  2%|‚ñè         | 133/5674 [00:31<21:21,  4.32it/s]  2%|‚ñè         | 139/5674 [00:31<13:20,  6.91it/s]  3%|‚ñé         | 143/5674 [00:31<11:17,  8.16it/s]  3%|‚ñé         | 149/5674 [00:31<07:40, 11.99it/s]  3%|‚ñé         | 153/5674 [00:31<06:20, 14.49it/s]  3%|‚ñé         | 157/5674 [00:39<51:47,  1.78it/s]  3%|‚ñé         | 160/5674 [00:39<40:54,  2.25it/s]  3%|‚ñé         | 163/5674 [00:39<32:05,  2.86it/s]  3%|‚ñé         | 170/5674 [00:39<18:20,  5.00it/s]  3%|‚ñé         | 174/5674 [00:39<14:18,  6.41it/s]  3%|‚ñé         | 178/5674 [00:39<11:21,  8.06it/s]  3%|‚ñé         | 182/5674 [00:40<09:44,  9.40it/s]  3%|‚ñé         | 190/5674 [00:40<06:00, 15.23it/s]  3%|‚ñé         | 195/5674 [00:40<04:51, 18.80it/s]  4%|‚ñé         | 203/5674 [00:40<03:29, 26.08it/s]  4%|‚ñé         | 208/5674 [00:40<03:05, 29.52it/s]  4%|‚ñç         | 217/5674 [00:40<02:19, 39.26it/s]  4%|‚ñç         | 231/5674 [00:49<27:04,  3.35it/s]  4%|‚ñç         | 238/5674 [00:49<20:35,  4.40it/s]  4%|‚ñç         | 243/5674 [00:49<16:47,  5.39it/s]  4%|‚ñç         | 248/5674 [00:49<13:36,  6.65it/s]  4%|‚ñç         | 253/5674 [00:49<10:51,  8.33it/s]  5%|‚ñç         | 258/5674 [00:50<09:26,  9.56it/s]  5%|‚ñç         | 266/5674 [00:50<06:25, 14.03it/s]  5%|‚ñç         | 271/5674 [00:50<05:29, 16.38it/s]  5%|‚ñç         | 276/5674 [00:50<05:00, 17.94it/s]  5%|‚ñç         | 280/5674 [00:50<04:35, 19.60it/s]  5%|‚ñå         | 286/5674 [00:50<03:50, 23.39it/s]  5%|‚ñå         | 290/5674 [00:50<03:33, 25.17it/s]  5%|‚ñå         | 297/5674 [00:51<02:55, 30.70it/s]  5%|‚ñå         | 301/5674 [00:51<03:07, 28.69it/s]  5%|‚ñå         | 305/5674 [01:00<56:07,  1.59it/s]  5%|‚ñå         | 308/5674 [01:01<45:08,  1.98it/s]  6%|‚ñå         | 315/5674 [01:01<26:58,  3.31it/s]  6%|‚ñå         | 320/5674 [01:01<19:29,  4.58it/s]  6%|‚ñå         | 325/5674 [01:01<14:17,  6.24it/s]  6%|‚ñå         | 331/5674 [01:01<09:57,  8.94it/s]  6%|‚ñå         | 340/5674 [01:01<06:12, 14.33it/s]  6%|‚ñå         | 346/5674 [01:01<04:53, 18.13it/s]  6%|‚ñå         | 353/5674 [01:01<03:53, 22.76it/s]  6%|‚ñã         | 360/5674 [01:01<03:11, 27.71it/s]  6%|‚ñã         | 368/5674 [01:02<02:32, 34.75it/s]  7%|‚ñã         | 374/5674 [01:02<02:23, 37.00it/s]  7%|‚ñã         | 381/5674 [01:02<02:06, 41.90it/s]  7%|‚ñã         | 390/5674 [01:02<01:49, 48.30it/s]  7%|‚ñã         | 397/5674 [01:02<01:40, 52.71it/s]  7%|‚ñã         | 404/5674 [01:03<03:50, 22.85it/s]  7%|‚ñã         | 410/5674 [01:03<03:14, 27.03it/s]  7%|‚ñã         | 415/5674 [01:03<02:59, 29.24it/s]  7%|‚ñã         | 422/5674 [01:03<02:30, 34.82it/s]  8%|‚ñä         | 427/5674 [01:03<02:28, 35.32it/s]  8%|‚ñä         | 436/5674 [01:03<02:03, 42.58it/s]  8%|‚ñä         | 452/5674 [01:04<01:19, 65.72it/s]  8%|‚ñä         | 464/5674 [01:04<01:11, 73.02it/s]  8%|‚ñä         | 473/5674 [01:04<01:07, 76.73it/s]  8%|‚ñä         | 482/5674 [01:04<01:09, 74.40it/s]  9%|‚ñä         | 491/5674 [01:04<01:21, 63.27it/s]  9%|‚ñä         | 491/5674 [01:16<01:21, 63.27it/s]  9%|‚ñâ         | 497/5674 [01:16<36:47,  2.35it/s]  9%|‚ñâ         | 501/5674 [01:16<31:06,  2.77it/s]  9%|‚ñâ         | 507/5674 [01:16<23:43,  3.63it/s]  9%|‚ñâ         | 512/5674 [01:16<18:26,  4.67it/s]  9%|‚ñâ         | 518/5674 [01:16<13:35,  6.32it/s]  9%|‚ñâ         | 523/5674 [01:16<10:36,  8.09it/s]  9%|‚ñâ         | 528/5674 [01:17<08:32, 10.03it/s]  9%|‚ñâ         | 538/5674 [01:17<05:13, 16.40it/s] 10%|‚ñâ         | 545/5674 [01:17<04:00, 21.34it/s] 10%|‚ñâ         | 552/5674 [01:17<03:35, 23.78it/s] 10%|‚ñâ         | 558/5674 [01:17<03:21, 25.37it/s] 10%|‚ñà         | 568/5674 [01:17<02:25, 35.14it/s] 10%|‚ñà         | 574/5674 [01:17<02:12, 38.45it/s] 10%|‚ñà         | 584/5674 [01:18<01:43, 49.31it/s] 10%|‚ñà         | 591/5674 [01:18<01:36, 52.84it/s] 11%|‚ñà         | 602/5674 [01:18<01:17, 65.57it/s] 11%|‚ñà         | 610/5674 [01:18<01:14, 67.94it/s] 11%|‚ñà         | 618/5674 [01:18<01:19, 63.29it/s] 11%|‚ñà         | 626/5674 [01:18<01:15, 66.89it/s] 11%|‚ñà         | 634/5674 [01:18<01:19, 63.68it/s] 11%|‚ñà‚ñè        | 641/5674 [01:19<01:43, 48.86it/s] 11%|‚ñà‚ñè        | 647/5674 [01:19<01:39, 50.76it/s] 12%|‚ñà‚ñè        | 653/5674 [01:19<01:35, 52.39it/s] 12%|‚ñà‚ñè        | 653/5674 [01:32<01:35, 52.39it/s] 12%|‚ñà‚ñè        | 654/5674 [01:32<1:07:20,  1.24it/s] 12%|‚ñà‚ñè        | 661/5674 [01:32<42:57,  1.95it/s]   12%|‚ñà‚ñè        | 668/5674 [01:32<28:31,  2.93it/s] 12%|‚ñà‚ñè        | 675/5674 [01:33<19:39,  4.24it/s] 12%|‚ñà‚ñè        | 681/5674 [01:33<14:33,  5.72it/s] 12%|‚ñà‚ñè        | 687/5674 [01:33<10:48,  7.69it/s] 12%|‚ñà‚ñè        | 695/5674 [01:33<07:18, 11.35it/s] 12%|‚ñà‚ñè        | 701/5674 [01:33<05:45, 14.40it/s] 12%|‚ñà‚ñè        | 707/5674 [01:33<04:32, 18.21it/s] 13%|‚ñà‚ñé        | 713/5674 [01:33<03:44, 22.10it/s] 13%|‚ñà‚ñé        | 719/5674 [01:33<03:26, 23.98it/s] 13%|‚ñà‚ñé        | 724/5674 [01:34<03:05, 26.62it/s] 13%|‚ñà‚ñé        | 729/5674 [01:34<02:52, 28.59it/s] 13%|‚ñà‚ñé        | 734/5674 [01:34<02:44, 29.95it/s] 13%|‚ñà‚ñé        | 738/5674 [01:34<02:38, 31.19it/s] 13%|‚ñà‚ñé        | 745/5674 [01:34<02:16, 36.10it/s] 13%|‚ñà‚ñé        | 752/5674 [01:34<02:02, 40.20it/s] 13%|‚ñà‚ñé        | 759/5674 [01:34<01:56, 42.07it/s] 13%|‚ñà‚ñé        | 764/5674 [01:35<02:28, 33.10it/s] 14%|‚ñà‚ñé        | 769/5674 [01:35<02:17, 35.65it/s] 14%|‚ñà‚ñé        | 778/5674 [01:35<02:07, 38.40it/s] 14%|‚ñà‚ñç        | 787/5674 [01:35<01:43, 47.31it/s] 14%|‚ñà‚ñç        | 793/5674 [01:35<01:57, 41.66it/s] 14%|‚ñà‚ñç        | 798/5674 [01:35<02:01, 40.16it/s] 14%|‚ñà‚ñç        | 808/5674 [01:36<01:34, 51.64it/s] 14%|‚ñà‚ñç        | 814/5674 [01:36<01:59, 40.67it/s] 14%|‚ñà‚ñç        | 820/5674 [01:36<01:50, 43.89it/s] 14%|‚ñà‚ñç        | 820/5674 [01:52<01:50, 43.89it/s] 14%|‚ñà‚ñç        | 822/5674 [01:52<1:15:32,  1.07it/s] 15%|‚ñà‚ñç        | 825/5674 [01:52<1:01:30,  1.31it/s] 15%|‚ñà‚ñç        | 830/5674 [01:52<42:40,  1.89it/s]   15%|‚ñà‚ñç        | 834/5674 [01:52<32:00,  2.52it/s] 15%|‚ñà‚ñç        | 841/5674 [01:53<19:41,  4.09it/s] 15%|‚ñà‚ñç        | 846/5674 [01:53<15:04,  5.34it/s] 15%|‚ñà‚ñç        | 851/5674 [01:53<11:11,  7.18it/s] 15%|‚ñà‚ñå        | 855/5674 [01:53<08:57,  8.97it/s] 15%|‚ñà‚ñå        | 859/5674 [01:53<07:23, 10.85it/s] 15%|‚ñà‚ñå        | 864/5674 [01:53<05:32, 14.47it/s] 15%|‚ñà‚ñå        | 870/5674 [01:53<04:13, 18.93it/s] 15%|‚ñà‚ñå        | 875/5674 [01:54<03:50, 20.80it/s] 16%|‚ñà‚ñå        | 880/5674 [01:54<03:21, 23.81it/s] 16%|‚ñà‚ñå        | 887/5674 [01:54<02:32, 31.43it/s] 16%|‚ñà‚ñå        | 895/5674 [01:54<02:03, 38.67it/s] 16%|‚ñà‚ñå        | 902/5674 [01:54<01:46, 44.88it/s] 16%|‚ñà‚ñå        | 908/5674 [01:54<01:51, 42.81it/s] 16%|‚ñà‚ñå        | 915/5674 [01:54<01:50, 43.06it/s] 16%|‚ñà‚ñã        | 923/5674 [01:55<01:34, 50.42it/s] 16%|‚ñà‚ñã        | 929/5674 [01:55<01:38, 48.41it/s] 16%|‚ñà‚ñã        | 935/5674 [01:55<01:40, 47.11it/s] 17%|‚ñà‚ñã        | 941/5674 [01:55<01:40, 47.28it/s] 17%|‚ñà‚ñã        | 947/5674 [01:55<01:34, 50.27it/s] 17%|‚ñà‚ñã        | 953/5674 [01:55<02:02, 38.68it/s] 17%|‚ñà‚ñã        | 958/5674 [01:55<02:10, 36.06it/s] 17%|‚ñà‚ñã        | 962/5674 [01:56<02:21, 33.29it/s] 17%|‚ñà‚ñã        | 966/5674 [01:56<02:25, 32.40it/s] 17%|‚ñà‚ñã        | 973/5674 [01:56<01:59, 39.22it/s] 17%|‚ñà‚ñã        | 980/5674 [01:56<01:44, 44.84it/s] 17%|‚ñà‚ñã        | 985/5674 [01:56<01:46, 44.01it/s] 17%|‚ñà‚ñã        | 990/5674 [01:56<02:11, 35.51it/s] 18%|‚ñà‚ñä        | 996/5674 [01:56<02:06, 37.10it/s] 18%|‚ñà‚ñä        | 996/5674 [02:16<02:06, 37.10it/s] 18%|‚ñà‚ñä        | 1002/5674 [02:16<1:21:26,  1.05s/it] 18%|‚ñà‚ñä        | 1006/5674 [02:16<1:03:34,  1.22it/s] 18%|‚ñà‚ñä        | 1013/5674 [02:16<40:46,  1.90it/s]   18%|‚ñà‚ñä        | 1019/5674 [02:17<28:33,  2.72it/s] 18%|‚ñà‚ñä        | 1024/5674 [02:17<22:05,  3.51it/s] 18%|‚ñà‚ñä        | 1032/5674 [02:17<14:02,  5.51it/s] 18%|‚ñà‚ñä        | 1042/5674 [02:17<08:39,  8.92it/s] 18%|‚ñà‚ñä        | 1049/5674 [02:17<06:44, 11.44it/s] 19%|‚ñà‚ñä        | 1055/5674 [02:17<05:46, 13.34it/s] 19%|‚ñà‚ñä        | 1062/5674 [02:18<04:28, 17.20it/s] 19%|‚ñà‚ñâ        | 1069/5674 [02:18<03:29, 22.02it/s] 19%|‚ñà‚ñâ        | 1075/5674 [02:18<02:53, 26.49it/s] 19%|‚ñà‚ñâ        | 1082/5674 [02:18<02:20, 32.61it/s] 19%|‚ñà‚ñâ        | 1088/5674 [02:18<02:03, 37.02it/s] 19%|‚ñà‚ñâ        | 1094/5674 [02:18<01:56, 39.45it/s] 19%|‚ñà‚ñâ        | 1100/5674 [02:18<01:56, 39.32it/s] 20%|‚ñà‚ñâ        | 1108/5674 [02:18<01:44, 43.49it/s] 20%|‚ñà‚ñâ        | 1114/5674 [02:19<02:07, 35.90it/s] 20%|‚ñà‚ñâ        | 1120/5674 [02:19<01:53, 40.19it/s] 20%|‚ñà‚ñâ        | 1130/5674 [02:19<01:28, 51.40it/s] 20%|‚ñà‚ñà        | 1138/5674 [02:19<01:29, 50.41it/s] 20%|‚ñà‚ñà        | 1144/5674 [02:19<01:48, 41.62it/s] 20%|‚ñà‚ñà        | 1152/5674 [02:19<01:31, 49.26it/s] 21%|‚ñà‚ñà        | 1164/5674 [02:19<01:12, 61.82it/s] 21%|‚ñà‚ñà        | 1183/5674 [02:20<00:49, 91.41it/s] 21%|‚ñà‚ñà        | 1196/5674 [02:20<00:45, 97.61it/s] 21%|‚ñà‚ñà‚ñè       | 1212/5674 [02:20<00:39, 113.28it/s] 22%|‚ñà‚ñà‚ñè       | 1225/5674 [02:20<00:38, 116.57it/s] 22%|‚ñà‚ñà‚ñè       | 1238/5674 [02:20<00:37, 118.66it/s] 22%|‚ñà‚ñà‚ñè       | 1254/5674 [02:20<00:34, 129.87it/s] 22%|‚ñà‚ñà‚ñè       | 1273/5674 [02:20<00:30, 144.83it/s] 23%|‚ñà‚ñà‚ñé       | 1288/5674 [02:20<00:32, 135.88it/s] 23%|‚ñà‚ñà‚ñé       | 1302/5674 [02:20<00:33, 130.87it/s] 23%|‚ñà‚ñà‚ñé       | 1318/5674 [02:21<00:31, 138.29it/s] 23%|‚ñà‚ñà‚ñé       | 1333/5674 [02:21<00:36, 118.22it/s] 24%|‚ñà‚ñà‚ñé       | 1346/5674 [02:21<00:38, 111.63it/s] 24%|‚ñà‚ñà‚ñç       | 1358/5674 [02:21<00:50, 85.88it/s]  24%|‚ñà‚ñà‚ñç       | 1368/5674 [02:21<00:54, 79.31it/s] 24%|‚ñà‚ñà‚ñç       | 1377/5674 [02:21<00:59, 71.97it/s] 24%|‚ñà‚ñà‚ñç       | 1388/5674 [02:22<00:55, 77.84it/s] 24%|‚ñà‚ñà‚ñç       | 1388/5674 [02:45<00:55, 77.84it/s] 24%|‚ñà‚ñà‚ñç       | 1390/5674 [02:45<1:00:24,  1.18it/s] 25%|‚ñà‚ñà‚ñç       | 1394/5674 [02:45<50:35,  1.41it/s]   25%|‚ñà‚ñà‚ñç       | 1402/5674 [02:46<34:41,  2.05it/s] 25%|‚ñà‚ñà‚ñç       | 1409/5674 [02:46<25:08,  2.83it/s] 25%|‚ñà‚ñà‚ñç       | 1415/5674 [02:46<19:21,  3.67it/s] 25%|‚ñà‚ñà‚ñå       | 1424/5674 [02:46<12:42,  5.57it/s] 25%|‚ñà‚ñà‚ñå       | 1430/5674 [02:46<09:56,  7.11it/s] 25%|‚ñà‚ñà‚ñå       | 1436/5674 [02:47<07:55,  8.92it/s] 25%|‚ñà‚ñà‚ñå       | 1441/5674 [02:47<06:21, 11.09it/s] 26%|‚ñà‚ñà‚ñå       | 1448/5674 [02:47<04:42, 14.98it/s] 26%|‚ñà‚ñà‚ñå       | 1454/5674 [02:47<03:43, 18.91it/s] 26%|‚ñà‚ñà‚ñå       | 1460/5674 [02:47<03:00, 23.32it/s] 26%|‚ñà‚ñà‚ñå       | 1466/5674 [02:47<02:34, 27.23it/s] 26%|‚ñà‚ñà‚ñå       | 1472/5674 [02:47<02:15, 31.00it/s] 26%|‚ñà‚ñà‚ñå       | 1477/5674 [02:47<02:05, 33.32it/s] 26%|‚ñà‚ñà‚ñå       | 1485/5674 [02:47<01:39, 42.04it/s] 26%|‚ñà‚ñà‚ñã       | 1491/5674 [02:48<02:15, 30.90it/s] 26%|‚ñà‚ñà‚ñã       | 1497/5674 [02:48<01:57, 35.69it/s] 26%|‚ñà‚ñà‚ñã       | 1502/5674 [02:48<01:52, 37.07it/s] 27%|‚ñà‚ñà‚ñã       | 1507/5674 [02:48<01:54, 36.28it/s] 27%|‚ñà‚ñà‚ñã       | 1517/5674 [02:48<01:29, 46.44it/s] 27%|‚ñà‚ñà‚ñã       | 1523/5674 [02:48<01:36, 43.01it/s] 27%|‚ñà‚ñà‚ñã       | 1528/5674 [02:49<01:56, 35.48it/s] 27%|‚ñà‚ñà‚ñã       | 1539/5674 [02:49<01:23, 49.71it/s] 27%|‚ñà‚ñà‚ñã       | 1545/5674 [02:49<01:28, 46.80it/s] 27%|‚ñà‚ñà‚ñã       | 1551/5674 [02:49<01:57, 35.14it/s] 27%|‚ñà‚ñà‚ñã       | 1556/5674 [02:49<01:50, 37.38it/s] 28%|‚ñà‚ñà‚ñä       | 1561/5674 [02:49<01:51, 36.82it/s] 28%|‚ñà‚ñà‚ñä       | 1566/5674 [02:50<01:58, 34.76it/s] 28%|‚ñà‚ñà‚ñä       | 1570/5674 [02:50<02:12, 31.06it/s] 28%|‚ñà‚ñà‚ñä       | 1574/5674 [02:50<02:08, 31.89it/s] 28%|‚ñà‚ñà‚ñä       | 1578/5674 [02:50<02:09, 31.65it/s] 28%|‚ñà‚ñà‚ñä       | 1582/5674 [02:50<03:00, 22.64it/s] 28%|‚ñà‚ñà‚ñä       | 1586/5674 [02:50<02:45, 24.77it/s] 28%|‚ñà‚ñà‚ñä       | 1590/5674 [02:51<02:27, 27.69it/s] 28%|‚ñà‚ñà‚ñä       | 1594/5674 [02:51<02:15, 30.19it/s] 28%|‚ñà‚ñà‚ñä       | 1601/5674 [02:51<01:58, 34.47it/s] 28%|‚ñà‚ñà‚ñä       | 1605/5674 [02:51<02:06, 32.17it/s] 28%|‚ñà‚ñà‚ñä       | 1613/5674 [02:51<01:40, 40.39it/s] 29%|‚ñà‚ñà‚ñä       | 1618/5674 [02:51<01:55, 34.98it/s] 29%|‚ñà‚ñà‚ñä       | 1622/5674 [02:51<01:55, 35.16it/s] 29%|‚ñà‚ñà‚ñä       | 1626/5674 [02:52<01:51, 36.14it/s] 29%|‚ñà‚ñà‚ñä       | 1630/5674 [02:52<01:57, 34.39it/s] 29%|‚ñà‚ñà‚ñä       | 1630/5674 [03:21<01:57, 34.39it/s] 29%|‚ñà‚ñà‚ñâ       | 1633/5674 [03:21<2:26:02,  2.17s/it] 29%|‚ñà‚ñà‚ñâ       | 1640/5674 [03:21<1:24:16,  1.25s/it] 29%|‚ñà‚ñà‚ñâ       | 1645/5674 [03:21<59:20,  1.13it/s]   29%|‚ñà‚ñà‚ñâ       | 1650/5674 [03:21<41:51,  1.60it/s] 29%|‚ñà‚ñà‚ñâ       | 1655/5674 [03:21<29:38,  2.26it/s] 29%|‚ñà‚ñà‚ñâ       | 1660/5674 [03:21<21:19,  3.14it/s] 29%|‚ñà‚ñà‚ñâ       | 1667/5674 [03:21<13:41,  4.88it/s] 29%|‚ñà‚ñà‚ñâ       | 1672/5674 [03:22<10:23,  6.42it/s] 30%|‚ñà‚ñà‚ñâ       | 1677/5674 [03:22<07:51,  8.48it/s] 30%|‚ñà‚ñà‚ñâ       | 1682/5674 [03:22<06:02, 11.00it/s] 30%|‚ñà‚ñà‚ñâ       | 1689/5674 [03:22<04:11, 15.87it/s] 30%|‚ñà‚ñà‚ñâ       | 1695/5674 [03:22<03:21, 19.78it/s] 30%|‚ñà‚ñà‚ñâ       | 1700/5674 [03:22<02:50, 23.25it/s] 30%|‚ñà‚ñà‚ñà       | 1708/5674 [03:22<02:11, 30.26it/s] 30%|‚ñà‚ñà‚ñà       | 1714/5674 [03:22<02:11, 30.23it/s] 30%|‚ñà‚ñà‚ñà       | 1719/5674 [03:23<01:57, 33.64it/s] 30%|‚ñà‚ñà‚ñà       | 1724/5674 [03:23<01:47, 36.58it/s] 30%|‚ñà‚ñà‚ñà       | 1729/5674 [03:23<02:07, 30.82it/s] 31%|‚ñà‚ñà‚ñà       | 1733/5674 [03:23<02:38, 24.87it/s] 31%|‚ñà‚ñà‚ñà       | 1737/5674 [03:23<02:23, 27.53it/s] 31%|‚ñà‚ñà‚ñà       | 1747/5674 [03:24<02:14, 29.25it/s] 31%|‚ñà‚ñà‚ñà       | 1759/5674 [03:24<01:29, 43.81it/s] 31%|‚ñà‚ñà‚ñà       | 1769/5674 [03:24<01:13, 53.06it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1778/5674 [03:24<01:05, 59.61it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1794/5674 [03:24<00:47, 81.67it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1804/5674 [03:24<00:48, 80.61it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1814/5674 [03:24<00:47, 80.79it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1823/5674 [03:24<00:52, 73.81it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1832/5674 [03:25<00:52, 73.81it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1840/5674 [03:25<00:57, 66.33it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1847/5674 [03:25<01:01, 61.88it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1856/5674 [03:25<00:59, 64.50it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1864/5674 [03:25<00:55, 68.16it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1874/5674 [03:25<00:49, 76.13it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1885/5674 [03:25<00:44, 84.55it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1894/5674 [03:25<00:54, 69.13it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1902/5674 [03:26<01:03, 59.86it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1909/5674 [03:26<01:08, 55.20it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1915/5674 [03:26<01:08, 55.16it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1921/5674 [03:26<01:12, 51.76it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1929/5674 [03:26<01:04, 58.22it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1936/5674 [03:26<01:01, 60.86it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1946/5674 [03:26<00:53, 69.97it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1956/5674 [03:26<00:48, 76.72it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1967/5674 [03:27<00:45, 81.37it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1976/5674 [03:27<00:46, 80.30it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1987/5674 [03:27<00:44, 83.72it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1997/5674 [03:27<00:42, 86.66it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 2006/5674 [03:27<00:43, 84.26it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 2015/5674 [03:27<00:47, 77.18it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 2023/5674 [03:27<00:47, 76.85it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 2032/5674 [03:27<00:52, 69.01it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 2040/5674 [03:28<00:52, 69.66it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 2050/5674 [03:28<00:47, 76.63it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 2058/5674 [03:28<00:57, 62.86it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 2066/5674 [03:28<00:59, 60.17it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 2073/5674 [03:28<01:02, 57.65it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 2080/5674 [03:28<01:13, 49.06it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 2086/5674 [03:28<01:10, 51.07it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 2092/5674 [03:29<01:08, 52.02it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 2092/5674 [04:03<01:08, 52.02it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 2095/5674 [04:03<1:49:14,  1.83s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 2099/5674 [04:03<1:24:15,  1.41s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 2108/5674 [04:03<48:32,  1.22it/s]   37%|‚ñà‚ñà‚ñà‚ñã      | 2114/5674 [04:03<34:49,  1.70it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 2125/5674 [04:04<20:18,  2.91it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 2134/5674 [04:04<13:43,  4.30it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 2144/5674 [04:04<09:09,  6.43it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 2154/5674 [04:04<06:17,  9.32it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 2162/5674 [04:04<05:09, 11.35it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 2169/5674 [04:04<04:03, 14.40it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 2176/5674 [04:04<03:12, 18.16it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 2183/5674 [04:05<02:37, 22.22it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 2190/5674 [04:05<02:19, 25.03it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 2196/5674 [04:05<02:09, 26.89it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 2206/5674 [04:05<01:33, 37.16it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 2213/5674 [04:05<01:27, 39.56it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 2220/5674 [04:05<01:29, 38.54it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 2226/5674 [04:06<01:35, 35.94it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 2231/5674 [04:06<01:30, 38.01it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 2236/5674 [04:06<01:53, 30.30it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 2240/5674 [04:06<02:12, 25.93it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 2244/5674 [04:06<02:02, 28.11it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 2252/5674 [04:06<01:30, 37.65it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 2257/5674 [04:07<01:27, 38.98it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 2262/5674 [04:07<01:49, 31.13it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 2266/5674 [04:07<01:58, 28.76it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 2273/5674 [04:07<01:34, 36.06it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 2279/5674 [04:07<01:27, 39.02it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 2287/5674 [04:07<01:13, 46.33it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 2294/5674 [04:07<01:05, 51.66it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 2300/5674 [04:08<01:05, 51.64it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 2307/5674 [04:08<01:02, 53.60it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 2317/5674 [04:08<00:53, 63.21it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 2324/5674 [04:08<01:32, 36.13it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 2330/5674 [04:08<01:23, 40.02it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 2336/5674 [04:08<01:24, 39.74it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2343/5674 [04:09<01:20, 41.47it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2350/5674 [04:09<01:12, 45.95it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2356/5674 [04:09<01:07, 48.83it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2364/5674 [04:09<01:04, 51.67it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2370/5674 [04:09<01:09, 47.30it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2376/5674 [04:09<01:26, 38.19it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2386/5674 [04:09<01:05, 50.49it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2397/5674 [04:10<00:51, 63.47it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2405/5674 [04:10<00:58, 56.34it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2414/5674 [04:10<01:02, 52.31it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2424/5674 [04:10<01:11, 45.74it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2432/5674 [04:10<01:03, 50.97it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2440/5674 [04:10<00:57, 56.15it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2448/5674 [04:11<01:03, 50.77it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2460/5674 [04:11<00:49, 64.32it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2468/5674 [04:11<00:49, 65.01it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2476/5674 [04:11<01:06, 48.18it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2482/5674 [04:11<01:08, 46.42it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2488/5674 [04:11<01:08, 46.57it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2494/5674 [04:12<01:10, 45.25it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2499/5674 [04:12<01:18, 40.68it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2504/5674 [04:12<01:17, 40.67it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2509/5674 [04:12<01:18, 40.23it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2516/5674 [04:12<01:07, 46.81it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2521/5674 [04:12<01:08, 46.12it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2526/5674 [04:12<01:10, 44.37it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2533/5674 [04:12<01:02, 50.04it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2539/5674 [04:13<01:06, 46.89it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2544/5674 [04:13<01:11, 43.88it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2544/5674 [04:57<01:11, 43.88it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2546/5674 [04:57<2:31:23,  2.90s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2549/5674 [04:57<1:58:30,  2.28s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2553/5674 [04:57<1:23:54,  1.61s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2557/5674 [04:57<59:26,  1.14s/it]   45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2564/5674 [04:57<34:27,  1.50it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2569/5674 [04:57<24:28,  2.11it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2575/5674 [04:57<16:25,  3.15it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2580/5674 [04:58<12:05,  4.27it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2585/5674 [04:58<09:27,  5.44it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2589/5674 [04:58<07:29,  6.86it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2593/5674 [04:58<06:02,  8.50it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2598/5674 [04:58<04:27, 11.48it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2602/5674 [04:58<03:38, 14.05it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2609/5674 [04:58<02:30, 20.37it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2617/5674 [04:59<01:46, 28.83it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2628/5674 [04:59<01:13, 41.20it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2639/5674 [04:59<01:00, 50.40it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2646/5674 [04:59<00:56, 53.14it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2653/5674 [04:59<01:05, 45.77it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2659/5674 [04:59<01:02, 48.49it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2665/5674 [04:59<00:59, 50.47it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2674/5674 [05:00<00:57, 51.80it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2681/5674 [05:00<00:56, 52.80it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2687/5674 [05:00<01:00, 49.39it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2693/5674 [05:00<00:58, 50.94it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2700/5674 [05:00<00:55, 53.56it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2706/5674 [05:00<00:55, 53.78it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2712/5674 [05:00<00:55, 53.37it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2720/5674 [05:00<00:50, 58.40it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2726/5674 [05:01<01:16, 38.66it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2732/5674 [05:01<01:10, 41.64it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2737/5674 [05:01<01:08, 42.99it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2743/5674 [05:01<01:04, 45.73it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2749/5674 [05:01<01:02, 46.73it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2754/5674 [05:01<01:05, 44.59it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2759/5674 [05:01<01:06, 43.78it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2764/5674 [05:02<01:18, 36.95it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2770/5674 [05:02<01:10, 41.32it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2776/5674 [05:02<01:07, 42.95it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2785/5674 [05:02<00:53, 54.11it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2791/5674 [05:02<01:03, 45.65it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2797/5674 [05:02<01:12, 39.59it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2803/5674 [05:02<01:06, 43.08it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2808/5674 [05:02<01:06, 43.00it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2814/5674 [05:03<01:02, 46.01it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2821/5674 [05:03<00:59, 47.79it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2829/5674 [05:03<00:52, 54.49it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2835/5674 [05:03<00:51, 55.50it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2843/5674 [05:03<00:45, 61.63it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2852/5674 [05:03<00:42, 65.78it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2859/5674 [05:03<01:00, 46.46it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2868/5674 [05:04<00:50, 55.36it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2876/5674 [05:04<00:46, 59.74it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2884/5674 [05:04<00:46, 60.64it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2891/5674 [05:04<00:46, 60.00it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2898/5674 [05:04<00:46, 59.33it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2905/5674 [05:04<00:57, 48.11it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2911/5674 [05:04<01:02, 44.54it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2916/5674 [05:05<01:05, 42.01it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2921/5674 [05:05<01:23, 33.09it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2925/5674 [05:05<01:19, 34.39it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2932/5674 [05:05<01:09, 39.26it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2938/5674 [05:05<01:05, 41.72it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2945/5674 [05:05<01:01, 44.58it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2950/5674 [05:05<01:03, 42.73it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2955/5674 [05:06<01:05, 41.60it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2960/5674 [05:06<01:17, 34.81it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2964/5674 [05:06<01:17, 35.19it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2968/5674 [05:06<01:14, 36.14it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2973/5674 [05:06<01:10, 38.52it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2978/5674 [05:06<01:05, 41.05it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2984/5674 [05:06<01:04, 41.43it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2990/5674 [05:06<01:01, 43.80it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2995/5674 [05:07<01:06, 40.10it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3000/5674 [05:07<01:06, 40.44it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3006/5674 [05:07<01:05, 40.74it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3013/5674 [05:07<00:56, 47.44it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3018/5674 [05:07<00:59, 44.47it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3023/5674 [05:07<01:01, 43.03it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3031/5674 [05:07<00:51, 51.59it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3038/5674 [05:07<00:50, 52.47it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3044/5674 [05:08<00:50, 52.58it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3050/5674 [05:08<01:03, 41.28it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3056/5674 [05:08<00:58, 45.14it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3066/5674 [05:08<00:50, 51.58it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3072/5674 [05:08<00:52, 49.52it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3078/5674 [05:08<00:59, 43.40it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3083/5674 [06:02<1:53:15,  2.62s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3088/5674 [06:02<1:24:13,  1.95s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3093/5674 [06:02<1:01:38,  1.43s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3099/5674 [06:02<42:17,  1.01it/s]   55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3105/5674 [06:02<29:21,  1.46it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3114/5674 [06:02<17:44,  2.40it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3121/5674 [06:03<12:32,  3.39it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3129/5674 [06:03<08:31,  4.98it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3135/5674 [06:03<06:29,  6.51it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3141/5674 [06:03<04:54,  8.61it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3148/5674 [06:03<03:32, 11.87it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3155/5674 [06:03<02:38, 15.91it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3162/5674 [06:03<02:00, 20.79it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3169/5674 [06:03<01:41, 24.58it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3175/5674 [06:03<01:28, 28.24it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3182/5674 [06:04<01:13, 33.71it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3188/5674 [06:04<01:10, 35.22it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3196/5674 [06:04<00:57, 43.06it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3202/5674 [06:04<00:53, 46.18it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3209/5674 [06:04<00:49, 49.51it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3217/5674 [06:04<00:44, 55.41it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3224/5674 [06:04<00:44, 55.29it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3235/5674 [06:04<00:36, 66.99it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3245/5674 [06:05<00:33, 71.56it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3253/5674 [06:05<00:49, 48.85it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3261/5674 [06:05<00:44, 54.15it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3269/5674 [06:05<00:41, 58.36it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3276/5674 [06:05<00:45, 52.30it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3284/5674 [06:05<00:44, 53.91it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3295/5674 [06:05<00:35, 66.56it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3303/5674 [06:06<01:01, 38.83it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3309/5674 [06:06<01:00, 39.05it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3316/5674 [06:06<01:11, 33.02it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3327/5674 [06:06<00:52, 44.83it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3334/5674 [06:07<00:57, 40.59it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3341/5674 [06:07<00:51, 45.18it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3347/5674 [06:07<01:02, 37.15it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3352/5674 [06:07<01:09, 33.30it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3362/5674 [06:07<00:51, 44.81it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3368/5674 [06:07<00:50, 45.27it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3378/5674 [06:08<00:41, 55.27it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3385/5674 [06:08<00:48, 47.18it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3391/5674 [06:08<00:46, 49.49it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3397/5674 [06:08<00:59, 38.34it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3404/5674 [06:08<00:56, 40.42it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3409/5674 [06:08<00:56, 40.18it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3416/5674 [06:09<00:51, 44.26it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3421/5674 [06:09<01:00, 37.18it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3426/5674 [06:09<01:06, 33.92it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3430/5674 [06:09<01:12, 30.82it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3434/5674 [06:09<01:10, 31.81it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3438/5674 [06:09<01:17, 29.04it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3444/5674 [06:09<01:02, 35.46it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3450/5674 [06:10<00:54, 41.06it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3459/5674 [06:10<00:41, 53.10it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3466/5674 [06:10<00:39, 55.91it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3472/5674 [06:10<00:43, 50.11it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3478/5674 [06:10<00:44, 49.58it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3488/5674 [06:10<00:40, 54.07it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3494/5674 [06:10<00:51, 42.37it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3501/5674 [06:11<00:51, 42.09it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3506/5674 [06:11<00:54, 40.03it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3512/5674 [06:11<00:50, 42.60it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3519/5674 [06:11<00:44, 48.27it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3525/5674 [06:11<01:08, 31.34it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3532/5674 [06:11<00:57, 37.07it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3537/5674 [06:12<01:01, 34.98it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3550/5674 [06:12<00:40, 52.67it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3563/5674 [06:12<00:32, 63.98it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3574/5674 [06:12<00:29, 72.24it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3585/5674 [06:12<00:27, 75.59it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3598/5674 [06:12<00:24, 85.32it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3608/5674 [06:12<00:23, 88.93it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3618/5674 [06:12<00:22, 89.57it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3628/5674 [06:13<00:24, 81.96it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3637/5674 [06:13<00:42, 48.22it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3644/5674 [06:13<00:50, 39.91it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3650/5674 [06:13<00:51, 39.64it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3655/5674 [06:14<01:01, 32.57it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3662/5674 [06:14<00:53, 37.41it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3667/5674 [06:14<01:00, 33.01it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3671/5674 [06:14<01:02, 32.19it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3675/5674 [06:14<01:00, 33.07it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3681/5674 [06:14<00:52, 37.73it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3686/5674 [06:15<00:57, 34.44it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3691/5674 [06:15<00:55, 35.75it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3698/5674 [06:15<00:45, 42.97it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3708/5674 [06:15<00:39, 49.97it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3714/5674 [06:15<00:37, 52.00it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3720/5674 [06:15<00:40, 48.68it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3726/5674 [06:15<00:41, 46.61it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3733/5674 [06:15<00:39, 49.37it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3746/5674 [06:16<00:28, 68.34it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3758/5674 [06:16<00:24, 78.78it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3758/5674 [07:21<00:24, 78.78it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3764/5674 [07:21<1:13:38,  2.31s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3767/5674 [07:21<1:04:01,  2.01s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3774/5674 [07:21<44:29,  1.41s/it]   67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3786/5674 [07:21<25:27,  1.24it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3798/5674 [07:21<15:48,  1.98it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3807/5674 [07:21<11:26,  2.72it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3814/5674 [07:22<08:45,  3.54it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3822/5674 [07:22<06:21,  4.85it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3829/5674 [07:22<04:48,  6.38it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3840/5674 [07:22<03:07,  9.78it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3854/5674 [07:22<01:56, 15.62it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3866/5674 [07:22<01:22, 21.83it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3877/5674 [07:22<01:03, 28.43it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3888/5674 [07:22<00:49, 36.10it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3898/5674 [07:23<00:42, 41.59it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3907/5674 [07:23<00:40, 43.89it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3917/5674 [07:23<00:33, 52.46it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3926/5674 [07:23<00:42, 41.08it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3933/5674 [07:23<00:43, 40.18it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3939/5674 [07:23<00:42, 40.65it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3945/5674 [07:24<00:41, 41.98it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3955/5674 [07:24<00:34, 49.17it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3962/5674 [07:24<00:34, 50.14it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3971/5674 [07:24<00:31, 53.44it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 3981/5674 [07:24<00:27, 62.35it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 3988/5674 [07:24<00:27, 60.66it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 3996/5674 [07:24<00:27, 60.90it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 4003/5674 [07:25<00:26, 62.27it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 4010/5674 [07:25<00:30, 53.76it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 4020/5674 [07:25<00:25, 64.25it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 4027/5674 [07:25<00:30, 54.67it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 4034/5674 [07:25<00:31, 51.36it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4043/5674 [07:25<00:27, 59.81it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4056/5674 [07:25<00:21, 74.12it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4067/5674 [07:26<00:27, 57.64it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4079/5674 [07:26<00:23, 67.41it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4087/5674 [07:26<00:27, 57.25it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4094/5674 [07:26<00:26, 59.80it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4101/5674 [07:26<00:35, 44.28it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4107/5674 [07:26<00:33, 46.27it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4115/5674 [07:27<00:30, 51.95it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4121/5674 [07:27<00:31, 49.24it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4128/5674 [07:27<00:29, 51.90it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4139/5674 [07:27<00:23, 65.12it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4147/5674 [07:27<00:24, 61.31it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4154/5674 [07:27<00:26, 58.15it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4161/5674 [07:27<00:27, 55.29it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4167/5674 [07:27<00:28, 53.79it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4174/5674 [07:28<00:30, 49.13it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4180/5674 [07:28<00:33, 44.61it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4186/5674 [07:28<00:32, 45.65it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4198/5674 [07:28<00:24, 61.15it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4206/5674 [07:28<00:25, 58.11it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4216/5674 [07:28<00:22, 64.07it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4224/5674 [07:28<00:21, 66.56it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4231/5674 [07:29<00:29, 49.31it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4237/5674 [07:29<00:29, 48.19it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4243/5674 [07:29<00:28, 50.73it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4249/5674 [07:29<00:33, 43.02it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4254/5674 [07:29<00:32, 44.30it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4263/5674 [07:29<00:28, 49.98it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4269/5674 [07:30<00:34, 40.49it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4274/5674 [07:30<00:35, 39.92it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4279/5674 [07:30<00:34, 40.61it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4286/5674 [07:30<00:29, 46.29it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4292/5674 [07:30<00:28, 48.25it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4300/5674 [07:30<00:25, 53.21it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4306/5674 [07:30<00:28, 47.89it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4313/5674 [07:30<00:25, 52.98it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4319/5674 [07:31<00:25, 52.37it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4326/5674 [07:31<00:23, 56.87it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4335/5674 [07:31<00:21, 61.60it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4342/5674 [07:31<00:23, 55.87it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4348/5674 [07:31<00:24, 53.77it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4354/5674 [07:31<00:26, 50.25it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4372/5674 [07:31<00:18, 70.55it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4382/5674 [07:31<00:17, 73.59it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4394/5674 [07:32<00:15, 82.42it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4403/5674 [07:32<00:15, 83.83it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4412/5674 [07:32<00:14, 84.93it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4421/5674 [07:32<00:23, 52.51it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4428/5674 [07:32<00:24, 51.24it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4439/5674 [07:32<00:22, 55.34it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4457/5674 [07:33<00:16, 74.90it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4466/5674 [07:33<00:15, 76.02it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4487/5674 [07:33<00:11, 104.11it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4499/5674 [07:33<00:11, 104.86it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4517/5674 [07:33<00:09, 123.66it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4531/5674 [07:33<00:09, 126.38it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4548/5674 [07:33<00:10, 107.31it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4569/5674 [07:33<00:08, 130.19it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4584/5674 [07:34<00:08, 134.82it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4600/5674 [07:34<00:07, 139.45it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4616/5674 [07:34<00:07, 144.11it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4632/5674 [07:34<00:09, 112.06it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4653/5674 [07:34<00:08, 126.88it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4667/5674 [07:34<00:10, 94.52it/s]  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4679/5674 [07:34<00:11, 89.16it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4690/5674 [07:35<00:15, 65.29it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4699/5674 [07:35<00:14, 65.37it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4707/5674 [07:35<00:16, 59.07it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4714/5674 [07:35<00:16, 57.79it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4725/5674 [07:35<00:13, 68.20it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4733/5674 [07:36<00:17, 54.06it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4741/5674 [07:36<00:16, 57.90it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4755/5674 [07:36<00:13, 66.83it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4763/5674 [07:36<00:13, 67.43it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4771/5674 [07:36<00:13, 69.23it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4781/5674 [07:36<00:12, 72.60it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4797/5674 [07:36<00:09, 91.79it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4811/5674 [07:36<00:08, 98.67it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4827/5674 [07:37<00:07, 112.21it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4839/5674 [07:37<00:08, 95.25it/s]  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4850/5674 [07:37<00:09, 86.65it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4860/5674 [07:37<00:12, 63.35it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4881/5674 [07:37<00:09, 87.14it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 4895/5674 [07:37<00:07, 97.56it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 4909/5674 [07:38<00:08, 92.77it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 4924/5674 [07:38<00:07, 104.71it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 4941/5674 [07:38<00:06, 119.96it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 4955/5674 [07:38<00:05, 121.08it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 4968/5674 [07:38<00:05, 121.96it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 4968/5674 [08:56<00:05, 121.96it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 4979/5674 [08:56<20:23,  1.76s/it]  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 4989/5674 [08:56<15:13,  1.33s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 5002/5674 [08:56<10:18,  1.09it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 5015/5674 [08:56<07:01,  1.56it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 5027/5674 [08:56<04:56,  2.18it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5039/5674 [08:56<03:28,  3.05it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5050/5674 [08:57<02:30,  4.14it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5060/5674 [08:57<01:50,  5.54it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5071/5674 [08:57<01:18,  7.65it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5083/5674 [08:57<00:54, 10.80it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5095/5674 [08:57<00:38, 15.02it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5106/5674 [08:57<00:29, 19.39it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 5117/5674 [08:57<00:21, 25.50it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 5127/5674 [08:57<00:17, 31.16it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 5137/5674 [08:58<00:14, 37.73it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 5148/5674 [08:58<00:11, 47.24it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 5158/5674 [08:58<00:09, 55.02it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 5170/5674 [08:58<00:07, 65.65it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5185/5674 [08:58<00:05, 82.07it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5197/5674 [08:58<00:05, 89.14it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5209/5674 [08:58<00:05, 84.46it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5220/5674 [08:59<00:07, 57.81it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5229/5674 [08:59<00:07, 55.84it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5238/5674 [08:59<00:07, 60.13it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5247/5674 [08:59<00:06, 62.51it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5255/5674 [08:59<00:07, 59.47it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5264/5674 [08:59<00:06, 65.50it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5275/5674 [08:59<00:05, 68.70it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5294/5674 [08:59<00:04, 92.74it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5304/5674 [09:00<00:03, 93.39it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5318/5674 [09:00<00:03, 103.62it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5329/5674 [09:00<00:03, 100.65it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5340/5674 [09:00<00:03, 97.43it/s]  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5350/5674 [09:00<00:03, 97.93it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5360/5674 [09:00<00:03, 96.53it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5374/5674 [09:00<00:02, 101.19it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5387/5674 [09:00<00:02, 105.65it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5407/5674 [09:00<00:02, 130.70it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5421/5674 [09:01<00:02, 115.89it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5434/5674 [09:01<00:02, 116.71it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5447/5674 [09:01<00:01, 115.82it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5459/5674 [09:01<00:02, 102.84it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5476/5674 [09:01<00:01, 118.33it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5489/5674 [09:01<00:01, 117.15it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5503/5674 [09:01<00:01, 121.22it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5516/5674 [09:01<00:01, 113.34it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5528/5674 [09:02<00:01, 114.82it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5549/5674 [09:02<00:00, 138.43it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5572/5674 [09:02<00:00, 155.82it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5588/5674 [09:02<00:00, 151.70it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5604/5674 [09:02<00:00, 106.05it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5617/5674 [09:02<00:00, 102.12it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5635/5674 [09:02<00:00, 118.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5649/5674 [09:03<00:00, 113.90it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5662/5674 [09:03<00:00, 85.98it/s] 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5673/5674 [09:03<00:00, 56.31it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5674/5674 [09:03<00:00, 10.43it/s]
2025-12-15 11:08:56.906 | INFO     | __main__:main:229 - Starting 16 workers for epoch 4
2025-12-15 11:19:38.025 | INFO     | __main__:main:247 - Starting Epoch 4/10
2025-12-15 11:19:38.120 | INFO     | __main__:main:263 - Processing 128 theorems with 16 workers.
2025-12-15 11:19:46.488 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Function.Bijective.iterate
2025-12-15 11:19:47.071 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Function.update_same
2025-12-15 11:19:48.961 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Order.PFilter.nonempty
2025-12-15 11:19:49.864 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Finset.card_insertNone
2025-12-15 11:19:50.221 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: WType.depth_lt_depth_mk
2025-12-15 11:19:50.368 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: SimpleGraph.dart_edge_eq_mk'_iff
2025-12-15 11:19:52.396 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Finset.subset_cons
2025-12-15 11:19:52.509 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Infinite.exists_subset_card_eq
2025-12-15 11:19:53.044 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:19:54.552 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:19:54.888 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Matrix.toBlock_diagonal_disjoint
2025-12-15 11:19:56.906 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:19:57.886 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:19:58.175 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: isPreconnected_Icc
2025-12-15 11:19:58.271 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:19:58.337 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:19:59.054 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: induction' n with n ih
2025-12-15 11:19:59.118 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error='<stdin>:1:1: unknown tactic')
2025-12-15 11:19:59.118 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 12.63s.
2025-12-15 11:19:59.118 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error='<stdin>:1:1: unknown tactic')
2025-12-15 11:19:59.265 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:19:59.486 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:19:59.756 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:20:00.385 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: map_le_lineMap_iff_slope_le_slope
2025-12-15 11:20:01.404 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:20:03.113 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: skewAdjointLieSubalgebraEquiv_symm_apply
2025-12-15 11:20:03.837 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:20:05.555 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: rw [insertNone, card_union_of_disjoint, card_image_of_injOn]
2025-12-15 11:20:05.668 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  (?m.31109 ‚à™ ?m.31110).card\nŒ± : Type u_1\nŒ≤ : Type u_2\ns : Finset Œ±\n‚ä¢ ((OrderEmbedding.ofMapLEIff (fun s => Finset.cons none (Finset.map Function.Embedding.some s) ‚ãØ) ‚ãØ) s).card =\n    s.card + 1")
2025-12-15 11:20:05.668 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 15.80s.
2025-12-15 11:20:05.668 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  (?m.31109 ‚à™ ?m.31110).card\nŒ± : Type u_1\nŒ≤ : Type u_2\ns : Finset Œ±\n‚ä¢ ((OrderEmbedding.ofMapLEIff (fun s => Finset.cons none (Finset.map Function.Embedding.some s) ‚ãØ) ‚ãØ) s).card =\n    s.card + 1")
2025-12-15 11:20:05.807 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:20:05.813 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:20:07.670 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: MeasureTheory.Mem‚Ñíp.variance_eq
2025-12-15 11:20:08.215 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:20:08.372 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: DFinsupp.extendWith_some
2025-12-15 11:20:12.492 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:20:13.242 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:20:15.631 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: WeierstrassCurve.Œ®_two
2025-12-15 11:20:16.091 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: continuous_toAdd
2025-12-15 11:20:17.391 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: CategoryTheory.Idempotents.DoldKan.equivalence_counitIso
2025-12-15 11:20:20.327 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: ContinuousMultilinearMap.changeOriginSeries_support
2025-12-15 11:20:20.515 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:20:21.065 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:20:22.179 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:20:25.054 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:20:29.418 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: rintro ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© ‚ü®‚ü®‚ü©‚ü© 
2025-12-15 11:20:29.451 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: exact lt_of_le_of_lt (depth_mk _ _) (depth_mk _ _)
2025-12-15 11:20:29.490 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error='rcases tactic failed: fst‚úù : V is not an inductive datatype')
2025-12-15 11:20:29.490 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 39.12s.
2025-12-15 11:20:29.490 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error='rcases tactic failed: fst‚úù : V is not an inductive datatype')
2025-12-15 11:20:29.515 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error='internal exception #4')
2025-12-15 11:20:29.515 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 39.29s.
2025-12-15 11:20:29.515 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error='internal exception #4')
2025-12-15 11:20:29.630 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:20:29.651 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:20:36.615 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: PEquiv.ofSet_symm
2025-12-15 11:20:37.437 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: finAddFlip_apply_mk_right
2025-12-15 11:20:41.402 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:20:41.984 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:21:46.648 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: rwa [cons_eq_insert, cons_eq_insert]
2025-12-15 11:21:46.736 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.38534\nŒ± : Type u_1\nŒ≤ : Type u_2\nŒ≥ : Type u_3\ns t : Finset Œ±\na b : Œ±\nh : a ‚àâ s\n‚ä¢ s ‚äÜ Finset.cons a s h")
2025-12-15 11:21:46.736 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 114.34s.
2025-12-15 11:21:46.737 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.38534\nŒ± : Type u_1\nŒ≤ : Type u_2\nŒ≥ : Type u_3\ns t : Finset Œ±\na b : Œ±\nh : a ‚àâ s\n‚ä¢ s ‚äÜ Finset.cons a s h")
2025-12-15 11:21:46.842 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: cases n with
| zero => cases n
| succ n =>
  cases n with
  | zero => cases n with
  | zero => cases n with
  | zero => cases n with
  | zero => cases n with
  | zero => cases n with
  | zero => cases n with
  | zero => cases n with
  | succ n => cases n with
  | zero => cases n with
  | zero => cases n with
  | zero => cases n with
  | zero => contradiction
  | succ n => cases n with
  | zero => cases n with
  | zero => cases n with
  | zero => cases n with
  | zero => contradiction
  | succ n => cases n with
  | zero => contradiction
  | succ n => cases n with
  | zero => contradiction
  | succ n => cases n with
  | zero => cases n with
  | zero => cases n with
  | zero => cases n with
  | zero => cases n with
  | zero => cases n with
  | zero => cases n with
  | zero => cases n with
  | zero => cases n with
  | zero => contradiction
  | succ n => cases n with
  | zero => contradiction
  | succ n => cases n with
  | zero => contradiction
  | succ n => cases n with
  | zero => contradiction
  | succ n =>
  
2025-12-15 11:21:46.879 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:21:46.882 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: simpa only [isPreconnected_iff_subset] using isPreconnected_Icc
2025-12-15 11:21:46.914 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="<stdin>:43:2: unexpected end of input; expected '?', '_' or '{'")
2025-12-15 11:21:46.914 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 114.40s.
2025-12-15 11:21:46.914 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="<stdin>:43:2: unexpected end of input; expected '?', '_' or '{'")
2025-12-15 11:21:46.951 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="unknown identifier 'isPreconnected_iff_subset'")
2025-12-15 11:21:46.951 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 108.78s.
2025-12-15 11:21:46.951 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="unknown identifier 'isPreconnected_iff_subset'")
2025-12-15 11:21:47.056 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:21:47.092 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:21:49.071 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: rw [toBlock_diagonal, diagonal_apply_eq]
2025-12-15 11:21:49.203 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.60159\nl : Type u_1\nm : Type u_2\nn : Type u_3\no : Type u_4\np‚úù : Type u_5\nq‚úù : Type u_6\nm' : o ‚Üí Type u_7\nn' : o ‚Üí Type u_8\np' : o ‚Üí Type u_9\nR : Type u_10\nS : Type u_11\nŒ± : Type u_12\nŒ≤ : Type u_13\ninst‚úù¬≤ : DecidableEq l\ninst‚úù¬π : DecidableEq m\ninst‚úù : Zero Œ±\nd : m ‚Üí Œ±\np q : m ‚Üí Prop\nhpq : Disjoint p q\n‚ä¢ (Matrix.diagonal d).toBlock p q = 0")
2025-12-15 11:21:49.203 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 114.31s.
2025-12-15 11:21:49.203 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.60159\nl : Type u_1\nm : Type u_2\nn : Type u_3\no : Type u_4\np‚úù : Type u_5\nq‚úù : Type u_6\nm' : o ‚Üí Type u_7\nn' : o ‚Üí Type u_8\np' : o ‚Üí Type u_9\nR : Type u_10\nS : Type u_11\nŒ± : Type u_12\nŒ≤ : Type u_13\ninst‚úù¬≤ : DecidableEq l\ninst‚úù¬π : DecidableEq m\ninst‚úù : Zero Œ±\nd : m ‚Üí Œ±\np q : m ‚Üí Prop\nhpq : Disjoint p q\n‚ä¢ (Matrix.diagonal d).toBlock p q = 0")
2025-12-15 11:21:49.347 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:21:53.233 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: rw [slope_def_module, slope_def_module, slope_def_module, slope_def_module, slope_def_module,
  slope_def_module, slope_def_module, slope_def_module, slope_def_module, slope_def_module,
  slope_def_module, slope_def_module, slope_def_module, slope_def_module, slope_def_module,
  slope_def_module, slope_def_module, slope_def_module, slope_def_module, slope_def_module,
  slope_def_module, slope_def_module, slope_def_module]
2025-12-15 11:21:53.421 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  slope ?f ?a ?b\nk : Type u_1\nE : Type u_2\nPE : Type u_3\ninst‚úù¬≥ : LinearOrderedField k\ninst‚úù¬≤ : OrderedAddCommGroup E\ninst‚úù¬π : Module k E\ninst‚úù : OrderedSMul k E\nf : k ‚Üí E\na b r : k\nhab : a < b\nh‚ÇÄ : 0 < r\nh‚ÇÅ : r < 1\n‚ä¢ f ((AffineMap.lineMap a b) r) ‚â§ (AffineMap.lineMap (f a) (f b)) r ‚Üî\n    ((AffineMap.lineMap a b) r - a)‚Åª¬π ‚Ä¢ (f ((AffineMap.lineMap a b) r) - f a) ‚â§\n      (b - (AffineMap.lineMap a b) r)‚Åª¬π ‚Ä¢ (f b - f ((AffineMap.lineMap a b) r))")
2025-12-15 11:21:53.421 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 113.04s.
2025-12-15 11:21:53.421 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  slope ?f ?a ?b\nk : Type u_1\nE : Type u_2\nPE : Type u_3\ninst‚úù¬≥ : LinearOrderedField k\ninst‚úù¬≤ : OrderedAddCommGroup E\ninst‚úù¬π : Module k E\ninst‚úù : OrderedSMul k E\nf : k ‚Üí E\na b r : k\nhab : a < b\nh‚ÇÄ : 0 < r\nh‚ÇÅ : r < 1\n‚ä¢ f ((AffineMap.lineMap a b) r) ‚â§ (AffineMap.lineMap (f a) (f b)) r ‚Üî\n    ((AffineMap.lineMap a b) r - a)‚Åª¬π ‚Ä¢ (f ((AffineMap.lineMap a b) r) - f a) ‚â§\n      (b - (AffineMap.lineMap a b) r)‚Åª¬π ‚Ä¢ (f b - f ((AffineMap.lineMap a b) r))")
2025-12-15 11:21:53.564 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:21:56.744 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Set.le_einfsep_image_iff
2025-12-15 11:21:58.944 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Ideal.span_pair_add_mul_right
2025-12-15 11:21:59.722 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: CategoryTheory.CommSq.vert_comp
2025-12-15 11:22:01.786 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:22:02.854 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: LaurentPolynomial.involutive_invert
2025-12-15 11:22:03.874 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:22:04.488 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:22:07.322 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:22:08.142 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Basis.coe_dualBasis
2025-12-15 11:22:12.666 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:22:18.662 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: apply IsIdempotentComplete.equivalence_unique
2025-12-15 11:22:18.733 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="unknown constant 'CategoryTheory.IsIdempotentComplete.equivalence_unique'")
2025-12-15 11:22:18.733 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 121.34s.
2025-12-15 11:22:18.733 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="unknown constant 'CategoryTheory.IsIdempotentComplete.equivalence_unique'")
2025-12-15 11:22:18.874 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:22:22.225 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: rw [variance, ENNReal.toReal_ofNat, ENNReal.toReal_rpow, ENNReal.toReal_ofNat,
  ENNReal.toReal_rpow, ENNReal.toReal_ofNat, ENNReal.toReal_ofNat, ENNReal.toReal_ofNat,
  ENNReal.toReal_ofNat, ENNReal.toReal_ofNat, ENNReal.toReal_ofNat, ENNReal.toReal_ofNat,
  ENNReal.toReal_ofNat, ENNReal.toReal_ofNat, ENNReal.toReal_ofNat]
2025-12-15 11:22:22.354 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  (OfNat.ofNat ?n).toReal\nŒ© : Type u_1\nm : MeasurableSpace Œ©\nX : Œ© ‚Üí ‚Ñù\nŒº : MeasureTheory.Measure Œ©\ninst‚úù : MeasureTheory.IsFiniteMeasure Œº\nhX : MeasureTheory.Mem‚Ñíp X 2 Œº\n‚ä¢ (ProbabilityTheory.evariance X Œº).toReal = ‚à´ (x : Œ©), ((X - fun x => ‚à´ (x : Œ©), X x ‚àÇŒº) ^ 2) x ‚àÇŒº")
2025-12-15 11:22:22.354 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 134.68s.
2025-12-15 11:22:22.354 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  (OfNat.ofNat ?n).toReal\nŒ© : Type u_1\nm : MeasurableSpace Œ©\nX : Œ© ‚Üí ‚Ñù\nŒº : MeasureTheory.Measure Œ©\ninst‚úù : MeasureTheory.IsFiniteMeasure Œº\nhX : MeasureTheory.Mem‚Ñíp X 2 Œº\n‚ä¢ (ProbabilityTheory.evariance X Œº).toReal = ‚à´ (x : Œ©), ((X - fun x => ‚à´ (x : Œ©), X x ‚àÇŒº) ^ 2) x ‚àÇŒº")
2025-12-15 11:22:22.497 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:22:24.166 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: rw [‚Üê f.toFormalMultilinearSeries.changeOriginSeries_eq_changeOriginSeries f f.toFormalMultilinearSeries,
  f.toFormalMultilinearSeries.changeOriginSeries_eq_toFormalMultilinearSeries,
  f.toFormalMultilinearSeries.changeOriginSeries_eq_toFormalMultilinearSeries,
  f.toFormalMultilinearSeries.changeOriginSeries_eq_toFormalMultilinearSeries,
  f.toFormalMultilinearSeries.changeOriginSeries_eq_toFormalMultilinearSeries,
  f.toFormalMultilinearSeries.changeOriginSeries_eq_toFormalMultilinearSeries]
2025-12-15 11:22:24.325 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.376332\nùïú : Type u_1\ninst‚úù‚Å∑ : NontriviallyNormedField ùïú\nE‚úù : Type u\ninst‚úù‚Å∂ : NormedAddCommGroup E‚úù\ninst‚úù‚Åµ : NormedSpace ùïú E‚úù\nF : Type v\ninst‚úù‚Å¥ : NormedAddCommGroup F\ninst‚úù¬≥ : NormedSpace ùïú F\nŒπ : Type u_2\nE : Œπ ‚Üí Type u_3\ninst‚úù¬≤ : (i : Œπ) ‚Üí NormedAddCommGroup (E i)\ninst‚úù¬π : (i : Œπ) ‚Üí NormedSpace ùïú (E i)\ninst‚úù : Fintype Œπ\nf : ContinuousMultilinearMap ùïú E F\nk l : ‚Ñï\nh : k + l ‚â† Fintype.card Œπ\n‚ä¢ f.toFormalMultilinearSeries.changeOriginSeries k l = 0")
2025-12-15 11:22:24.325 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 124.00s.
2025-12-15 11:22:24.325 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.376332\nùïú : Type u_1\ninst‚úù‚Å∑ : NontriviallyNormedField ùïú\nE‚úù : Type u\ninst‚úù‚Å∂ : NormedAddCommGroup E‚úù\ninst‚úù‚Åµ : NormedSpace ùïú E‚úù\nF : Type v\ninst‚úù‚Å¥ : NormedAddCommGroup F\ninst‚úù¬≥ : NormedSpace ùïú F\nŒπ : Type u_2\nE : Œπ ‚Üí Type u_3\ninst‚úù¬≤ : (i : Œπ) ‚Üí NormedAddCommGroup (E i)\ninst‚úù¬π : (i : Œπ) ‚Üí NormedSpace ùïú (E i)\ninst‚úù : Fintype Œπ\nf : ContinuousMultilinearMap ùïú E F\nk l : ‚Ñï\nh : k + l ‚â† Fintype.card Œπ\n‚ä¢ f.toFormalMultilinearSeries.changeOriginSeries k l = 0")
2025-12-15 11:22:24.466 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:22:27.363 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: List.tail_sublistForall‚ÇÇ_self
2025-12-15 11:22:29.911 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Trunc.lift_mk
2025-12-15 11:22:32.008 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:22:34.496 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:22:58.618 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: SchwartzMap.schwartzSeminormFamily_apply
2025-12-15 11:23:03.259 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:23:13.130 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: rw [nonempty_iff_ne_empty]
2025-12-15 11:23:13.215 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.14982\nP : Type u_1\ninst‚úù : Preorder P\nx y : P\nF s t : Order.PFilter P\n‚ä¢ (‚ÜëF).Nonempty")
2025-12-15 11:23:13.215 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 204.25s.
2025-12-15 11:23:13.215 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.14982\nP : Type u_1\ninst‚úù : Preorder P\nx y : P\nF s t : Order.PFilter P\n‚ä¢ (‚ÜëF).Nonempty")
2025-12-15 11:23:13.356 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:23:14.862 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: rw [finAddFlip_apply, finAddFlip_apply_of_lt h‚ÇÅ, finAddFlip_apply_of_lt h‚ÇÇ,
  finAddFlip_apply_of_lt h‚ÇÅ, finAddFlip_apply_of_lt h‚ÇÇ, finAddFlip_apply_of_lt h‚ÇÅ,
  finAddFlip_apply_of_lt h‚ÇÇ, finAddFlip_apply_of_lt h‚ÇÅ, finAddFlip_apply_of_lt h‚ÇÇ,
  finAddFlip_apply_of_lt h‚ÇÅ, finAddFlip_apply_of_lt h‚ÇÇ]
2025-12-15 11:23:14.947 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.29331\nm n k : ‚Ñï\nh‚ÇÅ : m ‚â§ k\nh‚ÇÇ : k < m + n\n‚ä¢ finAddFlip ‚ü®k, h‚ÇÇ‚ü© = ‚ü®k - m, ‚ãØ‚ü©")
2025-12-15 11:23:14.947 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 157.51s.
2025-12-15 11:23:14.947 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.29331\nm n k : ‚Ñï\nh‚ÇÅ : m ‚â§ k\nh‚ÇÇ : k < m + n\n‚ä¢ finAddFlip ‚ü®k, h‚ÇÇ‚ü© = ‚ü®k - m, ‚ãØ‚ü©")
2025-12-15 11:23:15.089 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:23:15.428 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: exact involutive_involutive
2025-12-15 11:23:15.494 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="unknown identifier 'involutive_involutive'")
2025-12-15 11:23:15.494 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 72.64s.
2025-12-15 11:23:15.494 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="unknown identifier 'involutive_involutive'")
2025-12-15 11:23:15.637 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:23:16.144 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: rw [span_insert, span_singleton_add_mul_eq_span_singleton, span_singleton_mul_eq_span_singleton]
2025-12-15 11:23:16.248 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.49245\nŒ± : Type u\nŒ≤ : Type v\ninst‚úù¬π : Semiring Œ±\nI : Ideal Œ±\na b : Œ±\nR : Type u\ninst‚úù : CommRing R\nx y z : R\n‚ä¢ Ideal.span {x} ‚äî Ideal.span {y + x * z} = Ideal.span {x, y}")
2025-12-15 11:23:16.248 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 77.30s.
2025-12-15 11:23:16.248 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.49245\nŒ± : Type u\nŒ≤ : Type v\ninst‚úù¬π : Semiring Œ±\nI : Ideal Œ±\na b : Œ±\nR : Type u\ninst‚úù : CommRing R\nx y z : R\n‚ä¢ Ideal.span {x} ‚äî Ideal.span {y + x * z} = Ideal.span {x, y}")
2025-12-15 11:23:16.392 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:23:18.706 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: rw [‚Üê Category.assoc, ‚Üê Category.assoc, ‚Üê Category.assoc, hsq‚ÇÇ.w]
2025-12-15 11:23:18.852 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  ?f ‚â´ ?g ‚â´ ?h\nC : Type u_1\ninst‚úù : CategoryTheory.Category.{u_2, u_1} C\nW‚úù X‚úù Y‚úù Z‚úù : C\nf‚úù : W‚úù ‚ü∂ X‚úù\ng‚úù : W‚úù ‚ü∂ Y‚úù\nh‚úù : X‚úù ‚ü∂ Z‚úù\ni‚úù : Y‚úù ‚ü∂ Z‚úù\nW X Y Y' Z Z' : C\nf : W ‚ü∂ X\ng : W ‚ü∂ Y\ng' : Y ‚ü∂ Y'\nh : X ‚ü∂ Z\nh' : Z ‚ü∂ Z'\ni : Y ‚ü∂ Z\ni' : Y' ‚ü∂ Z'\nhsq‚ÇÅ : CategoryTheory.CommSq f g h i\nhsq‚ÇÇ : CategoryTheory.CommSq i g' h' i'\n‚ä¢ CategoryTheory.CommSq f (g ‚â´ g') (h ‚â´ h') i'")
2025-12-15 11:23:18.852 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 79.13s.
2025-12-15 11:23:18.852 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  ?f ‚â´ ?g ‚â´ ?h\nC : Type u_1\ninst‚úù : CategoryTheory.Category.{u_2, u_1} C\nW‚úù X‚úù Y‚úù Z‚úù : C\nf‚úù : W‚úù ‚ü∂ X‚úù\ng‚úù : W‚úù ‚ü∂ Y‚úù\nh‚úù : X‚úù ‚ü∂ Z‚úù\ni‚úù : Y‚úù ‚ü∂ Z‚úù\nW X Y Y' Z Z' : C\nf : W ‚ü∂ X\ng : W ‚ü∂ Y\ng' : Y ‚ü∂ Y'\nh : X ‚ü∂ Z\nh' : Z ‚ü∂ Z'\ni : Y ‚ü∂ Z\ni' : Y' ‚ü∂ Z'\nhsq‚ÇÅ : CategoryTheory.CommSq f g h i\nhsq‚ÇÇ : CategoryTheory.CommSq i g' h' i'\n‚ä¢ CategoryTheory.CommSq f (g ‚â´ g') (h ‚â´ h') i'")
2025-12-15 11:23:18.996 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:23:23.919 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Mathlib.Meta.Positivity.nonneg_of_isNat
2025-12-15 11:23:28.572 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:23:31.209 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: FirstOrder.Language.Equiv.comp_refl
2025-12-15 11:23:32.881 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Finset.singleton_subset_set_iff
2025-12-15 11:23:35.949 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:23:37.535 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:23:40.315 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: MeasureTheory.Measure.addHaar_closedBall_mul_of_pos
2025-12-15 11:23:45.007 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:23:50.298 | INFO     | __main__:main:302 - Completed 16/128 proofs
2025-12-15 11:23:52.064 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: LinearMap.IsSymmetric.toSelfAdjoint_apply
2025-12-15 11:23:56.460 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:24:34.863 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: simp [schwartzSeminormFamily]
2025-12-15 11:24:34.939 | SUCCESS  | lean_reinforcement.agent.runner:run:218 - Proof finished in 1 steps and 96.32s.
2025-12-15 11:24:35.080 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:24:43.545 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Multiset.toFinsupp_inter
2025-12-15 11:24:48.402 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:25:12.997 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: simp only [Œ®, Œ®Sq_ofNat, if_pos <| by decide]
2025-12-15 11:25:13.073 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error='expected type must not contain free or meta variables\n  ?m.106699')
2025-12-15 11:25:13.073 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 297.44s.
2025-12-15 11:25:13.073 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error='expected type must not contain free or meta variables\n  ?m.106699')
2025-12-15 11:25:13.214 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:25:13.857 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: simp [extendWith]
2025-12-15 11:25:13.949 | SUCCESS  | lean_reinforcement.agent.runner:run:218 - Proof finished in 1 steps and 305.58s.
2025-12-15 11:25:14.090 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:25:14.570 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: simp
2025-12-15 11:25:14.634 | SUCCESS  | lean_reinforcement.agent.runner:run:218 - Proof finished in 1 steps and 101.75s.
2025-12-15 11:25:14.778 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:25:18.636 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: have : Œº (closedBall 0 s) = 0 := by
  rw [closedBall_zero_eq_empty, ENNReal.ofReal_zero, ENNReal.ofReal_zero, ENNReal.ofReal_zero,
    ENNReal.ofReal_zero, ENNReal.ofReal_zero]
2025-12-15 11:25:18.783 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="unknown identifier 'closedBall_zero_eq_empty'\ntactic 'rewrite' failed, equality or iff proof expected\n  ?m.296177\nE : Type u_1\ninst‚úù‚Å∏ : NormedAddCommGroup E\ninst‚úù‚Å∑ : NormedSpace ‚Ñù E\ninst‚úù‚Å∂ : MeasurableSpace E\ninst‚úù‚Åµ : BorelSpace E\ninst‚úù‚Å¥ : FiniteDimensional ‚Ñù E\nŒº : Measure E\ninst‚úù¬≥ : Œº.IsAddHaarMeasure\nF : Type u_2\ninst‚úù¬≤ : NormedAddCommGroup F\ninst‚úù¬π : NormedSpace ‚Ñù F\ninst‚úù : CompleteSpace F\ns‚úù : Set E\nx : E\nr : ‚Ñù\nhr : 0 < r\ns : ‚Ñù\n‚ä¢ Œº (closedBall 0 s) = 0")
2025-12-15 11:25:18.783 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 98.47s.
2025-12-15 11:25:18.783 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="unknown identifier 'closedBall_zero_eq_empty'\ntactic 'rewrite' failed, equality or iff proof expected\n  ?m.296177\nE : Type u_1\ninst‚úù‚Å∏ : NormedAddCommGroup E\ninst‚úù‚Å∑ : NormedSpace ‚Ñù E\ninst‚úù‚Å∂ : MeasurableSpace E\ninst‚úù‚Åµ : BorelSpace E\ninst‚úù‚Å¥ : FiniteDimensional ‚Ñù E\nŒº : Measure E\ninst‚úù¬≥ : Œº.IsAddHaarMeasure\nF : Type u_2\ninst‚úù¬≤ : NormedAddCommGroup F\ninst‚úù¬π : NormedSpace ‚Ñù F\ninst‚úù : CompleteSpace F\ns‚úù : Set E\nx : E\nr : ‚Ñù\nhr : 0 < r\ns : ‚Ñù\n‚ä¢ Œº (closedBall 0 s) = 0")
2025-12-15 11:25:18.927 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:25:22.955 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: UniformContinuous.pow_const
2025-12-15 11:25:25.593 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Matrix.isHermitian_conjTranspose_mul_mul
2025-12-15 11:25:27.446 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Module.sum_smul_eq_zero_of_isTrivialRelation
2025-12-15 11:25:27.576 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:25:30.262 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:25:32.075 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:25:38.540 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: rw [hT.toSelfAdjoint_eq_toAddSubgroup_closure, hT.adjoint_eq_toAddSubgroup_closure,
  hT.adjoint_eq_toAddSubgroup_closure, hT.adjoint_eq_toAddSubgroup_closure, hT.adjoint_eq_toAddSubgroup_closure,
  hT.adjoint_eq_toAddSubgroup_closure, hT.adjoint_eq_toAddSubgroup_closure, hT.adjoint_eq_toAddSubgroup_closure,
  hT.adjoint_eq_toAddSubgroup_closure, hT.adjoint_eq_toAddSubgroup_closure, hT.adjoint_eq_toAddSubgroup_closure,
  hT.adjoint_eq_toAddSubgroup_closure, hT.adjoint_eq_toAddSubgroup_closure, hT.adjoint_eq_toAddSubgroup_closure,
  hT.adjoint_eq_toAddSubgroup_closure, hT.adjoint_eq_toAddSubgroup_closure, hT.adjoint_eq_toAddSubgroup_closure,
  hT.adjoint_eq_toAddSubgroup_closure, hT.adjoint_eq_toAddSubgroup_closure, hT.adjoint_eq_toAddSubgroup_closure,
  hT.adjoint_eq_toAddSubgroup_closure, hT.adjoint_eq_toAddSubgroup_closure, hT.adjoint_eq_toAddSubgroup_closure,
  hT.adjoint_eq_toAddSubgroup_closure, hT.adjoint_eq_toAddSubgroup_closure, hT.adjoint_eq_toAddSubgroup_closure,
  hT.adjoint_eq_toAddSubgroup_closu
2025-12-15 11:25:38.608 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="<stdin>:10:35: unexpected end of input; expected ']'")
2025-12-15 11:25:38.608 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 106.54s.
2025-12-15 11:25:38.608 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="<stdin>:10:35: unexpected end of input; expected ']'")
2025-12-15 11:25:38.749 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:25:49.714 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: LowerSet.disjoint_prod
2025-12-15 11:25:54.375 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:26:07.462 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: FractionalIdeal.spanSingleton_mul_coeIdeal_eq_coeIdeal
2025-12-15 11:26:11.829 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:26:32.961 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: simp [SublistForall‚ÇÇ]
2025-12-15 11:26:33.024 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error='simp made no progress')
2025-12-15 11:26:33.025 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 245.66s.
2025-12-15 11:26:33.025 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error='simp made no progress')
2025-12-15 11:26:33.142 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: rw [‚Üê Finset.sum_eq_zero_iff_of_nonneg h.nonneg, Finset.sum_eq_zero_iff_of_nonneg h.nonneg,
  Finset.sum_eq_zero_iff_of_nonneg h.nonneg, Finset.sum_eq_zero_iff_of_nonneg h.nonneg,
  Finset.sum_eq_zero_iff_of_nonneg h.nonneg, Finset.sum_eq_zero_iff_of_nonneg h.nonneg,
  Finset.sum_eq_zero_iff_of_nonneg h.nonneg, Finset.sum_eq_zero_iff_of_nonneg h.nonneg,
  Finset.sum_eq_zero_iff_of_nonneg h.nonneg, Finset.sum_eq_zero_iff_of_nonneg h.nonneg,
  Finset.sum_eq_zero_iff_of_nonneg h.nonneg, Finset.sum_eq_zero_iff_of_nonneg h.nonneg,
  Finset.sum_eq_zero_iff_of_nonneg h.nonneg, Finset.sum_eq_zero_iff_of_nonneg h.nonneg,
  Finset.sum_eq_zero_iff_of_nonneg h.nonneg, Finset.sum_eq_zero_iff_of_nonneg h.nonneg,
  Finset.sum_eq_zero_iff_of_nonneg h.nonneg, Finset.sum_eq_zero_iff_of_nonneg h.nonneg,
  Finset.sum_eq_zero_iff_of_nonneg h.nonneg, Finset.sum_eq_zero_iff_of_nonneg h.nonneg,
  Finset.sum_eq_zero_iff_of_nonneg h.nonneg, Finset.sum_eq_zero_iff_of_nonneg h.nonneg,
  Finset.sum_eq_zero_iff_of_nonneg h.nonneg]
2025-12-15 11:26:33.165 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:26:33.258 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  ‚àÄ i ‚àà ?m.12550, ?m.12549 i = 0\nR M : Type u\ninst‚úù¬≥ : CommRing R\ninst‚úù¬≤ : AddCommGroup M\ninst‚úù¬π : Module R M\nŒπ : Type u\ninst‚úù : Fintype Œπ\nf : Œπ ‚Üí R\nx : Œπ ‚Üí M\nh : Module.IsTrivialRelation f x\n‚ä¢ ‚àë i : Œπ, f i ‚Ä¢ x i = 0")
2025-12-15 11:26:33.259 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 65.81s.
2025-12-15 11:26:33.259 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  ‚àÄ i ‚àà ?m.12550, ?m.12549 i = 0\nR M : Type u\ninst‚úù¬≥ : CommRing R\ninst‚úù¬≤ : AddCommGroup M\ninst‚úù¬π : Module R M\nŒπ : Type u\ninst‚úù : Fintype Œπ\nf : Œπ ‚Üí R\nx : Œπ ‚Üí M\nh : Module.IsTrivialRelation f x\n‚ä¢ ‚àë i : Œπ, f i ‚Ä¢ x i = 0")
2025-12-15 11:26:33.401 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:26:33.877 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: rw [IsHermitian, Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc,
  Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc, ‚Üê Matrix.mul_assoc,
  Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc,
  Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc,
  Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc,
  Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc,
  Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc,
  Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc,
  Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc,
  Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc,
  Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc,
  Matrix.mul_assoc, Matrix.m
2025-12-15 11:26:33.945 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="<stdin>:12:28: unexpected end of input; expected ']'")
2025-12-15 11:26:33.945 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 68.35s.
2025-12-15 11:26:33.945 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="<stdin>:12:28: unexpected end of input; expected ']'")
2025-12-15 11:26:34.089 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:26:41.885 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Batteries.RBNode.foldr_eq_foldr_toList
2025-12-15 11:26:41.953 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Finset.compl_ssubset_compl
2025-12-15 11:26:42.600 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: ENNReal.add_le_add_iff_right
2025-12-15 11:26:46.973 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:26:47.135 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:26:47.546 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:26:57.031 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: simpa [NormNum.IsNat.to_eq h] using h
2025-12-15 11:26:57.123 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error='type mismatch\n  h‚úù\nhas type\n  Mathlib.Meta.NormNum.IsNat e n : Prop\nbut is expected to have type\n  0 ‚â§ e : Prop')
2025-12-15 11:26:57.123 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 213.20s.
2025-12-15 11:26:57.123 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error='type mismatch\n  h‚úù\nhas type\n  Mathlib.Meta.NormNum.IsNat e n : Prop\nbut is expected to have type\n  0 ‚â§ e : Prop')
2025-12-15 11:26:57.265 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:27:03.183 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: simp_rw [disjoint_prod_iff, prod_disjoint_prod_iff, prod_disjoint_prod_iff, prod_disjoint_prod_iff]
2025-12-15 11:27:03.257 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error='simp made no progress')
2025-12-15 11:27:03.257 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 73.54s.
2025-12-15 11:27:03.257 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error='simp made no progress')
2025-12-15 11:27:03.398 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:27:07.099 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Real.arcsin_eq_pi_div_two
2025-12-15 11:27:07.538 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: induction t generalizing init <;> simp [*]
2025-12-15 11:27:07.609 | SUCCESS  | lean_reinforcement.agent.runner:run:218 - Proof finished in 1 steps and 25.72s.
2025-12-15 11:27:07.753 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:27:08.190 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: simp only [ssubset_iff, compl_subset_comm]
2025-12-15 11:27:08.206 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: rw [Ideal.span_singleton_eq_span_singleton, Ideal.span_singleton_eq_span_singleton,
  Ideal.span_singleton_eq_span_singleton, Ideal.span_singleton_eq_span_singleton]
2025-12-15 11:27:08.263 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="unknown identifier 'compl_subset_comm'")
2025-12-15 11:27:08.263 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 26.31s.
2025-12-15 11:27:08.263 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="unknown identifier 'compl_subset_comm'")
2025-12-15 11:27:08.368 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  Ideal.span {?m.496629} = Ideal.span {?m.496630}\nR : Type u_1\ninst‚úù‚Å∂ : CommRing R\nS : Submonoid R\nP : Type u_2\ninst‚úù‚Åµ : CommRing P\ninst‚úù‚Å¥ : Algebra R P\nloc : IsLocalization S P\nR‚ÇÅ : Type u_3\ninst‚úù¬≥ : CommRing R‚ÇÅ\nK : Type u_4\ninst‚úù¬≤ : Field K\ninst‚úù¬π : Algebra R‚ÇÅ K\ninst‚úù : IsFractionRing R‚ÇÅ K\nI J : Ideal R‚ÇÅ\nz : K\n‚ä¢ FractionalIdeal.spanSingleton R‚ÇÅ‚Å∞ z * ‚ÜëI = ‚ÜëJ ‚Üî\n    Ideal.span {(IsLocalization.sec R‚ÇÅ‚Å∞ z).1} * I = Ideal.span {‚Üë(IsLocalization.sec R‚ÇÅ‚Å∞ z).2} * J")
2025-12-15 11:27:08.368 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 60.91s.
2025-12-15 11:27:08.368 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  Ideal.span {?m.496629} = Ideal.span {?m.496630}\nR : Type u_1\ninst‚úù‚Å∂ : CommRing R\nS : Submonoid R\nP : Type u_2\ninst‚úù‚Åµ : CommRing P\ninst‚úù‚Å¥ : Algebra R P\nloc : IsLocalization S P\nR‚ÇÅ : Type u_3\ninst‚úù¬≥ : CommRing R‚ÇÅ\nK : Type u_4\ninst‚úù¬≤ : Field K\ninst‚úù¬π : Algebra R‚ÇÅ K\ninst‚úù : IsFractionRing R‚ÇÅ K\nI J : Ideal R‚ÇÅ\nz : K\n‚ä¢ FractionalIdeal.spanSingleton R‚ÇÅ‚Å∞ z * ‚ÜëI = ‚ÜëJ ‚Üî\n    Ideal.span {(IsLocalization.sec R‚ÇÅ‚Å∞ z).1} * I = Ideal.span {‚Üë(IsLocalization.sec R‚ÇÅ‚Å∞ z).2} * J")
2025-12-15 11:27:08.407 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:27:08.515 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:27:12.627 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:27:15.347 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: HahnSeries.support_nonempty_iff
2025-12-15 11:27:18.059 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: DirichletCharacter.changeLevel_self_toUnitHom
2025-12-15 11:27:18.992 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: MeasureTheory.FiniteMeasure.restrict_apply
2025-12-15 11:27:19.944 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:27:19.975 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Algebra.ofId_apply
2025-12-15 11:27:22.815 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:27:23.094 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: simp [skewAdjointLieSubalgebraEquiv]
2025-12-15 11:27:23.472 | SUCCESS  | lean_reinforcement.agent.runner:run:218 - Proof finished in 1 steps and 440.36s.
2025-12-15 11:27:23.618 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:27:23.987 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:27:24.912 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:27:25.483 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: rw [continuous_def]
2025-12-15 11:27:29.009 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: refine ‚ü®fun h =>?_, fun h => arcsin_of_le_pi_div_two h‚ü©
2025-12-15 11:27:29.077 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="unknown identifier 'arcsin_of_le_pi_div_two'")
2025-12-15 11:27:29.077 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 21.98s.
2025-12-15 11:27:29.077 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="unknown identifier 'arcsin_of_le_pi_div_two'")
2025-12-15 11:27:29.220 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:27:29.406 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: simp only [Ne, support_eq_empty, support_eq_empty]
2025-12-15 11:27:29.480 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="unknown identifier 'support_eq_empty'\nunknown identifier 'support_eq_empty'")
2025-12-15 11:27:29.480 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 14.13s.
2025-12-15 11:27:29.480 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="unknown identifier 'support_eq_empty'\nunknown identifier 'support_eq_empty'")
2025-12-15 11:27:29.624 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:27:30.208 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 2: Running MCTS search for 200 iterations...
2025-12-15 11:27:35.302 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: map_lt_lineMap_iff_slope_lt_slope_left
2025-12-15 11:27:37.775 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Finset.image_subset_infs_right
2025-12-15 11:27:39.884 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:27:41.005 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Finset.singleton_diffs_singleton
2025-12-15 11:27:42.357 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:27:42.703 | INFO     | __main__:main:302 - Completed 32/128 proofs
2025-12-15 11:27:45.638 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:27:58.262 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: rw [restrict_apply s_mble, inter_comm]
2025-12-15 11:27:58.396 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  ((sorryAx (MeasureTheory.FiniteMeasure Œ©) true).restrict ?A) ?s\nŒ© : Type u_1\ninst‚úù‚Å¥ : MeasurableSpace Œ©\nR : Type u_2\ninst‚úù¬≥ : SMul R ‚Ñù‚â•0\ninst‚úù¬≤ : SMul R ‚Ñù‚â•0‚àû\ninst‚úù¬π : IsScalarTower R ‚Ñù‚â•0 ‚Ñù‚â•0‚àû\ninst‚úù : IsScalarTower R ‚Ñù‚â•0‚àû ‚Ñù‚â•0‚àû\nŒº : MeasureTheory.FiniteMeasure Œ©\nA s : Set Œ©\ns_mble : MeasurableSet s\n‚ä¢ (Œº.restrict A) s = Œº (s ‚à© A)")
2025-12-15 11:27:58.396 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 39.40s.
2025-12-15 11:27:58.396 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  ((sorryAx (MeasureTheory.FiniteMeasure Œ©) true).restrict ?A) ?s\nŒ© : Type u_1\ninst‚úù‚Å¥ : MeasurableSpace Œ©\nR : Type u_2\ninst‚úù¬≥ : SMul R ‚Ñù‚â•0\ninst‚úù¬≤ : SMul R ‚Ñù‚â•0‚àû\ninst‚úù¬π : IsScalarTower R ‚Ñù‚â•0 ‚Ñù‚â•0‚àû\ninst‚úù : IsScalarTower R ‚Ñù‚â•0‚àû ‚Ñù‚â•0‚àû\nŒº : MeasureTheory.FiniteMeasure Œ©\nA s : Set Œ©\ns_mble : MeasurableSet s\n‚ä¢ (Œº.restrict A) s = Œº (s ‚à© A)")
2025-12-15 11:27:58.538 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:28:07.256 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 2: Applying best tactic: exact fun _ ‚Ü¶ isOpen_toAdd_preimage _
2025-12-15 11:28:07.322 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="unknown identifier 'isOpen_toAdd_preimage'")
2025-12-15 11:28:07.322 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 2 steps and 471.23s.
2025-12-15 11:28:07.322 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="unknown identifier 'isOpen_toAdd_preimage'")
2025-12-15 11:28:07.463 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:28:11.534 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Cardinal.prod_eq_two_power
2025-12-15 11:28:14.102 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: rw [slope_def_module, slope_def_module, slope_def_module, slope_def_module, slope_def_module,
  slope_def_module, slope_def_module, slope_def_module, sub_lt_iff_lt_add', sub_lt_iff_lt_add',
  sub_lt_iff_lt_add']
2025-12-15 11:28:14.277 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  slope ?f ?a ?b\nk : Type u_1\nE : Type u_2\nPE : Type u_3\ninst‚úù¬≥ : LinearOrderedField k\ninst‚úù¬≤ : OrderedAddCommGroup E\ninst‚úù¬π : Module k E\ninst‚úù : OrderedSMul k E\nf : k ‚Üí E\na b r : k\nh : 0 < r * (b - a)\n‚ä¢ f ((AffineMap.lineMap a b) r) < (AffineMap.lineMap (f a) (f b)) r ‚Üî\n    ((AffineMap.lineMap a b) r - a)‚Åª¬π ‚Ä¢ (f ((AffineMap.lineMap a b) r) - f a) < (b - a)‚Åª¬π ‚Ä¢ (f b - f a)")
2025-12-15 11:28:14.277 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 38.97s.
2025-12-15 11:28:14.277 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  slope ?f ?a ?b\nk : Type u_1\nE : Type u_2\nPE : Type u_3\ninst‚úù¬≥ : LinearOrderedField k\ninst‚úù¬≤ : OrderedAddCommGroup E\ninst‚úù¬π : Module k E\ninst‚úù : OrderedSMul k E\nf : k ‚Üí E\na b r : k\nh : 0 < r * (b - a)\n‚ä¢ f ((AffineMap.lineMap a b) r) < (AffineMap.lineMap (f a) (f b)) r ‚Üî\n    ((AffineMap.lineMap a b) r - a)‚Åª¬π ‚Ä¢ (f ((AffineMap.lineMap a b) r) - f a) < (b - a)‚Åª¬π ‚Ä¢ (f b - f a)")
2025-12-15 11:28:14.421 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:28:16.346 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:28:18.386 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: LinearIsometry.toSpanSingleton_apply
2025-12-15 11:28:22.853 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:28:24.099 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: NormedSpace.dualPairing_separatingLeft
2025-12-15 11:28:28.672 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:28:42.446 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: rw [sdiff_sdiff, sdiff_singleton_eq_erase, sdiff_singleton_eq_erase]
2025-12-15 11:28:42.558 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  (?a \\ ?b) \\ ?c\nF : Type u_1\nŒ± : Type u_2\nŒ≤ : Type u_3\ninst‚úù¬≤ : DecidableEq Œ±\ninst‚úù¬π : DecidableEq Œ≤\ninst‚úù : GeneralizedBooleanAlgebra Œ±\ns s‚ÇÅ s‚ÇÇ t t‚ÇÅ t‚ÇÇ u v : Finset Œ±\na b c : Œ±\n‚ä¢ {a} \\\\ {b} = {a \\ b}")
2025-12-15 11:28:42.558 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 61.55s.
2025-12-15 11:28:42.558 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  (?a \\ ?b) \\ ?c\nF : Type u_1\nŒ± : Type u_2\nŒ≤ : Type u_3\ninst‚úù¬≤ : DecidableEq Œ±\ninst‚úù¬π : DecidableEq Œ≤\ninst‚úù : GeneralizedBooleanAlgebra Œ±\ns s‚ÇÅ s‚ÇÇ t t‚ÇÅ t‚ÇÇ u v : Finset Œ±\na b c : Œ±\n‚ä¢ {a} \\\\ {b} = {a \\ b}")
2025-12-15 11:28:42.698 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:28:59.120 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: HasGradientAtFilter.tendsto_nhds
2025-12-15 11:29:03.728 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:29:19.864 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: ext
2025-12-15 11:29:22.295 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: rw [separatingLeft_iff_dualPairing_separatingLeft, dualPairing_separatingLeft_iff_dualPairing_separatingLeft,
  dualPairing_separatingLeft_iff_dualPairing_separatingLeft_iff_dualPairing_separatingLeft,
  dualPairing_separatingLeft_iff_dualPairing_separatingLeft_iff_dualPairing_separatingLeft,
  dualPairing_separatingLeft_iff_dualPairing_separatingLeft_iff_dualPairing_separatingLeft,
  dualPairing_separatingLeft_iff_dualPairing_separatingLeft_iff_dualPairing_separatingLeft,
  dualPairing_separatingLeft_iff_dualPairing_separatingLeft_iff_dualPairing_separatingLeft,
  dualPairing_separatingLeft_iff_dualPairing_separatingLeft_iff_dualPairing_separatingLeft,
  dualPairing_separatingLeft_iff_dualPairing_separatingLeft_iff_dualPairing_separatingLeft,
  dualPairing_separatingLeft_iff_dualPairing_separatingLeft_iff_dualPairing_separatingLeft,
  dualPairing_separatingLeft_iff_dualPairing_separatingLeft_iff_dualPairing_separatingLeft,
  dualPairing_separatingLeft_iff_dualPairing_separatingLeft_iff_dualPairing_separatin
2025-12-15 11:29:22.362 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="<stdin>:11:85: unexpected end of input; expected ']'")
2025-12-15 11:29:22.363 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 58.26s.
2025-12-15 11:29:22.363 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="<stdin>:11:85: unexpected end of input; expected ']'")
2025-12-15 11:29:22.505 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:29:22.848 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: ext
2025-12-15 11:29:22.978 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: rw [prod_eq_prod_of_one_le h‚ÇÅ h‚ÇÇ h‚ÇÅ, prod_eq_prod_of_one_le h‚ÇÅ h‚ÇÇ h‚ÇÅ, prod_eq_prod_of_one_le h‚ÇÅ h‚ÇÇ,
  prod_eq_prod_of_one_le h‚ÇÅ h‚ÇÇ h‚ÇÅ, prod_eq_prod_of_one_le h‚ÇÅ h‚ÇÇ h‚ÇÅ h‚ÇÇ]
2025-12-15 11:29:23.085 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.88890\nŒπ : Type u\ninst‚úù : Infinite Œπ\nc : Œπ ‚Üí Cardinal.{v}\nh‚ÇÅ : ‚àÄ (i : Œπ), 2 ‚â§ c i\nh‚ÇÇ : ‚àÄ (i : Œπ), Cardinal.lift.{u, v} (c i) ‚â§ Cardinal.lift.{v, u} #Œπ\n‚ä¢ Cardinal.prod c = 2 ^ Cardinal.lift.{v, u} #Œπ")
2025-12-15 11:29:23.085 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 71.55s.
2025-12-15 11:29:23.085 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.88890\nŒπ : Type u\ninst‚úù : Infinite Œπ\nc : Œπ ‚Üí Cardinal.{v}\nh‚ÇÅ : ‚àÄ (i : Œπ), 2 ‚â§ c i\nh‚ÇÇ : ‚àÄ (i : Œπ), Cardinal.lift.{u, v} (c i) ‚â§ Cardinal.lift.{v, u} #Œπ\n‚ä¢ Cardinal.prod c = 2 ^ Cardinal.lift.{v, u} #Œπ")
2025-12-15 11:29:23.230 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:29:24.848 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: rw [LinearIsometry.toSpanSingleton_apply]
2025-12-15 11:29:24.932 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="kernel type check failed: (kernel) declaration has free variables '[anonymous]'")
2025-12-15 11:29:24.932 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 66.55s.
2025-12-15 11:29:24.932 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="kernel type check failed: (kernel) declaration has free variables '[anonymous]'")
2025-12-15 11:29:24.993 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 2: Running MCTS search for 200 iterations...
2025-12-15 11:29:25.001 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 2: Applying best tactic: simp only [comp_apply, refl_apply]
2025-12-15 11:29:25.070 | SUCCESS  | lean_reinforcement.agent.runner:run:218 - Proof finished in 2 steps and 353.86s.
2025-12-15 11:29:25.076 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:29:25.214 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:29:28.919 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 2: Running MCTS search for 200 iterations...
2025-12-15 11:29:34.114 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: QPF.supp_eq
2025-12-15 11:29:35.599 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Bornology.IsVonNBounded.vadd
2025-12-15 11:29:38.872 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:29:40.217 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:29:44.255 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Zspan.exist_unique_vadd_mem_fundamentalDomain
2025-12-15 11:29:46.259 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Finset.inter_comm
2025-12-15 11:29:48.899 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:29:51.022 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:30:00.858 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: simp only [update, ite_eq_right_iff, eq_self_iff_true, Function.update_same]
2025-12-15 11:30:05.444 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 2: Running MCTS search for 200 iterations...
2025-12-15 11:30:55.826 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: exact fun n ‚Ü¶ UniformContinuous.pow hf (UniformContinuous.pow hf n)
2025-12-15 11:30:55.910 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error='invalid field notation, type is not of the form (C ...) where C is a constant\n  UniformContinuous\nhas type\n  (?m.42674 ‚Üí ?m.42675) ‚Üí Prop')
2025-12-15 11:30:55.910 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 332.96s.
2025-12-15 11:30:55.910 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error='invalid field notation, type is not of the form (C ...) where C is a constant\n  UniformContinuous\nhas type\n  (?m.42674 ‚Üí ?m.42675) ‚Üí Prop')
2025-12-15 11:30:56.050 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:31:03.291 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 2: Applying best tactic: exact dif_pos trivial
2025-12-15 11:31:03.354 | SUCCESS  | lean_reinforcement.agent.runner:run:218 - Proof finished in 2 steps and 676.28s.
2025-12-15 11:31:03.496 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:31:07.185 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: card_orderOf_eq_totient_aux‚ÇÇ
2025-12-15 11:31:12.002 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:31:27.992 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 2: Applying best tactic: simp [mem_ofSet_symm_apply]
2025-12-15 11:31:28.064 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="unknown identifier 'mem_ofSet_symm_apply'")
2025-12-15 11:31:28.064 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 2 steps and 651.45s.
2025-12-15 11:31:28.064 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="unknown identifier 'mem_ofSet_symm_apply'")
2025-12-15 11:31:28.204 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:31:30.743 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: DFinsupp.sigmaUncurry_apply
2025-12-15 11:31:34.996 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Set.empty_sups
2025-12-15 11:31:35.416 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:31:39.570 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:31:59.812 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: rw [inter_comm, inter_comm]
2025-12-15 11:31:59.887 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="kernel type check failed: (kernel) declaration has free variables '[anonymous]'")
2025-12-15 11:31:59.887 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 133.63s.
2025-12-15 11:31:59.887 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="kernel type check failed: (kernel) declaration has free variables '[anonymous]'")
2025-12-15 11:32:00.027 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:32:00.733 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: simpa only [add_comm] using isVonNBounded_add ùïú s x
2025-12-15 11:32:00.801 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="unknown identifier 'isVonNBounded_add'")
2025-12-15 11:32:00.802 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 145.20s.
2025-12-15 11:32:00.802 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="unknown identifier 'isVonNBounded_add'")
2025-12-15 11:32:00.944 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:32:02.579 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: rw [totient_eq_card_filter_eq_totient, card_filter_eq_card_filter_eq_totient,
  card_filter_eq_card_filter_eq_card_filter_eq_card_filter_eq_card_filter_eq_card_filter,
  card_filter_eq_card_filter_eq_card_filter_eq_card_filter_eq_card_filter_eq_card_filter,
  card_filter_eq_card_filter_eq_card_filter_eq_card_filter_eq_card_filter_eq_card_filter,
  card_filter_eq_card_filter_eq_card_filter_eq_card_filter_eq_card_filter_eq_card_filter,
  card_filter_eq_card_filter_eq_card_filter_eq_card_filter_eq_card_filter_eq_card_filter,
  card_filter_eq_card_filter_eq_card_filter_eq_card_filter_eq_card_filter_eq_card_filter,
  card_filter_eq_card_filter_eq_card_filter_eq_card_filter_eq_card_filter_eq_card_filter]
2025-12-15 11:32:02.697 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.77835\nŒ± : Type u\na : Œ±\ninst‚úù¬≤ : Group Œ±\ninst‚úù¬π : DecidableEq Œ±\ninst‚úù : Fintype Œ±\nhn : ‚àÄ (n : ‚Ñï), 0 < n ‚Üí (Finset.filter (fun a => a ^ n = 1) Finset.univ).card ‚â§ n\nd : ‚Ñï\nhd : d ‚à£ Fintype.card Œ±\n‚ä¢ (Finset.filter (fun a => orderOf a = d) Finset.univ).card = œÜ d")
2025-12-15 11:32:02.697 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 55.51s.
2025-12-15 11:32:02.697 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.77835\nŒ± : Type u\na : Œ±\ninst‚úù¬≤ : Group Œ±\ninst‚úù¬π : DecidableEq Œ±\ninst‚úù : Fintype Œ±\nhn : ‚àÄ (n : ‚Ñï), 0 < n ‚Üí (Finset.filter (fun a => a ^ n = 1) Finset.univ).card ‚â§ n\nd : ‚Ñï\nhd : d ‚à£ Fintype.card Œ±\n‚ä¢ (Finset.filter (fun a => orderOf a = d) Finset.univ).card = œÜ d")
2025-12-15 11:32:02.840 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:32:10.060 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: OmegaCompletePartialOrder.ContinuousHom.coe_apply
2025-12-15 11:32:11.066 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: xor_iff_not_iff
2025-12-15 11:32:15.014 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:32:15.775 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:32:23.977 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Filter.eventually_iSup
2025-12-15 11:32:28.645 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:32:33.896 | INFO     | __main__:main:302 - Completed 48/128 proofs
2025-12-15 11:32:39.481 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: simp [sup_subset_iff]
2025-12-15 11:32:39.545 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error='simp made no progress')
2025-12-15 11:32:39.545 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 64.55s.
2025-12-15 11:32:39.545 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error='simp made no progress')
2025-12-15 11:32:39.685 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:32:46.085 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: nmem_nonZeroDivisorsLeft_iff
2025-12-15 11:32:50.642 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:32:51.407 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: simp_rw [le_einfsep_iff]
2025-12-15 11:32:55.864 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 2: Running MCTS search for 200 iterations...
2025-12-15 11:32:55.867 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 2: Applying best tactic: simp (config := { contextual := true }) [mem_image]
2025-12-15 11:32:56.452 | SUCCESS  | lean_reinforcement.agent.runner:run:218 - Proof finished in 2 steps and 659.71s.
2025-12-15 11:32:56.592 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:33:03.784 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Equiv.Perm.cycleOf_self_apply_pow
2025-12-15 11:33:08.250 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:33:14.179 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: rw [‚Üê OrderHom.coe_coe, ‚Üê OrderHom.coe_coe, OrderHom.coe_mk, OrderHom.coe_mk,
  OrderHom.coe_mk, OrderHom.coe_mk, OrderHom.coe_mk, OrderHom.coe_mk, OrderHom.coe_mk,
  OrderHom.coe_mk, OrderHom.coe_mk, OrderHom.coe_mk, OrderHom.coe_mk, OrderHom.coe_mk,
  OrderHom.coe_mk, OrderHom.coe_mk, OrderHom.coe_mk, OrderHom.coe_mk, OrderHom.coe_mk,
  OrderHom.coe_mk, OrderHom.coe_mk, OrderHom.coe_mk, OrderHom.coe_mk, OrderHom.coe_mk]
2025-12-15 11:33:14.308 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.60541\nŒ± : Type u\nŒ±' : Type u_1\nŒ≤ : Type v\nŒ≤' : Type u_2\nŒ≥ : Type u_3\nœÜ : Type u_4\ninst‚úù‚Åµ : OmegaCompletePartialOrder Œ±\ninst‚úù‚Å¥ : OmegaCompletePartialOrder Œ≤\ninst‚úù¬≥ : OmegaCompletePartialOrder Œ≥\ninst‚úù¬≤ : OmegaCompletePartialOrder œÜ\ninst‚úù¬π : OmegaCompletePartialOrder Œ±'\ninst‚úù : OmegaCompletePartialOrder Œ≤'\na : Œ±\nf : Œ± ‚ÜíùíÑ Œ≤\n‚ä¢ ‚Üëf a = f a")
2025-12-15 11:33:14.308 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 64.25s.
2025-12-15 11:33:14.308 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.60541\nŒ± : Type u\nŒ±' : Type u_1\nŒ≤ : Type v\nŒ≤' : Type u_2\nŒ≥ : Type u_3\nœÜ : Type u_4\ninst‚úù‚Åµ : OmegaCompletePartialOrder Œ±\ninst‚úù‚Å¥ : OmegaCompletePartialOrder Œ≤\ninst‚úù¬≥ : OmegaCompletePartialOrder Œ≥\ninst‚úù¬≤ : OmegaCompletePartialOrder œÜ\ninst‚úù¬π : OmegaCompletePartialOrder Œ±'\ninst‚úù : OmegaCompletePartialOrder Œ≤'\na : Œ±\nf : Œ± ‚ÜíùíÑ Œ≤\n‚ä¢ ‚Üëf a = f a")
2025-12-15 11:33:14.449 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:33:16.643 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: simp [sigmaUncurry]
2025-12-15 11:33:16.800 | SUCCESS  | lean_reinforcement.agent.runner:run:218 - Proof finished in 1 steps and 106.06s.
2025-12-15 11:33:16.942 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:33:22.552 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: List.sublistsLen_sublist_of_sublist
2025-12-15 11:33:27.389 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:33:33.584 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Finset.not_mem_empty
2025-12-15 11:33:38.245 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:33:52.332 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: simp
2025-12-15 11:33:52.396 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error='simp made no progress')
2025-12-15 11:33:52.396 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 18.81s.
2025-12-15 11:33:52.396 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error='simp made no progress')
2025-12-15 11:33:52.537 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:34:07.563 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: CliffordAlgebraQuaternion.toQuaternion_ofQuaternion
2025-12-15 11:34:12.348 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:35:10.059 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: induction' l‚ÇÅ with _ l‚ÇÅ_invariant
2025-12-15 11:35:12.085 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: simp only [ofQuaternion, QuaternionAlgebra.toQuaternion, QuaternionAlgebra.toQuaternion,
  QuaternionAlgebra.toQuaternionAlgebra, QuaternionAlgebra.toQuaternionAlgebra,
  QuaternionAlgebra.toQuaternionAlgebra, QuaternionAlgebra.toQuaternionAlgebra,
  QuaternionAlgebra.toQuaternionAlgebra, QuaternionAlgebra.toQuaternionAlgebra,
  QuaternionAlgebra.toQuaternionAlgebra, QuaternionAlgebra.toQuaternionAlgebra,
  QuaternionAlgebra.toQuaternionAlgebra, QuaternionAlgebra.toQuaternionAlgebra,
  QuaternionAlgebra.toQuaternionAlgebra, QuaternionAlgebra.toQuaternionAlgebra,
  QuaternionAlgebra.toQuaternionAlgebra, QuaternionAlgebra.toQuaternionAlgebra,
  QuaternionAlgebra.toQuaternionAlgebra, QuaternionAlgebra.toQuaternionAlgebra,
  QuaternionAlgebra.toQuaternionAlgebra, QuaternionAlgebra.toQuaternionAlgebra,
  QuaternionAlgebra.toQuaternionAlgebra, QuaternionAlgebra.toQuaternionAlgebra,
  QuaternionAlgebra.toQuaternionAlgebra, QuaternionAlgebra.toQuaternionAlgebra,
  QuaternionAlgebra.toQuaternionAlgebra, QuaternionAlg
2025-12-15 11:35:12.153 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="<stdin>:13:54: unexpected end of input; expected ']'")
2025-12-15 11:35:12.153 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 64.59s.
2025-12-15 11:35:12.153 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="<stdin>:13:54: unexpected end of input; expected ']'")
2025-12-15 11:35:12.296 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:35:12.797 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: simp (config := { contextual := true })
2025-12-15 11:35:12.885 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error='simp made no progress')
2025-12-15 11:35:12.885 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 455.11s.
2025-12-15 11:35:12.885 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error='simp made no progress')
2025-12-15 11:35:13.031 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:35:15.011 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 2: Running MCTS search for 200 iterations...
2025-12-15 11:35:21.545 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: exists_mem_of_exists
2025-12-15 11:35:21.830 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Nat.minFac_has_prop
2025-12-15 11:35:26.455 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:35:26.582 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:35:41.824 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 2: Applying best tactic: all_goals apply sublistsLen_sublist_cons
2025-12-15 11:35:41.898 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="unknown identifier 'sublistsLen_sublist_cons'\nunknown identifier 'sublistsLen_sublist_cons'")
2025-12-15 11:35:41.899 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 2 steps and 139.35s.
2025-12-15 11:35:41.899 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="unknown identifier 'sublistsLen_sublist_cons'\nunknown identifier 'sublistsLen_sublist_cons'")
2025-12-15 11:35:42.038 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:35:48.906 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Matrix.charpoly.univ_map_eval‚ÇÇHom
2025-12-15 11:35:53.456 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:36:17.030 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: have n2 : n ‚â† 0 := by rintro rfl; simp at n1
2025-12-15 11:36:17.103 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error='unsolved goals\nn : ‚Ñï\nn1 : True\n‚ä¢ False')
2025-12-15 11:36:17.103 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 55.27s.
2025-12-15 11:36:17.103 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error='unsolved goals\nn : ‚Ñï\nn1 : True\n‚ä¢ False')
2025-12-15 11:36:17.244 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:36:33.736 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: CategoryTheory.ShortComplex.RightHomologyData.p_comp_opcyclesIso_inv
2025-12-15 11:36:38.343 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:36:48.348 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: rw [‚Üê Polynomial.map_map, eval‚ÇÇHom_map_eval‚ÇÇHom, eval‚ÇÇHom_map_eval‚ÇÇHom,
  eval‚ÇÇHom_map_eval‚ÇÇHom, eval‚ÇÇHom_map_eval‚ÇÇHom, eval‚ÇÇ_map, eval‚ÇÇHom_map_eval‚ÇÇHom,
  eval‚ÇÇHom_map_eval‚ÇÇHom, eval‚ÇÇHom_map_eval‚ÇÇHom, eval‚ÇÇHom_map_eval‚ÇÇHom, eval‚ÇÇHom_map_eval‚ÇÇHom,
  eval‚ÇÇHom_map_eval‚ÇÇHom, eval‚ÇÇHom_map_eval‚ÇÇHom, eval‚ÇÇHom_map_eval‚ÇÇHom, eval‚ÇÇ_map,
  eval‚ÇÇHom_map_eval‚ÇÇHom, eval‚ÇÇHom_map_eval‚ÇÇHom, eval‚ÇÇHom_map_eval‚ÇÇHom, eval‚ÇÇHom_map_eval‚ÇÇHom,
  eval‚ÇÇHom_map_eval‚ÇÇHom, eval‚ÇÇHom_map_eval‚ÇÇHom, eval‚ÇÇHom_map_eval‚ÇÇHom, eval‚ÇÇHom_map_eval‚ÇÇHom,
  eval‚ÇÇHom_map_eval‚ÇÇHom, eval‚ÇÇHom_map_eval‚ÇÇHom, eval‚ÇÇHom_map_eval‚ÇÇHom]
2025-12-15 11:36:48.475 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  Polynomial.map (?g.comp ?f) ?p\nR : Type u_1\nS : Type u_2\nn : Type u_3\ninst‚úù¬≥ : CommRing R\ninst‚úù¬≤ : CommRing S\ninst‚úù¬π : Fintype n\ninst‚úù : DecidableEq n\nf : R ‚Üí+* S\nM : n √ó n ‚Üí S\n‚ä¢ Polynomial.map (MvPolynomial.eval‚ÇÇHom f M) (Matrix.charpoly.univ R n) = (Matrix.of (Function.curry M)).charpoly")
2025-12-15 11:36:48.475 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 59.57s.
2025-12-15 11:36:48.476 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  Polynomial.map (?g.comp ?f) ?p\nR : Type u_1\nS : Type u_2\nn : Type u_3\ninst‚úù¬≥ : CommRing R\ninst‚úù¬≤ : CommRing S\ninst‚úù¬π : Fintype n\ninst‚úù : DecidableEq n\nf : R ‚Üí+* S\nM : n √ó n ‚Üí S\n‚ä¢ Polynomial.map (MvPolynomial.eval‚ÇÇHom f M) (Matrix.charpoly.univ R n) = (Matrix.of (Function.curry M)).charpoly")
2025-12-15 11:36:48.615 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:36:57.199 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Ordinal.sup_opow_nat
2025-12-15 11:37:01.781 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:37:29.061 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: simp only [toUnitHom, MonoidWithZeroHom.coe_mk, MonoidWithZeroHom.coe_mk,
  MonoidWithZeroHom.coe_mk, MonoidWithZeroHom.coe_mk, MonoidWithZeroHom.coe_mk,
  MonoidWithZeroHom.coe_mk, MonoidWithZeroHom.coe_mk, MonoidWithZeroHom.coe_mk,
  MonoidWithZeroHom.coe_mk, MonoidWithZeroHom.coe_mk, MonoidWithZeroHom.coe_mk,
  MonoidWithZeroHom.coe_mk, MonoidWithZeroHom.coe_mk, MonoidWithZeroHom.coe_mk,
  MonoidWithZeroHom.coe_mk, MonoidWithZeroHom.coe_mk, MonoidWithZeroHom.coe_mk,
  MonoidWithZeroHom.coe_mk, MonoidWithZeroHom.coe_mk, MonoidWithZeroHom.coe_mk,
  MonoidWithZeroHom.coe_mk, MonoidWithZeroHom.coe_mk, MonoidWithZeroHom.coe_mk,
  MonoidWithZeroHom.coe_mk, MonoidWithZeroHom.coe_mk, MonoidWithZeroHom.coe_mk]
2025-12-15 11:37:33.485 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 2: Running MCTS search for 200 iterations...
2025-12-15 11:38:06.136 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: cases subsingleton_or_nontrivial R
2025-12-15 11:38:10.712 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 2: Running MCTS search for 200 iterations...
2025-12-15 11:39:09.770 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 2: Applying best tactic: exacts [Subsingleton.elim (‚ä§ : Subsingleton R) ‚ä§, Subsingleton.elim (‚ä§ : Subsingleton R) ‚ä§,
  Subsingleton.elim (‚ä§ : Subsingleton R) ‚ä§, Subsingleton.elim (‚ä§ : Subsingleton R) ‚ä§,
  Subsingleton.elim (‚ä§ : Subsingleton R) ‚ä§, Subsingleton.elim (‚ä§ : Subsingleton R) ‚ä§,
  Subsingleton.elim (‚ä§ : Subsingleton R) ‚ä§, Subsingleton.elim (‚ä§ : Subsingleton R) ‚ä§,
  Subsingleton.elim (‚ä§ : Subsingleton R) ‚ä§, Subsingleton.elim (‚ä§ : Subsingleton R) ‚ä§,
  Subsingleton.elim (‚ä§ : Subsingleton R) ‚ä§, Subsingleton.elim (‚ä§ : Subsingleton R) ‚ä§,
  Subsingleton.elim (‚ä§ : Subsingleton R) ‚ä§, Subsingleton.elim (‚ä§ : Subsingleton R) ‚ä§,
  Subsingleton.elim (‚ä§ : Subsingleton R) ‚ä§, Subsingleton.elim (‚ä§ : Subsingleton R) ‚ä§,
  Subsingleton.elim (‚ä§ : Subsingleton R) ‚ä§, Subsingleton.elim (‚ä§ : Subsingleton R) ‚ä§,
  Subsingleton.elim (‚ä§ : Subsingleton R) ‚ä§, Subsingleton.elim (‚ä§ : Subsingleton R) ‚ä§,
  Subsingleton.elim (‚ä§ : Subsingleton R) ‚ä§, Subsingleton.elim (‚ä§ : Subs
2025-12-15 11:39:09.839 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="<stdin>:11:71: unexpected end of input; expected ')'")
2025-12-15 11:39:09.839 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 2 steps and 1021.70s.
2025-12-15 11:39:09.839 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="<stdin>:11:71: unexpected end of input; expected ')'")
2025-12-15 11:39:09.981 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:39:26.578 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 2: Applying best tactic: simp [changeLevel_def]
2025-12-15 11:39:26.656 | SUCCESS  | lean_reinforcement.agent.runner:run:218 - Proof finished in 2 steps and 728.60s.
2025-12-15 11:39:26.797 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:39:39.113 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Measurable.const_smul'
2025-12-15 11:39:43.639 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:39:56.571 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: ContDiff.comp‚ÇÉ
2025-12-15 11:40:00.511 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: rw [ofId_apply, Algebra.algebraMap_eq_smul_one, Algebra.algebraMap_eq_smul_one]
2025-12-15 11:40:00.615 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  (algebraMap ?m.227913 ?m.227914) ?r\nR : Type u\nA : Type v\ninst‚úù¬≤ : CommSemiring R\ninst‚úù¬π : Semiring A\ninst‚úù : Algebra R A\nr : R\n‚ä¢ r ‚Ä¢ 1 = r ‚Ä¢ 1")
2025-12-15 11:40:00.615 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 760.64s.
2025-12-15 11:40:00.615 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  (algebraMap ?m.227913 ?m.227914) ?r\nR : Type u\nA : Type v\ninst‚úù¬≤ : CommSemiring R\ninst‚úù¬π : Semiring A\ninst‚úù : Algebra R A\nr : R\n‚ä¢ r ‚Ä¢ 1 = r ‚Ä¢ 1")
2025-12-15 11:40:00.757 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:40:00.835 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: simpa only [inv_smul_smul] using hg.const_smul c‚Åª¬π
2025-12-15 11:40:00.942 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="invalid field 'const_smul', the environment does not contain 'Measurable.const_smul'\n  hg\nhas type\n  Measurable g\ninvalid field notation, type is not of the form (C ...) where C is a constant\n  hg\nhas type\n  MeasurableSet ?m.99164 ‚Üí MeasurableSet (g ‚Åª¬π' ?m.99164)")
2025-12-15 11:40:00.942 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 21.83s.
2025-12-15 11:40:00.942 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="invalid field 'const_smul', the environment does not contain 'Measurable.const_smul'\n  hg\nhas type\n  Measurable g\ninvalid field notation, type is not of the form (C ...) where C is a constant\n  hg\nhas type\n  MeasurableSet ?m.99164 ‚Üí MeasurableSet (g ‚Åª¬π' ?m.99164)")
2025-12-15 11:40:01.085 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:40:01.128 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:40:07.461 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Prod.snd_mul
2025-12-15 11:40:07.616 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Set.sups_subset_right
2025-12-15 11:40:11.653 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: simp (config := { contextual := true })
2025-12-15 11:40:12.259 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:40:12.363 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:40:16.479 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 2: Running MCTS search for 200 iterations...
2025-12-15 11:40:37.107 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: exact FormalMultilinearSeries.pi ùïú E F f‚ÇÅ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f‚ÇÇ f‚ÇÅ f‚ÇÇ f
2025-12-15 11:40:37.176 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="unknown constant 'FormalMultilinearSeries.pi'")
2025-12-15 11:40:37.176 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 40.61s.
2025-12-15 11:40:37.176 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="unknown constant 'FormalMultilinearSeries.pi'")
2025-12-15 11:40:37.317 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:40:41.384 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: simp [mul_def]
2025-12-15 11:40:41.449 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error='simp made no progress')
2025-12-15 11:40:41.449 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 33.99s.
2025-12-15 11:40:41.449 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error='simp made no progress')
2025-12-15 11:40:41.592 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:40:44.291 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: OpenSubgroup.toSubgroup_top
2025-12-15 11:40:46.802 | INFO     | __main__:main:302 - Completed 64/128 proofs
2025-12-15 11:40:48.985 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:40:57.476 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: rw [tendsto_iff_norm_sub_tendsto_zero]
2025-12-15 11:40:59.344 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: RCLike.isCauSeq_re
2025-12-15 11:41:02.431 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 2: Running MCTS search for 200 iterations...
2025-12-15 11:41:04.142 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:41:08.903 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: rw [coe_top, Set.top_eq_univ, Set.top_eq_univ, Set.top_eq_univ]
2025-12-15 11:41:08.996 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  ‚Üë‚ä§\nG : Type u_1\ninst‚úù¬π : Group G\ninst‚úù : TopologicalSpace G\nU V : OpenSubgroup G\ng : G\n‚ä¢ ‚Üë‚ä§ = ‚ä§")
2025-12-15 11:41:08.996 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 24.71s.
2025-12-15 11:41:08.996 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  ‚Üë‚ä§\nG : Type u_1\ninst‚úù¬π : Group G\ninst‚úù : TopologicalSpace G\nU V : OpenSubgroup G\ng : G\n‚ä¢ ‚Üë‚ä§ = ‚ä§")
2025-12-15 11:41:09.136 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:41:17.025 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: CoalgEquiv.toCoalgHom_eq_coe
2025-12-15 11:41:21.682 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:41:38.999 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: simp [mem_nonZeroDivisorsLeft_iff_ne_zero]
2025-12-15 11:41:39.578 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="unknown identifier 'mem_nonZeroDivisorsLeft_iff_ne_zero'")
2025-12-15 11:41:39.578 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 533.49s.
2025-12-15 11:41:39.578 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="unknown identifier 'mem_nonZeroDivisorsLeft_iff_ne_zero'")
2025-12-15 11:41:39.717 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:41:42.678 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: exact isCauSeq_re_of_cauSeq_of_cauSeq_of_cauSeq_of_cauSeq f.cauSeq_of_cauSeq f.cauSeq_of_cauSeq_of_cauSeq
  f.cauSeq_of_cauSeq_of_cauSeq f.cauSeq_of_cauSeq_of_cauSeq f.cauSeq_of_cauSeq_of_cauSeq f.cauSeq_of_cauSeq_of_cauSeq
  f.cauSeq_of_cauSeq_of_cauSeq f.cauSeq_of_cauSeq_of_cauSeq f.cauSeq_of_cauSeq_of_cauSeq f.cauSeq_of_cauSeq_of_cauSeq
  f.cauSeq_of_cauSeq_of_cauSeq f.cauSeq_of_cauSeq_of_cauSeq f.cauSeq_of_cauSeq_of_cauSeq f.cauSeq_of_cauSeq_of_cauSeq
  f.cauSeq_of_cauSeq_of_cauSeq f.cauSeq_of_cauSeq_of_cauSeq f.cauSeq_of_cauSeq_of_cauSeq f.cauSeq_of_cauSeq_of_cauSeq
  f.cauSeq_of_cauSeq_of_cauSeq f.cauSeq_of_cauSeq_of_cauSeq f.cauSeq_of_cauSeq_of_cauSeq f.cauSeq_of_cauSeq_of_cauSeq
  f.cauSeq_of_cauSeq_of_cauSeq f.cauSeq_of_cauSeq_of_cauSeq f.cauSeq_of_cauSeq_of_cauSeq f.cauSeq_of_cauSeq_of_cauSeq
  f.cauSeq_of_cauSeq_of_cauSeq f.cauSeq_of_cauSeq_of_cauSeq f.cauSeq_of_cauSeq_of_cauSeq f.cauSeq_of_cauSeq
2025-12-15 11:41:42.750 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="unknown identifier 'isCauSeq_re_of_cauSeq_of_cauSeq_of_cauSeq_of_cauSeq'")
2025-12-15 11:41:42.750 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 43.41s.
2025-12-15 11:41:42.750 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="unknown identifier 'isCauSeq_re_of_cauSeq_of_cauSeq_of_cauSeq_of_cauSeq'")
2025-12-15 11:41:42.890 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:41:55.876 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Filter.smul_le_smul
2025-12-15 11:42:00.538 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:42:07.184 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: rw [‚Üê Coalgebra.coe_toCoalgHom, ‚Üê Coalgebra.coe_toCoalgHom, Coalgebra.coe_toCoalgHom,
  Coalgebra.coe_toCoalgHom, Coalgebra.coe_toCoalgHom, Coalgebra.coe_toCoalgHom,
  Coalgebra.coe_toCoalgHom, Coalgebra.coe_toCoalgHom, Coalgebra.coe_toCoalgHom,
  Coalgebra.coe_toCoalgHom, Coalgebra.coe_toCoalgHom, Coalgebra.coe_toCoalgHom,
  Coalgebra.coe_toCoalgHom, Coalgebra.coe_toCoalgHom, Coalgebra.coe_toCoalgHom,
  Coalgebra.coe_toCoalgHom, Coalgebra.coe_toCoalgHom, Coalgebra.coe_toCoalgHom,
  Coalgebra.coe_toCoalgHom, Coalgebra.coe_toCoalgHom, Coalgebra.coe_toCoalgHom]
2025-12-15 11:42:07.316 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.54800\nR : Type u_1\nA : Type u_2\nB : Type u_3\nC : Type u_4\ninst‚úù‚Åπ : CommSemiring R\ninst‚úù‚Å∏ : AddCommMonoid A\ninst‚úù‚Å∑ : AddCommMonoid B\ninst‚úù‚Å∂ : AddCommMonoid C\ninst‚úù‚Åµ : Module R A\ninst‚úù‚Å¥ : Module R B\ninst‚úù¬≥ : Module R C\ninst‚úù¬≤ : CoalgebraStruct R A\ninst‚úù¬π : CoalgebraStruct R B\ninst‚úù : CoalgebraStruct R C\ne e' f : A ‚âÉ‚Çóc[R] B\n‚ä¢ f.toCoalgHom = ‚Üëf")
2025-12-15 11:42:07.316 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 50.29s.
2025-12-15 11:42:07.316 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.54800\nR : Type u_1\nA : Type u_2\nB : Type u_3\nC : Type u_4\ninst‚úù‚Åπ : CommSemiring R\ninst‚úù‚Å∏ : AddCommMonoid A\ninst‚úù‚Å∑ : AddCommMonoid B\ninst‚úù‚Å∂ : AddCommMonoid C\ninst‚úù‚Åµ : Module R A\ninst‚úù‚Å¥ : Module R B\ninst‚úù¬≥ : Module R C\ninst‚úù¬≤ : CoalgebraStruct R A\ninst‚úù¬π : CoalgebraStruct R B\ninst‚úù : CoalgebraStruct R C\ne e' f : A ‚âÉ‚Çóc[R] B\n‚ä¢ f.toCoalgHom = ‚Üëf")
2025-12-15 11:42:07.456 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:42:14.730 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: exact smul_le_smul_of_nonneg_left
2025-12-15 11:42:14.797 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="unknown identifier 'smul_le_smul_of_nonneg_left'")
2025-12-15 11:42:14.797 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 18.92s.
2025-12-15 11:42:14.797 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="unknown identifier 'smul_le_smul_of_nonneg_left'")
2025-12-15 11:42:14.937 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:42:15.420 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: DivisorChain.card_subset_divisors_le_length_of_chain
2025-12-15 11:42:18.051 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: simp (config := { contextual := true }) [H]
2025-12-15 11:42:18.120 | SUCCESS  | lean_reinforcement.agent.runner:run:218 - Proof finished in 1 steps and 416.57s.
2025-12-15 11:42:18.264 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:42:20.321 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:42:20.491 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 2: Applying best tactic: simp (config := { contextual := true })
2025-12-15 11:42:20.761 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error='simp made no progress')
2025-12-15 11:42:20.761 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 2 steps and 938.16s.
2025-12-15 11:42:20.761 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error='simp made no progress')
2025-12-15 11:42:20.903 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:42:22.426 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: simp [Xor', not_iff_not]
2025-12-15 11:42:24.526 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Rat.cast_inj
2025-12-15 11:42:25.336 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Primrec.encdec
2025-12-15 11:42:27.636 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 2: Running MCTS search for 200 iterations...
2025-12-15 11:42:29.390 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:42:30.204 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:42:35.102 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Behrend.threeAPFree_sphere
2025-12-15 11:42:39.538 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:42:47.706 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: rw [Finset.card_eq_sum_ones, ‚Üê Finset.card_eq_sum_ones, ‚Üê Finset.card_eq_sum_ones,
  Finset.card_eq_sum_ones, Finset.card_eq_sum_ones, Finset.card_eq_sum_ones, Finset.card_eq_sum_ones,
  Finset.card_eq_sum_ones, Finset.card_eq_sum_ones, Finset.card_eq_sum_ones, ‚Üê Finset.card_eq_sum_ones,
  Finset.card_eq_sum_ones, Finset.card_eq_sum_ones, Finset.card_eq_sum_ones, Finset.card_eq_sum_ones,
  Finset.card_eq_sum_ones, Finset.card_eq_sum_ones, Finset.card_eq_sum_ones, Finset.card_eq_sum_ones,
  Finset.card_eq_sum_ones, Finset.card_eq_sum_ones, Finset.card_eq_sum_ones, Finset.card_eq_sum_ones,
  Finset.card_eq_sum_ones, Finset.card_eq_sum_ones, Finset.card_eq_sum_ones, Finset.card_eq_sum_ones,
  Finset.card_eq_sum_ones, Finset.card_eq_sum_ones, Finset.card_eq_sum_ones, Finset.card_eq_sum_ones,
  Finset.card_eq_sum_ones, Finset.card_eq_sum_ones, Finset.card_eq_sum_ones, Finset.card_eq_sum_ones,
  Finset.card_eq_sum_ones, Finset.card_eq_sum_ones, Finset.card_eq_sum_ones, Finset.card_eq_sum_ones,
  Finset.card_
2025-12-15 11:42:47.775 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="<stdin>:11:14: unexpected end of input; expected ']'")
2025-12-15 11:42:47.775 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 32.35s.
2025-12-15 11:42:47.775 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="<stdin>:11:14: unexpected end of input; expected ']'")
2025-12-15 11:42:47.913 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:42:49.190 | ERROR    | lean_reinforcement.utilities.gym:reset:40 - Error during environment reset: Timeout during initialization
2025-12-15 11:42:49.190 | ERROR    | lean_reinforcement.training.worker:process_theorem:45 - Failed to initialize environment for theorem ContDiffAt.div: Timeout during initialization
2025-12-15 11:42:49.454 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:42:53.001 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 2: Applying best tactic: rw [tendsto_zero_iff_norm_sub_tendsto_zero]
2025-12-15 11:42:53.121 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.225609\nùïú : Type u_1\nF : Type u_2\ninst‚úù¬≥ : RCLike ùïú\ninst‚úù¬≤ : NormedAddCommGroup F\ninst‚úù¬π : InnerProductSpace ùïú F\ninst‚úù : CompleteSpace F\nf : F ‚Üí ùïú\nf' x : F\ns : Set F\nL : Filter F\nhL : L ‚â§ ùìù x\nh : HasGradientAtFilter f f' x L\n‚ä¢ Filter.Tendsto (fun e => ‚Äñf e - f x‚Äñ) L (ùìù 0)")
2025-12-15 11:42:53.121 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 2 steps and 834.00s.
2025-12-15 11:42:53.121 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.225609\nùïú : Type u_1\nF : Type u_2\ninst‚úù¬≥ : RCLike ùïú\ninst‚úù¬≤ : NormedAddCommGroup F\ninst‚úù¬π : InnerProductSpace ùïú F\ninst‚úù : CompleteSpace F\nf : F ‚Üí ùïú\nf' x : F\ns : Set F\nL : Filter F\nhL : L ‚â§ ùìù x\nh : HasGradientAtFilter f f' x L\n‚ä¢ Filter.Tendsto (fun e => ‚Äñf e - f x‚Äñ) L (ùìù 0)")
2025-12-15 11:42:53.261 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:42:53.337 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 2: Applying best tactic: tauto
2025-12-15 11:42:53.400 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error='<stdin>:1:1: unknown tactic')
2025-12-15 11:42:53.401 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 2 steps and 642.33s.
2025-12-15 11:42:53.401 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error='<stdin>:1:1: unknown tactic')
2025-12-15 11:42:53.406 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: induction' f : Primcodable Œ± using Primcodable.id <;> infer_instance
2025-12-15 11:42:53.471 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="unknown constant 'Primcodable.id'")
2025-12-15 11:42:53.472 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 28.14s.
2025-12-15 11:42:53.472 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="unknown constant 'Primcodable.id'")
2025-12-15 11:42:53.542 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:42:53.611 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:42:53.795 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: simp (config := { contextual := true })
2025-12-15 11:42:53.868 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error='simp made no progress')
2025-12-15 11:42:53.868 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 166.25s.
2025-12-15 11:42:53.868 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error='simp made no progress')
2025-12-15 11:42:53.877 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: simp
2025-12-15 11:42:53.950 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error='simp made no progress')
2025-12-15 11:42:53.950 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 29.42s.
2025-12-15 11:42:53.950 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error='simp made no progress')
2025-12-15 11:42:54.013 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:42:54.094 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:42:54.500 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: CategoryTheory.Limits.Types.Quot.Œπ_desc
2025-12-15 11:43:01.174 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:43:02.599 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: CategoryTheory.Adjunction.homEquiv_naturality_left
2025-12-15 11:43:04.640 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Computable.ofNat
2025-12-15 11:43:07.430 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:43:07.453 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: csSup_union
2025-12-15 11:43:07.481 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: NumberField.Embeddings.coeff_bdd_of_norm_le
2025-12-15 11:43:08.031 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: intrinsicInterior_subset
2025-12-15 11:43:08.418 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Matrix.isHermitian_zero
2025-12-15 11:43:10.153 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:43:13.054 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:43:13.280 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:43:13.840 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:43:13.880 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:43:22.021 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: rw [‚Üê cancel_epi (c.Œπ.naturality j), ‚Üê cancel_epi (c.Œπ.naturality j),
  ‚Üê cancel_epi (c.Œπ.naturality j), ‚Üê cancel_epi (c.Œπ.naturality j),
  ‚Üê cancel_epi (c.Œπ.naturality j), ‚Üê cancel_epi (c.Œπ.naturality j), ‚Üê cancel_epi (c.Œπ.naturality j),
  ‚Üê cancel_epi (c.Œπ.naturality j), ‚Üê cancel_epi (c.Œπ.naturality j), ‚Üê cancel_epi (c.Œπ.naturality j),
  ‚Üê cancel_epi (c.Œπ.naturality j), ‚Üê cancel_epi (c.Œπ.naturality j), ‚Üê cancel_epi (c.Œπ.naturality j),
  ‚Üê cancel_epi (c.Œπ.naturality j), ‚Üê cancel_epi (c.Œπ.naturality j)]
2025-12-15 11:43:22.164 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  ?m.294349 = ?m.294350\nJ : Type v\ninst‚úù : CategoryTheory.Category.{w, v} J\nF : J ‚•§ Type u\nc : CategoryTheory.Limits.Cocone F\nj : J\nx : F.obj j\n‚ä¢ CategoryTheory.Limits.Types.Quot.desc c (CategoryTheory.Limits.Types.Quot.Œπ F j x) = c.Œπ.app j x")
2025-12-15 11:43:22.164 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 27.66s.
2025-12-15 11:43:22.164 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  ?m.294349 = ?m.294350\nJ : Type v\ninst‚úù : CategoryTheory.Category.{w, v} J\nF : J ‚•§ Type u\nc : CategoryTheory.Limits.Cocone F\nj : J\nx : F.obj j\n‚ä¢ CategoryTheory.Limits.Types.Quot.desc c (CategoryTheory.Limits.Types.Quot.Œπ F j x) = c.Œπ.app j x")
2025-12-15 11:43:22.302 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:43:50.295 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: MeasureTheory.AEEqFun.integrable_iff_mem_L1
2025-12-15 11:43:54.997 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:44:11.736 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: infer_instance
2025-12-15 11:44:11.806 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error='type class instance expected\n  Computable (Denumerable.ofNat Œ±)')
2025-12-15 11:44:11.806 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 67.17s.
2025-12-15 11:44:11.806 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error='type class instance expected\n  Computable (Denumerable.ofNat Œ±)')
2025-12-15 11:44:11.830 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: rcases sne.eq_or_ne tne with h | h <;> rcases sne with h | h <;> rcases tne with h | h <;> rcases tne with h | h <;> rcases tne with h | h <;> rcases tne with h | h <;> rcases tne with h | h <;> rcases tne with h | h <;> rcases tne with h | h <;> rcases tne with h | h <;>
  rcases tne with h | h <;> rcases tne with h | h <;> rcases tne with h | h <;> rcases tne with h | h <;>
  rcases tne with h | h <;> rcases tne with h | h <;> rcases tne with h | h <;> rcases tne with h | h <;>
  rcases tne with h | h <;> rcases tne with h | h <;> rcases tne with h | h <;>
  rcases tne with h | h <;> rcases tne with h | h <;> rcases tne with h | h <;>
  rcases tne with h | h <;> rcases tne with h | h <;> rcases tne with h | h <;>
  rcases tne with h | h <;> rcases tne with h | h <;> rcases tne with h | h <;>
  rcases tne with h | h <;> rcases tne with h | h <;> rcases tne with h | h <;>
  rcases tne with h | h <;> rcases tne with h | h <;> rcases tne with h | h <;>
  rcases tne with h | h <;>
  rcases tne with h | h <;>
  
2025-12-15 11:44:11.896 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: simp only [coeff_minpoly, RingHom.map_mul, RingHom.map_pow, RingHom.coe_mk, RingHom.coe_mk,
  RingHom.coe_mk, RingHom.coe_mk, RingHom.coe_mk, RingHom.coe_mk, RingHom.coe_mk, RingHom.coe_mk,
  RingHom.coe_mk, RingHom.coe_mk, RingHom.coe_mk, RingHom.coe_mk, RingHom.coe_mk, RingHom.coe_mk,
  RingHom.coe_mk, RingHom.coe_mk, RingHom.coe_mk, RingHom.coe_mk, RingHom.coe_mk, RingHom.coe_mk,
  RingHom.coe_mk, RingHom.coe_mk, RingHom.coe_mk, RingHom.coe_mk, RingHom.coe_mk, RingHom.coe_mk,
  RingHom.coe_mk, RingHom.coe_mk, RingHom.coe_mk, RingHom.coe_mk, RingHom.coe_mk, RingHom.coe_mk,
  RingHom.coe_mk, RingHom.coe_mk, RingHom.coe_mk, RingHom.coe_mk, RingHom.coe_mk, RingHom.coe_mk,
  RingHom.coe_mk, RingHom.coe_mk, RingHom.coe_mk, RingHom.coe_mk, RingHom.coe_mk, RingHom.coe_mk,
  RingHom.coe_mk, RingHom.coe_mk, RingHom.coe_mk, RingHom.coe_mk, RingHom.coe_mk, RingHom.coe_mk,
  RingHom.coe_mk, RingHom.coe_mk, RingHom.coe_mk, RingHom.coe_mk, RingHom.coe_mk, RingHom.coe_mk,
  RingHom.coe_mk, RingHom.coe_mk, RingHom.coe_mk,
2025-12-15 11:44:11.899 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="<stdin>:12:2: unexpected end of input; expected '['")
2025-12-15 11:44:11.899 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 64.45s.
2025-12-15 11:44:11.899 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="<stdin>:12:2: unexpected end of input; expected '['")
2025-12-15 11:44:11.945 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:44:11.965 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="<stdin>:11:49: unexpected end of input; expected ']'")
2025-12-15 11:44:11.965 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 64.48s.
2025-12-15 11:44:11.966 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="<stdin>:11:49: unexpected end of input; expected ']'")
2025-12-15 11:44:12.037 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:44:12.105 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:44:13.419 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: rw [‚Üê adj.homEquiv_naturality_left_symm, ‚Üê adj.homEquiv_naturality_right_symm,
  adj.homEquiv_naturality_right_symm, adj.homEquiv_naturality_right_symm, adj.homEquiv_naturality_right_symm,
  adj.homEquiv_naturality_right_symm, adj.homEquiv_naturality_right_symm, adj.homEquiv_naturality_right_symm,
  adj.homEquiv_naturality_right_symm, adj.homEquiv_naturality_right_symm, adj.homEquiv_naturality_right_symm,
  adj.homEquiv_naturality_right_symm, adj.homEquiv_naturality_right_symm, adj.homEquiv_naturality_right_symm,
  adj.homEquiv_naturality_right_symm, adj.homEquiv_naturality_right_symm, adj.homEquiv_naturality_right_symm,
  adj.homEquiv_naturality_right_symm, adj.homEquiv_naturality_right_symm, adj.homEquiv_naturality_right_symm,
  adj.homEquiv_naturality_right_symm, adj.homEquiv_naturality_right_symm, adj.homEquiv_naturality_right_symm,
  adj.homEquiv_naturality_right_symm, adj.homEquiv_naturality_right_symm, adj.homEquiv_naturality_right_symm,
  adj.homEquiv_naturality_right_symm, adj.homEquiv_naturalit
2025-12-15 11:44:13.487 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="<stdin>:10:60: unexpected end of input; expected ']'")
2025-12-15 11:44:13.487 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 70.89s.
2025-12-15 11:44:13.487 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="<stdin>:10:60: unexpected end of input; expected ']'")
2025-12-15 11:44:13.630 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:44:17.024 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: simp [IsHermitian, IsHermitian.transpose]
2025-12-15 11:44:17.098 | SUCCESS  | lean_reinforcement.agent.runner:run:218 - Proof finished in 1 steps and 68.68s.
2025-12-15 11:44:17.243 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:44:18.416 | INFO     | __main__:main:302 - Completed 80/128 proofs
2025-12-15 11:44:19.573 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Option.map_map‚ÇÇ_antidistrib_right
2025-12-15 11:44:22.530 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: TopologicalSpace.Opens.IsBasis.isCompact_open_iff_eq_finite_iUnion
2025-12-15 11:44:24.328 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:44:24.382 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: rw [Lp.mem_Lp_iff_mem_Lp, mem_Lp_iff_mem_Lp]
2025-12-15 11:44:24.499 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.374764\nŒ± : Type u_1\nŒ≤ : Type u_2\nŒ≥ : Type u_3\nŒ¥ : Type u_4\nm : MeasurableSpace Œ±\nŒº ŒΩ : MeasureTheory.Measure Œ±\ninst‚úù¬≤ : MeasurableSpace Œ¥\ninst‚úù¬π : NormedAddCommGroup Œ≤\ninst‚úù : NormedAddCommGroup Œ≥\nf : Œ± ‚Üí‚Çò[Œº] Œ≤\n‚ä¢ f.Integrable ‚Üî f ‚àà MeasureTheory.Lp Œ≤ 1 Œº")
2025-12-15 11:44:24.499 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 34.20s.
2025-12-15 11:44:24.499 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.374764\nŒ± : Type u_1\nŒ≤ : Type u_2\nŒ≥ : Type u_3\nŒ¥ : Type u_4\nm : MeasurableSpace Œ±\nŒº ŒΩ : MeasureTheory.Measure Œ±\ninst‚úù¬≤ : MeasurableSpace Œ¥\ninst‚úù¬π : NormedAddCommGroup Œ≤\ninst‚úù : NormedAddCommGroup Œ≥\nf : Œ± ‚Üí‚Çò[Œº] Œ≤\n‚ä¢ f.Integrable ‚Üî f ‚àà MeasureTheory.Lp Œ≤ 1 Œº")
2025-12-15 11:44:24.641 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:44:25.983 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Convex.combo_interior_closure_subset_interior
2025-12-15 11:44:27.350 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Nat.pow_mod
2025-12-15 11:44:27.404 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:44:30.980 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:44:31.947 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:44:45.038 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Filter.tendsto_const_mul_pow_atBot_iff
2025-12-15 11:44:49.568 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:44:53.007 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: LinearIndependent.map_of_isPurelyInseparable_of_separable
2025-12-15 11:44:57.473 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:45:08.740 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: exact hs.smul_interior_subset_interior_closure_subset_interior hb ha hb hab
2025-12-15 11:45:08.856 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="invalid field 'smul_interior_subset_interior_closure_subset_interior', the environment does not contain 'Convex.smul_interior_subset_interior_closure_subset_interior'\n  hs\nhas type\n  Convex ùïú s\ninvalid field notation, type is not of the form (C ...) where C is a constant\n  hs\nhas type\n  ?m.29578 ‚àà s ‚Üí StarConvex ùïú ?m.29578 s")
2025-12-15 11:45:08.856 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 42.87s.
2025-12-15 11:45:08.856 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="invalid field 'smul_interior_subset_interior_closure_subset_interior', the environment does not contain 'Convex.smul_interior_subset_interior_closure_subset_interior'\n  hs\nhas type\n  Convex ùïú s\ninvalid field notation, type is not of the form (C ...) where C is a constant\n  hs\nhas type\n  ?m.29578 ‚àà s ‚Üí StarConvex ùïú ?m.29578 s")
2025-12-15 11:45:08.996 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:45:10.237 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: rw [Nat.mod_eq_of_lt (Nat.mod_eq_of_lt (Nat.mod_eq_of_lt (Nat.pos_of_ne_zero a n))),
  Nat.mod_eq_of_lt (Nat.mod_eq_of_lt (Nat.pos_of_ne_zero b n)),
  Nat.mod_eq_of_lt (Nat.mod_eq_of_lt (Nat.pos_of_ne_zero n)),
  Nat.mod_eq_of_lt (Nat.mod_eq_of_lt (Nat.pos_of_ne_zero n)),
  Nat.mod_eq_of_lt (Nat.mod_eq_of_lt (Nat.pos_of_ne_zero n)),
  Nat.mod_eq_of_lt (Nat.mod_eq_of_lt (Nat.pos_of_ne_zero n)),
  Nat.mod_eq_of_lt (Nat.pos_of_ne_zero n), Nat.mod_eq_of_lt (Nat.pos_of_ne_zero n),
  Nat.mod_eq_of_lt (Nat.pos_of_ne_zero n), Nat.mod_eq_of_lt (Nat.pos_of_ne_zero n),
  Nat.mod_eq_of_lt (Nat.pos_of_ne_zero n), Nat.mod_eq_of_lt (Nat.pos_of_ne_zero n)]
2025-12-15 11:45:10.374 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  ?m.158474 % ?m.158475\na‚úù b‚úù c d m n‚úù k : ‚Ñï\np q : ‚Ñï ‚Üí Prop\na b n : ‚Ñï\n‚ä¢ a ^ b = a ^ b")
2025-12-15 11:45:10.374 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 43.02s.
2025-12-15 11:45:10.374 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  ?m.158474 % ?m.158475\na‚úù b‚úù c d m n‚úù k : ‚Ñï\np q : ‚Ñï ‚Üí Prop\na b n : ‚Ñï\n‚ä¢ a ^ b = a ^ b")
2025-12-15 11:45:10.515 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:45:17.556 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: infPrime_ofDual
2025-12-15 11:45:20.859 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: cases a <;> cases b <;> simp [h_antidistrib]
2025-12-15 11:45:20.941 | SUCCESS  | lean_reinforcement.agent.runner:run:218 - Proof finished in 1 steps and 61.37s.
2025-12-15 11:45:21.082 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:45:22.031 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:45:27.235 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Subgroup.mem_mk
2025-12-15 11:45:32.119 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:45:37.672 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: List.singleton_eq
2025-12-15 11:45:42.305 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:46:15.273 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: simp_rw [mem_carrier_iff_mul_mem, mem_carrier_iff_mul_mem, mem_carrier_iff_mul_mem]
2025-12-15 11:46:15.343 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error='simp made no progress')
2025-12-15 11:46:15.343 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 48.11s.
2025-12-15 11:46:15.343 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error='simp made no progress')
2025-12-15 11:46:15.482 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:46:17.205 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: exact threeAPFree_sphere n d k
2025-12-15 11:46:17.373 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error='type mismatch\n  threeAPFree_sphere (sorryAx (?m.383125 ‚àà ‚Üë(Behrend.sphere n d k)) true)\n    (sorryAx (?m.383486 ‚àà ‚Üë(Behrend.sphere n d k)) true) (sorryAx (?m.383847 ‚àà ‚Üë(Behrend.sphere n d k)) true)\nhas type\n  ?m.383125 + ?m.383847 = ?m.383486 + ?m.383486 ‚Üí ?m.383125 = ?m.383486 : Prop\nbut is expected to have type\n  ThreeAPFree ‚Üë(Behrend.sphere n d k) : Prop')
2025-12-15 11:46:17.374 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 222.27s.
2025-12-15 11:46:17.374 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error='type mismatch\n  threeAPFree_sphere (sorryAx (?m.383125 ‚àà ‚Üë(Behrend.sphere n d k)) true)\n    (sorryAx (?m.383486 ‚àà ‚Üë(Behrend.sphere n d k)) true) (sorryAx (?m.383847 ‚àà ‚Üë(Behrend.sphere n d k)) true)\nhas type\n  ?m.383125 + ?m.383847 = ?m.383486 + ?m.383486 ‚Üí ?m.383125 = ?m.383486 : Prop\nbut is expected to have type\n  ThreeAPFree ‚Üë(Behrend.sphere n d k) : Prop')
2025-12-15 11:46:17.514 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:46:19.867 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: rw [singleton_eq_singleton_iff]
2025-12-15 11:46:19.953 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.6510\nŒπ : Type u_1\nŒ± : Type u\nŒ≤ : Type v\nŒ≥ : Type w\nl‚ÇÅ l‚ÇÇ : List Œ±\nx : Œ±\n‚ä¢ {x} = [x]")
2025-12-15 11:46:19.953 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 42.28s.
2025-12-15 11:46:19.953 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.6510\nŒπ : Type u_1\nŒ± : Type u\nŒ≤ : Type v\nŒ≥ : Type w\nl‚ÇÅ l‚ÇÇ : List Œ±\nx : Œ±\n‚ä¢ {x} = [x]")
2025-12-15 11:46:20.093 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:46:25.149 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: CategoryTheory.ChosenFiniteProducts.associator_inv_snd
2025-12-15 11:46:30.012 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:46:30.367 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: CategoryTheory.NonPreadditiveAbelian.neg_add_self
2025-12-15 11:46:31.037 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: intrinsicClosure_empty
2025-12-15 11:46:35.064 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:46:35.627 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:47:13.609 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: simp [lift_snd_assoc, lift_snd_assoc, lift_snd_assoc, lift_snd_assoc, lift_snd_assoc,
  lift_snd_assoc, lift_snd_assoc, lift_snd_assoc, lift_snd_assoc, lift_snd_assoc, lift_snd_assoc,
  lift_snd_assoc, lift_snd_assoc, lift_snd_assoc, lift_snd_assoc, lift_snd_assoc, lift_snd_assoc,
  lift_snd_assoc, lift_snd_assoc, lift_snd_assoc, lift_snd_assoc, lift_snd_assoc, lift_snd_assoc,
  lift_snd_assoc, lift_snd_assoc, lift_snd_assoc, lift_snd_assoc, lift_snd_assoc, lift_snd_assoc,
  lift_snd_assoc, lift_snd_assoc, lift_snd_assoc, lift_snd_assoc, lift_snd_assoc, lift_snd_assoc,
  lift_snd_assoc, lift_snd_assoc, lift_snd_assoc, lift_snd_assoc, lift_snd_assoc, lift_snd_assoc,
  lift_snd_assoc, lift_snd_assoc, lift_snd_assoc, lift_snd_assoc, lift_snd_assoc, lift_snd_assoc,
  lift_snd_assoc, lift_snd_assoc, lift_snd_assoc, lift_snd_assoc, lift_snd_assoc, lift_snd_assoc,
  lift_snd_assoc, lift_snd_assoc, lift_snd_assoc, lift_snd_assoc, lift_snd_assoc, lift_snd_assoc,
  lift_snd_assoc, lift_snd_assoc, lift_snd_assoc, lift_
2025-12-15 11:47:13.678 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="<stdin>:11:55: unexpected end of input; expected ']'")
2025-12-15 11:47:13.679 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 48.53s.
2025-12-15 11:47:13.679 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="<stdin>:11:55: unexpected end of input; expected ']'")
2025-12-15 11:47:13.819 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:47:14.360 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: simp [intrinsicCClosure]
2025-12-15 11:47:14.424 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error='simp made no progress')
2025-12-15 11:47:14.424 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 43.39s.
2025-12-15 11:47:14.424 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error='simp made no progress')
2025-12-15 11:47:14.565 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:47:23.022 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Nat.Primrec.casesOn'
2025-12-15 11:47:26.347 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: MeasureTheory.SignedMeasure.toSignedMeasure_toJordanDecomposition
2025-12-15 11:47:27.818 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:47:30.901 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:47:38.425 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: refine Nat.Primrec.of_eq fun n =>?_
2025-12-15 11:47:38.538 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error='type mismatch\n  Nat.Primrec.of_eq (sorryAx (Nat.Primrec ?m.17745) true)\nhas type\n  (‚àÄ (n : ‚Ñï), ?m.17745 n = ?m.17746 n) ‚Üí Nat.Primrec ?m.17746 : Prop\nbut is expected to have type\n  Nat.Primrec (Nat.unpaired fun z n => Nat.casesOn n (f z) fun y => g (Nat.pair z y)) : Prop')
2025-12-15 11:47:38.538 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 15.52s.
2025-12-15 11:47:38.538 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error='type mismatch\n  Nat.Primrec.of_eq (sorryAx (Nat.Primrec ?m.17745) true)\nhas type\n  (‚àÄ (n : ‚Ñï), ?m.17745 n = ?m.17746 n) ‚Üí Nat.Primrec ?m.17746 : Prop\nbut is expected to have type\n  Nat.Primrec (Nat.unpaired fun z n => Nat.casesOn n (f z) fun y => g (Nat.pair z y)) : Prop')
2025-12-15 11:47:38.677 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:47:46.962 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: rw [toJordanDecomposition_toSignedMeasure, toJordanDecomposition_toSignedMeasure]
2025-12-15 11:47:47.082 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.40654\nŒ± : Type u_1\nŒ≤ : Type u_2\ninst‚úù¬≤ : MeasurableSpace Œ±\ns‚úù : MeasureTheory.SignedMeasure Œ±\nŒº ŒΩ : MeasureTheory.Measure Œ±\ninst‚úù¬π : MeasureTheory.IsFiniteMeasure Œº\ninst‚úù : MeasureTheory.IsFiniteMeasure ŒΩ\ns : MeasureTheory.SignedMeasure Œ±\n‚ä¢ s.toJordanDecomposition.toSignedMeasure = s")
2025-12-15 11:47:47.082 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 20.73s.
2025-12-15 11:47:47.082 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.40654\nŒ± : Type u_1\nŒ≤ : Type u_2\ninst‚úù¬≤ : MeasurableSpace Œ±\ns‚úù : MeasureTheory.SignedMeasure Œ±\nŒº ŒΩ : MeasureTheory.Measure Œ±\ninst‚úù¬π : MeasureTheory.IsFiniteMeasure Œº\ninst‚úù : MeasureTheory.IsFiniteMeasure ŒΩ\ns : MeasureTheory.SignedMeasure Œ±\n‚ä¢ s.toJordanDecomposition.toSignedMeasure = s")
2025-12-15 11:47:47.221 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:47:53.709 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: CategoryTheory.Limits.spanExt_app_left
2025-12-15 11:47:58.418 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:47:58.670 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: DFinsupp.single_tsub
2025-12-15 11:48:03.044 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:48:10.860 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: simp [Filter.Eventually, eventually_iSup]
2025-12-15 11:48:10.946 | SUCCESS  | lean_reinforcement.agent.runner:run:218 - Proof finished in 1 steps and 946.97s.
2025-12-15 11:48:11.086 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:48:15.689 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: rw [‚Üê neg_add_self a, neg_zero]
2025-12-15 11:48:15.715 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: simp [lift, Function.funext_iff, Function.funext_iff, Function.funext_iff]
2025-12-15 11:48:15.790 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  -0\nC : Type u\ninst‚úù¬π : CategoryTheory.Category.{v, u} C\ninst‚úù : CategoryTheory.NonPreadditiveAbelian C\nX Y : C\na : X ‚ü∂ Y\n‚ä¢ -a + a = -a + a")
2025-12-15 11:48:15.790 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 105.42s.
2025-12-15 11:48:15.790 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  -0\nC : Type u\ninst‚úù¬π : CategoryTheory.Category.{v, u} C\ninst‚úù : CategoryTheory.NonPreadditiveAbelian C\nX Y : C\na : X ‚ü∂ Y\n‚ä¢ -a + a = -a + a")
2025-12-15 11:48:15.931 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:48:17.583 | INFO     | __main__:main:302 - Completed 96/128 proofs
2025-12-15 11:48:18.552 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Topology.IsUpper.continuous_iff_Iic
2025-12-15 11:48:19.207 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: simp_rw [single_eq_pi_single, sub_single, single_eq_pi_single]
2025-12-15 11:48:19.280 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error='simp made no progress')
2025-12-15 11:48:19.280 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 20.61s.
2025-12-15 11:48:19.280 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error='simp made no progress')
2025-12-15 11:48:19.425 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:48:20.000 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: dsimp [spanExt]
2025-12-15 11:48:20.070 | SUCCESS  | lean_reinforcement.agent.runner:run:218 - Proof finished in 1 steps and 26.36s.
2025-12-15 11:48:20.215 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:48:20.839 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 2: Running MCTS search for 200 iterations...
2025-12-15 11:48:20.848 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 2: Applying best tactic: rw [Quot.lift_mk, Quot.lift_mk]
2025-12-15 11:48:22.918 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Filter.isOpen_setOf_mem
2025-12-15 11:48:24.230 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:48:26.264 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 3: Running MCTS search for 200 iterations...
2025-12-15 11:48:28.159 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:48:29.008 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: PFun.mem_prodLift
2025-12-15 11:48:33.486 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:48:45.443 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: LieModuleHom.map_lie‚ÇÇ
2025-12-15 11:48:50.243 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:49:40.172 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 3: Applying best tactic: apply Quot.inductionOn (motive := fun a‚ÇÅ a‚ÇÇ => Quot.inductionOn f (fun a‚ÇÅ a‚ÇÇ => Quot.inductionOn f (fun a‚ÇÅ a‚ÇÇ => Quot.inductionOn f (fun a‚ÇÅ a‚ÇÇ => Quot.inductionOn f (fun a‚ÇÅ a‚ÇÇ : Œ±‚ÇÅ a‚ÇÇ => Quot.inductionOn f (fun a‚ÇÅ a‚ÇÇ => Quot.inductionOn f (fun a‚ÇÅ a‚ÇÇ => Quot.inductionOn f (fun a‚ÇÅ a‚ÇÇ => Quot.inductionOn f (fun a‚ÇÅ a‚ÇÇ : Œ±‚ÇÅ a‚ÇÇ => Quot.inductionOn f (fun a‚ÇÅ a‚ÇÇ => Quot.inductionOn f (fun a‚ÇÅ a‚ÇÇ => Quot.inductionOn f (fun a‚ÇÅ a‚ÇÇ => Quot.inductionOn f (fun a‚ÇÇ a‚ÇÇ : Œ±‚ÇÅ a‚ÇÇ => Quot.inductionOn f (fun a‚ÇÅ a‚ÇÇ => Quot.inductionOn f (fun a‚ÇÅ a‚ÇÇ => Quot.inductionOn f (fun a‚ÇÅ a‚ÇÇ => f a‚ÇÇ a‚ÇÇ) a‚ÇÇ)
  (motive := fun a‚ÇÅ a‚ÇÇ => Quot.inductionOn f (fun a‚ÇÅ a‚ÇÇ => Quot.inductionOn f (fun a‚ÇÅ a‚ÇÇ => Quot.inductionOn f (fun a‚ÇÇ a‚ÇÇ : Œ±‚ÇÅ a‚ÇÇ) a‚ÇÅ a‚ÇÇ)
  (motive := fun a‚ÇÅ a‚ÇÇ => Quot.inductionOn f (fun a‚ÇÅ a‚ÇÇ => Quot.inductionOn f (fun a‚ÇÅ a‚ÇÇ => Quot.inductionOn f (fun a‚ÇÇ a‚ÇÇ : Œ±‚ÇÅ a‚ÇÇ))
    (motive := fun a‚ÇÅ a‚ÇÇ => Quot.induct
2025-12-15 11:49:40.238 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="<stdin>:2:129: expected '‚Ü¶', '=>'")
2025-12-15 11:49:40.238 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 3 steps and 1630.33s.
2025-12-15 11:49:40.239 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="<stdin>:2:129: expected '‚Ü¶', '=>'")
2025-12-15 11:49:40.378 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:49:41.616 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: rw [‚Üê isOpen_compl_iff]
2025-12-15 11:49:41.712 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  IsClosed ?m.16038\nŒπ : Sort u_1\nŒ± : Type u_2\nŒ≤ : Type u_3\nX : Type u_4\nY : Type u_5\ns : Set Œ±\n‚ä¢ IsOpen {l | s ‚àà l}")
2025-12-15 11:49:41.712 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 78.79s.
2025-12-15 11:49:41.712 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  IsClosed ?m.16038\nŒπ : Sort u_1\nŒ± : Type u_2\nŒ≤ : Type u_3\nX : Type u_4\nY : Type u_5\ns : Set Œ±\n‚ä¢ IsOpen {l | s ‚àà l}")
2025-12-15 11:49:41.853 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:49:51.788 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Finset.prod_div_prod_mem_mulSpan
2025-12-15 11:49:56.225 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:50:02.016 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Multiset.aestronglyMeasurable_prod
2025-12-15 11:50:06.621 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:50:12.690 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: simp only [LinearMap.map_add, LinearMap.map_sub, LinearMap.map_smul‚Çõ‚Çó, LinearMap.map_smul‚Çõ‚Çó,
  LinearMap.map_smul‚Çõ‚Çó, LinearMap.map_smul‚Çõ‚Çó, LinearMap.map_smul‚Çõ‚Çó, LinearMap.map_smul‚Çõ‚Çó,
  LinearMap.map_smul‚Çõ‚Çó, LinearMap.map_smul‚Çõ‚Çó, LinearMap.map_smul‚Çõ‚Çó, LinearMap.map_smul‚Çõ‚Çó,
  LinearMap.map_smul‚Çõ‚Çó, LinearMap.map_smul‚Çõ‚Çó, LinearMap.map_smul‚Çõ‚Çó, LinearMap.map_smul‚Çõ‚Çó,
  LinearMap.map_smul‚Çõ‚Çó, LinearMap.map_smul‚Çõ‚Çó, LinearMap.map_smul‚Çõ‚Çó, LinearMap.map_smul‚Çõ‚Çó,
  LinearMap.map_smul‚Çõ‚Çó, LinearMap.map_smul‚Çõ‚Çó, LinearMap.map_smul‚Çõ‚Çó, LinearMap.map_smul‚Çõ‚Çó,
  LinearMap.map_smul‚Çõ‚Çó, LinearMap.map_smul‚Çõ‚Çó, LinearMap.map_smul‚Çõ‚Çó, LinearMap.map_smul‚Çõ‚Çó,
  LinearMap.map_smul‚Çõ‚Çó, LinearMap.map_smul‚Çõ‚Çó, LinearMap.map_smul‚Çõ‚Çó, LinearMap.map_smul‚Çõ‚Çó,
  LinearMap.map_smul‚Çõ‚Çó, LinearMap.map_smul‚Çõ‚Çó, LinearMap.map_smul‚Çõ‚Çó, LinearMap.map_smul‚Çõ‚Çó,
  LinearMap.map_smul‚Çõ‚Çó, LinearMap.map_smul‚Çõ‚Çó, LinearMap.map_smul
2025-12-15 11:50:12.759 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="<stdin>:10:64: unexpected end of input; expected ']'")
2025-12-15 11:50:12.759 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 87.32s.
2025-12-15 11:50:12.759 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="<stdin>:10:64: unexpected end of input; expected ']'")
2025-12-15 11:50:12.899 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:50:19.962 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: GaussianInt.toComplex_add
2025-12-15 11:50:20.601 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: have : ‚àè a ‚àà u, a ‚àà s.mulSpan := by
  rw [mem_mulSpan_iff_finset_subset]
  exact Finset.mul_mem_mulSpan ht
2025-12-15 11:50:20.719 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="unknown identifier 'mem_mulSpan_iff_finset_subset'\ntactic 'rewrite' failed, equality or iff proof expected\n  ?m.132046\nŒ± : Type u_1\nŒ≤ : Type u_2\ninst‚úù¬≥ : CommGroup Œ±\ninst‚úù¬≤ : CommGroup Œ≤\ninst‚úù¬π : DecidableEq Œ±\ninst‚úù : Fintype Œ±\ns t u : Finset Œ±\na : Œ±\nd : ‚Ñï\nht : t ‚äÜ s\nhu : u ‚äÜ s\n‚ä¢ ‚àè a ‚àà u, a ‚àà s.mulSpan")
2025-12-15 11:50:20.719 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 28.93s.
2025-12-15 11:50:20.719 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="unknown identifier 'mem_mulSpan_iff_finset_subset'\ntactic 'rewrite' failed, equality or iff proof expected\n  ?m.132046\nŒ± : Type u_1\nŒ≤ : Type u_2\ninst‚úù¬≥ : CommGroup Œ±\ninst‚úù¬≤ : CommGroup Œ≤\ninst‚úù¬π : DecidableEq Œ±\ninst‚úù : Fintype Œ±\ns t u : Finset Œ±\na : Œ±\nd : ‚Ñï\nht : t ‚äÜ s\nhu : u ‚äÜ s\n‚ä¢ ‚àè a ‚àà u, a ‚àà s.mulSpan")
2025-12-15 11:50:20.860 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:50:24.600 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:50:32.776 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: CategoryTheory.InjectiveResolution.rightDerivedToHomotopyCategory_app_eq
2025-12-15 11:50:37.458 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:51:33.078 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: refine ‚ü®fun h ‚Ü¶?_, fun h ‚Ü¶?_‚ü©
2025-12-15 11:51:37.658 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 2: Running MCTS search for 200 iterations...
2025-12-15 11:51:58.771 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: simp [toComplex_def]
2025-12-15 11:51:58.860 | SUCCESS  | lean_reinforcement.agent.runner:run:218 - Proof finished in 1 steps and 98.90s.
2025-12-15 11:51:59.000 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:52:16.614 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: ExteriorAlgebra.algebraMap_eq_one_iff
2025-12-15 11:52:21.144 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:52:30.125 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 2: Applying best tactic: exacts [h.ofDual_infPrime a, h.ofDual_infPrime a]
2025-12-15 11:52:30.288 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="invalid field 'ofDual_infPrime', the environment does not contain 'InfPrime.ofDual_infPrime'\n  h\nhas type\n  InfPrime (ofDual a)\ninvalid field 'ofDual_infPrime', the environment does not contain 'And.ofDual_infPrime'\n  h\nhas type\n  ¬¨IsMax (ofDual a) ‚àß ‚àÄ ‚¶Éb c : Œ±‚¶Ñ, b ‚äì c ‚â§ ofDual a ‚Üí b ‚â§ ofDual a ‚à® c ‚â§ ofDual a\ninvalid field 'ofDual_infPrime', the environment does not contain 'SupPrime.ofDual_infPrime'\n  h\nhas type\n  SupPrime a\ninvalid field 'ofDual_infPrime', the environment does not contain 'And.ofDual_infPrime'\n  h\nhas type\n  ¬¨IsMin a ‚àß ‚àÄ ‚¶Éb c : Œ±·µí·µà‚¶Ñ, a ‚â§ b ‚äî c ‚Üí a ‚â§ b ‚à® a ‚â§ c")
2025-12-15 11:52:30.289 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 2 steps and 432.73s.
2025-12-15 11:52:30.289 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="invalid field 'ofDual_infPrime', the environment does not contain 'InfPrime.ofDual_infPrime'\n  h\nhas type\n  InfPrime (ofDual a)\ninvalid field 'ofDual_infPrime', the environment does not contain 'And.ofDual_infPrime'\n  h\nhas type\n  ¬¨IsMax (ofDual a) ‚àß ‚àÄ ‚¶Éb c : Œ±‚¶Ñ, b ‚äì c ‚â§ ofDual a ‚Üí b ‚â§ ofDual a ‚à® c ‚â§ ofDual a\ninvalid field 'ofDual_infPrime', the environment does not contain 'SupPrime.ofDual_infPrime'\n  h\nhas type\n  SupPrime a\ninvalid field 'ofDual_infPrime', the environment does not contain 'And.ofDual_infPrime'\n  h\nhas type\n  ¬¨IsMin a ‚àß ‚àÄ ‚¶Éb c : Œ±·µí·µà‚¶Ñ, a ‚â§ b ‚äî c ‚Üí a ‚â§ b ‚à® a ‚â§ c")
2025-12-15 11:52:30.428 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:52:49.710 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Complex.differentiableOn_update_limUnder_of_bddAbove
2025-12-15 11:52:54.318 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:53:01.512 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: refine aestronglyMeasurable_iff_aemeasurable_separable.2 ‚ü®hs,?_‚ü©
2025-12-15 11:53:01.583 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="unknown identifier 'aestronglyMeasurable_iff_aemeasurable_separable'")
2025-12-15 11:53:01.583 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 179.57s.
2025-12-15 11:53:01.583 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="unknown identifier 'aestronglyMeasurable_iff_aemeasurable_separable'")
2025-12-15 11:53:01.723 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:53:03.437 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: rw [Algebra.algebraMap_eq_smul_one, Algebra.algebraMap_eq_smul_one, Algebra.algebraMap_eq_smul_one,
  Algebra.algebraMap_eq_smul_one, Algebra.algebraMap_eq_smul_one]
2025-12-15 11:53:03.553 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  (algebraMap ?m.121173 ?m.121174) ?r\nR : Type u1\ninst‚úù‚Å¥ : CommRing R\nM : Type u2\ninst‚úù¬≥ : AddCommGroup M\ninst‚úù¬≤ : Module R M\nA : Type u_1\ninst‚úù¬π : Semiring A\ninst‚úù : Algebra R A\nx : R\n‚ä¢ x ‚Ä¢ 1 = 1 ‚Üî x = 1")
2025-12-15 11:53:03.553 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 46.94s.
2025-12-15 11:53:03.553 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  (algebraMap ?m.121173 ?m.121174) ?r\nR : Type u1\ninst‚úù‚Å¥ : CommRing R\nM : Type u2\ninst‚úù¬≥ : AddCommGroup M\ninst‚úù¬≤ : Module R M\nA : Type u_1\ninst‚úù¬π : Semiring A\ninst‚úù : Algebra R A\nx : R\n‚ä¢ x ‚Ä¢ 1 = 1 ‚Üî x = 1")
2025-12-15 11:53:03.694 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:53:11.762 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: PartialEquiv.refl_restr_source
2025-12-15 11:53:16.450 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:53:17.523 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: MeasureTheory.measure_mul_right_null
2025-12-15 11:53:21.934 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:53:52.755 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: rw [‚Üê differentiableOn_update_iff_differentiableOn_differentiableOn_differentiableOn,
  differentiableOn_differentiableOn_iff_differentiableOn_differentiableOn_differentiableOn_differentiableOn,
  differentiableOn_differentiableOn_iff_differentiableOn_differentiableOn_differentiableOn,
  differentiableOn_differentiableOn_iff_differentiableOn_differentiableOn_differentiableOn,
  differentiableOn_differentiableOn_iff_differentiableOn_differentiableOn_differentiableOn_differentiableOn,
  differentiableOn_differentiableOn_iff_differentiableOn_differentiableOn_differentiableOn_differentiableOn_differentiableOn,
  differentiableOn_differentiableOn_iff_differentiableOn_differentiableOn_differentiableOn_differentiableOn_differentiableOn,
  differentiableOn_differentiableOn_iff_differentiableOn_differentiableOn_differentiableOn_differentiableOn_differentiableOn,
  differentiableOn_differentiableOn_iff_differentiableOn_differentiableOn_differentiableOn_differentiableOn_differentiableOn_differentiableOn_differentiabl
2025-12-15 11:53:52.823 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="<stdin>:9:155: unexpected end of input; expected ']'")
2025-12-15 11:53:52.823 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 63.11s.
2025-12-15 11:53:52.823 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="<stdin>:9:155: unexpected end of input; expected ']'")
2025-12-15 11:53:52.962 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:53:54.617 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: simp only [‚Üê cancel_mono h.opcyclesIso.hom, ‚Üê cancel_mono h.opcyclesIso.hom,
  Iso.inv_hom_id_assoc, Iso.inv_hom_id_assoc, Iso.inv_hom_id_assoc,
  Iso.inv_hom_id_assoc, Iso.inv_hom_id_assoc, Iso.inv_hom_id_assoc,
  Iso.inv_hom_id_assoc, Iso.inv_hom_id_assoc, Iso.inv_hom_id_assoc,
  Iso.inv_hom_id_assoc, Iso.inv_hom_id_assoc, Iso.inv_hom_id_assoc,
  Iso.inv_hom_id_assoc, Iso.inv_hom_id_assoc, Iso.inv_hom_id_assoc,
  Iso.inv_hom_id_assoc, Iso.inv_hom_id_assoc, Iso.inv_hom_id_assoc,
  Iso.inv_hom_id_assoc, Iso.inv_hom_id_assoc, Iso.inv_hom_id_assoc,
  Iso.inv_hom_id_assoc, Iso.inv_hom_id_assoc, Iso.inv_hom_id_assoc,
  Iso.inv_hom_id_assoc, Iso.inv_hom_id_assoc, Iso.inv_hom_id_assoc,
  Iso.inv_hom_id_assoc, Iso.inv_hom_id_assoc, Iso.inv_hom_id_assoc,
  Iso.inv_hom_id_assoc, Iso.inv_hom_id_assoc, Iso.inv_hom_id_assoc,
  Iso.inv_hom_id_assoc, Iso.inv_hom_id_assoc, Iso.inv_hom_id_assoc,
  Iso.inv_hom_id_assoc, Iso.inv_hom_id_assoc, Iso.inv_hom_id_assoc,
  Iso.inv_hom_id_assoc, Iso.inv_hom_id_assoc]
2025-12-15 11:53:59.259 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 2: Running MCTS search for 200 iterations...
2025-12-15 11:54:09.254 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: rw [‚Üê measure_symmDiff_eq_zero_iff, measure_symmDiff_eq_zero_iff]
2025-12-15 11:54:09.389 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  ?m.66855 =·µê[?m.66854] ?m.66856\nG : Type u_1\ninst‚úù‚Å∂ : MeasurableSpace G\ninst‚úù‚Åµ : Group G\ninst‚úù‚Å¥ : MeasurableMul‚ÇÇ G\nŒº ŒΩ : MeasureTheory.Measure G\ninst‚úù¬≥ : MeasureTheory.SigmaFinite ŒΩ\ninst‚úù¬≤ : MeasureTheory.SigmaFinite Œº\ns : Set G\ninst‚úù¬π : MeasurableInv G\ninst‚úù : Œº.IsMulLeftInvariant\ny : G\n‚ä¢ Œº ((fun x => x * y) ‚Åª¬π' s) = 0 ‚Üî Œº s = 0")
2025-12-15 11:54:09.389 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 51.87s.
2025-12-15 11:54:09.389 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  ?m.66855 =·µê[?m.66854] ?m.66856\nG : Type u_1\ninst‚úù‚Å∂ : MeasurableSpace G\ninst‚úù‚Åµ : Group G\ninst‚úù‚Å¥ : MeasurableMul‚ÇÇ G\nŒº ŒΩ : MeasureTheory.Measure G\ninst‚úù¬≥ : MeasureTheory.SigmaFinite ŒΩ\ninst‚úù¬≤ : MeasureTheory.SigmaFinite Œº\ns : Set G\ninst‚úù¬π : MeasurableInv G\ninst‚úù : Œº.IsMulLeftInvariant\ny : G\n‚ä¢ Œº ((fun x => x * y) ‚Åª¬π' s) = 0 ‚Üî Œº s = 0")
2025-12-15 11:54:09.529 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:54:09.917 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: CategoryTheory.Presheaf.isSheaf_coherent_of_hasPullbacks_of_comp
2025-12-15 11:54:14.681 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:54:16.790 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Int.gcd_div
2025-12-15 11:54:21.211 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:56:51.513 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: apply Nat.dvd_antisymm
2025-12-15 11:56:55.980 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 2: Running MCTS search for 200 iterations...
2025-12-15 11:57:51.100 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 2: Applying best tactic: all_goals
  apply Int.dvd_of_dvd_mul_right
  apply Int.dvd_of_dvd_of_dvd (Int.dvd_of_dvd_of_dvd (Int.dvd_of_dvd_of_dvd (Int.dvd_of_dvd_of_dvd
    (Int.dvd_of_dvd_of_dvd
      (Int.dvd_of_dvd_of_dvd (Int.dvd_of_dvd_of_dvd (Int.dvd_of_dvd_of_dvd
      (Int.dvd_of_dvd_of_dvd (Int.dvd_of_dvd_of_dvd (Int.dvd_of_dvd_of_dvd
      (Int.dvd_of_dvd_of_dvd (Int.dvd_of_dvd_of_dvd
      (Int.dvd_of_dvd_of_dvd (Int.dvd_of_dvd_of_dvd
      (Int.dvd_of_dvd_of_dvd (Int.dvd_of_dvd_of_dvd
      (Int.dvd_of_dvd_of_dvd (Int.dvd_of_dvd_of_dvd
      (Int.dvd_of_dvd_of_dvd (Int.dvd_of_dvd_of_dvd
      (Int.dvd_of_dvd_of_dvd (Int.dvd_of_dvd_of_dvd
      (Int.dvd_of_dvd_of_dvd (Int.dvd_of_dvd_of_dvd
      (Int.dvd_of_dvd_of_dvd (Int.dvd_of_dvd_of_dvd
      (Int.dvd_of_dvd_of_dvd (Int.dvd_of_dvd_of_dvd
      (Int.dvd_of_dvd_of_dvd (Int.dvd_of_dvd_of_dvd
      (Int.dvd_of_dvd_of_dvd (Int.dvd_of_dvd_of_dvd
      (Int.dvd_of_dvd_of_dvd (Int.dvd_of_dvd_of_dvd
      (Int.dvd_of_dvd_of_dvd (Int.dvd_of_dvd_of_dvd (Int.dvd_of_dvd (Int.dvd_of_
2025-12-15 11:57:51.171 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="<stdin>:19:80: unexpected end of input; expected ')', ',' or ':'")
2025-12-15 11:57:51.171 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 2 steps and 214.38s.
2025-12-15 11:57:51.171 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="<stdin>:19:80: unexpected end of input; expected ')', ',' or ':'")
2025-12-15 11:57:51.312 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:58:10.106 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: Primrec.fin_curry
2025-12-15 11:58:14.840 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:58:25.647 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: simp [prodLift]
2025-12-15 11:58:30.195 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 2: Running MCTS search for 200 iterations...
2025-12-15 11:58:32.447 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: rw [restr_source, PartialEquiv.refl_source]
2025-12-15 11:58:36.864 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 2: Running MCTS search for 200 iterations...
2025-12-15 11:58:36.872 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 2: Applying best tactic: simp [univ_inter]
2025-12-15 11:58:36.936 | SUCCESS  | lean_reinforcement.agent.runner:run:218 - Proof finished in 2 steps and 325.17s.
2025-12-15 11:58:37.076 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:58:57.877 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: SimpleGraph.ConnectedComponent.exists
2025-12-15 11:59:02.253 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 11:59:48.561 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 2: Applying best tactic: simp only [‚Üê cancel_mono h.opcyclesIso.hom, assoc, Iso.inv_hom_id, comp_id,
  Iso.inv_hom_id_assoc, Iso.inv_hom_id_assoc, Iso.inv_hom_id_assoc,
  Iso.inv_hom_id_assoc, Iso.inv_hom_id_assoc, Iso.inv_hom_id_assoc,
  Iso.inv_hom_id_assoc, Iso.inv_hom_id_assoc, Iso.inv_hom_id_assoc,
  Iso.inv_hom_id_assoc, Iso.inv_hom_id_assoc, Iso.inv_hom_id_assoc,
  Iso.inv_hom_id_assoc, Iso.inv_hom_id_assoc, Iso.inv_hom_id_assoc,
  Iso.inv_hom_id_assoc, Iso.inv_hom_id_assoc, Iso.inv_hom_id_assoc]
2025-12-15 11:59:51.718 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: refine ‚ü®fun h =>?_, fun h => Primcodable.primrec f‚ü©
2025-12-15 11:59:51.785 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="unknown constant 'Primcodable.primrec'")
2025-12-15 11:59:51.785 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 1 steps and 101.68s.
2025-12-15 11:59:51.785 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="unknown constant 'Primcodable.primrec'")
2025-12-15 11:59:51.928 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 11:59:53.263 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 3: Running MCTS search for 200 iterations...
2025-12-15 11:59:57.626 | INFO     | __main__:main:302 - Completed 112/128 proofs
2025-12-15 11:59:58.467 | INFO     | lean_reinforcement.agent.runner:run:82 - Starting proof search for: CategoryTheory.wellPowered_congr
2025-12-15 12:00:03.195 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 1: Running MCTS search for 200 iterations...
2025-12-15 12:01:41.451 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: dsimp [NatTrans.rightDerivedToHomotopyCategory, NatTrans.rightDerivedToHomotopyCategory,
  NatTrans.rightDerivedToHomotopyCategory, NatTrans.rightDerivedToHomotopyCategory,
  NatTrans.rightDerivedToHomotopyCategory, NatTrans.rightDerivedToHomotopyCategory,
  NatTrans.rightDerivedToHomotopyCategory, NatTrans.rightDerivedToHomotopyCategory,
  NatTrans.rightDerivedToHomotopyCategory, NatTrans.rightDerivedToHomotopyCategory,
  NatTrans.rightDerivedToHomotopyCategory, NatTrans.rightDerivedToHomotopyCategory,
  NatTrans.rightDerivedToHomotopyCategory, NatTrans.rightDerivedToHomotopyCategory]
2025-12-15 12:01:46.430 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 2: Running MCTS search for 200 iterations...
2025-12-15 12:02:35.024 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 2: Applying best tactic: dsimp [isoRightDerivedToHomotopyCategoryObj, Functor.mapHomotopyCategoryObjIso,
  Functor.mapHomotopyCategoryObjIso, Functor.mapHomotopyCategoryObjIso, Functor.mapHomotopyCategoryObjIso,
  Functor.mapHomotopyCategoryObjIso, Functor.mapHomotopyCategoryObjIso,
  Functor.mapHomotopyCategoryObjIso, Functor.mapHomotopyCategoryObjIso,
  Functor.mapHomotopyCategoryObjIso, Functor.mapHomotopyCategoryObjIso,
  Functor.mapHomotopyCategoryObjIso, Functor.mapHomotopyCategoryObjIso,
  Functor.mapHomotopyCategoryObjIso, Functor.mapHomotopyCategoryObjIso,
  Functor.mapHomotopyCategoryObjIso, Functor.mapHomotopyCategoryObjIso,
  Functor.mapHomotopyCategoryObjIso, Functor.mapHomotopyCategoryObjIso,
  Functor.mapHomotopyCategoryObjIso, Functor.mapHomotopyCategoryObjIso,
  Functor.mapHomotopyCategoryObjIso, Functor.mapHomotopyCategoryObjIso,
  Functor.mapHomotopyCategoryObjIso, Functor.mapHomotopyCategoryObjIso,
  Functor.mapHomotopyCategoryObjIso, Functor.mapHomotopyCategoryObjIso,
  Functor.mapHomotopyCategoryObjIso, Functor
2025-12-15 12:02:35.092 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="<stdin>:14:44: unexpected end of input; expected ']'")
2025-12-15 12:02:35.092 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 2 steps and 722.32s.
2025-12-15 12:02:35.092 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="<stdin>:14:44: unexpected end of input; expected ']'")
2025-12-15 12:02:35.232 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 12:02:52.081 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 2: Applying best tactic: constructor
2025-12-15 12:02:56.741 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 3: Running MCTS search for 200 iterations...
2025-12-15 12:03:29.627 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 3: Applying best tactic: exacts [fun ‚ü®h‚ÇÅ, h‚ÇÇ‚ü© => ‚ü®h‚ÇÅ, h‚ÇÇ‚ü©, fun ‚ü®h‚ÇÇ, h‚ÇÉ‚ü© => ‚ü®h‚ÇÅ, h‚ÇÇ‚ü©]
2025-12-15 12:03:29.740 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="application type mismatch\n  And.intro h‚ÇÅ\nargument\n  h‚ÇÅ\nhas type\n  (f x).Dom ‚àß (g x).Dom : Prop\nbut is expected to have type\n  y.1 ‚àà f x : Prop\nunknown identifier 'h‚ÇÅ'")
2025-12-15 12:03:29.740 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 3 steps and 900.73s.
2025-12-15 12:03:29.740 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="application type mismatch\n  And.intro h‚ÇÅ\nargument\n  h‚ÇÅ\nhas type\n  (f x).Dom ‚àß (g x).Dom : Prop\nbut is expected to have type\n  y.1 ‚àà f x : Prop\nunknown identifier 'h‚ÇÅ'")
2025-12-15 12:03:29.879 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 12:04:04.569 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: rw [isSheaf_iff_isLimit] at hF ‚ä¢
2025-12-15 12:04:09.202 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 2: Running MCTS search for 200 iterations...
2025-12-15 12:04:35.486 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: constructor
2025-12-15 12:04:40.291 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 2: Running MCTS search for 200 iterations...
2025-12-15 12:05:05.640 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 2: Applying best tactic: exacts [inferInstanceWellPowered_of_equivalenceWellPowered D e,
  inferInstanceWellPowered_of_equivalenceWellPowered_of_equivalenceWellPowered D e,
  inferInstanceWellPowered_of_equivalenceWellPowered_of_equivalenceWellPowered D e,
  inferInstanceWellPowered_of_equivalenceWellPowered_of_equivalenceWellPowered D e,
  inferInstanceWellPowered_of_equivalenceWellPowered_of_equivalenceWellPowered D e,
  inferInstanceWellPowered_of_equivalenceWellPowered_of_equivalenceWellPowered D e,
  inferInstanceWellPowered_of_equivalenceWellPowered_of_equivalenceWellPowered D e,
  inferInstanceWellPowered_of_equivalenceWellPowered_of_equivalenceWellPowered D e,
  inferInstanceWellPowered_of_equivalenceWellPowered_of_equivalenceWellPowered D e,
  inferInstanceWellPowered_of_equivalenceWellPowered_of_equivalenceWellPowered D e,
  inferInstanceWellPowered_of_equivalenceWellPowered_of_equivalenceWellPowered D e,
  inferInstanceWellPowered_of_equivalenceWellPowered_of_equivalenceWellPowered D e,
  inferInstanceWellPowered_of_equiv
2025-12-15 12:05:05.708 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="<stdin>:13:35: unexpected end of input; expected ']'")
2025-12-15 12:05:05.708 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 2 steps and 307.24s.
2025-12-15 12:05:05.708 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="<stdin>:13:35: unexpected end of input; expected ']'")
2025-12-15 12:05:05.849 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 12:05:09.426 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: simp only [continuous_def, continuous_def]
2025-12-15 12:05:14.118 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 2: Running MCTS search for 200 iterations...
2025-12-15 12:05:14.120 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 2: Applying best tactic: simp only [‚Üê isOpen_compl_iff, isOpen_induced_iff, preimage_compl]
2025-12-15 12:05:18.808 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 3: Running MCTS search for 200 iterations...
2025-12-15 12:05:18.810 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 3: Applying best tactic: simp only [‚Üê isOpen_compl_iff, preimage_compl]
2025-12-15 12:05:18.874 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error='simp made no progress')
2025-12-15 12:05:18.874 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 3 steps and 1020.32s.
2025-12-15 12:05:18.874 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error='simp made no progress')
2025-12-15 12:05:19.013 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 12:05:50.123 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 2: Applying best tactic: intro X S hS
2025-12-15 12:05:54.666 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 3: Running MCTS search for 200 iterations...
2025-12-15 12:06:05.391 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: simp only [intrinsicInterior, subset_def, mem_interior_iff_mem_nhds]
2025-12-15 12:06:09.975 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 2: Running MCTS search for 200 iterations...
2025-12-15 12:06:45.919 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 3: Applying best tactic: obtain ‚ü®S', hS', ‚ü®e‚ü©‚ü© := h S
2025-12-15 12:06:46.056 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="rcases tactic failed: fac‚úù : ‚àÄ\n  (s :\n    CategoryTheory.Limits.Cone\n      (CategoryTheory.Limits.cospan (sorryAx (?m.149557 ‚ü∂ ?m.149558) true) (sorryAx (?m.149557 ‚ü∂ ?m.149558) true)))\n  (j : CategoryTheory.Limits.WalkingCospan), hS' s ‚â´ S'.œÄ.app j = s.œÄ.app j is not an inductive datatype")
2025-12-15 12:06:46.056 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 3 steps and 756.14s.
2025-12-15 12:06:46.057 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="rcases tactic failed: fac‚úù : ‚àÄ\n  (s :\n    CategoryTheory.Limits.Cone\n      (CategoryTheory.Limits.cospan (sorryAx (?m.149557 ‚ü∂ ?m.149558) true) (sorryAx (?m.149557 ‚ü∂ ?m.149558) true)))\n  (j : CategoryTheory.Limits.WalkingCospan), hS' s ‚â´ S'.œÄ.app j = s.œÄ.app j is not an inductive datatype")
2025-12-15 12:06:46.196 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 12:07:00.402 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: constructor
2025-12-15 12:07:05.039 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 2: Running MCTS search for 200 iterations...
2025-12-15 12:07:17.764 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 2: Applying best tactic: exacts [fun ‚ü®c, hc‚ü© => ‚ü®c, hc‚ü©, fun ‚ü®c, hc‚ü© => ‚ü®c, hc‚ü©]
2025-12-15 12:07:17.907 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error='application type mismatch\n  Exists.intro c\nargument\n  c\nhas type\n  G.ConnectedComponent : Type u\nbut is expected to have type\n  V : Type u\napplication type mismatch\n  Exists.intro c\nargument\n  c\nhas type\n  V : Type u\nbut is expected to have type\n  G.ConnectedComponent : Type u')
2025-12-15 12:07:17.907 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 2 steps and 500.03s.
2025-12-15 12:07:17.907 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error='application type mismatch\n  Exists.intro c\nargument\n  c\nhas type\n  G.ConnectedComponent : Type u\nbut is expected to have type\n  V : Type u\napplication type mismatch\n  Exists.intro c\nargument\n  c\nhas type\n  V : Type u\nbut is expected to have type\n  G.ConnectedComponent : Type u')
2025-12-15 12:07:18.046 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 12:07:21.354 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 3: Applying best tactic: simp only [‚Üê cancel_mono h.opcyclesIso.inv, ‚Üê cancel_mono h.opcyclesIso.inv,
  ‚Üê cancel_mono h.opcyclesIso.inv, ‚Üê cancel_mono h.opcyclesIso.inv, ‚Üê cancel_mono h.opcyclesIso.inv,
  ‚Üê cancel_mono h.opcyclesIso.inv, ‚Üê cancel_mono h.opcyclesIso.inv, ‚Üê cancel_mono h.opcyclesIso.inv,
  ‚Üê cancel_mono h.opcyclesIso.inv, ‚Üê cancel_mono h.opcyclesIso.inv, ‚Üê cancel_mono h.opcyclesIso.inv,
  ‚Üê cancel_mono h.opcyclesIso.inv, ‚Üê cancel_mono h.opcyclesIso.inv, ‚Üê cancel_mono h.opcyclesIso.inv,
  ‚Üê cancel_mono h.opcyclesIso.inv, ‚Üê cancel_mono h.opcyclesIso.inv, ‚Üê cancel_mono h.opcyclesIso.inv,
  ‚Üê cancel_mono h.opcyclesIso.inv, ‚Üê cancel_mono h.opcyclesIso.inv, ‚Üê cancel_mono h.opcyclesIso.inv,
  ‚Üê cancel_mono h.opcyclesIso.inv, ‚Üê cancel_mono h.opcyclesIso.inv, ‚Üê cancel_mono h.opcyclesIso.inv,
  ‚Üê cancel_mono h.opcyclesIso.inv, ‚Üê cancel_mono h.opcyclesIso.inv, ‚Üê cancel_mono h.opcyclesIso.inv,
  ‚Üê cancel_mono h.opcyclesIso.inv, ‚Üê cancel_mono h.opcyclesIso.inv, ‚Üê cancel_mon
2025-12-15 12:07:21.423 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="<stdin>:10:80: unexpected end of input; expected ']'")
2025-12-15 12:07:21.423 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 3 steps and 1847.69s.
2025-12-15 12:07:21.423 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="<stdin>:10:80: unexpected end of input; expected ']'")
2025-12-15 12:07:21.564 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 12:07:43.836 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 2: Applying best tactic: rintro _ ‚ü®v, hv, rfl‚ü©
2025-12-15 12:07:48.411 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 3: Running MCTS search for 200 iterations...
2025-12-15 12:07:48.412 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 3: Applying best tactic: rw [mem_interior_iff_mem_nhds] at hv
2025-12-15 12:07:52.939 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 4: Running MCTS search for 200 iterations...
2025-12-15 12:07:52.940 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 4: Applying best tactic: exact mem_of_superset v.preimage_mem_nhds v.preimage_subset v.preimage_subset v.preimage_subset
  v.preimage_subset v.preimage_subset v.preimage_subset v.preimage_subset v.preimage_subset
2025-12-15 12:07:53.006 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="unknown identifier 'mem_of_superset'")
2025-12-15 12:07:53.006 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 4 steps and 1484.98s.
2025-12-15 12:07:53.006 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="unknown identifier 'mem_of_superset'")
2025-12-15 12:07:53.145 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 12:08:27.160 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: rw [linearIndependent_iff']
2025-12-15 12:08:31.940 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 2: Running MCTS search for 200 iterations...
2025-12-15 12:09:21.792 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: rcases eq_zero_or_pos o with (rfl | ho')
2025-12-15 12:09:26.356 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 2: Running MCTS search for 200 iterations...
2025-12-15 12:09:26.358 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 2: Applying best tactic: case inl =>
  rw [zero_pow ho.ne', zero_opow ho.ne']
  exact zero_opow omega_ne_zero
2025-12-15 12:09:26.446 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  0 ^ ?m.69989\nho : 0 < 0\n‚ä¢ (sup fun n => 0 ^ ‚Üën) = 0 ^ œâ")
2025-12-15 12:09:26.446 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 2 steps and 1949.25s.
2025-12-15 12:09:26.446 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  0 ^ ?m.69989\nho : 0 < 0\n‚ä¢ (sup fun n => 0 ^ ‚Üën) = 0 ^ œâ")
2025-12-15 12:09:26.512 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 2: Applying best tactic: intro s g hg i hi
2025-12-15 12:09:26.584 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 12:09:31.325 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 3: Running MCTS search for 200 iterations...
2025-12-15 12:09:31.327 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 3: Applying best tactic: rw [‚Üê Finset.sum_eq_zero hi, Finset.sum_eq_zero_iff] at hg
2025-12-15 12:09:31.512 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  ‚àë x ‚àà ?m.676183, ?m.676182 x = 0\nF : Type u\nE : Type v\ninst‚úù‚Å∑ : Field F\ninst‚úù‚Å∂ : Field E\ninst‚úù‚Åµ : Algebra F E\nK : Type w\ninst‚úù‚Å¥ : Field K\ninst‚úù¬≥ : Algebra F K\ninst‚úù¬≤ : Algebra E K\ninst‚úù¬π : IsScalarTower F E K\ninst‚úù : IsPurelyInseparable F E\nŒπ : Type u_1\nv : Œπ ‚Üí K\nhsep : ‚àÄ (i : Œπ), (minpoly F (v i)).Separable\nh : LinearIndependent F v\ns : Finset Œπ\ng : Œπ ‚Üí E\nhg‚úù : ‚àë i ‚àà s, g i ‚Ä¢ v i = 0\nhg : ‚àë i ‚àà s, g i ‚Ä¢ v i = ‚àë x ‚àà ?m.675585, ?m.675584 x\ni : Œπ\nhi : i ‚àà s\n‚ä¢ g i = 0")
2025-12-15 12:09:31.512 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 3 steps and 1478.51s.
2025-12-15 12:09:31.513 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  ‚àë x ‚àà ?m.676183, ?m.676182 x = 0\nF : Type u\nE : Type v\ninst‚úù‚Å∑ : Field F\ninst‚úù‚Å∂ : Field E\ninst‚úù‚Åµ : Algebra F E\nK : Type w\ninst‚úù‚Å¥ : Field K\ninst‚úù¬≥ : Algebra F K\ninst‚úù¬≤ : Algebra E K\ninst‚úù¬π : IsScalarTower F E K\ninst‚úù : IsPurelyInseparable F E\nŒπ : Type u_1\nv : Œπ ‚Üí K\nhsep : ‚àÄ (i : Œπ), (minpoly F (v i)).Separable\nh : LinearIndependent F v\ns : Finset Œπ\ng : Œπ ‚Üí E\nhg‚úù : ‚àë i ‚àà s, g i ‚Ä¢ v i = 0\nhg : ‚àë i ‚àà s, g i ‚Ä¢ v i = ‚àë x ‚àà ?m.675585, ?m.675584 x\ni : Œπ\nhi : i ‚àà s\n‚ä¢ g i = 0")
2025-12-15 12:09:31.652 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 12:16:53.422 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: induction' n with n n_ih
2025-12-15 12:16:58.208 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 2: Running MCTS search for 200 iterations...
2025-12-15 12:18:34.353 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: simp only [tendsto_const_mul_atBot_iff, tendsto_mul_const_atTop_iff]
2025-12-15 12:18:39.222 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 2: Running MCTS search for 200 iterations...
2025-12-15 12:20:23.750 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: simp only [supp, image_univ, mem_image, forall_exists_index, and_imp, forall_apply_eq_imp_iff‚ÇÇ,
  forall_exists_index, and_imp, forall_exists_index, and_imp, forall_apply_eq_imp_iff‚ÇÇ,
  forall_exists_index, and_imp, forall_exists_index, and_imp, forall_apply_eq_imp_iff‚ÇÇ,
  forall_exists_index, and_imp, forall_exists_index, and_imp, forall_apply_eq_imp_iff‚ÇÇ,
  forall_exists_index, and_imp, forall_exists_index, and_imp, forall_apply_eq_imp_iff‚ÇÇ,
  forall_exists_index, and_imp, forall_exists_index, and_imp, forall_apply_eq_imp_iff‚ÇÇ,
  forall_exists_index, and_imp, forall_apply_eq_imp_iff‚ÇÇ]
2025-12-15 12:20:28.339 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 2: Running MCTS search for 200 iterations...
2025-12-15 12:22:01.430 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: induction' s using Multiset.induction_on with a s ha ih
2025-12-15 12:22:06.212 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 2: Running MCTS search for 200 iterations...
2025-12-15 12:23:48.536 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 2: Applying best tactic: simp only [mem_range, forall_exists_index, and_imp, forall_apply_eq_imp_iff‚ÇÇ,
  forall_exists_index, and_imp, forall_exists_index, and_imp, forall_apply_eq_imp_iff‚ÇÇ,
  forall_exists_index, and_imp, forall_exists_index, and_imp, forall_apply_eq_imp_iff‚ÇÇ,
  forall_exists_index, and_imp, forall_exists_index, and_imp, forall_apply_eq_imp_iff‚ÇÇ,
  forall_exists_index, and_imp, forall_apply_eq_imp_iff‚ÇÇ]
2025-12-15 12:23:52.902 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 3: Running MCTS search for 200 iterations...
2025-12-15 12:23:52.904 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 3: Applying best tactic: simp only [liftp_iff', forall_exists_index, and_imp, forall_apply_eq_imp_iff‚ÇÇ,
  forall_exists_index, and_imp, forall_exists_index, and_imp, forall_apply_eq_imp_iff‚ÇÇ,
  forall_exists_index, and_imp, forall_exists_index, and_imp, forall_apply_eq_imp_iff‚ÇÇ,
  forall_exists_index, and_imp, forall_exists_index, and_imp, forall_apply_eq_imp_iff‚ÇÇ,
  forall_exists_index, and_imp, forall_apply_eq_imp_iff‚ÇÇ]
2025-12-15 12:23:57.296 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 4: Running MCTS search for 200 iterations...
2025-12-15 12:23:57.298 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 4: Applying best tactic: refine funext fun y => ‚ü®funext fun i =>?_, fun ‚ü®a, f‚ü© => ‚ü®‚ü®a, f‚ü©, fun ‚ü®a, f‚ü© => ‚ü®‚ü®a, f‚ü©, fun ‚ü®a, f‚ü© => ‚ü®a, f‚ü©, fun ‚ü®a, f‚ü© => ‚ü®a, f‚ü©, fun ‚ü®a, f‚ü© => ‚ü®‚ü®a, f‚ü©, fun ‚ü®a, f‚ü© => ‚ü®a, f‚ü©, fun ‚ü®a, f‚ü© => ‚ü®a, f‚ü©, fun ‚ü®a, f‚ü© => ‚ü®a, f‚ü©, fun ‚ü®a, f‚ü© => ‚ü®a, f‚ü©, fun ‚ü®a, f‚ü© => ‚ü®a, f‚ü©, fun ‚ü®a, f‚ü© => ‚ü®a, f‚ü©, fun ‚ü®a, f‚ü© => ‚ü®a, f‚ü©, fun ‚ü®a, f‚ü© => ‚ü®a, f‚ü©, fun ‚ü®a, f‚ü© => ‚ü®a, f‚ü©, fun ‚ü®a, f‚ü© => ‚ü®a, f‚ü©, fun ‚ü®a, f‚ü© => ‚ü®a, f‚ü©, fun ‚ü®a, f‚ü© => ‚ü®a, f‚ü©, fun ‚ü®a, f‚ü© => ‚ü®a, f‚ü©, fun ‚ü®a, f‚ü© => ‚ü®a, f‚ü©, fun ‚ü®a, f‚ü© => ‚ü®a, f‚ü©, fun ‚ü®a, f‚ü© => ‚ü®a, f‚ü©, fun ‚ü®a, f‚ü© => ‚ü®a, f‚ü©, fun ‚ü®a, f‚ü© => ‚ü®a, f‚ü©, fun ‚ü®a, f‚ü© => ‚ü®a, f‚ü©, fun ‚ü®a, f‚ü© => ‚ü®a, f‚ü©, fun ‚ü®a, f‚ü© => ‚ü®a, f‚ü©, fun ‚ü®a, f‚ü© => ‚ü®a, f‚ü©, fun ‚ü®a, f‚ü© => ‚ü®a, f‚ü©, fun ‚ü®a, f‚ü© => ‚ü®a, f‚ü©, fun ‚ü®a, f‚ü© => ‚ü®a, f‚ü©, fun ‚ü®a, f‚ü© => ‚ü®a, f‚ü©, fun ‚ü®a, f‚ü© => ‚ü®a, f‚ü©‚ü©
2025-12-15 12:23:57.368 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error="<stdin>:1:749: unexpected end of input; expected '‚ü©'")
2025-12-15 12:23:57.368 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 4 steps and 3263.25s.
2025-12-15 12:23:57.368 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error="<stdin>:1:749: unexpected end of input; expected '‚ü©'")
2025-12-15 12:23:57.505 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 12:25:10.464 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: cases nonempty_fintype Œπ
2025-12-15 12:25:15.026 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 2: Running MCTS search for 200 iterations...
2025-12-15 12:27:41.642 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 2: Applying best tactic: cases nonempty_fintype Œπ
2025-12-15 12:27:46.208 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 3: Running MCTS search for 200 iterations...
2025-12-15 12:28:53.491 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 3: Applying best tactic: cases nonempty_fintype Œπ
2025-12-15 12:28:57.841 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 4: Running MCTS search for 200 iterations...
2025-12-15 12:29:11.880 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 4: Applying best tactic: cases nonempty_fintype Œπ
2025-12-15 12:29:16.302 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 5: Running MCTS search for 200 iterations...
2025-12-15 12:29:28.424 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 5: Applying best tactic: cases nonempty_fintype Œπ
2025-12-15 12:29:32.809 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 6: Running MCTS search for 200 iterations...
2025-12-15 12:29:44.152 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 6: Applying best tactic: cases nonempty_fintype Œπ
2025-12-15 12:29:48.536 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 7: Running MCTS search for 200 iterations...
2025-12-15 12:29:59.224 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 7: Applying best tactic: cases nonempty_fintype Œπ
2025-12-15 12:30:03.618 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 8: Running MCTS search for 200 iterations...
2025-12-15 12:30:30.829 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 8: Applying best tactic: cases nonempty_fintype Œπ
2025-12-15 12:30:35.178 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 9: Running MCTS search for 200 iterations...
2025-12-15 12:30:46.107 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 9: Applying best tactic: cases nonempty_fintype Œπ
2025-12-15 12:30:50.504 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 10: Running MCTS search for 200 iterations...
2025-12-15 12:31:00.182 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 10: Applying best tactic: cases nonempty_fintype Œπ
2025-12-15 12:31:01.193 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 2: Applying best tactic: swap
2025-12-15 12:31:04.674 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 11: Running MCTS search for 200 iterations...
2025-12-15 12:31:06.001 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 3: Running MCTS search for 200 iterations...
2025-12-15 12:31:14.923 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 11: Applying best tactic: cases nonempty_fintype Œπ
2025-12-15 12:31:19.272 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 12: Running MCTS search for 200 iterations...
2025-12-15 12:31:27.941 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 12: Applying best tactic: cases nonempty_fintype Œπ
2025-12-15 12:31:32.280 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 13: Running MCTS search for 200 iterations...
2025-12-15 12:31:40.633 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 13: Applying best tactic: cases nonempty_fintype Œπ
2025-12-15 12:31:44.992 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 14: Running MCTS search for 200 iterations...
2025-12-15 12:32:05.004 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 14: Applying best tactic: cases nonempty_fintype Œπ
2025-12-15 12:32:09.376 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 15: Running MCTS search for 200 iterations...
2025-12-15 12:32:18.037 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 15: Applying best tactic: cases nonempty_fintype Œπ
2025-12-15 12:32:22.435 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 16: Running MCTS search for 200 iterations...
2025-12-15 12:32:30.114 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 16: Applying best tactic: cases nonempty_fintype Œπ
2025-12-15 12:32:34.467 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 17: Running MCTS search for 200 iterations...
2025-12-15 12:32:43.571 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 17: Applying best tactic: cases nonempty_fintype Œπ
2025-12-15 12:32:47.935 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 18: Running MCTS search for 200 iterations...
2025-12-15 12:33:11.099 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 18: Applying best tactic: cases nonempty_fintype Œπ
2025-12-15 12:33:15.501 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 19: Running MCTS search for 200 iterations...
2025-12-15 12:33:39.746 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 19: Applying best tactic: cases nonempty_fintype Œπ
2025-12-15 12:33:44.115 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 20: Running MCTS search for 200 iterations...
2025-12-15 12:33:55.010 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 20: Applying best tactic: cases nonempty_fintype Œπ
2025-12-15 12:33:59.486 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 21: Running MCTS search for 200 iterations...
2025-12-15 12:34:09.851 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 21: Applying best tactic: cases nonempty_fintype Œπ
2025-12-15 12:34:14.276 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 22: Running MCTS search for 200 iterations...
2025-12-15 12:34:22.788 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 2: Applying best tactic: swap
2025-12-15 12:34:27.494 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 3: Running MCTS search for 200 iterations...
2025-12-15 12:34:41.843 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 22: Applying best tactic: cases nonempty_fintype Œπ
2025-12-15 12:34:46.320 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 23: Running MCTS search for 200 iterations...
2025-12-15 12:34:52.316 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 23: Applying best tactic: cases nonempty_fintype Œπ
2025-12-15 12:34:56.741 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 24: Running MCTS search for 200 iterations...
2025-12-15 12:35:01.245 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 24: Applying best tactic: cases nonempty_fintype Œπ
2025-12-15 12:35:05.734 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 25: Running MCTS search for 200 iterations...
2025-12-15 12:35:10.032 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 25: Applying best tactic: cases nonempty_fintype Œπ
2025-12-15 12:35:14.462 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 26: Running MCTS search for 200 iterations...
2025-12-15 12:35:18.358 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 26: Applying best tactic: cases nonempty_fintype Œπ
2025-12-15 12:35:22.820 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 27: Running MCTS search for 200 iterations...
2025-12-15 12:35:35.954 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 27: Applying best tactic: cases nonempty_fintype Œπ
2025-12-15 12:35:40.389 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 28: Running MCTS search for 200 iterations...
2025-12-15 12:35:43.724 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 28: Applying best tactic: cases nonempty_fintype Œπ
2025-12-15 12:35:48.209 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 29: Running MCTS search for 200 iterations...
2025-12-15 12:35:53.025 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 29: Applying best tactic: cases nonempty_fintype Œπ
2025-12-15 12:35:57.447 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 30: Running MCTS search for 200 iterations...
2025-12-15 12:36:03.153 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 2: Applying best tactic: rcases lt_trichotomy c 0 with (hc | hc | hc)
2025-12-15 12:36:08.231 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 3: Running MCTS search for 200 iterations...
2025-12-15 12:36:13.221 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 30: Applying best tactic: cases nonempty_fintype Œπ
2025-12-15 12:36:13.395 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 30 steps and 3989.14s.
2025-12-15 12:36:13.534 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 12:41:10.834 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 3: Applying best tactic: swap
2025-12-15 12:41:12.617 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 3: Applying best tactic: swap
2025-12-15 12:41:15.767 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 4: Running MCTS search for 200 iterations...
2025-12-15 12:41:17.525 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 4: Running MCTS search for 200 iterations...
2025-12-15 12:42:46.567 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 3: Applying best tactic: swap
2025-12-15 12:42:50.130 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 4: Applying best tactic: swap
2025-12-15 12:42:51.488 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 4: Running MCTS search for 200 iterations...
2025-12-15 12:42:55.139 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 5: Running MCTS search for 200 iterations...
2025-12-15 12:44:03.493 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 4: Applying best tactic: swap
2025-12-15 12:44:08.494 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 5: Running MCTS search for 200 iterations...
2025-12-15 12:44:28.603 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 4: Applying best tactic: swap
2025-12-15 12:44:33.238 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 5: Running MCTS search for 200 iterations...
2025-12-15 12:51:27.491 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 5: Applying best tactic: swap
2025-12-15 12:51:32.189 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 6: Running MCTS search for 200 iterations...
2025-12-15 12:51:52.137 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 5: Applying best tactic: swap
2025-12-15 12:51:56.832 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 6: Running MCTS search for 200 iterations...
2025-12-15 12:55:05.282 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 5: Applying best tactic: swap
2025-12-15 12:55:10.303 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 6: Running MCTS search for 200 iterations...
2025-12-15 12:58:38.874 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 6: Applying best tactic: swap
2025-12-15 12:58:43.788 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 7: Running MCTS search for 200 iterations...
2025-12-15 12:59:14.277 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 6: Applying best tactic: swap
2025-12-15 12:59:18.923 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 7: Running MCTS search for 200 iterations...
2025-12-15 13:00:42.609 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 6: Applying best tactic: swap
2025-12-15 13:00:47.393 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 7: Running MCTS search for 200 iterations...
2025-12-15 13:06:10.956 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 1: Applying best tactic: simp only [isCompact_iff_finite_subcover, isOpen_induced_iff]
2025-12-15 13:06:16.532 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 2: Running MCTS search for 200 iterations...
2025-12-15 13:07:20.910 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 7: Applying best tactic: swap
2025-12-15 13:07:25.819 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 8: Running MCTS search for 200 iterations...
2025-12-15 13:09:31.502 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 7: Applying best tactic: swap
2025-12-15 13:09:36.382 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 8: Running MCTS search for 200 iterations...
2025-12-15 13:12:23.750 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 7: Applying best tactic: swap
2025-12-15 13:12:28.669 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 8: Running MCTS search for 200 iterations...
2025-12-15 13:13:25.410 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 8: Applying best tactic: swap
2025-12-15 13:13:30.215 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 9: Running MCTS search for 200 iterations...
2025-12-15 13:16:25.928 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 9: Applying best tactic: swap
2025-12-15 13:16:30.794 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 10: Running MCTS search for 200 iterations...
2025-12-15 13:16:45.882 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 8: Applying best tactic: swap
2025-12-15 13:16:50.543 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 9: Running MCTS search for 200 iterations...
2025-12-15 13:18:32.737 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 8: Applying best tactic: swap
2025-12-15 13:18:37.583 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 9: Running MCTS search for 200 iterations...
2025-12-15 13:20:13.934 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 9: Applying best tactic: swap
2025-12-15 13:20:18.712 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 10: Running MCTS search for 200 iterations...
2025-12-15 13:22:01.283 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 2: Applying best tactic: constructor
2025-12-15 13:22:06.272 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 3: Running MCTS search for 200 iterations...
2025-12-15 13:22:06.273 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 3: Applying best tactic: exacts [fun ‚ü®s, hs, rfl‚ü© => ‚ü®s, hs, rfl‚ü©, fun ‚ü®t, ht, rfl‚ü© => ‚ü®t, ht, rfl‚ü©]
2025-12-15 13:22:06.383 | WARNING  | lean_reinforcement.agent.runner:run:185 - Tactic resulted in error: LeanError(error='invalid constructor ‚ü®...‚ü©, expected type must be an inductive type \n  inst‚úù¬≤.1 U\napplication type mismatch\n  ‚ü®ht, rfl‚ü©\nargument\n  rfl\nhas type\n  U = U : Prop\nbut is expected to have type\n  U = ‚ãÉ i ‚àà t, ‚Üë(b i) : Prop')
2025-12-15 13:22:06.383 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 3 steps and 5863.85s.
2025-12-15 13:22:06.383 | WARNING  | lean_reinforcement.agent.runner:run:226 - Final state: LeanError(error='invalid constructor ‚ü®...‚ü©, expected type must be an inductive type \n  inst‚úù¬≤.1 U\napplication type mismatch\n  ‚ü®ht, rfl‚ü©\nargument\n  rfl\nhas type\n  U = U : Prop\nbut is expected to have type\n  U = ‚ãÉ i ‚àà t, ‚Üë(b i) : Prop')
2025-12-15 13:22:06.522 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 13:24:28.666 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 10: Applying best tactic: swap
2025-12-15 13:24:33.320 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 11: Running MCTS search for 200 iterations...
2025-12-15 13:26:40.852 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 10: Applying best tactic: swap
2025-12-15 13:26:45.581 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 11: Running MCTS search for 200 iterations...
2025-12-15 13:27:23.697 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 11: Applying best tactic: swap
2025-12-15 13:27:28.563 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 12: Running MCTS search for 200 iterations...
2025-12-15 13:29:22.583 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 9: Applying best tactic: swap
2025-12-15 13:29:27.521 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 10: Running MCTS search for 200 iterations...
2025-12-15 13:30:36.663 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 11: Applying best tactic: swap
2025-12-15 13:30:41.371 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 12: Running MCTS search for 200 iterations...
2025-12-15 13:38:01.488 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 12: Applying best tactic: swap
2025-12-15 13:38:06.480 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 13: Running MCTS search for 200 iterations...
2025-12-15 13:39:13.371 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 10: Applying best tactic: swap
2025-12-15 13:39:18.462 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 11: Running MCTS search for 200 iterations...
2025-12-15 13:41:09.529 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 12: Applying best tactic: swap
2025-12-15 13:41:14.586 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 13: Running MCTS search for 200 iterations...
2025-12-15 13:44:10.756 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 11: Applying best tactic: swap
2025-12-15 13:44:15.586 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 12: Running MCTS search for 200 iterations...
2025-12-15 13:44:19.208 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 13: Applying best tactic: swap
2025-12-15 13:44:23.848 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 14: Running MCTS search for 200 iterations...
2025-12-15 13:46:59.862 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 13: Applying best tactic: swap
2025-12-15 13:47:04.708 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 14: Running MCTS search for 200 iterations...
2025-12-15 13:49:45.721 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 14: Applying best tactic: swap
2025-12-15 13:49:50.439 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 15: Running MCTS search for 200 iterations...
2025-12-15 13:55:34.754 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 15: Applying best tactic: swap
2025-12-15 13:55:39.601 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 16: Running MCTS search for 200 iterations...
2025-12-15 13:57:42.481 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 12: Applying best tactic: swap
2025-12-15 13:57:47.647 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 13: Running MCTS search for 200 iterations...
2025-12-15 13:58:07.724 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 14: Applying best tactic: swap
2025-12-15 13:58:12.516 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 15: Running MCTS search for 200 iterations...
2025-12-15 14:03:23.789 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 15: Applying best tactic: swap
2025-12-15 14:03:28.386 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 16: Running MCTS search for 200 iterations...
2025-12-15 14:04:24.541 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 16: Applying best tactic: swap
2025-12-15 14:04:29.251 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 17: Running MCTS search for 200 iterations...
2025-12-15 14:05:50.491 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 13: Applying best tactic: swap
2025-12-15 14:05:55.347 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 14: Running MCTS search for 200 iterations...
2025-12-15 14:10:12.385 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 17: Applying best tactic: swap
2025-12-15 14:10:17.107 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 18: Running MCTS search for 200 iterations...
2025-12-15 14:10:57.133 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 14: Applying best tactic: swap
2025-12-15 14:11:01.802 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 15: Running MCTS search for 200 iterations...
2025-12-15 14:12:54.232 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 16: Applying best tactic: swap
2025-12-15 14:12:58.928 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 17: Running MCTS search for 200 iterations...
2025-12-15 14:17:14.153 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 17: Applying best tactic: swap
2025-12-15 14:17:19.101 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 18: Running MCTS search for 200 iterations...
2025-12-15 14:20:21.635 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 15: Applying best tactic: swap
2025-12-15 14:20:26.569 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 16: Running MCTS search for 200 iterations...
2025-12-15 14:20:54.018 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 18: Applying best tactic: swap
2025-12-15 14:20:58.937 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 19: Running MCTS search for 200 iterations...
2025-12-15 14:25:50.082 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 16: Applying best tactic: swap
2025-12-15 14:25:54.775 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 17: Running MCTS search for 200 iterations...
2025-12-15 14:26:30.214 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 18: Applying best tactic: swap
2025-12-15 14:26:35.296 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 19: Running MCTS search for 200 iterations...
2025-12-15 14:29:47.216 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 19: Applying best tactic: swap
2025-12-15 14:29:52.144 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 20: Running MCTS search for 200 iterations...
2025-12-15 14:30:59.726 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 19: Applying best tactic: swap
2025-12-15 14:31:04.483 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 20: Running MCTS search for 200 iterations...
2025-12-15 14:34:01.792 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 20: Applying best tactic: swap
2025-12-15 14:34:06.439 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 21: Running MCTS search for 200 iterations...
2025-12-15 14:39:16.504 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 21: Applying best tactic: swap
2025-12-15 14:39:21.309 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 22: Running MCTS search for 200 iterations...
2025-12-15 14:41:14.756 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 20: Applying best tactic: swap
2025-12-15 14:41:19.527 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 21: Running MCTS search for 200 iterations...
2025-12-15 14:41:21.225 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 17: Applying best tactic: swap
2025-12-15 14:41:26.529 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 18: Running MCTS search for 200 iterations...
2025-12-15 14:44:57.756 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 21: Applying best tactic: swap
2025-12-15 14:45:02.429 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 22: Running MCTS search for 200 iterations...
2025-12-15 14:47:37.140 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 18: Applying best tactic: swap
2025-12-15 14:47:42.282 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 19: Running MCTS search for 200 iterations...
2025-12-15 14:49:10.424 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 22: Applying best tactic: swap
2025-12-15 14:49:15.113 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 23: Running MCTS search for 200 iterations...
2025-12-15 14:53:29.736 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 23: Applying best tactic: swap
2025-12-15 14:53:34.651 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 24: Running MCTS search for 200 iterations...
2025-12-15 14:58:00.947 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 22: Applying best tactic: swap
2025-12-15 14:58:05.898 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 23: Running MCTS search for 200 iterations...
2025-12-15 14:59:57.031 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 19: Applying best tactic: swap
2025-12-15 15:00:02.217 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 20: Running MCTS search for 200 iterations...
2025-12-15 15:01:04.321 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 23: Applying best tactic: swap
2025-12-15 15:01:09.014 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 24: Running MCTS search for 200 iterations...
2025-12-15 15:03:15.793 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 24: Applying best tactic: swap
2025-12-15 15:03:20.550 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 25: Running MCTS search for 200 iterations...
2025-12-15 15:07:27.137 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 20: Applying best tactic: swap
2025-12-15 15:07:32.124 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 21: Running MCTS search for 200 iterations...
2025-12-15 15:09:07.575 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 25: Applying best tactic: swap
2025-12-15 15:09:12.194 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 26: Running MCTS search for 200 iterations...
2025-12-15 15:12:34.982 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 21: Applying best tactic: swap
2025-12-15 15:12:39.879 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 22: Running MCTS search for 200 iterations...
2025-12-15 15:12:45.678 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 26: Applying best tactic: swap
2025-12-15 15:12:50.270 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 27: Running MCTS search for 200 iterations...
2025-12-15 15:13:00.466 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 24: Applying best tactic: swap
2025-12-15 15:13:05.263 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 25: Running MCTS search for 200 iterations...
2025-12-15 15:17:17.992 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 25: Applying best tactic: swap
2025-12-15 15:17:22.840 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 26: Running MCTS search for 200 iterations...
2025-12-15 15:21:42.891 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 27: Applying best tactic: swap
2025-12-15 15:21:47.586 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 28: Running MCTS search for 200 iterations...
2025-12-15 15:25:04.877 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 22: Applying best tactic: swap
2025-12-15 15:25:09.916 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 23: Running MCTS search for 200 iterations...
2025-12-15 15:25:11.265 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 28: Applying best tactic: swap
2025-12-15 15:25:15.837 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 29: Running MCTS search for 200 iterations...
2025-12-15 15:30:02.518 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 23: Applying best tactic: swap
2025-12-15 15:30:07.418 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 24: Running MCTS search for 200 iterations...
2025-12-15 15:31:24.259 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 26: Applying best tactic: swap
2025-12-15 15:31:29.271 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 27: Running MCTS search for 200 iterations...
2025-12-15 15:32:59.937 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 29: Applying best tactic: swap
2025-12-15 15:33:04.637 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 30: Running MCTS search for 200 iterations...
2025-12-15 15:34:40.866 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 27: Applying best tactic: swap
2025-12-15 15:34:45.413 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 28: Running MCTS search for 200 iterations...
2025-12-15 15:41:35.673 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 24: Applying best tactic: swap
2025-12-15 15:41:40.750 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 25: Running MCTS search for 200 iterations...
2025-12-15 15:44:42.070 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 30: Applying best tactic: swap
2025-12-15 15:44:42.196 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 30 steps and 15598.65s.
2025-12-15 15:44:42.334 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 15:45:33.608 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 28: Applying best tactic: swap
2025-12-15 15:45:38.443 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 29: Running MCTS search for 200 iterations...
2025-12-15 15:48:56.232 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 29: Applying best tactic: swap
2025-12-15 15:49:01.240 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 30: Running MCTS search for 200 iterations...
2025-12-15 15:50:49.385 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 25: Applying best tactic: swap
2025-12-15 15:50:54.467 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 26: Running MCTS search for 200 iterations...
2025-12-15 15:53:12.846 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 26: Applying best tactic: swap
2025-12-15 15:53:17.717 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 27: Running MCTS search for 200 iterations...
2025-12-15 15:54:57.642 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 30: Applying best tactic: swap
2025-12-15 15:54:57.796 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 30 steps and 15714.01s.
2025-12-15 15:54:57.935 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 15:55:45.942 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 27: Applying best tactic: swap
2025-12-15 15:55:50.838 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 28: Running MCTS search for 200 iterations...
2025-12-15 16:03:19.573 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 28: Applying best tactic: swap
2025-12-15 16:03:24.446 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 29: Running MCTS search for 200 iterations...
2025-12-15 16:05:01.590 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 29: Applying best tactic: swap
2025-12-15 16:05:06.318 | INFO     | lean_reinforcement.agent.runner:run:113 - Step 30: Running MCTS search for 200 iterations...
2025-12-15 16:15:05.514 | INFO     | lean_reinforcement.agent.runner:run:176 - Step 30: Applying best tactic: swap
2025-12-15 16:15:05.723 | ERROR    | lean_reinforcement.agent.runner:run:222 - Proof failed after 30 steps and 16220.69s.
2025-12-15 16:15:05.863 | INFO     | lean_reinforcement.utilities.gym:close:88 - Environment closed.
2025-12-15 16:15:10.746 | INFO     | __main__:main:302 - Completed 128/128 proofs
2025-12-15 16:15:10.757 | INFO     | __main__:main:330 - Stopping workers for this epoch...
2025-12-15 16:15:14.505 | INFO     | __main__:main:337 - Draining queues...
2025-12-15 16:15:14.568 | INFO     | __main__:main:370 - Loading training data from temporary file...
2025-12-15 16:15:14.577 | INFO     | lean_reinforcement.utilities.analyze_training_data:print_training_stats:87 - ============================================================
2025-12-15 16:15:14.577 | INFO     | lean_reinforcement.utilities.analyze_training_data:print_training_stats:88 - TRAINING DATA STATISTICS
2025-12-15 16:15:14.577 | INFO     | lean_reinforcement.utilities.analyze_training_data:print_training_stats:89 - ============================================================
2025-12-15 16:15:14.577 | INFO     | lean_reinforcement.utilities.analyze_training_data:print_training_stats:91 - Total samples: 281
2025-12-15 16:15:14.577 | INFO     | lean_reinforcement.utilities.analyze_training_data:print_training_stats:92 -   Positive (successful proofs): 22 (7.8%)
2025-12-15 16:15:14.577 | INFO     | lean_reinforcement.utilities.analyze_training_data:print_training_stats:96 -   Negative (failed proofs): 259 (92.2%)
2025-12-15 16:15:14.578 | INFO     | lean_reinforcement.utilities.analyze_training_data:print_training_stats:101 - 
Value Targets:
2025-12-15 16:15:14.578 | INFO     | lean_reinforcement.utilities.analyze_training_data:print_training_stats:103 -   Mean: -0.8434, Std: 0.5373, Range: [-1.0000, 1.0000]
2025-12-15 16:15:14.578 | INFO     | lean_reinforcement.utilities.analyze_training_data:print_training_stats:107 - 
Visit Counts:
2025-12-15 16:15:14.578 | INFO     | lean_reinforcement.utilities.analyze_training_data:print_training_stats:109 -   Mean: 268.2, Std: 109.1, Range: [200, 656]
2025-12-15 16:15:14.578 | INFO     | lean_reinforcement.utilities.analyze_training_data:print_training_stats:113 - 
Steps in Trajectory:
2025-12-15 16:15:14.578 | INFO     | lean_reinforcement.utilities.analyze_training_data:print_training_stats:115 -   Mean: 7.4, Std: 9.0, Range: [1, 30]
2025-12-15 16:15:14.578 | INFO     | lean_reinforcement.utilities.analyze_training_data:print_training_stats:120 - 
MCTS Value Estimates:
2025-12-15 16:15:14.578 | INFO     | lean_reinforcement.utilities.analyze_training_data:print_training_stats:122 -   Mean: -0.4805, Std: 0.6482, Range: [-1.0000, 1.0000]
2025-12-15 16:15:14.578 | INFO     | lean_reinforcement.utilities.analyze_training_data:print_training_stats:125 -   Samples with MCTS values: 281
2025-12-15 16:15:14.578 | INFO     | lean_reinforcement.utilities.analyze_training_data:print_training_stats:127 - ============================================================
2025-12-15 16:15:14.590 | INFO     | lean_reinforcement.utilities.analyze_training_data:save_training_data:143 - Training data saved to /gpfs/scratch1/shared/lean-reinforcement/checkpoints/training_data_epoch_4.json
2025-12-15 16:15:14.591 | INFO     | __main__:train_value_head:70 - Training Value Head on 281 samples...
2025-12-15 16:15:14.591 | INFO     | __main__:train_value_head:71 -   Data distribution: 22 positive, 259 negative
2025-12-15 16:15:14.591 | INFO     | __main__:train_value_head:74 -   Average target value: -0.8434
2025-12-15 16:15:14.591 | INFO     | __main__:train_value_head:81 -   Average MCTS value estimate: -0.4805
2025-12-15 16:15:14.591 | INFO     | __main__:train_value_head:89 -   Balancing dataset to 22 samples per class.
2025-12-15 16:15:15.838 | INFO     | __main__:train_value_head:150 - Value Head Epoch 1/1, Avg. Loss: 1.0044
2025-12-15 16:18:03.836 | INFO     | lean_reinforcement.agent.value_head:save_checkpoint:172 - Checkpoint saved to /gpfs/scratch1/shared/lean-reinforcement/checkpoints/value_head_latest.pth
2025-12-15 16:18:03.872 | INFO     | lean_reinforcement.agent.value_head:save_checkpoint:172 - Checkpoint saved to /gpfs/scratch1/shared/lean-reinforcement/checkpoints/value_head_epoch_4.pth
2025-12-15 16:18:03.937 | INFO     | lean_reinforcement.utilities.checkpoint:save_checkpoint:61 - Saved checkpoints: value_head_latest.pth and value_head_epoch_4.pth
2025-12-15 16:18:03.980 | INFO     | __main__:main:417 - Checkpoint saved for epoch 4
2025-12-15 16:18:04.021 | INFO     | __main__:main:229 - Starting 16 workers for epoch 5
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
[2025-12-15T16:28:52.687] error: *** JOB 17603289 ON gcn38 CANCELLED AT 2025-12-15T16:28:52 DUE to SIGNAL Terminated ***
[2025-12-15T16:28:52.688] error: *** STEP 17603289.0 ON gcn38 CANCELLED AT 2025-12-15T16:28:52 DUE to SIGNAL Terminated ***
