============================================================================================== 
Warning! Mixing Conda and module environments may lead to corruption of the
user environment. 
We do not recommend users mixing those two environments unless absolutely
necessary. Note that 
SURF does not provide any support for Conda environment.
For more information, please refer to our software policy page:
https://servicedesk.surf.nl/wiki/display/WIKI/Software+policy+Snellius#SoftwarepolicySnellius-UseofAnacondaandMinicondaenvironmentsonSnellius 

Remember that many packages have already been installed on the system and can
be loaded using 
the 'module load <package__name>' command. If you are uncertain if a package is
already available 
on the system, please use 'module avail' or 'module spider' to search for it.
============================================================================================== 
Building Cython extensions...
running build_ext
copying build/lib.linux-x86_64-cpython-310/lean_reinforcement/agent/mcts/mcts_cy/base_mcts_cy.cpython-310-x86_64-linux-gnu.so -> lean_reinforcement/agent/mcts/mcts_cy
copying build/lib.linux-x86_64-cpython-310/lean_reinforcement/agent/mcts/mcts_cy/alphazero_cy.cpython-310-x86_64-linux-gnu.so -> lean_reinforcement/agent/mcts/mcts_cy
copying build/lib.linux-x86_64-cpython-310/lean_reinforcement/agent/mcts/mcts_cy/guidedrollout_cy.cpython-310-x86_64-linux-gnu.so -> lean_reinforcement/agent/mcts/mcts_cy
copying build/lib.linux-x86_64-cpython-310/ReProver/common_cy.cpython-310-x86_64-linux-gnu.so -> ReProver
Starting training run with distributed environment...
wandb: Currently logged in as: gerbennkoopman to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.23.1
wandb: Run data is saved locally in /gpfs/home1/gkoopman/lean_reinforcement/wandb/run-20260111_161614-autp65eb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-waterfall-64
wandb: ‚≠êÔ∏è View project at https://wandb.ai/gerbennkoopman-university-of-amsterdam/lean-reinforcement
wandb: üöÄ View run at https://wandb.ai/gerbennkoopman-university-of-amsterdam/lean-reinforcement/runs/autp65eb
2026-01-11 16:16:15.372 | INFO     | lean_reinforcement.training.trainer:_setup_models:56 - Using checkpoint directory: /gpfs/scratch1/shared/lean-reinforcement/checkpoints
2026-01-11 16:16:18.569 | INFO     | lean_reinforcement.utilities.checkpoint:load_checkpoint:101 - No checkpoint found at /gpfs/scratch1/shared/lean-reinforcement/checkpoints/value_head_guided_rollout_latest.pth, starting from scratch
2026-01-11 16:16:18.569 | INFO     | lean_reinforcement.training.trainer:_setup_models:77 - Resuming training from epoch 0
2026-01-11 16:16:18.570 | INFO     | lean_reinforcement.training.trainer:_log_gpu_memory:123 - After model initialization - GPU Memory: 1.12GB allocated, 1.23GB reserved
2026-01-11 16:16:18.570 | INFO     | lean_reinforcement.training.trainer:_setup_data:87 - Loading data from 'leandojo_benchmark_4/novel_premises'
2026-01-11 16:16:18.571 | INFO     | lean_reinforcement.training.trainer:_setup_data:92 - Loading indexed corpus from /gpfs/scratch1/shared/lean-reinforcement/indexed_corpus/indexed_corpus.pkl
2026-01-11 16:16:57.300 | INFO     | lean_dojo.data_extraction.trace:trace:248 - Loading the traced repo from /gpfs/scratch1/shared/lean-reinforcement/datasets/lean_dojo_cache/leanprover-community-mathlib4-29dcec074de168ac2bf835a77ef68bbe069194c5/mathlib4
2026-01-11 16:17:07,434	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
  0%|          | 0/5674 [00:00<?, ?it/s]  0%|          | 1/5674 [00:01<2:44:03,  1.74s/it]  0%|          | 5/5674 [00:01<26:45,  3.53it/s]    0%|          | 11/5674 [00:01<10:34,  8.93it/s]  0%|          | 15/5674 [00:02<07:38, 12.34it/s]  0%|          | 19/5674 [00:02<05:50, 16.12it/s]  0%|          | 25/5674 [00:02<04:10, 22.54it/s]  1%|          | 29/5674 [00:07<36:37,  2.57it/s]  1%|          | 35/5674 [00:07<23:15,  4.04it/s]  1%|          | 39/5674 [00:07<17:44,  5.29it/s]  1%|          | 46/5674 [00:07<11:15,  8.33it/s]  1%|          | 51/5674 [00:07<09:13, 10.17it/s]  1%|          | 55/5674 [00:12<36:09,  2.59it/s]  1%|          | 58/5674 [00:13<29:39,  3.16it/s]  1%|          | 62/5674 [00:13<21:53,  4.27it/s]  1%|          | 65/5674 [00:13<17:58,  5.20it/s]  1%|          | 69/5674 [00:13<13:12,  7.07it/s]  1%|‚ñè         | 74/5674 [00:13<09:37,  9.69it/s]  1%|‚ñè         | 80/5674 [00:13<06:37, 14.08it/s]  1%|‚ñè         | 84/5674 [00:19<39:35,  2.35it/s]  2%|‚ñè         | 88/5674 [00:19<29:22,  3.17it/s]  2%|‚ñè         | 91/5674 [00:19<23:30,  3.96it/s]  2%|‚ñè         | 95/5674 [00:19<17:37,  5.28it/s]  2%|‚ñè         | 98/5674 [00:19<14:37,  6.35it/s]  2%|‚ñè         | 102/5674 [00:19<10:45,  8.63it/s]  2%|‚ñè         | 105/5674 [00:20<09:43,  9.55it/s]  2%|‚ñè         | 109/5674 [00:26<55:19,  1.68it/s]  2%|‚ñè         | 114/5674 [00:26<35:46,  2.59it/s]  2%|‚ñè         | 117/5674 [00:26<28:16,  3.28it/s]  2%|‚ñè         | 122/5674 [00:27<19:06,  4.84it/s]  2%|‚ñè         | 127/5674 [00:27<13:13,  6.99it/s]  2%|‚ñè         | 131/5674 [00:27<10:35,  8.73it/s]  2%|‚ñè         | 134/5674 [00:27<09:59,  9.24it/s]  2%|‚ñè         | 137/5674 [00:27<08:55, 10.35it/s]  2%|‚ñè         | 140/5674 [00:35<1:05:25,  1.41it/s]  3%|‚ñé         | 144/5674 [00:35<45:04,  2.05it/s]    3%|‚ñé         | 146/5674 [00:35<37:38,  2.45it/s]  3%|‚ñé         | 151/5674 [00:35<23:11,  3.97it/s]  3%|‚ñé         | 156/5674 [00:35<15:28,  5.94it/s]  3%|‚ñé         | 159/5674 [00:35<13:12,  6.96it/s]  3%|‚ñé         | 162/5674 [00:35<10:38,  8.64it/s]  3%|‚ñé         | 166/5674 [00:36<08:00, 11.47it/s]  3%|‚ñé         | 171/5674 [00:36<05:45, 15.93it/s]  3%|‚ñé         | 175/5674 [00:36<05:10, 17.71it/s]  3%|‚ñé         | 181/5674 [00:36<03:48, 24.07it/s]  3%|‚ñé         | 185/5674 [00:36<03:34, 25.59it/s]  3%|‚ñé         | 192/5674 [00:36<02:40, 34.21it/s]  3%|‚ñé         | 197/5674 [00:45<49:29,  1.84it/s]  4%|‚ñé         | 201/5674 [00:45<37:40,  2.42it/s]  4%|‚ñé         | 205/5674 [00:45<28:28,  3.20it/s]  4%|‚ñé         | 209/5674 [00:46<21:35,  4.22it/s]  4%|‚ñç         | 220/5674 [00:46<10:56,  8.31it/s]  4%|‚ñç         | 228/5674 [00:46<07:38, 11.88it/s]  4%|‚ñç         | 236/5674 [00:46<05:50, 15.51it/s]  4%|‚ñç         | 241/5674 [00:46<05:23, 16.80it/s]  4%|‚ñç         | 246/5674 [00:46<04:42, 19.19it/s]  4%|‚ñç         | 254/5674 [00:46<03:28, 26.03it/s]  5%|‚ñç         | 260/5674 [00:47<03:00, 29.94it/s]  5%|‚ñç         | 265/5674 [00:47<02:55, 30.82it/s]  5%|‚ñç         | 270/5674 [00:47<03:11, 28.29it/s]  5%|‚ñç         | 274/5674 [00:57<54:06,  1.66it/s]  5%|‚ñç         | 278/5674 [00:57<41:14,  2.18it/s]  5%|‚ñç         | 282/5674 [00:57<31:04,  2.89it/s]  5%|‚ñå         | 286/5674 [00:57<23:18,  3.85it/s]  5%|‚ñå         | 294/5674 [00:57<13:45,  6.52it/s]  5%|‚ñå         | 303/5674 [00:58<08:53, 10.06it/s]  5%|‚ñå         | 308/5674 [00:58<07:23, 12.10it/s]  6%|‚ñå         | 314/5674 [00:58<05:46, 15.45it/s]  6%|‚ñå         | 321/5674 [00:58<04:22, 20.39it/s]  6%|‚ñå         | 327/5674 [00:58<03:36, 24.69it/s]  6%|‚ñå         | 334/5674 [00:58<02:52, 30.95it/s]  6%|‚ñå         | 342/5674 [00:58<02:19, 38.17it/s]  6%|‚ñå         | 349/5674 [00:58<02:14, 39.56it/s]  6%|‚ñã         | 355/5674 [00:59<02:10, 40.82it/s]  6%|‚ñã         | 362/5674 [00:59<01:55, 46.10it/s]  6%|‚ñã         | 368/5674 [00:59<01:50, 48.16it/s]  7%|‚ñã         | 376/5674 [00:59<01:36, 54.73it/s]  7%|‚ñã         | 388/5674 [00:59<01:16, 69.14it/s]  7%|‚ñã         | 388/5674 [01:10<01:16, 69.14it/s]  7%|‚ñã         | 397/5674 [01:10<35:28,  2.48it/s]  7%|‚ñã         | 409/5674 [01:10<22:29,  3.90it/s]  8%|‚ñä         | 426/5674 [01:11<13:00,  6.73it/s]  8%|‚ñä         | 447/5674 [01:11<07:33, 11.53it/s]  8%|‚ñä         | 461/5674 [01:11<05:36, 15.51it/s]  8%|‚ñä         | 474/5674 [01:11<04:20, 19.96it/s]  9%|‚ñä         | 485/5674 [01:11<03:45, 23.03it/s]  9%|‚ñä         | 494/5674 [01:11<03:14, 26.63it/s]  9%|‚ñâ         | 502/5674 [01:12<02:50, 30.25it/s]  9%|‚ñâ         | 510/5674 [01:12<02:39, 32.47it/s]  9%|‚ñâ         | 517/5674 [01:12<02:40, 32.12it/s]  9%|‚ñâ         | 524/5674 [01:12<02:20, 36.54it/s]  9%|‚ñâ         | 530/5674 [01:12<02:18, 37.08it/s]  9%|‚ñâ         | 539/5674 [01:12<01:51, 46.02it/s] 10%|‚ñâ         | 548/5674 [01:12<01:35, 53.60it/s] 10%|‚ñâ         | 559/5674 [01:13<01:24, 60.33it/s] 10%|‚ñâ         | 567/5674 [01:13<01:22, 61.69it/s] 10%|‚ñà         | 574/5674 [01:13<01:22, 61.57it/s] 10%|‚ñà         | 581/5674 [01:13<01:51, 45.80it/s] 10%|‚ñà         | 588/5674 [01:13<01:44, 48.58it/s] 10%|‚ñà         | 588/5674 [01:26<01:44, 48.58it/s] 10%|‚ñà         | 593/5674 [01:26<50:13,  1.69it/s] 11%|‚ñà         | 602/5674 [01:27<32:39,  2.59it/s] 11%|‚ñà         | 608/5674 [01:27<25:03,  3.37it/s] 11%|‚ñà         | 617/5674 [01:27<16:35,  5.08it/s] 11%|‚ñà         | 623/5674 [01:27<12:47,  6.58it/s] 11%|‚ñà         | 633/5674 [01:27<08:19, 10.10it/s] 11%|‚ñà‚ñè        | 640/5674 [01:27<06:41, 12.53it/s] 11%|‚ñà‚ñè        | 647/5674 [01:27<05:13, 16.01it/s] 12%|‚ñà‚ñè        | 655/5674 [01:28<03:55, 21.31it/s] 12%|‚ñà‚ñè        | 663/5674 [01:28<03:04, 27.17it/s] 12%|‚ñà‚ñè        | 671/5674 [01:28<02:27, 33.83it/s] 12%|‚ñà‚ñè        | 678/5674 [01:28<02:12, 37.63it/s] 12%|‚ñà‚ñè        | 687/5674 [01:28<01:46, 46.64it/s] 12%|‚ñà‚ñè        | 695/5674 [01:28<01:39, 49.99it/s] 12%|‚ñà‚ñè        | 702/5674 [01:28<01:38, 50.34it/s] 12%|‚ñà‚ñè        | 709/5674 [01:28<01:52, 44.11it/s] 13%|‚ñà‚ñé        | 715/5674 [01:29<01:48, 45.62it/s] 13%|‚ñà‚ñé        | 721/5674 [01:29<01:53, 43.50it/s] 13%|‚ñà‚ñé        | 726/5674 [01:29<02:30, 32.92it/s] 13%|‚ñà‚ñé        | 730/5674 [01:29<02:25, 34.03it/s] 13%|‚ñà‚ñé        | 738/5674 [01:29<01:53, 43.35it/s] 13%|‚ñà‚ñé        | 745/5674 [01:29<01:41, 48.38it/s] 13%|‚ñà‚ñé        | 751/5674 [01:29<01:46, 46.14it/s] 13%|‚ñà‚ñé        | 757/5674 [01:30<01:40, 49.09it/s] 13%|‚ñà‚ñé        | 763/5674 [01:30<01:37, 50.20it/s] 13%|‚ñà‚ñé        | 763/5674 [01:45<01:37, 50.20it/s] 13%|‚ñà‚ñé        | 765/5674 [01:45<1:19:32,  1.03it/s] 14%|‚ñà‚ñé        | 771/5674 [01:45<52:42,  1.55it/s]   14%|‚ñà‚ñé        | 777/5674 [01:46<36:01,  2.27it/s] 14%|‚ñà‚ñç        | 782/5674 [01:46<26:25,  3.08it/s] 14%|‚ñà‚ñç        | 787/5674 [01:46<19:30,  4.18it/s] 14%|‚ñà‚ñç        | 796/5674 [01:46<11:36,  7.00it/s] 14%|‚ñà‚ñç        | 802/5674 [01:46<08:43,  9.31it/s] 14%|‚ñà‚ñç        | 808/5674 [01:46<06:55, 11.70it/s] 14%|‚ñà‚ñç        | 813/5674 [01:47<05:58, 13.55it/s] 14%|‚ñà‚ñç        | 818/5674 [01:47<05:31, 14.67it/s] 15%|‚ñà‚ñç        | 823/5674 [01:47<04:26, 18.19it/s] 15%|‚ñà‚ñç        | 829/5674 [01:47<03:33, 22.64it/s] 15%|‚ñà‚ñç        | 836/5674 [01:47<02:44, 29.40it/s] 15%|‚ñà‚ñç        | 841/5674 [01:47<02:27, 32.87it/s] 15%|‚ñà‚ñç        | 846/5674 [01:47<02:25, 33.29it/s] 15%|‚ñà‚ñå        | 852/5674 [01:47<02:10, 37.02it/s] 15%|‚ñà‚ñå        | 857/5674 [01:48<02:11, 36.60it/s] 15%|‚ñà‚ñå        | 862/5674 [01:48<02:06, 38.03it/s] 15%|‚ñà‚ñå        | 867/5674 [01:48<02:09, 37.25it/s] 15%|‚ñà‚ñå        | 872/5674 [01:48<02:13, 36.10it/s] 15%|‚ñà‚ñå        | 876/5674 [01:48<02:18, 34.57it/s] 16%|‚ñà‚ñå        | 880/5674 [01:48<02:20, 34.13it/s] 16%|‚ñà‚ñå        | 885/5674 [01:48<02:10, 36.61it/s] 16%|‚ñà‚ñå        | 890/5674 [01:49<02:01, 39.36it/s] 16%|‚ñà‚ñå        | 896/5674 [01:49<01:51, 42.96it/s] 16%|‚ñà‚ñå        | 901/5674 [01:49<01:49, 43.49it/s] 16%|‚ñà‚ñå        | 906/5674 [01:49<01:51, 42.85it/s] 16%|‚ñà‚ñå        | 911/5674 [01:49<01:49, 43.31it/s] 16%|‚ñà‚ñå        | 919/5674 [01:49<01:44, 45.63it/s] 16%|‚ñà‚ñã        | 926/5674 [01:49<01:36, 49.23it/s] 16%|‚ñà‚ñã        | 931/5674 [01:49<01:38, 48.08it/s] 16%|‚ñà‚ñã        | 931/5674 [02:08<01:38, 48.08it/s] 17%|‚ñà‚ñã        | 937/5674 [02:09<1:18:08,  1.01it/s] 17%|‚ñà‚ñã        | 942/5674 [02:09<57:47,  1.36it/s]   17%|‚ñà‚ñã        | 947/5674 [02:09<42:18,  1.86it/s] 17%|‚ñà‚ñã        | 952/5674 [02:09<31:00,  2.54it/s] 17%|‚ñà‚ñã        | 960/5674 [02:09<19:14,  4.08it/s] 17%|‚ñà‚ñã        | 966/5674 [02:09<13:57,  5.62it/s] 17%|‚ñà‚ñã        | 972/5674 [02:09<10:25,  7.52it/s] 17%|‚ñà‚ñã        | 977/5674 [02:10<08:18,  9.43it/s] 17%|‚ñà‚ñã        | 982/5674 [02:10<06:52, 11.37it/s] 17%|‚ñà‚ñã        | 990/5674 [02:10<04:50, 16.14it/s] 18%|‚ñà‚ñä        | 995/5674 [02:10<04:01, 19.35it/s] 18%|‚ñà‚ñä        | 1000/5674 [02:10<03:37, 21.50it/s] 18%|‚ñà‚ñä        | 1007/5674 [02:10<03:05, 25.18it/s] 18%|‚ñà‚ñä        | 1013/5674 [02:10<02:38, 29.45it/s] 18%|‚ñà‚ñä        | 1018/5674 [02:11<02:37, 29.65it/s] 18%|‚ñà‚ñä        | 1023/5674 [02:11<02:24, 32.28it/s] 18%|‚ñà‚ñä        | 1029/5674 [02:11<02:06, 36.69it/s] 18%|‚ñà‚ñä        | 1034/5674 [02:11<02:36, 29.73it/s] 18%|‚ñà‚ñä        | 1038/5674 [02:11<02:32, 30.45it/s] 18%|‚ñà‚ñä        | 1042/5674 [02:11<02:23, 32.25it/s] 18%|‚ñà‚ñä        | 1046/5674 [02:11<02:23, 32.35it/s] 19%|‚ñà‚ñä        | 1051/5674 [02:12<02:12, 34.84it/s] 19%|‚ñà‚ñä        | 1061/5674 [02:12<01:36, 47.84it/s] 19%|‚ñà‚ñâ        | 1069/5674 [02:12<01:23, 55.20it/s] 19%|‚ñà‚ñâ        | 1075/5674 [02:12<01:24, 54.45it/s] 19%|‚ñà‚ñâ        | 1081/5674 [02:12<01:30, 50.87it/s] 19%|‚ñà‚ñâ        | 1090/5674 [02:12<01:23, 55.11it/s] 19%|‚ñà‚ñâ        | 1096/5674 [02:12<01:30, 50.62it/s] 19%|‚ñà‚ñâ        | 1102/5674 [02:13<01:43, 44.39it/s] 20%|‚ñà‚ñâ        | 1107/5674 [02:13<02:02, 37.31it/s] 20%|‚ñà‚ñâ        | 1115/5674 [02:13<01:39, 45.93it/s] 20%|‚ñà‚ñâ        | 1122/5674 [02:13<01:29, 50.79it/s] 20%|‚ñà‚ñâ        | 1129/5674 [02:13<01:22, 55.38it/s] 20%|‚ñà‚ñà        | 1138/5674 [02:13<01:12, 62.38it/s] 20%|‚ñà‚ñà        | 1146/5674 [02:13<01:12, 62.72it/s] 20%|‚ñà‚ñà        | 1160/5674 [02:13<01:03, 71.41it/s] 21%|‚ñà‚ñà        | 1180/5674 [02:14<00:43, 102.21it/s] 21%|‚ñà‚ñà        | 1180/5674 [02:37<00:43, 102.21it/s] 21%|‚ñà‚ñà        | 1195/5674 [02:37<39:21,  1.90it/s]  21%|‚ñà‚ñà        | 1205/5674 [02:37<29:57,  2.49it/s] 22%|‚ñà‚ñà‚ñè       | 1222/5674 [02:37<18:57,  3.91it/s] 22%|‚ñà‚ñà‚ñè       | 1235/5674 [02:37<13:37,  5.43it/s] 22%|‚ñà‚ñà‚ñè       | 1248/5674 [02:37<09:51,  7.48it/s] 22%|‚ñà‚ñà‚ñè       | 1268/5674 [02:37<06:08, 11.97it/s] 23%|‚ñà‚ñà‚ñé       | 1284/5674 [02:37<04:22, 16.73it/s] 23%|‚ñà‚ñà‚ñé       | 1298/5674 [02:38<03:19, 21.93it/s] 23%|‚ñà‚ñà‚ñé       | 1312/5674 [02:38<02:31, 28.71it/s] 23%|‚ñà‚ñà‚ñé       | 1326/5674 [02:38<02:03, 35.12it/s] 24%|‚ñà‚ñà‚ñé       | 1338/5674 [02:38<01:45, 41.26it/s] 24%|‚ñà‚ñà‚ñç       | 1352/5674 [02:38<01:25, 50.79it/s] 24%|‚ñà‚ñà‚ñç       | 1364/5674 [02:38<01:15, 57.06it/s] 24%|‚ñà‚ñà‚ñç       | 1374/5674 [02:38<01:15, 56.67it/s] 24%|‚ñà‚ñà‚ñç       | 1383/5674 [02:39<01:31, 46.80it/s] 24%|‚ñà‚ñà‚ñç       | 1390/5674 [02:39<01:35, 44.80it/s] 25%|‚ñà‚ñà‚ñç       | 1397/5674 [02:39<01:29, 47.97it/s] 25%|‚ñà‚ñà‚ñç       | 1404/5674 [02:39<01:28, 48.44it/s] 25%|‚ñà‚ñà‚ñç       | 1410/5674 [02:39<01:35, 44.72it/s] 25%|‚ñà‚ñà‚ñç       | 1416/5674 [02:39<01:36, 44.08it/s] 25%|‚ñà‚ñà‚ñå       | 1423/5674 [02:40<01:27, 48.84it/s] 25%|‚ñà‚ñà‚ñå       | 1429/5674 [02:40<01:53, 37.49it/s] 25%|‚ñà‚ñà‚ñå       | 1434/5674 [02:40<01:54, 37.15it/s] 25%|‚ñà‚ñà‚ñå       | 1442/5674 [02:40<01:39, 42.34it/s] 26%|‚ñà‚ñà‚ñå       | 1452/5674 [02:40<01:24, 50.11it/s] 26%|‚ñà‚ñà‚ñå       | 1460/5674 [02:40<01:15, 55.94it/s] 26%|‚ñà‚ñà‚ñå       | 1467/5674 [02:41<01:19, 53.03it/s] 26%|‚ñà‚ñà‚ñå       | 1473/5674 [02:41<01:21, 51.67it/s] 26%|‚ñà‚ñà‚ñå       | 1479/5674 [02:41<01:21, 51.31it/s] 26%|‚ñà‚ñà‚ñå       | 1487/5674 [02:41<01:14, 56.25it/s] 26%|‚ñà‚ñà‚ñã       | 1493/5674 [02:41<01:29, 46.62it/s] 26%|‚ñà‚ñà‚ñã       | 1498/5674 [02:41<01:30, 46.05it/s] 26%|‚ñà‚ñà‚ñã       | 1503/5674 [02:41<01:41, 41.28it/s] 27%|‚ñà‚ñà‚ñã       | 1510/5674 [02:41<01:36, 43.10it/s] 27%|‚ñà‚ñà‚ñã       | 1515/5674 [02:42<01:43, 40.04it/s] 27%|‚ñà‚ñà‚ñã       | 1520/5674 [02:42<01:47, 38.67it/s] 27%|‚ñà‚ñà‚ñã       | 1524/5674 [02:42<02:09, 32.11it/s] 27%|‚ñà‚ñà‚ñã       | 1530/5674 [02:42<02:15, 30.51it/s] 27%|‚ñà‚ñà‚ñã       | 1538/5674 [02:42<01:46, 38.75it/s] 27%|‚ñà‚ñà‚ñã       | 1543/5674 [02:42<01:54, 35.98it/s] 27%|‚ñà‚ñà‚ñã       | 1552/5674 [02:43<01:28, 46.36it/s] 27%|‚ñà‚ñà‚ñã       | 1558/5674 [02:43<01:47, 38.42it/s] 27%|‚ñà‚ñà‚ñã       | 1558/5674 [03:09<01:47, 38.42it/s] 28%|‚ñà‚ñà‚ñä       | 1562/5674 [03:09<1:35:50,  1.40s/it] 28%|‚ñà‚ñà‚ñä       | 1565/5674 [03:09<1:18:51,  1.15s/it] 28%|‚ñà‚ñà‚ñä       | 1569/5674 [03:10<1:00:35,  1.13it/s] 28%|‚ñà‚ñà‚ñä       | 1572/5674 [03:10<47:59,  1.42it/s]   28%|‚ñà‚ñà‚ñä       | 1577/5674 [03:10<32:09,  2.12it/s] 28%|‚ñà‚ñà‚ñä       | 1582/5674 [03:10<22:15,  3.06it/s] 28%|‚ñà‚ñà‚ñä       | 1586/5674 [03:10<16:41,  4.08it/s] 28%|‚ñà‚ñà‚ñä       | 1591/5674 [03:11<11:51,  5.74it/s] 28%|‚ñà‚ñà‚ñä       | 1595/5674 [03:11<09:18,  7.31it/s] 28%|‚ñà‚ñà‚ñä       | 1599/5674 [03:11<07:14,  9.37it/s] 28%|‚ñà‚ñà‚ñä       | 1603/5674 [03:11<05:44, 11.82it/s] 28%|‚ñà‚ñà‚ñä       | 1610/5674 [03:11<03:45, 18.05it/s] 28%|‚ñà‚ñà‚ñä       | 1615/5674 [03:11<03:32, 19.11it/s] 29%|‚ñà‚ñà‚ñä       | 1621/5674 [03:11<02:44, 24.57it/s] 29%|‚ñà‚ñà‚ñä       | 1626/5674 [03:12<02:57, 22.81it/s] 29%|‚ñà‚ñà‚ñä       | 1630/5674 [03:12<02:43, 24.74it/s] 29%|‚ñà‚ñà‚ñâ       | 1634/5674 [03:12<02:30, 26.81it/s] 29%|‚ñà‚ñà‚ñâ       | 1641/5674 [03:12<02:05, 32.09it/s] 29%|‚ñà‚ñà‚ñâ       | 1648/5674 [03:12<01:41, 39.70it/s] 29%|‚ñà‚ñà‚ñâ       | 1653/5674 [03:12<01:42, 39.27it/s] 29%|‚ñà‚ñà‚ñâ       | 1658/5674 [03:12<01:42, 39.20it/s] 29%|‚ñà‚ñà‚ñâ       | 1665/5674 [03:13<01:30, 44.20it/s] 29%|‚ñà‚ñà‚ñâ       | 1670/5674 [03:13<01:49, 36.55it/s] 30%|‚ñà‚ñà‚ñâ       | 1675/5674 [03:13<01:45, 37.77it/s] 30%|‚ñà‚ñà‚ñâ       | 1680/5674 [03:13<01:55, 34.54it/s] 30%|‚ñà‚ñà‚ñâ       | 1686/5674 [03:13<01:41, 39.37it/s] 30%|‚ñà‚ñà‚ñâ       | 1691/5674 [03:13<01:42, 38.80it/s] 30%|‚ñà‚ñà‚ñâ       | 1696/5674 [03:13<01:48, 36.61it/s] 30%|‚ñà‚ñà‚ñà       | 1706/5674 [03:14<01:24, 47.17it/s] 30%|‚ñà‚ñà‚ñà       | 1711/5674 [03:14<01:42, 38.62it/s] 30%|‚ñà‚ñà‚ñà       | 1716/5674 [03:14<01:51, 35.58it/s] 30%|‚ñà‚ñà‚ñà       | 1722/5674 [03:14<01:39, 39.80it/s] 31%|‚ñà‚ñà‚ñà       | 1731/5674 [03:14<01:44, 37.70it/s] 31%|‚ñà‚ñà‚ñà       | 1736/5674 [03:14<01:49, 36.05it/s] 31%|‚ñà‚ñà‚ñà       | 1741/5674 [03:15<01:45, 37.28it/s] 31%|‚ñà‚ñà‚ñà       | 1752/5674 [03:15<01:16, 51.57it/s] 31%|‚ñà‚ñà‚ñà       | 1761/5674 [03:15<01:05, 60.14it/s] 31%|‚ñà‚ñà‚ñà       | 1770/5674 [03:15<00:59, 65.18it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1780/5674 [03:15<00:53, 73.47it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1795/5674 [03:15<00:42, 92.27it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1805/5674 [03:15<00:43, 88.77it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1815/5674 [03:15<00:44, 87.43it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1824/5674 [03:15<00:49, 78.03it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1833/5674 [03:16<00:53, 71.37it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1842/5674 [03:16<00:52, 73.11it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1850/5674 [03:16<00:57, 66.63it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1858/5674 [03:16<00:56, 67.95it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1869/5674 [03:16<00:51, 74.14it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1877/5674 [03:16<00:58, 64.84it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1886/5674 [03:16<00:56, 67.13it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1893/5674 [03:17<01:06, 56.83it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1901/5674 [03:17<01:02, 60.29it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1901/5674 [03:51<01:02, 60.29it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1902/5674 [03:51<1:45:54,  1.68s/it] 34%|‚ñà‚ñà‚ñà‚ñé      | 1905/5674 [03:51<1:27:47,  1.40s/it] 34%|‚ñà‚ñà‚ñà‚ñé      | 1913/5674 [03:51<52:57,  1.18it/s]   34%|‚ñà‚ñà‚ñà‚ñç      | 1920/5674 [03:51<35:36,  1.76it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1932/5674 [03:51<19:48,  3.15it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1942/5674 [03:51<13:07,  4.74it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1950/5674 [03:51<09:40,  6.41it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1958/5674 [03:51<07:09,  8.64it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1968/5674 [03:52<04:56, 12.51it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1980/5674 [03:52<03:19, 18.54it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1991/5674 [03:52<02:25, 25.24it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 2000/5674 [03:52<01:57, 31.20it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 2009/5674 [03:52<01:40, 36.35it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 2018/5674 [03:52<01:29, 40.85it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 2026/5674 [03:52<01:17, 46.98it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 2034/5674 [03:52<01:12, 50.18it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 2042/5674 [03:53<01:11, 50.61it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 2050/5674 [03:53<01:04, 55.87it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 2057/5674 [03:53<01:02, 58.04it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 2065/5674 [03:53<01:02, 57.43it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 2072/5674 [03:53<01:08, 52.39it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 2079/5674 [03:53<01:04, 56.06it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 2086/5674 [03:53<01:23, 43.08it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 2093/5674 [03:54<01:20, 44.73it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 2099/5674 [03:54<01:19, 44.81it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 2104/5674 [03:54<01:22, 43.18it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 2117/5674 [03:54<00:56, 62.78it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 2125/5674 [03:54<00:55, 64.21it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 2133/5674 [03:54<01:00, 58.49it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 2142/5674 [03:54<00:54, 65.01it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 2154/5674 [03:54<00:45, 76.75it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 2165/5674 [03:55<00:41, 84.82it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 2174/5674 [03:55<00:48, 71.54it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 2182/5674 [03:55<00:49, 70.04it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 2190/5674 [03:55<01:18, 44.21it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 2196/5674 [03:55<01:17, 45.12it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 2202/5674 [03:56<01:25, 40.49it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 2211/5674 [03:56<01:10, 49.21it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 2217/5674 [03:56<01:34, 36.50it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 2222/5674 [03:56<01:42, 33.59it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 2227/5674 [03:56<01:37, 35.21it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 2232/5674 [03:56<01:38, 34.83it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 2236/5674 [03:57<01:49, 31.49it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 2240/5674 [03:57<02:12, 25.95it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 2243/5674 [03:57<02:23, 23.84it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 2248/5674 [03:57<02:11, 26.10it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 2257/5674 [03:57<01:28, 38.56it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 2266/5674 [03:57<01:13, 46.30it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 2274/5674 [03:57<01:06, 51.01it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 2280/5674 [03:58<01:06, 51.19it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 2288/5674 [03:58<00:58, 57.60it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 2295/5674 [03:58<00:57, 58.70it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 2303/5674 [03:58<00:57, 58.18it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 2311/5674 [03:58<00:54, 61.85it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 2319/5674 [03:58<00:52, 63.61it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 2326/5674 [03:58<01:00, 55.43it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 2334/5674 [03:58<00:56, 59.41it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2341/5674 [03:59<01:00, 55.02it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2347/5674 [03:59<01:20, 41.33it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2352/5674 [03:59<01:25, 39.02it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2362/5674 [03:59<01:10, 46.66it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2368/5674 [03:59<01:11, 46.21it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2377/5674 [03:59<01:07, 48.55it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2386/5674 [04:00<00:57, 57.14it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2386/5674 [04:40<00:57, 57.14it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2387/5674 [04:40<1:52:38,  2.06s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2389/5674 [04:40<1:38:52,  1.81s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2398/5674 [04:40<54:56,  1.01s/it]   42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2403/5674 [04:40<41:02,  1.33it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2409/5674 [04:41<28:53,  1.88it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2425/5674 [04:41<13:22,  4.05it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2433/5674 [04:41<09:56,  5.43it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2444/5674 [04:41<06:37,  8.12it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2451/5674 [04:41<05:14, 10.25it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2458/5674 [04:41<04:13, 12.69it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2466/5674 [04:42<03:22, 15.81it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2473/5674 [04:42<02:41, 19.86it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2481/5674 [04:42<02:05, 25.40it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2487/5674 [04:42<01:48, 29.38it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2493/5674 [04:42<01:37, 32.47it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2499/5674 [04:42<01:38, 32.34it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2506/5674 [04:42<01:24, 37.29it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2512/5674 [04:43<01:32, 34.24it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2518/5674 [04:43<01:21, 38.53it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2523/5674 [04:43<01:18, 40.16it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2528/5674 [04:43<01:29, 34.96it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2533/5674 [04:43<01:27, 36.04it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2540/5674 [04:43<01:12, 43.51it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2545/5674 [04:43<01:13, 42.53it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2550/5674 [04:43<01:12, 43.28it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2555/5674 [04:44<01:13, 42.45it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2562/5674 [04:44<01:04, 48.44it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2568/5674 [04:44<01:14, 41.86it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2575/5674 [04:44<01:04, 48.39it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2581/5674 [04:44<01:07, 46.09it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2586/5674 [04:44<01:23, 36.87it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2591/5674 [04:45<01:43, 29.87it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2596/5674 [04:45<01:37, 31.53it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2600/5674 [04:45<01:41, 30.34it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2604/5674 [04:45<01:48, 28.34it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2614/5674 [04:45<01:22, 37.10it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2620/5674 [04:45<01:16, 40.06it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2629/5674 [04:45<01:03, 47.62it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2638/5674 [04:46<00:54, 55.96it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2644/5674 [04:46<00:55, 54.13it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2650/5674 [04:46<01:08, 44.18it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2657/5674 [04:46<01:00, 49.59it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2664/5674 [04:46<01:00, 49.76it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2672/5674 [04:46<00:53, 56.48it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2679/5674 [04:46<00:59, 49.98it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2685/5674 [04:47<01:00, 49.01it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2691/5674 [04:47<01:00, 49.28it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2699/5674 [04:47<00:52, 56.47it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2706/5674 [04:47<00:49, 59.77it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2716/5674 [04:47<00:42, 68.88it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2724/5674 [04:47<00:41, 70.68it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2732/5674 [04:47<00:45, 64.33it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2739/5674 [04:47<00:48, 59.96it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2746/5674 [04:48<01:02, 46.67it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2752/5674 [04:48<01:12, 40.58it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2757/5674 [04:48<01:29, 32.71it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2761/5674 [04:48<01:39, 29.18it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2767/5674 [04:48<01:24, 34.56it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2772/5674 [04:48<01:23, 34.91it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2777/5674 [04:49<01:18, 37.06it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2785/5674 [04:49<01:01, 46.63it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2793/5674 [04:49<00:54, 53.21it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2799/5674 [04:49<00:59, 48.58it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2805/5674 [04:49<01:06, 43.44it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2811/5674 [04:49<01:02, 46.02it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2816/5674 [04:49<01:10, 40.52it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2825/5674 [04:50<00:55, 51.13it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2834/5674 [04:50<00:50, 56.75it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2841/5674 [04:50<00:48, 58.21it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2852/5674 [04:50<00:41, 68.82it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2860/5674 [04:50<00:40, 70.33it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2868/5674 [04:50<00:49, 57.20it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2877/5674 [04:50<00:48, 57.19it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2884/5674 [04:51<00:56, 49.19it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2890/5674 [04:51<00:56, 49.21it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2897/5674 [04:51<00:52, 52.42it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2897/5674 [05:41<00:52, 52.42it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2902/5674 [05:41<1:45:56,  2.29s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2903/5674 [05:41<1:39:44,  2.16s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2908/5674 [05:41<1:09:41,  1.51s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2913/5674 [05:41<49:00,  1.06s/it]   51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2920/5674 [05:41<30:42,  1.49it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2925/5674 [05:42<22:27,  2.04it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2931/5674 [05:42<15:31,  2.95it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2936/5674 [05:42<11:27,  3.98it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2941/5674 [05:42<08:28,  5.37it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2948/5674 [05:42<05:37,  8.07it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2955/5674 [05:42<03:56, 11.51it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2961/5674 [05:42<03:12, 14.07it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2967/5674 [05:42<02:34, 17.55it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2972/5674 [05:43<02:08, 21.10it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2978/5674 [05:43<01:47, 24.97it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2984/5674 [05:43<01:35, 28.15it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2989/5674 [05:43<01:35, 28.16it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2993/5674 [05:43<01:31, 29.21it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3002/5674 [05:43<01:08, 38.88it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3009/5674 [05:43<01:01, 43.52it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3015/5674 [05:44<01:08, 39.09it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3020/5674 [05:44<01:16, 34.47it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3024/5674 [05:44<01:22, 32.11it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3031/5674 [05:44<01:10, 37.57it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3036/5674 [05:44<01:05, 40.06it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3043/5674 [05:44<00:57, 45.55it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3048/5674 [05:44<01:03, 41.20it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3053/5674 [05:45<01:04, 40.41it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3063/5674 [05:45<00:49, 52.45it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3069/5674 [05:45<00:54, 47.71it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3078/5674 [05:45<00:45, 56.88it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3085/5674 [05:45<00:46, 56.24it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3091/5674 [05:45<00:47, 54.45it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3097/5674 [05:45<00:52, 49.40it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3103/5674 [05:45<00:50, 50.69it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3109/5674 [05:46<00:54, 47.13it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3114/5674 [05:46<01:06, 38.66it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3121/5674 [05:46<00:57, 44.37it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3126/5674 [05:46<01:02, 40.49it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3134/5674 [05:46<00:52, 48.75it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3140/5674 [05:46<00:50, 50.62it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3146/5674 [05:46<00:49, 51.18it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3152/5674 [05:47<00:57, 44.21it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3157/5674 [05:47<00:59, 42.65it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3162/5674 [05:47<00:56, 44.31it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3168/5674 [05:47<00:54, 45.71it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3174/5674 [05:47<00:54, 45.55it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3180/5674 [05:47<00:51, 48.55it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3185/5674 [05:47<00:55, 44.78it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3190/5674 [05:47<00:58, 42.36it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3204/5674 [05:48<00:37, 66.49it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3213/5674 [05:48<00:36, 67.53it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3221/5674 [05:48<00:35, 68.90it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3230/5674 [05:48<00:35, 68.59it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3240/5674 [05:48<00:34, 69.91it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3251/5674 [05:48<00:30, 79.63it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3262/5674 [05:48<00:27, 87.50it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3272/5674 [05:48<00:29, 80.86it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3281/5674 [05:48<00:30, 77.98it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3290/5674 [05:49<00:31, 74.80it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3298/5674 [05:49<00:36, 65.75it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3305/5674 [05:49<00:38, 61.89it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3315/5674 [05:49<00:34, 68.50it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3324/5674 [05:49<00:32, 71.34it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3332/5674 [05:50<01:02, 37.21it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3338/5674 [05:50<01:13, 31.63it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3343/5674 [05:50<01:08, 34.19it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3349/5674 [05:50<01:00, 38.36it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3356/5674 [05:50<00:52, 44.37it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3362/5674 [05:50<01:06, 34.67it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3369/5674 [05:51<01:09, 33.26it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3376/5674 [05:51<00:58, 39.14it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3382/5674 [05:51<00:52, 43.25it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3388/5674 [05:51<01:18, 29.30it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3393/5674 [05:52<01:21, 27.87it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3400/5674 [05:52<01:05, 34.52it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3408/5674 [05:52<00:54, 41.71it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3414/5674 [05:52<00:49, 45.31it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3420/5674 [05:52<01:30, 24.94it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3425/5674 [05:52<01:20, 28.01it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3433/5674 [05:53<01:01, 36.66it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3439/5674 [05:53<01:00, 36.70it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3444/5674 [05:53<01:09, 32.17it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3449/5674 [05:53<01:04, 34.73it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3456/5674 [05:53<00:54, 40.90it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3463/5674 [05:53<00:49, 45.06it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3472/5674 [05:53<00:40, 54.63it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3484/5674 [05:54<00:32, 68.36it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3492/5674 [05:54<00:38, 56.41it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3501/5674 [05:54<00:34, 63.79it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3511/5674 [05:54<00:30, 71.30it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3511/5674 [06:57<00:30, 71.30it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3517/5674 [06:57<1:23:45,  2.33s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3521/5674 [06:57<1:09:11,  1.93s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3528/5674 [06:57<48:32,  1.36s/it]   62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3534/5674 [06:57<35:33,  1.00it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3539/5674 [06:57<27:03,  1.32it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3544/5674 [06:58<20:15,  1.75it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3550/5674 [06:58<14:27,  2.45it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3567/5674 [06:58<06:30,  5.39it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3575/5674 [06:58<05:02,  6.94it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3585/5674 [06:58<03:30,  9.92it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3595/5674 [06:58<02:29, 13.89it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3603/5674 [06:59<02:02, 16.93it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3610/5674 [06:59<01:40, 20.58it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3617/5674 [06:59<01:23, 24.52it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3624/5674 [06:59<01:19, 25.88it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3630/5674 [06:59<01:13, 27.70it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3639/5674 [06:59<00:56, 36.02it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3645/5674 [06:59<00:56, 35.76it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3651/5674 [07:00<00:51, 39.58it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3659/5674 [07:00<00:43, 46.84it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3665/5674 [07:00<00:45, 44.50it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3671/5674 [07:00<00:47, 42.20it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3676/5674 [07:00<00:46, 43.05it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3681/5674 [07:00<00:50, 39.76it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3686/5674 [07:00<00:49, 40.08it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3692/5674 [07:01<00:47, 42.05it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3697/5674 [07:01<00:47, 41.51it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3704/5674 [07:01<00:41, 47.20it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3711/5674 [07:01<00:39, 50.32it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3720/5674 [07:01<00:33, 58.97it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3727/5674 [07:01<00:35, 54.68it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3736/5674 [07:01<00:31, 62.24it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3743/5674 [07:01<00:31, 62.14it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3751/5674 [07:01<00:29, 65.79it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3762/5674 [07:02<00:26, 72.17it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3770/5674 [07:02<00:28, 66.95it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3777/5674 [07:02<00:35, 53.56it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3785/5674 [07:02<00:32, 58.35it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3795/5674 [07:02<00:27, 68.16it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3803/5674 [07:02<00:29, 63.02it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3814/5674 [07:02<00:25, 72.91it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3822/5674 [07:03<00:27, 66.88it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3830/5674 [07:03<00:29, 62.72it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3840/5674 [07:03<00:28, 63.26it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3851/5674 [07:03<00:24, 73.62it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3863/5674 [07:03<00:21, 83.80it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3872/5674 [07:03<00:23, 75.69it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3882/5674 [07:03<00:22, 78.83it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3891/5674 [07:03<00:23, 77.47it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3900/5674 [07:04<00:22, 80.29it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3909/5674 [07:04<00:24, 73.54it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3917/5674 [07:04<00:24, 71.69it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3925/5674 [07:04<00:29, 60.25it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3932/5674 [07:04<00:32, 53.63it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3938/5674 [07:04<00:31, 54.76it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3944/5674 [07:04<00:32, 52.43it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3950/5674 [07:05<00:34, 50.64it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3956/5674 [07:05<00:40, 42.53it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3962/5674 [07:05<00:38, 43.96it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3968/5674 [07:05<00:38, 43.85it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 3978/5674 [07:05<00:30, 55.04it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 3989/5674 [07:05<00:25, 66.49it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 3997/5674 [07:05<00:25, 66.89it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 4004/5674 [07:05<00:25, 64.53it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 4011/5674 [07:06<00:25, 64.37it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 4018/5674 [07:06<00:28, 58.78it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 4025/5674 [07:06<00:32, 51.08it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 4031/5674 [07:06<00:33, 48.80it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 4041/5674 [07:06<00:37, 43.15it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4049/5674 [07:07<00:37, 43.12it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4058/5674 [07:07<00:34, 47.52it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4067/5674 [07:07<00:28, 55.80it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4074/5674 [07:07<00:28, 57.04it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4081/5674 [07:07<00:28, 55.59it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4087/5674 [07:07<00:30, 52.43it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4096/5674 [07:07<00:27, 58.39it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4103/5674 [07:07<00:26, 60.39it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4110/5674 [07:07<00:26, 58.49it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4116/5674 [07:08<00:26, 58.19it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4122/5674 [07:08<00:26, 58.22it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4130/5674 [07:08<00:24, 63.50it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4137/5674 [07:08<00:27, 55.04it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4146/5674 [07:08<00:24, 62.80it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4153/5674 [07:08<00:26, 58.46it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4160/5674 [07:08<00:25, 58.92it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4167/5674 [07:08<00:25, 59.81it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4174/5674 [07:09<00:34, 42.94it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4180/5674 [07:09<00:35, 42.59it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4188/5674 [07:09<00:30, 48.70it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4198/5674 [07:09<00:25, 57.99it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4205/5674 [07:09<00:26, 55.35it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4215/5674 [07:09<00:22, 65.27it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4225/5674 [07:09<00:19, 73.77it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4236/5674 [07:10<00:18, 77.51it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4245/5674 [07:10<00:23, 59.86it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4252/5674 [07:10<00:30, 46.52it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4258/5674 [07:10<00:35, 39.84it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4263/5674 [07:10<00:34, 41.18it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4269/5674 [07:11<00:32, 43.57it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4274/5674 [07:11<00:32, 43.53it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4283/5674 [07:11<00:26, 53.47it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4289/5674 [07:11<00:26, 51.80it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4295/5674 [07:11<00:29, 47.14it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4300/5674 [07:11<00:34, 39.40it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4305/5674 [07:11<00:32, 41.62it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4311/5674 [07:11<00:31, 43.26it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4318/5674 [07:12<00:27, 49.70it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4324/5674 [07:12<00:31, 43.46it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4330/5674 [07:12<00:29, 45.39it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4338/5674 [07:12<00:27, 48.83it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4352/5674 [07:12<00:19, 68.15it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4370/5674 [07:12<00:14, 90.52it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4380/5674 [07:12<00:14, 88.03it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4390/5674 [07:12<00:16, 79.57it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4401/5674 [07:13<00:15, 82.28it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4401/5674 [08:27<00:15, 82.28it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4402/5674 [08:27<1:00:31,  2.86s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4405/5674 [08:28<52:02,  2.46s/it]   78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4412/5674 [08:28<35:23,  1.68s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4419/5674 [08:28<24:18,  1.16s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4426/5674 [08:28<16:51,  1.23it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4432/5674 [08:28<12:25,  1.67it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4443/5674 [08:28<07:15,  2.83it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4453/5674 [08:28<04:44,  4.29it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4468/5674 [08:29<02:44,  7.34it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4490/5674 [08:29<01:27, 13.54it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4503/5674 [08:29<01:05, 17.96it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4518/5674 [08:29<00:46, 24.60it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4536/5674 [08:29<00:32, 35.40it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4560/5674 [08:29<00:20, 53.88it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4577/5674 [08:29<00:16, 65.43it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4599/5674 [08:29<00:12, 85.80it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4617/5674 [08:30<00:12, 87.41it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4632/5674 [08:30<00:12, 85.79it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4654/5674 [08:30<00:09, 106.18it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4670/5674 [08:30<00:08, 116.37it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4686/5674 [08:30<00:11, 89.45it/s]  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4699/5674 [08:30<00:11, 83.37it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4710/5674 [08:31<00:12, 78.53it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4720/5674 [08:31<00:14, 67.96it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4730/5674 [08:31<00:15, 60.89it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4747/5674 [08:31<00:12, 72.39it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4761/5674 [08:31<00:11, 81.02it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4770/5674 [08:31<00:11, 78.32it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4779/5674 [08:32<00:12, 73.70it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4791/5674 [08:32<00:11, 76.87it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4799/5674 [08:32<00:12, 72.12it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4811/5674 [08:32<00:13, 65.74it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4826/5674 [08:32<00:14, 58.45it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4833/5674 [08:33<00:14, 58.34it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4840/5674 [08:33<00:14, 58.74it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4847/5674 [08:33<00:13, 60.01it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4858/5674 [08:33<00:11, 69.63it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4868/5674 [08:33<00:10, 73.41it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4887/5674 [08:33<00:07, 101.48it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 4904/5674 [08:33<00:06, 118.62it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 4926/5674 [08:33<00:05, 144.30it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 4943/5674 [08:33<00:04, 146.84it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 4959/5674 [08:33<00:04, 145.16it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 4974/5674 [08:34<00:04, 142.72it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 4989/5674 [08:34<00:05, 124.62it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 5003/5674 [08:34<00:05, 122.00it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 5016/5674 [08:34<00:05, 117.23it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 5028/5674 [08:34<00:05, 111.16it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5040/5674 [08:34<00:06, 100.33it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5051/5674 [08:34<00:06, 95.35it/s]  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5061/5674 [08:35<00:06, 95.49it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5072/5674 [08:35<00:06, 98.02it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5083/5674 [08:35<00:06, 90.60it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5093/5674 [08:35<00:06, 92.44it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5103/5674 [08:35<00:06, 90.57it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 5118/5674 [08:35<00:05, 105.88it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 5129/5674 [08:35<00:05, 105.73it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 5140/5674 [08:35<00:05, 96.69it/s]  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 5150/5674 [08:36<00:06, 77.17it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 5162/5674 [08:36<00:05, 85.60it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 5172/5674 [08:36<00:05, 87.73it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5182/5674 [08:36<00:07, 66.38it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5190/5674 [08:36<00:07, 65.72it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5200/5674 [08:36<00:06, 73.02it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5209/5674 [08:36<00:07, 65.45it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5221/5674 [08:36<00:06, 75.45it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5230/5674 [08:37<00:05, 75.33it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5238/5674 [08:37<00:05, 75.22it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5246/5674 [08:37<00:05, 74.83it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5255/5674 [08:37<00:05, 78.79it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5266/5674 [08:37<00:04, 87.13it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5282/5674 [08:37<00:03, 106.73it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5297/5674 [08:37<00:03, 116.81it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5309/5674 [08:37<00:03, 113.30it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5321/5674 [08:38<00:05, 64.26it/s]  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5330/5674 [08:38<00:05, 64.19it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5343/5674 [08:38<00:04, 75.78it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5356/5674 [08:38<00:04, 76.51it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5369/5674 [08:38<00:03, 87.43it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5380/5674 [08:38<00:03, 88.60it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5395/5674 [08:38<00:02, 102.83it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5414/5674 [08:39<00:02, 120.73it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5427/5674 [08:39<00:02, 119.82it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5440/5674 [08:39<00:01, 120.97it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5453/5674 [08:39<00:01, 111.83it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5466/5674 [08:39<00:01, 116.12it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5481/5674 [08:39<00:01, 115.65it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5493/5674 [08:39<00:01, 96.43it/s]  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5510/5674 [08:39<00:01, 113.81it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5525/5674 [08:40<00:01, 121.44it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5540/5674 [08:40<00:01, 128.18it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5560/5674 [08:40<00:00, 146.10it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5581/5674 [08:40<00:00, 161.25it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5598/5674 [08:40<00:00, 140.50it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5613/5674 [08:40<00:00, 106.53it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5626/5674 [08:40<00:00, 111.31it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5649/5674 [08:41<00:00, 130.07it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5664/5674 [08:41<00:00, 78.09it/s] 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5674/5674 [08:41<00:00, 10.87it/s]
2026-01-11 16:26:54.404 | INFO     | lean_reinforcement.training.trainer:_start_workers:202 - Starting 16 workers
2026-01-11 16:37:16.991 | INFO     | lean_reinforcement.training.trainer:_run_epoch:152 - Starting Epoch 1/32
2026-01-11 16:37:17.089 | INFO     | lean_reinforcement.training.trainer:_run_epoch:163 - Processing 128 theorems with 16 workers.
2026-01-11 16:37:25.132 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Units.ext_iff
2026-01-11 16:37:27.079 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: toDual_min
2026-01-11 16:37:27.665 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: InfHom.bot_apply
2026-01-11 16:37:28.576 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: NNRat.coe_min
2026-01-11 16:37:28.910 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Set.infinite_smul_set
2026-01-11 16:37:29.039 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Filter.EventuallyEq.of_mulIndicator
2026-01-11 16:37:29.198 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Multiset.eq_zero_iff_forall_not_mem
2026-01-11 16:37:29.527 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Vector.get_set_of_ne
2026-01-11 16:37:31.618 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:37:34.711 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:37:35.041 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:37:36.011 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:37:36.080 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: CategoryTheory.PreGaloisCategory.isIso_of_mono_of_eq_card_fiber
2026-01-11 16:37:36.504 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:37:36.912 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:37:36.937 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:37:37.004 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:37:38.331 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: linearIndependent_iff_injective_total
2026-01-11 16:37:38.557 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: MeasureTheory.iUnion_spanningSets
2026-01-11 16:37:38.930 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Algebra.adjoin.powerBasis'_gen
2026-01-11 16:37:40.444 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: QuotSMulTop.equivTensorQuot_naturality_mk
2026-01-11 16:37:41.326 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:37:43.684 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: ProbabilityTheory.kernel.measurable_compProdFun_of_finite
2026-01-11 16:37:44.565 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:37:44.854 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:37:45.372 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:37:46.215 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:37:48.603 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:37:48.841 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [‚Üê Units.eq_iff, Units.val_inv_eq_iff, Units.val_inv_eq_iff]
2026-01-11 16:37:48.923 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.14248\nŒ± : Type u\ninst‚úù : Monoid Œ±\na b : Œ±À£\n‚ä¢ ‚Üëa = ‚Üëb ‚Üî ‚Üëa = ‚Üëb")
2026-01-11 16:37:48.923 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 23.79s.
2026-01-11 16:37:48.923 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.14248\nŒ± : Type u\ninst‚úù : Monoid Œ±\na b : Œ±À£\n‚ä¢ ‚Üëa = ‚Üëb ‚Üî ‚Üëa = ‚Üëb")
2026-01-11 16:37:49.054 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:37:49.055 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:37:53.877 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: RingHom.coe_mul
2026-01-11 16:37:58.542 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:38:19.848 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Ordinal.omega_pos
2026-01-11 16:38:20.116 | ERROR    | lean_reinforcement.utilities.gym:reset:41 - Error during environment reset: Timeout during initialization
2026-01-11 16:38:20.123 | ERROR    | lean_reinforcement.training.worker:process_theorem:44 - Failed to initialize environment for theorem IntermediateField.fg_adjoin_finset: Timeout during initialization
2026-01-11 16:38:20.293 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:38:22.761 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Multiset.le_iff_subset
2026-01-11 16:38:24.890 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:38:27.407 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:41:01.337 | WARNING  | lean_reinforcement.training.inference_server:_run_transformer_batch:150 - OOM encountered. Reducing max safe batch size to 28
2026-01-11 16:43:57.521 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simpa [mulIndicator_ae_eq_mulIndicator_neg] using h.mulIndicator_ae_eq_mulIndicator_ae_eq_mulIndicator_ae_eq_mulIndicator_ae_eq_mulIndicator
  h.mulIndicator_ae_eq_mulIndicator_ae_eq_mulIndicator_ae_eq_mulIndicator_ae_eq_mulIndicator_ae_eq_mulIndicator_ae_eq_mulIndicator
  h.mulIndicator_ae_eq_mulIndicator_ae_eq_mulIndicator_ae_eq_mulIndicator_ae_eq_mulIndicator hf h] using
  h.mulIndicator_ae_eq_mulIndicator_ae_eq_mulIndicator_ae_eq_mulIndicator_ae_eq_mulIndicator_ae_eq_mulIndicator_ae_eq_mulIndicator
  h.mulIndicator_ae_eq_mulIndicator_ae_eq_mulIndicator_ae_eq_mulIndicator_ae_eq_mulIndicator_ae_eq_mulIndicator_ae_eq_mulIndicator
  h.mulIndicator_ae_eq_mulIndicator_ae_eq_mulIndicator_ae_eq_mulIndicator_ae_eq_mulIndicator
  h.mulIndicator_ae_eq_mulIndicator_ae_eq_mulIndicator_ae_eq_mulIndicator_ae_eq_mulIndicator_ae_eq_mulIndicator
  h.mulIndicator_ae_eq_mulIndicator_ae_eq_mulIndicator_ae_eq_mulIndicator_ae_eq_mulIndicator
  h.mulIndicator_ae_eq_mulIndicator_ae_eq_mulIndicator_ae_eq_mulIndicator_ae_eq_mulInd
2026-01-11 16:43:57.586 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='<stdin>:3:97: expected end of input')
2026-01-11 16:43:57.587 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 388.55s.
2026-01-11 16:43:57.587 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='<stdin>:3:97: expected end of input')
2026-01-11 16:43:57.720 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:43:57.721 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:43:57.756 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: refine ‚ü®fun h =>?_, Infinite.smul_left_of_infinite h‚ü©
2026-01-11 16:43:57.824 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="unknown constant 'Infinite.smul_left_of_infinite'")
2026-01-11 16:43:57.824 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 388.91s.
2026-01-11 16:43:57.824 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="unknown constant 'Infinite.smul_left_of_infinite'")
2026-01-11 16:43:57.957 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:43:57.957 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:43:58.075 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: induction v.length with
| nil => rfl
| cons _ _ ih =>
  simp only [get_set, tail_cons, cons_val_zero, cons_val_one]
| cons _ _ ih =>
  simp only [get_set, tail_cons, cons_val_one]
| cons _ _ ih =>
  simp only [get_set, tail_cons, cons_val_zero, cons_val_one]
| cons _ _ ih =>
  simp only [get_set, tail_cons, cons_val_one]
| cons _ _ ih =>
  simp only [get_set, tail_cons, cons_val_one]
| cons _ _ ih =>
  simp only [get_set, tail_cons, cons_val_zero, cons_val_one]
| cons _ _ ih =>
  simp only [get_set, tail_cons, cons_val_one]
| cons _ _ ih =>
  simp only [get_set, tail_cons, cons_val_one]
| cons _ _ ih =>
  simp only [get_set, tail_cons, cons_val_one]
| cons _ _ ih =>
  simp only [get_set, tail_cons, cons_val_one]
| cons _ _ ih =>
  simp only [get_set, tail_cons, cons_val_one]
| cons _ _ ih =>
  simp only [get_set, tail_cons, cons_val_one]
| cons _ _ ih =>
  simp only [get_set, tail_cons, cons_val_one]
| cons _ _ ih =>
  simp only [get_set, tail_cons, cons_val_one]
| cons _ _ ih =>
  simp only [get_set, tail_c
2026-01-11 16:43:58.145 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="<stdin>:32:28: unexpected end of input; expected ']'")
2026-01-11 16:43:58.145 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 388.62s.
2026-01-11 16:43:58.146 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="<stdin>:32:28: unexpected end of input; expected ']'")
2026-01-11 16:43:58.280 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:43:58.280 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:43:58.829 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp [SemilatticeInf.eq_bot_iff]
2026-01-11 16:43:58.899 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="unknown constant 'SemilatticeInf.eq_bot_iff'")
2026-01-11 16:43:58.899 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 391.23s.
2026-01-11 16:43:58.899 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="unknown constant 'SemilatticeInf.eq_bot_iff'")
2026-01-11 16:43:59.034 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:43:59.035 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:43:59.587 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [Rat.cast_def, Rat.cast_def, Rat.cast_def, Rat.cast_def, Rat.cast_def, Rat.cast_def,
  Int.cast_mul, Int.cast_mul, Int.cast_mul, Int.cast_mul, Int.cast_mul, Int.cast_natCast,
  Int.cast_mul, Int.cast_natCast, Int.cast_mul, Int.cast_natCast, Int.cast_natCast,
  Int.cast_mul, Int.cast_mul, Int.cast_mul, Int.cast_mul, Int.cast_natCast, Int.cast_natCast,
  Int.cast_mul, Int.cast_mul, Int.cast_mul, Int.cast_mul, Int.cast_natCast, Int.cast_natCast,
  Int.cast_mul, Int.cast_mul, Int.cast_mul, Int.cast_mul, Int.cast_natCast, Int.cast_natCast,
  Int.cast_mul, Int.cast_mul, Int.cast_mul, Int.cast_mul, Int.cast_natCast, Int.cast_natCast,
  Int.cast_mul, Int.cast_mul, Int.cast_mul, Int.cast_mul, Int.cast_natCast, Int.cast_natCast,
  Int.cast_mul, Int.cast_mul, Int.cast_mul, Int.cast_mul, Int.cast_natCast, Int.cast_natCast,
  Int.cast_mul, Int.cast_mul, Int.cast_natCast, Int.cast_natCast, Int.cast_natCast]
2026-01-11 16:43:59.669 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.18519\nŒ± : Type u_1\np q x y : ‚Ñö‚â•0\n‚ä¢ ‚Üë(min x y) = min ‚Üëx ‚Üëy")
2026-01-11 16:43:59.669 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 391.09s.
2026-01-11 16:43:59.670 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.18519\nŒ± : Type u_1\np q x y : ‚Ñö‚â•0\n‚ä¢ ‚Üë(min x y) = min ‚Üëx ‚Üëy")
2026-01-11 16:43:59.805 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:43:59.805 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:44:07.503 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: FreeMonoid.toList_comp_ofList
2026-01-11 16:44:08.231 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: List.tails_append
2026-01-11 16:44:11.529 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: CategoryTheory.Bicategory.rightUnitor_inv_naturality
2026-01-11 16:44:12.231 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:44:12.910 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:44:15.961 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:44:20.876 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Matrix.smul_mul
2026-01-11 16:44:25.478 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:44:28.864 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: ContinuousLinearMap.map_add‚ÇÇ
2026-01-11 16:44:33.426 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:44:49.372 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h
2026-01-11 16:45:49.423 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h
2026-01-11 16:45:50.975 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: positivity
2026-01-11 16:45:51.039 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='<stdin>:1:1: unknown tactic')
2026-01-11 16:45:51.040 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 451.19s.
2026-01-11 16:45:51.040 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='<stdin>:1:1: unknown tactic')
2026-01-11 16:45:51.082 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: erw [LinearMap.rTensor_apply, LinearMap.rTensor_apply, LinearMap.rTensor_apply,
  LinearMap.rTensor_apply, LinearMap.rTensor_apply, LinearMap.rTensor_sub, LinearMap.rTensor_sub,
  LinearMap.rTensor_sub, LinearMap.rTensor_sub, LinearMap.rTensor_sub, LinearMap.rTensor_sub,
  LinearMap.rTensor_sub, LinearMap.rTensor_sub, LinearMap.rTensor_sub, LinearMap.rTensor_sub,
  LinearMap.rTensor_sub, LinearMap.rTensor_sub, LinearMap.rTensor_sub, LinearMap.rTensor_sub,
  LinearMap.rTensor_sub, LinearMap.rTensor_sub, LinearMap.rTensor_sub, LinearMap.rTensor_sub,
  LinearMap.rTensor_sub, LinearMap.rTensor_sub, LinearMap.rTensor_sub, LinearMap.rTensor_sub,
  LinearMap.rTensor_sub, LinearMap.rTensor_sub, LinearMap.rTensor_sub, LinearMap.rTensor_sub,
  LinearMap.rTensor_sub, LinearMap.rTensor_sub, LinearMap.rTensor_sub, LinearMap.rTensor_sub,
  LinearMap.rTensor_sub, LinearMap.rTensor_sub, LinearMap.rTensor_sub, LinearMap.rTensor_sub,
  LinearMap.rTensor_apply, LinearMap.rTensor_apply, LinearMap.rTensor_sub, LinearMap.rTensor_
2026-01-11 16:45:51.143 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: exact measurable_compProd (measurable_kernel_prod_mk_left_of_finite hs measurable_const)
  (measurable_kernel_prod_mk_left_of_finite hs measurable_const)
  (measurable_kernel_prod_mk_left_of_finite hs measurable_const)
  (measurable_kernel_prod_mk_left_of_finite hs measurable_const)
  (measurable_kernel_prod_mk_left_of_finite hs measurable_const)
  (measurable_kernel_prod_mk_left_of_finite hs measurable_const)
  (measurable_kernel_prod_mk_left_of_finite hs measurable_const)
  (measurable_kernel_prod_mk_left_of_finite hs measurable_const)
  (measurable_kernel_prod_mk_left_of_finite hs measurable_const)
  (measurable_kernel_prod_mk_left_of_finite hs measurable_const)
  (measurable_kernel_prod_mk_left_of_finite hs measurable_const)
  (measurable_kernel_prod_mk_left_of_finite hs measurable_const)
  (measurable_kernel_prod_mk_left_of_finite hs measurable_const)
  (measurable_kernel_prod_mk_left_of_finite hs measurable_const)
  (measurable_kernel_prod_mk_left_of_finite hs measurable_const)
2026-01-11 16:45:51.150 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="<stdin>:11:93: unexpected end of input; expected ']'")
2026-01-11 16:45:51.150 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 490.71s.
2026-01-11 16:45:51.150 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="<stdin>:11:93: unexpected end of input; expected ']'")
2026-01-11 16:45:51.170 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:45:51.171 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:45:51.211 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="unknown identifier 'measurable_compProd'")
2026-01-11 16:45:51.211 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 487.53s.
2026-01-11 16:45:51.211 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="unknown identifier 'measurable_compProd'")
2026-01-11 16:45:51.296 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:45:51.297 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:45:51.343 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:45:51.343 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:45:55.417 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [‚Üê iUnion_spanningSets, iUnion_spanningSets, iUnion_spanningSets Œº]
2026-01-11 16:45:55.497 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='failed to synthesize\n  MeasureTheory.SigmaFinite ?Œº\nuse `set_option diagnostics true` to get diagnostic information')
2026-01-11 16:45:55.497 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 496.94s.
2026-01-11 16:45:55.498 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='failed to synthesize\n  MeasureTheory.SigmaFinite ?Œº\nuse `set_option diagnostics true` to get diagnostic information')
2026-01-11 16:45:55.633 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:45:55.633 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:45:56.290 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [RingHom.map_mul, RingHom.map_comp, RingHom.map_mul]
2026-01-11 16:45:56.398 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  ?f (?a * ?b)\nF : Type u_1\nŒ± : Type u_2\nŒ≤ : Type u_3\nŒ≥ : Type u_4\nx‚úù¬≤ : NonAssocSemiring Œ±\nx‚úù¬π : NonAssocSemiring Œ≤\nx‚úù : NonAssocSemiring Œ≥\nf g : Œ± ‚Üí+* Œ±\n‚ä¢ ‚áë(f * g) = ‚áëf ‚àò ‚áëg")
2026-01-11 16:45:56.398 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 482.52s.
2026-01-11 16:45:56.398 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  ?f (?a * ?b)\nF : Type u_1\nŒ± : Type u_2\nŒ≤ : Type u_3\nŒ≥ : Type u_4\nx‚úù¬≤ : NonAssocSemiring Œ±\nx‚úù¬π : NonAssocSemiring Œ≤\nx‚úù : NonAssocSemiring Œ≥\nf g : Œ± ‚Üí+* Œ±\n‚ä¢ ‚áë(f * g) = ‚áëf ‚àò ‚áëg")
2026-01-11 16:45:56.530 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:45:56.531 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:45:57.129 | ERROR    | lean_reinforcement.utilities.gym:reset:41 - Error during environment reset: Cannot interact with theorems with the `where` keyword.
2026-01-11 16:45:57.129 | ERROR    | lean_reinforcement.training.worker:process_theorem:44 - Failed to initialize environment for theorem SMul.comp.smulCommClass': Cannot interact with theorems with the `where` keyword.
2026-01-11 16:45:57.132 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:45:58.464 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [‚Üê adjoin.powerBasis'_gen, adjoin.powerBasis'_gen]
2026-01-11 16:45:58.583 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.114989\nR : Type u_1\nS : Type u_2\ninst‚úù‚Å∂ : CommRing R\ninst‚úù‚Åµ : CommRing S\ninst‚úù‚Å¥ : IsDomain R\ninst‚úù¬≥ : Algebra R S\ninst‚úù¬≤ : IsDomain S\ninst‚úù¬π : NoZeroSMulDivisors R S\ninst‚úù : IsIntegrallyClosed R\nx : S\nhx : IsIntegral R x\n‚ä¢ (Algebra.adjoin.powerBasis' hx).gen = ‚ü®x, ‚ãØ‚ü©")
2026-01-11 16:45:58.583 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 499.65s.
2026-01-11 16:45:58.583 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.114989\nR : Type u_1\nS : Type u_2\ninst‚úù‚Å∂ : CommRing R\ninst‚úù‚Åµ : CommRing S\ninst‚úù‚Å¥ : IsDomain R\ninst‚úù¬≥ : Algebra R S\ninst‚úù¬≤ : IsDomain S\ninst‚úù¬π : NoZeroSMulDivisors R S\ninst‚úù : IsIntegrallyClosed R\nx : S\nhx : IsIntegral R x\n‚ä¢ (Algebra.adjoin.powerBasis' hx).gen = ‚ü®x, ‚ãØ‚ü©")
2026-01-11 16:45:58.717 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:45:58.717 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:46:04.726 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Order.succ_pred_of_not_isMin
2026-01-11 16:46:06.318 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Nat.add_eq_min_iff
2026-01-11 16:46:06.907 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: antitone_mul_left
2026-01-11 16:46:08.399 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: isOpen_singleton_iff_nhds_eq_pure
2026-01-11 16:46:10.002 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:46:11.482 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:46:12.162 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:46:12.378 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: have h' : Nat.card (F.obj Y) ‚â§ Nat.card (F.obj Y) :=
  Nat.card_eq_fiber_of_mono_fiber_of_preserves_of_mono_fiber_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserv
2026-01-11 16:46:12.613 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="unknown constant 'Nat.card_eq_fiber_of_mono_fiber_of_preserves_of_mono_fiber_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserv'")
2026-01-11 16:46:12.613 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 516.53s.
2026-01-11 16:46:12.613 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="unknown constant 'Nat.card_eq_fiber_of_mono_fiber_of_preserves_of_mono_fiber_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserves_of_preserv'")
2026-01-11 16:46:12.746 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:46:12.746 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:46:13.372 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:46:17.440 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: SheafOfModules.comp_val
2026-01-11 16:46:17.926 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: ContinuousLinearMap.dist_le_opNorm
2026-01-11 16:46:22.100 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Finmap.mem_iff
2026-01-11 16:46:22.500 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:46:22.831 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:46:26.627 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:46:49.516 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h
2026-01-11 16:47:49.569 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h
2026-01-11 16:48:15.145 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: induction l with
| nil => simp
| cons hd tl IH =>
  simp only [List.append_assoc, List.tails_append, foldl_append]
| cons hd tl IH =>
  simp only [List.tails_cons, foldl_cons, foldl_cons, foldl_cons, foldl_cons, append_assoc,
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             
2026-01-11 16:48:15.213 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="<stdin>:7:797: unexpected end of input; expected ']'")
2026-01-11 16:48:15.213 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 246.98s.
2026-01-11 16:48:15.213 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="<stdin>:7:797: unexpected end of input; expected ']'")
2026-01-11 16:48:15.345 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:48:15.346 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:48:16.674 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp
2026-01-11 16:48:16.751 | SUCCESS  | lean_reinforcement.agent.runner:run:217 - Proof finished in 1 steps and 245.22s.
2026-01-11 16:48:16.884 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:48:16.885 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:48:18.915 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [‚Üê coe_toList, ‚Üê coe_toList, ‚Üê coe_toList, ‚Üê coe_toList, ‚Üê coe_toList, ‚Üê
  coe_toList, ‚Üê coe_toList, ‚Üê coe_toList, ‚Üê coe_toList, ‚Üê coe_toList, ‚Üê coe_toList,
  ‚Üê coe_toList, ‚Üê coe_toList, ‚Üê coe_toList, ‚Üê coe_toList, ‚Üê coe_toList, ‚Üê coe_toList,
  ‚Üê coe_toList, ‚Üê coe_toList, ‚Üê coe_toList, ‚Üê coe_toList, ‚Üê coe_toList, ‚Üê coe_toList,
  ‚Üê coe_toList, ‚Üê coe_toList, ‚Üê coe_toList, ‚Üê coe_toList, ‚Üê coe_toList, ‚Üê coe_toList,
  coe_toList]
2026-01-11 16:48:19.013 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.2422\nŒ± : Type u_1\nŒ≤ : Type u_2\nŒ≥ : Type u_3\nM : Type u_4\ninst‚úù¬π : Monoid M\nN : Type u_5\ninst‚úù : Monoid N\n‚ä¢ ‚áëFreeMonoid.toList ‚àò ‚áëFreeMonoid.ofList = id")
2026-01-11 16:48:19.013 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 251.51s.
2026-01-11 16:48:19.013 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.2422\nŒ± : Type u_1\nŒ≤ : Type u_2\nŒ≥ : Type u_3\nM : Type u_4\ninst‚úù¬π : Monoid M\nN : Type u_5\ninst‚úù : Monoid N\n‚ä¢ ‚áëFreeMonoid.toList ‚àò ‚áëFreeMonoid.ofList = id")
2026-01-11 16:48:19.148 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:48:19.148 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:48:21.256 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [‚Üê Matrix.mul_assoc, ‚Üê Matrix.mul_assoc, ‚Üê Matrix.mul_assoc, ‚Üê Matrix.mul_assoc,
  Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc,
  Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc,
  Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc,
  Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc,
  Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc,
  Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc,
  Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc,
  Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc,
  Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc,
  Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc, Matrix.mul_assoc,
  Matrix.mu
2026-01-11 16:48:21.324 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="<stdin>:12:11: unexpected end of input; expected ']'")
2026-01-11 16:48:21.325 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 240.45s.
2026-01-11 16:48:21.325 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="<stdin>:12:11: unexpected end of input; expected ']'")
2026-01-11 16:48:21.458 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:48:21.458 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:48:27.984 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Filter.HasBasis.disjoint_iff_left
2026-01-11 16:48:30.427 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: ENNReal.log_one
2026-01-11 16:48:32.840 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:48:34.036 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: WittVector.one_coeff_zero
2026-01-11 16:48:35.065 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:48:35.869 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: strictConcaveOn_of_slope_strict_anti_adjacent
2026-01-11 16:48:38.720 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:48:40.475 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:48:49.680 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h
2026-01-11 16:49:42.211 | INFO     | lean_reinforcement.training.trainer:_collect_data:297 - Completed 16/128 proofs
2026-01-11 16:49:49.743 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h
2026-01-11 16:49:52.125 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: refine ‚ü®fun ‚ü®h‚ÇÅ, h‚ÇÇ‚ü© ‚Ü¶ ‚ü®h‚ÇÅ, h‚ÇÇ‚ü©, fun ‚ü®h‚ÇÇ, h‚ÇÉ‚ü© ‚Ü¶ ‚ü®‚ü®h‚ÇÅ, h‚ÇÇ‚ü©, fun ‚ü®h‚ÇÅ, h‚ÇÇ‚ü© ‚Ü¶ ‚ü®h‚ÇÅ, h‚ÇÇ‚ü©‚ü©
2026-01-11 16:49:52.193 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="<stdin>:1:83: unexpected end of input; expected '‚ü©'")
2026-01-11 16:49:52.193 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 225.88s.
2026-01-11 16:49:52.193 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="<stdin>:1:83: unexpected end of input; expected '‚ü©'")
2026-01-11 16:49:52.324 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:49:52.325 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:49:53.181 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: refine ‚ü®fun h =>?_, fun h => isOpen_singleton_eq‚ü©
2026-01-11 16:49:53.248 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="unknown identifier 'isOpen_singleton_eq'")
2026-01-11 16:49:53.248 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 224.85s.
2026-01-11 16:49:53.249 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="unknown identifier 'isOpen_singleton_eq'")
2026-01-11 16:49:53.381 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:49:53.382 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:49:54.101 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [succ_eq_of_not_isMin h, succ_pred]
2026-01-11 16:49:54.199 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.45916\nŒ± : Type u_1\nŒ≤ : Type u_2\ninst‚úù¬≤ : PartialOrder Œ±\ninst‚úù¬π : SuccOrder Œ±\ninst‚úù : PredOrder Œ±\na b : Œ±\nh : ¬¨IsMin a\n‚ä¢ Order.succ (Order.pred a) = a")
2026-01-11 16:49:54.199 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 229.47s.
2026-01-11 16:49:54.199 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.45916\nŒ± : Type u_1\nŒ≤ : Type u_2\ninst‚úù¬≤ : PartialOrder Œ±\ninst‚úù¬π : SuccOrder Œ±\ninst‚úù : PredOrder Œ±\na b : Œ±\nh : ¬¨IsMin a\n‚ä¢ Order.succ (Order.pred a) = a")
2026-01-11 16:49:54.332 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:49:54.332 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:49:55.451 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp only [Category.assoc, Category.comp_id, Category.assoc]
2026-01-11 16:49:55.517 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='simp made no progress')
2026-01-11 16:49:55.517 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 218.08s.
2026-01-11 16:49:55.517 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='simp made no progress')
2026-01-11 16:49:55.651 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:49:55.652 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:49:56.732 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simpa only [mul_comm] using mul_le_mul_of_nonpos_right ha ha
2026-01-11 16:49:56.822 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='type mismatch\n  h‚úù\nhas type\n  0 * a ‚â§ a * a : Prop\nbut is expected to have type\n  Antitone fun x => a * x : Prop')
2026-01-11 16:49:56.822 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 229.92s.
2026-01-11 16:49:56.822 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='type mismatch\n  h‚úù\nhas type\n  0 * a ‚â§ a * a : Prop\nbut is expected to have type\n  Antitone fun x => a * x : Prop')
2026-01-11 16:49:56.956 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:49:56.956 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:50:00.432 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [RingHomIsometric.is_iso, RingHomIsometric.is_iso, RingHomIsometric.is_iso, RingHomIsometric.is_iso,
  RingHomIsometric.is_iso, RingHomIsometric.is_iso, RingHomIsometric.is_iso, RingHomIsometric.is_iso,
  RingHomIsometric.is_iso, RingHomIsometric.is_iso, RingHomIsometric.is_iso, RingHomIsometric.is_iso,
  RingHomIsometric.is_iso, RingHomIsometric.is_iso, RingHomIsometric.is_iso, RingHomIsometric.is_iso,
  RingHomIsometric.is_iso, RingHomIsometric.is_iso, RingHomIsometric.is_iso, RingHomIsometric.is_iso,
  RingHomIsometric.is_iso, RingHomIsometric.is_iso, RingHomIsometric.is_iso, RingHomIsometric.is_iso,
  RingHomIsometric.is_iso, RingHomIsometric.is_iso, RingHomIsometric.is_iso, RingHomIsometric.is_iso,
  RingHomIsometric.is_iso, RingHomIsometric.is_iso, RingHomIsometric.is_iso, RingHomIsometric.is_iso,
  RingHomIsometric.is_iso, RingHomIsometric.is_iso, RingHomIsometric.is_iso, RingHomIsometric.is_iso,
  RingHomIsometric.is_iso, RingHomIsometric.is_iso, RingHomIsometric.is_iso, RingHomIsometric.is_iso,
 
2026-01-11 16:50:00.500 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="<stdin>:11:1: unexpected end of input; expected ']'")
2026-01-11 16:50:00.500 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 222.57s.
2026-01-11 16:50:00.500 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="<stdin>:11:1: unexpected end of input; expected ']'")
2026-01-11 16:50:00.633 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:50:00.634 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:50:03.346 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Set.unbounded_le_Ici
2026-01-11 16:50:07.888 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:50:11.488 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: monotone_sSup_of_monotone
2026-01-11 16:50:11.649 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: TopologicalSpace.IsTopologicalBasis.borel_eq_generateFrom
2026-01-11 16:50:16.125 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: SzemerediRegularity.card_eq_of_mem_parts_chunk
2026-01-11 16:50:16.423 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:50:16.571 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:50:17.176 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: ENNReal.exists_pos_sum_of_countable'
2026-01-11 16:50:21.122 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: LinearMap.BilinForm.tensorDistribEquiv_apply
2026-01-11 16:50:21.179 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:50:22.000 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:50:23.528 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp [Multiset.eq_zero_iff_forall_not_mem]
2026-01-11 16:50:23.592 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp [log]
2026-01-11 16:50:23.624 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="kernel type check failed: (kernel) declaration has free variables '[anonymous]'")
2026-01-11 16:50:23.624 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 774.43s.
2026-01-11 16:50:23.624 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="kernel type check failed: (kernel) declaration has free variables '[anonymous]'")
2026-01-11 16:50:23.677 | SUCCESS  | lean_reinforcement.agent.runner:run:217 - Proof finished in 1 steps and 113.25s.
2026-01-11 16:50:23.757 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:50:23.757 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:50:23.808 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:50:23.808 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:50:25.663 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [coeff_zero_eq_eval_zero, coeff_zero_eq_eval_zero]
2026-01-11 16:50:25.751 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.39228\np : ‚Ñï\nR : Type u_1\nhp : Fact (Nat.Prime p)\ninst‚úù : CommRing R\n‚ä¢ WittVector.coeff 1 0 = 1")
2026-01-11 16:50:25.751 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 111.72s.
2026-01-11 16:50:25.751 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.39228\np : ‚Ñï\nR : Type u_1\nhp : Fact (Nat.Prime p)\ninst‚úù : CommRing R\n‚ä¢ WittVector.coeff 1 0 = 1")
2026-01-11 16:50:25.883 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:50:25.884 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:50:25.884 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:50:26.632 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: exact unbounded_Ici a
2026-01-11 16:50:26.698 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="unknown identifier 'unbounded_Ici'")
2026-01-11 16:50:26.698 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 23.35s.
2026-01-11 16:50:26.698 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="unknown identifier 'unbounded_Ici'")
2026-01-11 16:50:26.833 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:50:26.833 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:50:32.046 | ERROR    | lean_reinforcement.utilities.gym:reset:41 - Error during environment reset: Cannot interact with theorems with the `where` keyword.
2026-01-11 16:50:32.046 | ERROR    | lean_reinforcement.training.worker:process_theorem:44 - Failed to initialize environment for theorem Module.injective_object_of_injective_module: Cannot interact with theorems with the `where` keyword.
2026-01-11 16:50:32.048 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:50:36.418 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Fin.append_left
2026-01-11 16:50:37.938 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Primrec‚ÇÇ.uncurry
2026-01-11 16:50:38.867 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rintro _ ‚ü®f, hf, rfl‚ü© _ ‚ü®g, hg, rfl‚ü© _ ‚ü®g, hg, rfl‚ü© _ ‚ü®g, hg, rfl‚ü© _ ‚ü®g, hg, rfl‚ü©
2026-01-11 16:50:38.936 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='rcases tactic failed: b‚úù : Œ± is not an inductive datatype')
2026-01-11 16:50:38.936 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 27.45s.
2026-01-11 16:50:38.936 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='rcases tactic failed: b‚úù : Œ± is not an inductive datatype')
2026-01-11 16:50:39.070 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:50:39.070 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:50:39.574 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Finset.card_div_mul_le_card_div_mul_card_mul
2026-01-11 16:50:41.361 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:50:43.144 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:50:43.444 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Polynomial.rootMultiplicity_eq_nat_find_of_nonzero
2026-01-11 16:50:44.528 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:50:48.248 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:50:49.854 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h
2026-01-11 16:50:59.326 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: MeasureTheory.volume_preserving_piFinsetUnion
2026-01-11 16:51:03.910 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:51:47.347 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [mem_parts_chunk hP G Œµ hU] at hs
2026-01-11 16:51:47.480 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.129897\nŒ± : Type u_1\ninst‚úù¬≤ : Fintype Œ±\ninst‚úù¬π : DecidableEq Œ±\nP : Finpartition Finset.univ\nhP : P.IsEquipartition\nG : SimpleGraph Œ±\ninst‚úù : DecidableRel G.Adj\nŒµ : ‚Ñù\nU : Finset Œ±\nhU : U ‚àà P.parts\nV : Finset Œ±\nùíú : Finset (Finset Œ±)\ns : Finset Œ±\nhs : s ‚àà (SzemerediRegularity.chunk hP G Œµ hU).parts\n‚ä¢ s.card = m ‚à® s.card = m + 1")
2026-01-11 16:51:47.480 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 91.36s.
2026-01-11 16:51:47.480 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.129897\nŒ± : Type u_1\ninst‚úù¬≤ : Fintype Œ±\ninst‚úù¬π : DecidableEq Œ±\nP : Finpartition Finset.univ\nhP : P.IsEquipartition\nG : SimpleGraph Œ±\ninst‚úù : DecidableRel G.Adj\nŒµ : ‚Ñù\nU : Finset Œ±\nhU : U ‚àà P.parts\nV : Finset Œ±\nùíú : Finset (Finset Œ±)\ns : Finset Œ±\nhs : s ‚àà (SzemerediRegularity.chunk hP G Œµ hU).parts\n‚ä¢ s.card = m ‚à® s.card = m + 1")
2026-01-11 16:51:47.612 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:51:47.612 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:51:49.932 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h
2026-01-11 16:51:52.786 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': Unexpected EOF
2026-01-11 16:51:52.787 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.787 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.787 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.787 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.787 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.787 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.788 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.788 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.788 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.788 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.788 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.788 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.788 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.788 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.789 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.789 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.789 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.789 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.789 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.789 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.789 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.789 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.789 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.789 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.790 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.790 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.790 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.790 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.790 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.790 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.790 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.790 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.790 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.791 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.791 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.791 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.791 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.791 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.791 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.791 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.791 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.791 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.791 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.791 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.792 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.792 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.792 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.792 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.792 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.792 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.792 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.792 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.792 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.793 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.793 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.793 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.793 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.793 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.793 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.793 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.793 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.793 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.793 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.793 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.794 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.794 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.794 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.794 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.794 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.794 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.794 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.794 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.794 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.795 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.795 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.795 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.795 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.795 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.795 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.795 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.795 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.795 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.795 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.796 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.796 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.796 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.796 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.796 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.796 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.796 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.796 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.796 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.796 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.797 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.797 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.797 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.797 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.797 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.797 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.797 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.797 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.797 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.797 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.798 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.798 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.798 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.798 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.798 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.798 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.798 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.798 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.798 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.799 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.799 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.799 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.799 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.799 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.799 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.800 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h <;>
  rcases le_total b a with h | h <;>
  rcases le_total b a with h | h <;>
  rcases le_total b a with h | h <;>
  rcases le_total b a with h | h <;>
  rcases le_total b a with h | h <;>
  rcases le_total b a with h | h <;>
  rcases le_total b a with h | h <;>
  rcases le_total b a with h | h <;>
  rcases le_total b a with h | h <;>
  rcases le_total b a with h | h <;>
  rcases le_total b a with h | h <;>
  rcases le_total b a with h | h <;>
  rcases le_total b a with h | h <;>
  rcases le_total b a with h | h <;>
  rcases le_total b a with h | h <;>
  rcases le_total b a with h | h <;>
  rcases le_total b a with h | h <;>
  rcases le_total b a with h | h <;>
  rcases le_total b a with h | h <;>
  rcases le_total b a with h | h <;>
  rcases le_total b a with h | h <;>
  rcases le_total b a with h | h <;>
  rcases le_total b a with h | h <;>
  rcases le_total b a with h | h <;>
  rcases le_total b a with h |
2026-01-11 16:51:52.801 | ERROR    | lean_reinforcement.utilities.gym:run_tactic_stateless:85 - Error running tactic 'rcases le_total a b with h | h <;> rcases le_total b a with h | h <;> rcases le_total b a with h | h': OOM
2026-01-11 16:51:52.801 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='Exception: OOM')
2026-01-11 16:51:52.801 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 865.72s.
2026-01-11 16:51:52.801 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='Exception: OOM')
2026-01-11 16:51:52.802 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:51:52.831 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: induction' i using Fin.cases with i ih
2026-01-11 16:51:52.908 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='target\n  i\nhas type\n  Fin m : Type\nbut is expected to have type\n  Fin (?m.23787 + 1) : Type')
2026-01-11 16:51:52.908 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 76.49s.
2026-01-11 16:51:52.908 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='target\n  i\nhas type\n  Fin m : Type\nbut is expected to have type\n  Fin (?m.23787 + 1) : Type')
2026-01-11 16:51:53.041 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:51:53.041 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:51:53.796 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [tensorDistribEquiv, LinearEquiv.coe_coe, LinearEquiv.coe_coe, LinearEquiv.coe_coe,
  LinearEquiv.coe_coe, LinearEquiv.coe_coe, LinearEquiv.coe_coe, LinearEquiv.coe_coe,
  LinearEquiv.coe_coe, LinearEquiv.coe_coe, LinearEquiv.coe_coe, LinearEquiv.coe_coe,
  LinearEquiv.coe_coe, LinearEquiv.coe_coe, LinearEquiv.coe_coe, LinearEquiv.coe_coe,
  LinearEquiv.coe_coe, LinearEquiv.coe_coe, LinearEquiv.coe_coe, LinearEquiv.coe_coe,
  LinearEquiv.coe_coe, LinearEquiv.coe_coe, LinearEquiv.coe_coe, LinearEquiv.coe_coe,
  LinearEquiv.coe_coe, LinearEquiv.coe_coe, LinearEquiv.coe_coe, LinearEquiv.coe_coe,
  LinearEquiv.coe_coe, LinearEquiv.coe_coe, LinearEquiv.coe_coe, LinearEquiv.coe_coe,
  LinearEquiv.coe_coe, LinearEquiv.coe_coe, LinearEquiv.coe_coe, LinearEquiv.coe_coe,
  LinearEquiv.coe_coe, LinearEquiv.coe_coe, LinearEquiv.coe_coe, LinearEquiv.coe_coe,
  LinearEquiv.coe_coe, LinearEquiv.coe_coe, LinearEquiv.coe_coe, LinearEquiv.coe_coe,
  LinearEquiv.coe_coe, LinearEquiv.coe_coe, LinearEquiv.coe_coe, LinearEquiv
2026-01-11 16:51:53.865 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="<stdin>:12:76: unexpected end of input; expected ']'")
2026-01-11 16:51:53.865 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 92.74s.
2026-01-11 16:51:53.865 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="<stdin>:12:76: unexpected end of input; expected ']'")
2026-01-11 16:51:53.998 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:51:53.999 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:51:57.816 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:51:59.272 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: exact Finset.mul_le_mul_of_nonneg_right (Finset.card_nonneg _) (Finset.card_nonneg _)
2026-01-11 16:51:59.340 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="unknown constant 'Finset.mul_le_mul_of_nonneg_right'")
2026-01-11 16:51:59.340 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 79.77s.
2026-01-11 16:51:59.340 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="unknown constant 'Finset.mul_le_mul_of_nonneg_right'")
2026-01-11 16:51:59.472 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:51:59.472 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:52:05.360 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: FirstOrder.Language.Substructure.closure_le
2026-01-11 16:52:09.718 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:52:10.955 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Finset.inf'_const
2026-01-11 16:52:12.954 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Algebra.top_toSubring
2026-01-11 16:52:14.476 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: LinearMap.dualMap_def
2026-01-11 16:52:15.913 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:52:17.443 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:52:19.007 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:52:35.398 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: MeasureTheory.L1.SimpleFunc.setToL1S_mono_left
2026-01-11 16:52:40.115 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:52:56.245 | INFO     | lean_reinforcement.training.trainer:_collect_data:297 - Completed 32/128 proofs
2026-01-11 16:53:07.599 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [rootMultiplicity_eq_multiplicity, Polynomial.multiplicity_eq_rootMultiplicity,
  Polynomial.multiplicity_eq_rootMultiplicity, Polynomial.multiplicity_eq_rootMultiplicity,
  Polynomial.multiplicity_eq_rootMultiplicity, Polynomial.multiplicity_eq_rootMultiplicity,
  Polynomial.multiplicity_eq_rootMultiplicity, Polynomial.multiplicity_eq_rootMultiplicity,
  Polynomial.multiplicity_eq_rootMultiplicity, Polynomial.multiplicity_eq_rootMultiplicity,
  Polynomial.multiplicity_eq_rootMultiplicity, Polynomial.multiplicity_eq_rootMultiplicity,
  Polynomial.multiplicity_eq_rootMultiplicity, Polynomial.multiplicity_eq_rootMultiplicity,
  Polynomial.multiplicity_eq_rootMultiplicity, Polynomial.multiplicity_eq_rootMultiplicity,
  Polynomial.multiplicity_eq_rootMultiplicity, Polynomial.multiplicity_eq_rootMultiplicity,
  Polynomial.multiplicity_eq_rootMultiplicity, Polynomial.multiplicity_eq_rootMultiplicity,
  Polynomial.multiplicity_eq_rootMultiplicity, Polynomial.multiplicity_eq_rootMultiplicity,
  Polynomial.multipl
2026-01-11 16:53:07.667 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="<stdin>:12:20: unexpected end of input; expected ']'")
2026-01-11 16:53:07.667 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 144.22s.
2026-01-11 16:53:07.668 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="<stdin>:12:20: unexpected end of input; expected ']'")
2026-01-11 16:53:07.798 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:53:07.798 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:53:08.449 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: exact MeasurableEquiv.measurePreserving (MeasurableEquiv.piFinsetUnion Œ± h)
2026-01-11 16:53:08.517 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="unknown constant 'MeasurableEquiv.measurePreserving'")
2026-01-11 16:53:08.517 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 129.19s.
2026-01-11 16:53:08.517 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="unknown constant 'MeasurableEquiv.measurePreserving'")
2026-01-11 16:53:08.649 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:53:08.649 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:53:26.265 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Filter.Tendsto.atBot_mul
2026-01-11 16:53:28.398 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: CategoryTheory.Limits.coequalizer.œÄ_desc
2026-01-11 16:53:30.988 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:53:33.222 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:54:37.697 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [Dual.transpose, Dual.transpose_apply, Dual.transpose_apply, Dual.transpose_apply,
  Dual.transpose_apply, Dual.transpose_apply, Dual.transpose_apply, Dual.transpose_apply,
  Dual.transpose_apply, Dual.transpose_apply, Dual.transpose_apply, Dual.transpose_apply,
  Dual.transpose_apply, Dual.transpose_apply, Dual.transpose_apply, Dual.transpose_apply,
  Dual.transpose_apply, Dual.transpose_apply, Dual.transpose_apply, Dual.transpose_apply,
  Dual.transpose_apply, Dual.transpose_apply, Dual.transpose_apply, Dual.transpose_apply,
  Dual.transpose_apply, Dual.transpose_apply, Dual.transpose_apply, Dual.transpose_apply,
  Dual.transpose_apply, Dual.transpose_apply, Dual.transpose_apply, Dual.transpose_apply,
  Dual.transpose_apply, Dual.transpose_apply, Dual.transpose_apply, Dual.transpose_apply,
  Dual.transpose_apply, Dual.transpose_apply, Dual.transpose_apply, Dual.transpose_apply]
2026-01-11 16:54:37.852 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  (Module.Dual.transpose ?u) ?l\nR : Type u\ninst‚úù‚Å¥ : CommSemiring R\nM‚ÇÅ : Type v\nM‚ÇÇ : Type v'\ninst‚úù¬≥ : AddCommMonoid M‚ÇÅ\ninst‚úù¬≤ : Module R M‚ÇÅ\ninst‚úù¬π : AddCommMonoid M‚ÇÇ\ninst‚úù : Module R M‚ÇÇ\nf : M‚ÇÅ ‚Üí‚Çó[R] M‚ÇÇ\n‚ä¢ f.dualMap = (LinearMap.llcomp R M‚ÇÅ M‚ÇÇ R).flip f")
2026-01-11 16:54:37.852 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 143.38s.
2026-01-11 16:54:37.852 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  (Module.Dual.transpose ?u) ?l\nR : Type u\ninst‚úù‚Å¥ : CommSemiring R\nM‚ÇÅ : Type v\nM‚ÇÇ : Type v'\ninst‚úù¬≥ : AddCommMonoid M‚ÇÅ\ninst‚úù¬≤ : Module R M‚ÇÅ\ninst‚úù¬π : AddCommMonoid M‚ÇÇ\ninst‚úù : Module R M‚ÇÇ\nf : M‚ÇÅ ‚Üí‚Çó[R] M‚ÇÇ\n‚ä¢ f.dualMap = (LinearMap.llcomp R M‚ÇÅ M‚ÇÇ R).flip f")
2026-01-11 16:54:37.983 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:54:37.983 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:54:50.454 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: tendsto_measure_thickening_of_isClosed
2026-01-11 16:54:54.912 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:55:24.628 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: lift Œµ to ‚Ñù‚â•0 using hŒµ
2026-01-11 16:55:24.710 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='type mismatch\n  hŒµ\nhas type\n  Œµ ‚â† 0 : Prop\nbut is expected to have type\n  Œµ ‚â† ‚ä§ : Prop')
2026-01-11 16:55:24.710 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 307.53s.
2026-01-11 16:55:24.710 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='type mismatch\n  hŒµ\nhas type\n  Œµ ‚â† 0 : Prop\nbut is expected to have type\n  Œµ ‚â† ‚ä§ : Prop')
2026-01-11 16:55:24.841 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:55:24.841 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:55:39.330 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Finset.inf_const
2026-01-11 16:55:43.824 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:56:20.545 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [LinearIndependent, Finsupp.linearIndependent_iff_injective]
2026-01-11 16:56:20.693 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.274405\nŒπ : Type u'\nŒπ' : Type u_1\nR : Type u_2\nK : Type u_3\nM : Type u_4\nM' : Type u_5\nM'' : Type u_6\nV : Type u\nV' : Type u_7\nv : Œπ ‚Üí M\ninst‚úù‚Å∂ : Ring R\ninst‚úù‚Åµ : AddCommGroup M\ninst‚úù‚Å¥ : AddCommGroup M'\ninst‚úù¬≥ : AddCommGroup M''\ninst‚úù¬≤ : Module R M\ninst‚úù¬π : Module R M'\ninst‚úù : Module R M''\na b : R\nx y : M\n‚ä¢ LinearMap.ker (Finsupp.total Œπ M R v) = ‚ä• ‚Üî Function.Injective ‚áë(Finsupp.total Œπ M R v)")
2026-01-11 16:56:20.693 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 1122.36s.
2026-01-11 16:56:20.693 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.274405\nŒπ : Type u'\nŒπ' : Type u_1\nR : Type u_2\nK : Type u_3\nM : Type u_4\nM' : Type u_5\nM'' : Type u_6\nV : Type u\nV' : Type u_7\nv : Œπ ‚Üí M\ninst‚úù‚Å∂ : Ring R\ninst‚úù‚Åµ : AddCommGroup M\ninst‚úù‚Å¥ : AddCommGroup M'\ninst‚úù¬≥ : AddCommGroup M''\ninst‚úù¬≤ : Module R M\ninst‚úù¬π : Module R M'\ninst‚úù : Module R M''\na b : R\nx y : M\n‚ä¢ LinearMap.ker (Finsupp.total Œπ M R v) = ‚ä• ‚Üî Function.Injective ‚áë(Finsupp.total Œπ M R v)")
2026-01-11 16:56:20.823 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:56:20.824 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:56:32.310 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp [eq_iff_true_of_subsingleton]
2026-01-11 16:56:32.387 | SUCCESS  | lean_reinforcement.agent.runner:run:217 - Proof finished in 1 steps and 183.99s.
2026-01-11 16:56:32.518 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:56:32.518 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:56:42.913 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: MeasureTheory.hitting_of_lt
2026-01-11 16:56:43.314 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: ContextFreeGrammar.Derives.eq_or_head
2026-01-11 16:56:47.722 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:56:48.049 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:57:08.961 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: obtain ‚ü®R, Rpos, hR‚ü© : ‚àÉ R > 0, Œº (thickening R s) ‚â† ‚àû := by
  rcases hs with ‚ü®R_pos, R_pos‚ü©
  rcases hs with ‚ü®R_pos, R_pos‚ü©
  rcases hs with ‚ü®R_pos, R_pos‚ü©
  rcases hs with ‚ü®R_pos, R_pos‚ü©
  rcases hs with ‚ü®R_pos, R_pos‚ü©
  rcases hs with ‚ü®R_pos, R_pos‚ü©
  rcases hs with ‚ü®R_pos, R_pos‚ü©
  rcases hs with ‚ü®R_pos, R_pos‚ü©
  rcases hs with ‚ü®R_pos, R_pos‚ü©
  rcases hs with ‚ü®R_pos, R_pos‚ü©
  rcases hs with ‚ü®R_pos, R_pos‚ü©
  rcases hs with ‚ü®R_pos, R_pos‚ü©
  rcases hs with ‚ü®R_pos, R_pos‚ü©
  rcases hs with ‚ü®R_pos, R_pos‚ü©
  rcases hs with ‚ü®R_pos, R_pos‚ü©
  rcases hs with ‚ü®R_pos, R_pos‚ü©
  rcases hs with ‚ü®R_pos, R_pos‚ü©
  rcases hs with ‚ü®R_pos, R_pos‚ü©
  rcases hs with ‚ü®R_pos, R_pos‚ü©
  rcases hs with ‚ü®R_pos, R_pos‚ü©
  rcases hs with ‚ü®R_pos, R_pos‚ü©
  rcases hs with ‚ü®R_pos, R_pos‚ü©
  rcases hs with ‚ü®R_pos, R_pos‚ü©
  rcases hs with ‚ü®R_pos, R_pos‚ü©
  rcases hs with ‚ü®R_pos, R_pos‚ü©
  rcases hs with ‚ü®R_pos, R_pos‚ü©
  exact ‚ü®R_po
2026-01-11 16:57:09.031 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="<stdin>:28:13: unexpected end of input; expected '‚ü©'")
2026-01-11 16:57:09.031 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 138.58s.
2026-01-11 16:57:09.031 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="<stdin>:28:13: unexpected end of input; expected '‚ü©'")
2026-01-11 16:57:09.162 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:57:09.162 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:57:15.934 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: NonUnitalRingHom.id_apply
2026-01-11 16:57:20.249 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: simpa only [‚Üê tendsto_neg_atTop_iff] using hf.atTop_mul_atBot hC hf
2026-01-11 16:57:20.279 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:58:20.360 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: simpa only [mul_comm] using hf.mul_const hC
2026-01-11 16:59:12.824 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: induction u generalizing u with
| nil => simp
| cons u _ ih =>
  simp only [ContextFreeGrammar.ext_iff, ContextFreeGrammar.ext_iff] at huw
  simp only [ContextFreeGrammar.ext_iff, ContextFreeGrammar.ext_iff, ContextFreeGrammar.ext_iff,
    ContextFreeGrammar.ext_iff] at huw
  simp only [ContextFreeGrammar.ext_iff, ContextFreeGrammar.ext_iff, ContextFreeGrammar.ext_iff,
    ContextFreeGrammar.ext_iff] at huw
  simp only [ContextFreeGrammar.ext_iff, ContextFreeGrammar.ext_iff, ContextFreeGrammar.ext_iff,
    ContextFreeGrammar.ext_iff] at huw
  simp only [ContextFreeGrammar.ext_iff, ContextFreeGrammar.ext_iff, ContextFreeGrammar.ext_iff,
    ContextFreeGrammar.ext_iff, ContextFreeGrammar.ext_iff, ContextFreeGrammar.ext_iff,
    ContextFreeGrammar.ext_iff, ContextFreeGrammar.ext_iff, ContextFreeGrammar.ext_iff,
    ContextFreeGrammar.ext_iff, ContextFreeGrammar.ext_iff, ContextFreeGrammar.ext_iff,
    ContextFreeGrammar.ext_iff, ContextFreeGrammar.ext_iff, ContextFreeGrammar.ext_iff,
    ContextFreeGrammar.ext_
2026-01-11 16:59:12.893 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="<stdin>:16:27: unexpected end of input; expected ']'")
2026-01-11 16:59:12.893 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 149.58s.
2026-01-11 16:59:12.893 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="<stdin>:16:27: unexpected end of input; expected ']'")
2026-01-11 16:59:13.023 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:59:13.024 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:59:20.471 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: simpa only [mul_comm] using mul_left_cancel‚ÇÄ hC.ne' hf
2026-01-11 16:59:29.112 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: CategoryTheory.Limits.IsLimit.OfNatIso.cone_fac
2026-01-11 16:59:33.849 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 16:59:57.666 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rfl
2026-01-11 16:59:57.728 | SUCCESS  | lean_reinforcement.agent.runner:run:217 - Proof finished in 1 steps and 161.79s.
2026-01-11 16:59:57.859 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 16:59:57.860 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:00:13.605 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Finset.inf_le
2026-01-11 17:00:18.371 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:00:20.528 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: simpa only [‚Üê tendsto_neg_atTop_iff] using hf.atBot_mul hC
2026-01-11 17:00:58.012 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [‚Üê SetLike.coe_subset_coe, closure_le]
2026-01-11 17:00:58.140 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  (FirstOrder.Language.Substructure.closure L).toFun s ‚â§ S\nL : FirstOrder.Language\nM : Type w\nN : Type u_1\nP : Type u_2\ninst‚úù¬≤ : L.Structure M\ninst‚úù¬π : L.Structure N\ninst‚úù : L.Structure P\nS : L.Substructure M\ns : Set M\n‚ä¢ ‚Üë((FirstOrder.Language.Substructure.closure L).toFun s) ‚äÜ ‚ÜëS ‚Üî s ‚äÜ ‚ÜëS")
2026-01-11 17:00:58.140 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 532.78s.
2026-01-11 17:00:58.140 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  (FirstOrder.Language.Substructure.closure L).toFun s ‚â§ S\nL : FirstOrder.Language\nM : Type w\nN : Type u_1\nP : Type u_2\ninst‚úù¬≤ : L.Structure M\ninst‚úù¬π : L.Structure N\ninst‚úù : L.Structure P\nS : L.Substructure M\ns : Set M\n‚ä¢ ‚Üë((FirstOrder.Language.Substructure.closure L).toFun s) ‚äÜ ‚ÜëS ‚Üî s ‚äÜ ‚ÜëS")
2026-01-11 17:00:58.272 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:00:58.272 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:01:26.830 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: AlgebraicGeometry.LocallyRingedSpace.Œì_map
2026-01-11 17:01:31.150 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:01:42.113 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: simpa only [‚Üê mul_assoc] using hf.atBot_mul hC
2026-01-11 17:02:02.558 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [‚Üê limit.w (homOfCone h s), Category.assoc, homOfCone_extend, Category.comp_id,
  Category.comp_id, Category.comp_id, Category.comp_id, Category.comp_id, Category.assoc,
  Category.comp_id, Category.comp_id, Category.comp_id, Category.comp_id, Category.assoc,
  Category.comp_id, Category.comp_id, Category.comp_id, Category.comp_id, Category.assoc,
  Category.comp_id, Category.comp_id, Category.comp_id, Category.id_comp]
2026-01-11 17:02:02.710 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.141151\nJ : Type u‚ÇÅ\ninst‚úù¬≤ : CategoryTheory.Category.{v‚ÇÅ, u‚ÇÅ} J\nK : Type u‚ÇÇ\ninst‚úù¬π : CategoryTheory.Category.{v‚ÇÇ, u‚ÇÇ} K\nC : Type u‚ÇÉ\ninst‚úù : CategoryTheory.Category.{v‚ÇÉ, u‚ÇÉ} C\nF : J ‚•§ C\nt : CategoryTheory.Limits.Cone F\nX : C\nh : CategoryTheory.yoneda.obj X ‚ãô CategoryTheory.uliftFunctor.{u‚ÇÅ, v‚ÇÉ} ‚âÖ F.cones\ns : CategoryTheory.Limits.Cone F\n‚ä¢ (CategoryTheory.Limits.IsLimit.OfNatIso.limitCone h).extend (CategoryTheory.Limits.IsLimit.OfNatIso.homOfCone h s) = s")
2026-01-11 17:02:02.711 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 153.60s.
2026-01-11 17:02:02.711 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.141151\nJ : Type u‚ÇÅ\ninst‚úù¬≤ : CategoryTheory.Category.{v‚ÇÅ, u‚ÇÅ} J\nK : Type u‚ÇÇ\ninst‚úù¬π : CategoryTheory.Category.{v‚ÇÇ, u‚ÇÇ} K\nC : Type u‚ÇÉ\ninst‚úù : CategoryTheory.Category.{v‚ÇÉ, u‚ÇÉ} C\nF : J ‚•§ C\nt : CategoryTheory.Limits.Cone F\nX : C\nh : CategoryTheory.yoneda.obj X ‚ãô CategoryTheory.uliftFunctor.{u‚ÇÅ, v‚ÇÉ} ‚âÖ F.cones\ns : CategoryTheory.Limits.Cone F\n‚ä¢ (CategoryTheory.Limits.IsLimit.OfNatIso.limitCone h).extend (CategoryTheory.Limits.IsLimit.OfNatIso.homOfCone h s) = s")
2026-01-11 17:02:02.842 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:02:02.842 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:02:13.203 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [‚Üê Finset.coe_inj, inf_coe_of_nonempty h, inf_coe_of_nonempty h]
2026-01-11 17:02:13.319 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  ?m.122657 = ?m.122658\nF : Type u_1\nŒ± : Type u_2\nŒ≤ : Type u_3\nŒ≥ : Type u_4\nŒπ : Type u_5\nŒ∫ : Type u_6\ninst‚úù¬π : SemilatticeInf Œ±\ninst‚úù : OrderTop Œ±\ns s‚ÇÅ s‚ÇÇ : Finset Œ≤\nf g : Œ≤ ‚Üí Œ±\na : Œ±\nh : s.Nonempty\nc : Œ±\n‚ä¢ (s.inf fun x => c) = c")
2026-01-11 17:02:13.319 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 393.99s.
2026-01-11 17:02:13.319 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  ?m.122657 = ?m.122658\nF : Type u_1\nŒ± : Type u_2\nŒ≤ : Type u_3\nŒ≥ : Type u_4\nŒπ : Type u_5\nŒ∫ : Type u_6\ninst‚úù¬π : SemilatticeInf Œ±\ninst‚úù : OrderTop Œ±\ns s‚ÇÅ s‚ÇÇ : Finset Œ≤\nf g : Œ≤ ‚Üí Œ±\na : Œ±\nh : s.Nonempty\nc : Œ±\n‚ä¢ (s.inf fun x => c) = c")
2026-01-11 17:02:13.450 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:02:13.450 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:02:16.569 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Cycle.isCycle_formPerm
2026-01-11 17:02:21.127 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:02:42.174 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: simpa only [mul_comm] using hf.atBot_mul hg
2026-01-11 17:02:46.573 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: exists_of_linearIndependent_of_finite_span
2026-01-11 17:02:51.252 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:03:00.625 | INFO     | lean_reinforcement.training.trainer:_collect_data:297 - Completed 48/128 proofs
2026-01-11 17:03:13.610 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [‚Üê Œì.right_triangular f, ‚Üê Œì.right_triangular f, ‚Üê f.right_triangular f,
  ‚Üê f.right_triangular f, ‚Üê f.right_triangular f, ‚Üê f.right_triangular f,
  ‚Üê f.right_triangular f, ‚Üê f.right_triangular f, ‚Üê f.right_triangular f,
  ‚Üê f.right_triangular f, ‚Üê f.right_triangular f, ‚Üê f.right_triangular f,
  ‚Üê f.right_triangular f, ‚Üê f.right_triangular f, ‚Üê f.right_triangular f,
  ‚Üê f.right_triangular f, ‚Üê f.right_triangular f, ‚Üê f.right_triangular f,
  ‚Üê f.right_triangular f, ‚Üê f.right_triangular f, ‚Üê f.right_triangular f,
  ‚Üê f.right_triangular f, ‚Üê f.right_triangular f, ‚Üê f.right_triangular f,
  ‚Üê f.right_triangular f, ‚Üê f.right_triangular f, ‚Üê f.right_triangular f,
  ‚Üê f.right_triangular f, ‚Üê f.right_triangular f, ‚Üê f.right_triangular f,
  ‚Üê f.right_triangular f, ‚Üê f.right_triangular f, ‚Üê f.right_triangular f,
  ‚Üê f.right_triangular f, ‚Üê f.right_triangular f, ‚Üê f.right_triangular f,
  ‚Üê f.right_triangular f, ‚Üê f.right_triangular f]
2026-01-11 17:03:13.714 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.19776\nX‚úù : AlgebraicGeometry.LocallyRingedSpace\nX Y : AlgebraicGeometry.LocallyRingedSpace·µí·µñ\nf : X ‚ü∂ Y\n‚ä¢ AlgebraicGeometry.LocallyRingedSpace.Œì.map f = f.unop.val.c.app { unop := ‚ä§ }")
2026-01-11 17:03:13.714 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 106.88s.
2026-01-11 17:03:13.714 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.19776\nX‚úù : AlgebraicGeometry.LocallyRingedSpace\nX Y : AlgebraicGeometry.LocallyRingedSpace·µí·µñ\nf : X ‚ü∂ Y\n‚ä¢ AlgebraicGeometry.LocallyRingedSpace.Œì.map f = f.unop.val.c.app { unop := ‚ä§ }")
2026-01-11 17:03:13.845 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:03:13.845 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:03:23.904 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: CategoryTheory.isSeparator_iff_faithful_preadditiveCoyoneda
2026-01-11 17:03:28.291 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:03:42.241 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: simpa only [mul_comm] using hf.atTop_mul_const hC hf
2026-01-11 17:04:42.352 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: simpa only [‚Üê tendsto_neg_atTop_iff] using hf.atTop_mul_const hC hf
2026-01-11 17:04:46.227 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [linearIndependent_iff_linearIndependent_of_linearIndependent hs, linearIndependent_iff_linearIndependent_span,
  linearIndependent_iff_linearIndependent_span, linearIndependent_iff_linearIndependent_span,
  linearIndependent_iff_linearIndependent_span, linearIndependent_iff_linearIndependent_span,
  linearIndependent_iff_linearIndependent_of_linearIndependent_span hst] at hs
2026-01-11 17:04:46.373 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.740986\nŒπ : Type u'\nŒπ' : Type u_1\nR : Type u_2\nK : Type u_3\nM : Type u_4\nM' : Type u_5\nM'' : Type u_6\nV : Type u\nV' : Type u_7\ninst‚úù‚Å¥ : DivisionRing K\ninst‚úù¬≥ : AddCommGroup V\ninst‚úù¬≤ : AddCommGroup V'\ninst‚úù¬π : Module K V\ninst‚úù : Module K V'\nv : Œπ ‚Üí V\ns t‚úù : Set V\nx y z : V\nt : Finset V\nhs : LinearIndependent K fun (x : ‚Üës) => ‚Üëx\nhst : s ‚äÜ ‚Üë(Submodule.span K ‚Üët)\n‚ä¢ ‚àÉ t', ‚Üët' ‚äÜ s ‚à™ ‚Üët ‚àß s ‚äÜ ‚Üët' ‚àß t'.card = t.card")
2026-01-11 17:04:46.374 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 119.80s.
2026-01-11 17:04:46.374 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.740986\nŒπ : Type u'\nŒπ' : Type u_1\nR : Type u_2\nK : Type u_3\nM : Type u_4\nM' : Type u_5\nM'' : Type u_6\nV : Type u\nV' : Type u_7\ninst‚úù‚Å¥ : DivisionRing K\ninst‚úù¬≥ : AddCommGroup V\ninst‚úù¬≤ : AddCommGroup V'\ninst‚úù¬π : Module K V\ninst‚úù : Module K V'\nv : Œπ ‚Üí V\ns t‚úù : Set V\nx y z : V\nt : Finset V\nhs : LinearIndependent K fun (x : ‚Üës) => ‚Üëx\nhst : s ‚äÜ ‚Üë(Submodule.span K ‚Üët)\n‚ä¢ ‚àÉ t', ‚Üët' ‚äÜ s ‚à™ ‚Üët ‚àß s ‚äÜ ‚Üët' ‚àß t'.card = t.card")
2026-01-11 17:04:46.505 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:04:46.505 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:04:54.612 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Set.Ioc.coe_one
2026-01-11 17:04:59.317 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:06:04.113 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: simpa only [‚Üê mul_assoc] using hf.atBot_mul hC
2026-01-11 17:06:22.311 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rintro x y z hx hy hxy a b ha hb hab
2026-01-11 17:06:22.449 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'introN' failed, insufficient number of binders\nùïú : Type u_1\ninst‚úù : LinearOrderedField ùïú\ns : Set ùïú\nf : ùïú ‚Üí ùïú\nhs : Convex ùïú s\nhf : ‚àÄ {x y z : ùïú}, x ‚àà s ‚Üí z ‚àà s ‚Üí x < y ‚Üí y < z ‚Üí (f z - f y) / (z - y) < (f y - f x) / (y - x)\n‚ä¢ StrictConcaveOn ùïú s f")
2026-01-11 17:06:22.449 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 1066.58s.
2026-01-11 17:06:22.449 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'introN' failed, insufficient number of binders\nùïú : Type u_1\ninst‚úù : LinearOrderedField ùïú\ns : Set ùïú\nf : ùïú ‚Üí ùïú\nhs : Convex ùïú s\nhf : ‚àÄ {x y z : ùïú}, x ‚àà s ‚Üí z ‚àà s ‚Üí x < y ‚Üí y < z ‚Üí (f z - f y) / (z - y) < (f y - f x) / (y - x)\n‚ä¢ StrictConcaveOn ùïú s f")
2026-01-11 17:06:22.580 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:06:22.580 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:06:36.865 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: MeasureTheory.OuterMeasure.restrict_iInf
2026-01-11 17:06:41.564 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:07:04.223 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: simpa only [mul_comm] using hf.atBot_mul hg
2026-01-11 17:07:12.398 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: refine ‚ü®fun h =>?_, fun ‚ü®b, hb‚ü© =>?_‚ü©
2026-01-11 17:07:13.657 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [Nat.cast_one]
2026-01-11 17:07:13.746 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  ‚Üë1\nŒ± : Type u_1\ninst‚úù¬π : StrictOrderedSemiring Œ±\ninst‚úù : Nontrivial Œ±\n‚ä¢ ‚Üë1 = 1")
2026-01-11 17:07:13.746 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 139.13s.
2026-01-11 17:07:13.746 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  ‚Üë1\nŒ± : Type u_1\ninst‚úù¬π : StrictOrderedSemiring Œ±\ninst‚úù : Nontrivial Œ±\n‚ä¢ ‚Üë1 = 1")
2026-01-11 17:07:13.878 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:07:13.879 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:07:16.916 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 2: Running MCTS search for 200 iterations...
2026-01-11 17:07:21.590 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Part.mem_bind_iff
2026-01-11 17:07:26.295 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:07:27.928 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp [Finset.inf'_def]
2026-01-11 17:07:27.992 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='simp made no progress')
2026-01-11 17:07:27.992 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 917.04s.
2026-01-11 17:07:27.992 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='simp made no progress')
2026-01-11 17:07:28.123 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:07:28.123 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:07:39.426 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 2: Applying best tactic: exacts [‚ü®_, h‚ü©, ‚ü®_, h‚ü©]
2026-01-11 17:07:39.495 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='internal exception #4')
2026-01-11 17:07:39.495 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 2 steps and 1277.40s.
2026-01-11 17:07:39.496 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='internal exception #4')
2026-01-11 17:07:39.625 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:07:39.626 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:07:40.163 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp (config := { contextual := true })
2026-01-11 17:07:40.237 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='simp made no progress')
2026-01-11 17:07:40.237 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 1757.48s.
2026-01-11 17:07:40.237 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='simp made no progress')
2026-01-11 17:07:40.369 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:07:40.369 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:07:44.874 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp only [ContinuousLinearMap.map_add, ContinuousLinearMap.add_apply]
2026-01-11 17:07:45.048 | SUCCESS  | lean_reinforcement.agent.runner:run:217 - Proof finished in 1 steps and 1396.18s.
2026-01-11 17:07:45.181 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:07:45.181 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:07:45.183 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: ext
2026-01-11 17:07:45.722 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: suffices setToL1S T f ‚â§ setToL1S T' f by rw [this]
2026-01-11 17:07:45.943 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  setToL1S T f ‚â§ setToL1S T' f\nŒ± : Type u_1\nE : Type u_2\nF : Type u_3\nF' : Type u_4\nG : Type u_5\nùïú : Type u_6\np : ‚Ñù‚â•0‚àû\ninst‚úù¬π¬≤ : NormedAddCommGroup E\ninst‚úù¬π¬π : NormedSpace ‚Ñù E\ninst‚úù¬π‚Å∞ : NormedAddCommGroup F\ninst‚úù‚Åπ : NormedSpace ‚Ñù F\ninst‚úù‚Å∏ : NormedAddCommGroup F'\ninst‚úù‚Å∑ : NormedSpace ‚Ñù F'\ninst‚úù‚Å∂ : NormedAddCommGroup G\nm : MeasurableSpace Œ±\nŒº : Measure Œ±\ninst‚úù‚Åµ : NormedField ùïú\ninst‚úù‚Å¥ : NormedSpace ùïú E\nG'' : Type u_7\nG' : Type u_8\ninst‚úù¬≥ : NormedLatticeAddCommGroup G'\ninst‚úù¬≤ : NormedSpace ‚Ñù G'\ninst‚úù¬π : NormedLatticeAddCommGroup G''\ninst‚úù : NormedSpace ‚Ñù G''\nT‚úù : Set Œ± ‚Üí G'' ‚ÜíL[‚Ñù] G'\nT T' : Set Œ± ‚Üí E ‚ÜíL[‚Ñù] G''\nhTT' : ‚àÄ (s : Set Œ±) (x : E), (T s) x ‚â§ (T' s) x\nf : ‚Ü•(simpleFunc E 1 Œº)\nthis : setToL1S T f ‚â§ setToL1S T' f\n‚ä¢ setToL1S T f ‚â§ setToL1S T' f")
2026-01-11 17:07:45.943 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 910.54s.
2026-01-11 17:07:45.943 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  setToL1S T f ‚â§ setToL1S T' f\nŒ± : Type u_1\nE : Type u_2\nF : Type u_3\nF' : Type u_4\nG : Type u_5\nùïú : Type u_6\np : ‚Ñù‚â•0‚àû\ninst‚úù¬π¬≤ : NormedAddCommGroup E\ninst‚úù¬π¬π : NormedSpace ‚Ñù E\ninst‚úù¬π‚Å∞ : NormedAddCommGroup F\ninst‚úù‚Åπ : NormedSpace ‚Ñù F\ninst‚úù‚Å∏ : NormedAddCommGroup F'\ninst‚úù‚Å∑ : NormedSpace ‚Ñù F'\ninst‚úù‚Å∂ : NormedAddCommGroup G\nm : MeasurableSpace Œ±\nŒº : Measure Œ±\ninst‚úù‚Åµ : NormedField ùïú\ninst‚úù‚Å¥ : NormedSpace ùïú E\nG'' : Type u_7\nG' : Type u_8\ninst‚úù¬≥ : NormedLatticeAddCommGroup G'\ninst‚úù¬≤ : NormedSpace ‚Ñù G'\ninst‚úù¬π : NormedLatticeAddCommGroup G''\ninst‚úù : NormedSpace ‚Ñù G''\nT‚úù : Set Œ± ‚Üí G'' ‚ÜíL[‚Ñù] G'\nT T' : Set Œ± ‚Üí E ‚ÜíL[‚Ñù] G''\nhTT' : ‚àÄ (s : Set Œ±) (x : E), (T s) x ‚â§ (T' s) x\nf : ‚Ü•(simpleFunc E 1 Œº)\nthis : setToL1S T f ‚â§ setToL1S T' f\n‚ä¢ setToL1S T f ‚â§ setToL1S T' f")
2026-01-11 17:07:46.076 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:07:46.076 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:07:49.029 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp only [mem_bind_iff, exists_prop]
2026-01-11 17:07:49.109 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="kernel type check failed: (kernel) declaration has free variables '[anonymous]'")
2026-01-11 17:07:49.109 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 27.52s.
2026-01-11 17:07:49.109 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="kernel type check failed: (kernel) declaration has free variables '[anonymous]'")
2026-01-11 17:07:49.243 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:07:49.243 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:07:50.073 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 2: Running MCTS search for 200 iterations...
2026-01-11 17:07:50.074 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 2: Applying best tactic: simp
2026-01-11 17:07:50.143 | SUCCESS  | lean_reinforcement.agent.runner:run:217 - Proof finished in 2 steps and 937.19s.
2026-01-11 17:07:50.277 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:07:50.278 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:07:50.683 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: MeasureTheory.Martingale.ae_not_tendsto_atTop_atBot
2026-01-11 17:07:53.369 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: List.insertNth_length_self
2026-01-11 17:07:55.894 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: HomologicalComplex.Hom.sqFrom_comp
2026-01-11 17:07:55.975 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:07:58.374 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:08:00.625 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:08:01.949 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: innerDualCone_insert
2026-01-11 17:08:04.334 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: simpa only [mul_comm] using hf.atTop_mul_const hC hf
2026-01-11 17:08:04.337 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: LinearEquiv.rank_eq
2026-01-11 17:08:04.616 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Finsupp.sum_cons
2026-01-11 17:08:07.074 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:08:09.023 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:08:09.278 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:08:13.413 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Orientation.oangle_eq_iff_eq_norm_div_norm_smul_rotation_or_eq_zero
2026-01-11 17:08:17.905 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:08:28.204 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: constructor
2026-01-11 17:08:32.612 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 2: Running MCTS search for 200 iterations...
2026-01-11 17:08:43.013 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: induction l generalizing l <;> simp [*]
2026-01-11 17:08:43.083 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='variable cannot be generalized because target depends on it\n  l')
2026-01-11 17:08:43.083 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 49.71s.
2026-01-11 17:08:43.083 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='variable cannot be generalized because target depends on it\n  l')
2026-01-11 17:08:43.213 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:08:43.214 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:09:04.446 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: simpa only [‚Üê tendsto_neg_atTop_iff] using hf.atTop_mul_const hC hf
2026-01-11 17:09:16.396 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: isPathConnected_iff
2026-01-11 17:09:20.890 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:10:25.963 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: simpa only [‚Üê tendsto_neg_atTop_iff] using hf.atTop_mul_atBot hC hf
2026-01-11 17:10:50.619 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [sum_fintype, sum_fintype, sum_fintype, sum_fintype, sum_fintype, sum_fintype,
  sum_fintype, sum_fintype, sum_fintype, sum_fintype, sum_fintype, sum_fintype,
  sum_fintype, sum_fintype, sum_fintype, sum_fintype, sum_fintype, sum_fintype, sum_fintype,
  sum_fintype, sum_fintype, sum_fintype, sum_fintype, sum_fintype, sum_fintype, sum_fintype,
  sum_fintype, sum_fintype, sum_fintype, sum_fintype, sum_fintype, sum_fintype, sum_fintype,
  sum_fintype, sum_fintype, sum_fintype, sum_fintype, sum_fintype, sum_fintype, sum_fintype,
  sum_fintype, sum_fintype, sum_fintype, sum_fintype, sum_fintype, sum_fintype, sum_fintype,
  sum_fintype, sum_fintype, sum_fintype, sum_fintype, sum_fintype, sum_fintype, sum_fintype,
  sum_fintype, sum_fintype, sum_fintype, sum_fintype, sum_fintype, sum_fintype, sum_fintype,
  sum_fintype, sum_fintype, sum_fintype, sum_fintype, sum_fintype, sum_fintype, sum_fintype,
  sum_fintype, sum_fintype, sum_fintype, sum_fintype, sum_fintype, sum_fintype, sum_fintype,
  sum_fintype, sum_finty
2026-01-11 17:10:50.624 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [innerDualCone_innerDualCone, inf_eq_left.2, inf_eq_right.2, inf_eq_right.2,
  inf_eq_right.2, inf_eq_right.2, inf_eq_right.2, inf_eq_right.2, inf_eq_right.2,
  inf_eq_right.2, inf_eq_right.2, inf_eq_right.2, inf_eq_right.2, inf_eq_right.2,
  inf_eq_right.2, inf_eq_right.2, inf_eq_right.2, inf_eq_right.2, inf_eq_right.2,
  inf_eq_right.2, inf_eq_right.2, inf_eq_right.2, inf_eq_right.2, inf_eq_right.2,
  inf_eq_right.2, inf_eq_right.2, inf_eq_right.2, inf_eq_right.2, inf_eq_right.2,
  inf_eq_right.2, inf_eq_right.2, inf_eq_right.2, inf_eq_right.2, inf_eq_right.2,
  inf_eq_right.2, inf_eq_right.2, inf_eq_right.2, inf_eq_right.2, inf_eq_right.2,
  inf_eq_right.2, inf_eq_right.2, inf_eq_right.2, inf_eq_right.2, inf_eq_right.2,
  inf_eq_right.2, inf_eq_right.2, inf_eq_right.2, inf_eq_right.2, inf_eq_right.2,
  inf_eq_right.2, inf_eq_right.2, inf_eq_right.2, inf_eq_right.2, inf_eq_right.2,
  inf_eq_right.2, inf_eq_right.2, inf_eq_right.2, inf_eq_right.2, inf_eq_right.2,
  inf_eq_right.2, inf_eq_right.2, inf_eq_
2026-01-11 17:10:50.688 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="<stdin>:12:24: unexpected end of input; expected ']'")
2026-01-11 17:10:50.688 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 166.07s.
2026-01-11 17:10:50.688 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="<stdin>:12:24: unexpected end of input; expected ']'")
2026-01-11 17:10:50.693 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="<stdin>:13:41: unexpected end of input; expected ']'")
2026-01-11 17:10:50.694 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 168.74s.
2026-01-11 17:10:50.694 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="<stdin>:13:41: unexpected end of input; expected ']'")
2026-01-11 17:10:50.704 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: exact rank_eq_of_injective_of_linearEquiv (LinearEquiv.ofInjective f.injective)
  (LinearEquiv.ofInjective f.injective) (LinearEquiv.ofInjective f.injective)
  (LinearEquiv.ofInjective f.injective) (LinearEquiv.ofInjective f.injective)
  (LinearEquiv.ofInjective f.injective) (LinearEquiv.ofInjective f.injective)
  (LinearEquiv.ofInjective f.injective) (LinearEquiv.ofInjective f.injective)
  (LinearEquiv.ofInjective f.injective) (LinearEquiv.ofInjective f.injective)
  (LinearEquiv.ofInjective f.injective) (LinearEquiv.ofInjective f.injective)
  (LinearEquiv.ofInjective f.injective) (LinearEquiv.ofInjective f.injective)
  (LinearEquiv.ofInjective f.injective) (LinearEquiv.ofInjective f.injective)
2026-01-11 17:10:50.774 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="unknown identifier 'rank_eq_of_injective_of_linearEquiv'")
2026-01-11 17:10:50.774 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 166.44s.
2026-01-11 17:10:50.774 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="unknown identifier 'rank_eq_of_injective_of_linearEquiv'")
2026-01-11 17:10:50.817 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:10:50.817 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:10:50.820 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:10:50.821 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:10:50.903 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:10:50.903 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:10:54.161 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: dsimp [sqFrom, sqFrom, sqFrom, sqFrom, sqFrom, sqFrom, sqFrom, sqFrom, sqFrom,
  sqFromAssoc, sqFromAssoc, sqFromAssoc, sqFromAssoc, sqFromAssoc, sqFromAssoc,
  sqFromAssoc, sqFromAssoc, sqFromAssoc, sqFromAssoc, sqFromAssoc, sqFromAssoc,
  sqFromAssoc, sqFromAssoc, sqFromAssoc, sqFromAssoc, sqFromAssoc, sqFromAssoc,
  sqFromAssoc, sqFromAssoc, sqFromAssoc, sqFromAssoc, sqFromAssoc, sqFromAssoc,
  sqFromAssoc, sqFromAssoc, sqFromAssoc, sqFromAssoc, sqFromAssoc, sqFromAssoc,
  sqFromAssoc, sqFromAssoc, sqFromAssoc, sqFromAssoc, sqFromAssoc, sqFromAssoc,
  sqFromAssoc, sqFromAssoc, sqFromAssoc, sqFromAssoc, sqFromAssoc, sqFromAssoc,
  sqFromAssoc, sqFromAssoc, sqFromAssoc, sqFromAssoc, sqFromAssoc, sqFromAssoc,
  sqFromAssoc, sqFromAssoc, sqFromAssoc, sqFromAssoc, sqFromAssoc, sqFromAssoc,
  sqFromAssoc, sqFromAssoc, sqFromAssoc, sqFromAssoc, sqFromAssoc, sqFromAssoc,
  sqFromAssoc, sqFromAssoc, sqFromAssoc, sqFromAssoc, sqFromAssoc, sqFromAssoc,
  sqFromAssoc, sqFromAssoc, sqFromAssoc, sqFromAssoc, sqFromAsso
2026-01-11 17:10:54.231 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="<stdin>:13:64: unexpected end of input; expected ']'")
2026-01-11 17:10:54.232 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 178.34s.
2026-01-11 17:10:54.232 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="<stdin>:13:64: unexpected end of input; expected ']'")
2026-01-11 17:10:54.365 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:10:54.366 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:11:00.311 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: tendstoUniformlyOn_singleton_iff_tendsto
2026-01-11 17:11:02.685 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: MeasureTheory.Measure.InnerRegularWRT.measurableSet_of_isOpen
2026-01-11 17:11:02.857 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: DihedralGroup.orderOf_r
2026-01-11 17:11:05.245 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:11:07.065 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Subalgebra.eq_bot_of_finrank_one
2026-01-11 17:11:07.344 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:11:07.889 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:11:11.604 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:11:26.074 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: simpa only [mul_comm] using hf.mul_const hC
2026-01-11 17:11:30.827 | INFO     | lean_reinforcement.training.trainer:_collect_data:297 - Completed 64/128 proofs
2026-01-11 17:11:39.556 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 2: Applying best tactic: exacts [IsSeparator.isSeparator_of_faithful_of_isSeparator G faithful_of_isSeparator G faithful_of_isSeparator
  faithful_of_isSeparator G faithful_of_isSeparator G faithful_of_isSeparator G faithful_of_isSeparator G
  faithful_of_isSeparator G faithful_of_isSeparator G faithful_of_isSeparator G faithful_of_isSeparator G
  faithful_of_isSeparator G faithful_of_isSeparator G faithful_of_isSeparator G faithful_of_isSeparator G
  faithful_of_isSeparator G faithful_of_isSeparator G faithful_of_isSeparator G faithful_of_isSeparator G
  faithful_of_isSeparator G faithful_of_isSeparator G faithful_of_isSeparator G faithful_of_isSeparator G
  faithful_of_isSeparator G faithful_of_isSeparator G faithful_of_isSeparator G faithful_of_isSeparator G
  faithful_of_isSeparator G faithful_of_isSeparator G faithful_of_isSeparator G faithful_of_isSeparator G
  faithful_of_isSeparator G faithful_of_isSeparator G faithful_of_isSeparator G faithful_of_isSeparator
  faithful_of_isSeparator G faithful_of_isSeparator G faithful_of_
2026-01-11 17:11:39.625 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="<stdin>:10:66: unexpected end of input; expected ']'")
2026-01-11 17:11:39.625 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 2 steps and 495.72s.
2026-01-11 17:11:39.625 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="<stdin>:10:66: unexpected end of input; expected ']'")
2026-01-11 17:11:39.755 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:11:39.755 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:11:48.562 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: List.forall‚ÇÇ_cons
2026-01-11 17:11:53.264 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:11:59.185 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp only [restrict_eq, iInf_subtype']
2026-01-11 17:11:59.252 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='simp made no progress')
2026-01-11 17:11:59.252 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 322.39s.
2026-01-11 17:11:59.252 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='simp made no progress')
2026-01-11 17:11:59.383 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:11:59.383 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:12:07.035 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Stream'.head_even
2026-01-11 17:12:11.528 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:12:26.184 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: simpa only [mul_comm] using mul_left_cancel‚ÇÄ hC.ne' hf
2026-01-11 17:12:28.061 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [‚Üê orderOf_dvd_iff_pow_eq_one, orderOf_dvd_iff_pow_eq_one, orderOf_dvd_iff_pow_eq_one,
  orderOf_dvd_iff_pow_eq_one, orderOf_dvd_iff_pow_eq_one, orderOf_dvd_iff_pow_eq_one,
  orderOf_dvd_iff_pow_eq_one, orderOf_dvd_iff_pow_eq_one, orderOf_dvd_iff_pow_eq_one,
  orderOf_dvd_iff_pow_eq_one, orderOf_dvd_iff_pow_eq_one, orderOf_dvd_iff_pow_eq_one,
  orderOf_dvd_iff_pow_eq_one, orderOf_dvd_iff_pow_eq_one, orderOf_dvd_iff_pow_eq_one,
  orderOf_dvd_iff_pow_eq_one, orderOf_dvd_iff_pow_eq_one, orderOf_dvd_iff_pow_eq_one]
2026-01-11 17:12:28.156 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  ?m.36862 ^ ?m.36863 = 1\nn : ‚Ñï\ninst‚úù : NeZero n\ni : ZMod n\n‚ä¢ orderOf (DihedralGroup.r i) = n / n.gcd i.val")
2026-01-11 17:12:28.156 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 85.30s.
2026-01-11 17:12:28.156 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  ?m.36862 ^ ?m.36863 = 1\nn : ‚Ñï\ninst‚úù : NeZero n\ni : ZMod n\n‚ä¢ orderOf (DihedralGroup.r i) = n / n.gcd i.val")
2026-01-11 17:12:28.286 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:12:28.287 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:12:31.441 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [‚Üê finrank_eq_card_chooseBasisIndex, finrank_eq_card_chooseBasisIndex] at h
2026-01-11 17:12:31.562 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  Fintype.card (Module.Free.ChooseBasisIndex ?R ?M)\nF : Type u_1\nE : Type u_2\ninst‚úù‚Å¥ : CommRing F\ninst‚úù¬≥ : StrongRankCondition F\ninst‚úù¬≤ : Ring E\ninst‚úù¬π : Algebra F E\nS : Subalgebra F E\nh : FiniteDimensional.finrank F ‚Ü•S = 1\ninst‚úù : Module.Free F ‚Ü•S\n‚ä¢ S = ‚ä•")
2026-01-11 17:12:31.562 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 84.50s.
2026-01-11 17:12:31.562 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  Fintype.card (Module.Free.ChooseBasisIndex ?R ?M)\nF : Type u_1\nE : Type u_2\ninst‚úù‚Å¥ : CommRing F\ninst‚úù¬≥ : StrongRankCondition F\ninst‚úù¬≤ : Ring E\ninst‚úù¬π : Algebra F E\nS : Subalgebra F E\nh : FiniteDimensional.finrank F ‚Ü•S = 1\ninst‚úù : Module.Free F ‚Ü•S\n‚ä¢ S = ‚ä•")
2026-01-11 17:12:31.694 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:12:31.694 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:12:34.389 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: NoMinOrder.infinite
2026-01-11 17:12:38.978 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:12:44.584 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Set.Infinite.nonempty
2026-01-11 17:12:49.146 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:13:26.295 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: simpa only [‚Üê tendsto_neg_atTop_iff] using hf.atBot_mul hC
2026-01-11 17:13:27.921 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [forall‚ÇÇ_cons_left_iff, forall‚ÇÇ_cons_right_iff, forall‚ÇÇ_cons_left_iff]
2026-01-11 17:13:28.031 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.45496\nŒ± : Type u_1\nŒ≤ : Type u_2\nŒ≥ : Sort ?u.44496\nŒ¥ : Sort ?u.44498\nr : Œ± ‚Üí Œ≤ ‚Üí Prop\np : Œ≥ ‚Üí Œ¥ ‚Üí Prop\nR : Œ± ‚Üí Œ≤ ‚Üí Prop\na : Œ±\nb : Œ≤\nl‚ÇÅ : List Œ±\nl‚ÇÇ : List Œ≤\n‚ä¢ List.Forall‚ÇÇ R (a :: l‚ÇÅ) (b :: l‚ÇÇ) ‚Üî R a b ‚àß List.Forall‚ÇÇ R l‚ÇÅ l‚ÇÇ")
2026-01-11 17:13:28.031 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 99.47s.
2026-01-11 17:13:28.031 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.45496\nŒ± : Type u_1\nŒ≤ : Type u_2\nŒ≥ : Sort ?u.44496\nŒ¥ : Sort ?u.44498\nr : Œ± ‚Üí Œ≤ ‚Üí Prop\np : Œ≥ ‚Üí Œ¥ ‚Üí Prop\nR : Œ± ‚Üí Œ≤ ‚Üí Prop\na : Œ±\nb : Œ≤\nl‚ÇÅ : List Œ±\nl‚ÇÇ : List Œ≤\n‚ä¢ List.Forall‚ÇÇ R (a :: l‚ÇÅ) (b :: l‚ÇÇ) ‚Üî R a b ‚àß List.Forall‚ÇÇ R l‚ÇÅ l‚ÇÇ")
2026-01-11 17:13:28.162 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:13:28.162 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:13:35.193 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: induction s with
| nil => rfl
| cons x s => rfl
| cons x s =>
  rw [head_cons, head_cons, head_cons, head_cons, head_cons]
| cons x s =>
  rw [head_cons, head_cons, head_cons, head_cons, head_cons, head_cons, head_cons, head_cons]
2026-01-11 17:13:35.279 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'induction' failed, major premise type is not an inductive type \n  ‚Ñï ‚Üí Œ±\nŒ± : Type u\nŒ≤ : Type v\nŒ¥ : Type w\ns : Stream' Œ±\n‚ä¢ s.even.head = s.head")
2026-01-11 17:13:35.279 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 88.24s.
2026-01-11 17:13:35.279 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'induction' failed, major premise type is not an inductive type \n  ‚Ñï ‚Üí Œ±\nŒ± : Type u\nŒ≤ : Type v\nŒ¥ : Type w\ns : Stream' Œ±\n‚ä¢ s.even.head = s.head")
2026-01-11 17:13:35.410 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:13:35.410 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:13:36.537 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: AlgHom.coe_addMonoidHom_injective
2026-01-11 17:13:41.007 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:13:51.262 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [‚Üê WithBot.coe_le_coe, WithBot.coe_le_coe]
2026-01-11 17:13:51.347 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: ContMDiffOn.mul
2026-01-11 17:13:55.925 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:13:55.950 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 2: Running MCTS search for 200 iterations...
2026-01-11 17:13:58.380 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: haveI : Nonempty Œ± := ‚ü®Classical.arbitrary _, Classical.arbitrary _, Classical.arbitrary _,
  Classical.arbitrary _, Classical.not_not.1 (Classical.arbitrary _, Classical.arbitrary _, Classical.arbitrary _,
  Classical.arbitrary _, Classical.arbitrary _, Classical.not_not.1 (Classical.arbitrary _, Classical.arbitrary _,
  Classical.arbitrary _, Classical.not_not.1 (Classical.arbitrary _, Classical.arbitrary _, Classical.arbitrary _,
  Classical.arbitrary _, Classical.arbitrary _‚ü©
2026-01-11 17:13:58.444 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="<stdin>:5:46: expected ')'")
2026-01-11 17:13:58.444 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 84.06s.
2026-01-11 17:13:58.444 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="<stdin>:5:46: expected ')'")
2026-01-11 17:13:58.574 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:13:58.574 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:14:17.522 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: CoxeterSystem.isRightDescent_iff
2026-01-11 17:14:21.988 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:14:33.264 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: exact AddMonoidHomClass.injective_of_injective_of_injective_of_injective_of_injective_of_injective
  AddMonoidHomClass.injective_of_injective_of_injective_of_injective
  AddMonoidHomClass.injective_of_injective_of_injective_of_injective
  AddMonoidHomClass.injective_of_injective_of_injective_of_injective
  AddMonoidHomClass.injective_of_injective_of_injective_of_injective
  AddMonoidHomClass.injective_of_injective_of_injective_of_injective
  AddMonoidHomClass.injective_of_injective_of_injective_of_injective
  AddMonoidHomClass.injective_of_injective_of_injective_of_injective_of_injective
  AddMonoidHomClass.injective_of_injective_of_injective_of_injective
  AddMonoidHomClass.injective_of_injective_of_injective_of_injective_of_injective
  AddMonoidHomClass.injective_of_injective_of_injective_of_injective_of_injective
  AddMonoidHomClass.injective_of_injective_of_injective_of_injective_of_injective
  AddMonoidHomClass.injective_of_injective_of_injective_of_injective
  AddMonoidHomClass.injective_of_injective_o
2026-01-11 17:14:33.342 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="unknown constant 'AddMonoidHomClass.injective_of_injective_of_injective_of_injective_of_injective_of_injective'")
2026-01-11 17:14:33.342 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 56.80s.
2026-01-11 17:14:33.342 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="unknown constant 'AddMonoidHomClass.injective_of_injective_of_injective_of_injective_of_injective_of_injective'")
2026-01-11 17:14:33.472 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:14:33.473 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:14:41.015 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: norm_indicator_eq_indicator_norm
2026-01-11 17:14:45.604 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:14:48.621 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: simpa only [‚Üê tendsto_neg_atTop_iff] using hf.atTop_mul_atBot hC hf
2026-01-11 17:15:40.501 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp only [Set.indicator_apply, norm_indicator_eq_indicator_norm]
2026-01-11 17:15:40.579 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="kernel type check failed: (kernel) declaration has free variables '[anonymous]'")
2026-01-11 17:15:40.579 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 59.56s.
2026-01-11 17:15:40.579 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="kernel type check failed: (kernel) declaration has free variables '[anonymous]'")
2026-01-11 17:15:40.709 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:15:40.709 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:15:48.731 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: simpa only [mul_comm] using hf.mul_const hC
2026-01-11 17:16:03.943 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Filter.eventually_or_distrib_left
2026-01-11 17:16:08.477 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:16:36.021 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: constructor
2026-01-11 17:16:40.898 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 2: Running MCTS search for 200 iterations...
2026-01-11 17:16:48.807 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: simpa only [mul_comm] using mul_left_cancel‚ÇÄ hC.ne' hf
2026-01-11 17:16:50.354 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rintro s ‚ü®hs_meas, hs_nonempty‚ü© ‚ü®hs_meas, hs_nonempty‚ü© ‚ü®hs_meas, hs_nonempty‚ü© ‚ü®hs_meas, hs_nonempty‚ü©
2026-01-11 17:16:50.505 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'introN' failed, insufficient number of binders\ncase intro.none.intro\nŒ± : Type u_1\nŒ≤ : Type u_2\ninst‚úù¬≤ : MeasurableSpace Œ±\ninst‚úù¬π : TopologicalSpace Œ±\nŒº : MeasureTheory.Measure Œ±\np q : Set Œ± ‚Üí Prop\nU s‚úù : Set Œ±\nŒµ r : ‚Ñù‚â•0‚àû\ninst‚úù : Œº.OuterRegular\nH : Œº.InnerRegularWRT p IsOpen\nhd : ‚àÄ ‚¶És U : Set Œ±‚¶Ñ, p s ‚Üí IsOpen U ‚Üí p (s \\ U)\ns : Set Œ±\nhs_meas‚úù : MeasurableSet s\nhs_nonempty‚úù : Œº s ‚â† ‚ä§\nhs_meas : ‚Ñù‚â•0\nhs_nonempty : hs_meas ‚àà none ‚àß ‚àÄ a ‚àà Œº s, hs_meas < a\n‚ä¢ ‚àÉ K ‚äÜ s, p K ‚àß none < Œº K")
2026-01-11 17:16:50.505 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 347.82s.
2026-01-11 17:16:50.505 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'introN' failed, insufficient number of binders\ncase intro.none.intro\nŒ± : Type u_1\nŒ≤ : Type u_2\ninst‚úù¬≤ : MeasurableSpace Œ±\ninst‚úù¬π : TopologicalSpace Œ±\nŒº : MeasureTheory.Measure Œ±\np q : Set Œ± ‚Üí Prop\nU s‚úù : Set Œ±\nŒµ r : ‚Ñù‚â•0‚àû\ninst‚úù : Œº.OuterRegular\nH : Œº.InnerRegularWRT p IsOpen\nhd : ‚àÄ ‚¶És U : Set Œ±‚¶Ñ, p s ‚Üí IsOpen U ‚Üí p (s \\ U)\ns : Set Œ±\nhs_meas‚úù : MeasurableSet s\nhs_nonempty‚úù : Œº s ‚â† ‚ä§\nhs_meas : ‚Ñù‚â•0\nhs_nonempty : hs_meas ‚àà none ‚àß ‚àÄ a ‚àà Œº s, hs_meas < a\n‚ä¢ ‚àÉ K ‚äÜ s, p K ‚àß none < Œº K")
2026-01-11 17:16:50.636 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:16:50.636 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:16:57.384 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: EuclideanDomain.dvd_div_of_mul_dvd
2026-01-11 17:17:01.965 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:17:48.918 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: simpa only [‚Üê tendsto_neg_atTop_iff] using hf.atBot_mul hC
2026-01-11 17:18:06.259 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 2: Applying best tactic: exacts [isPathConnected_iff.mpr ‚ü®isPathConnected_iff.mpr ‚ü®isPathConnected_iff.mpr ‚ü®isPathConnected_iff.mpr ‚ü®isPathConnected_iff.mpr isPathConnected_iff‚ü©,
  isPathConnected_iff.mpr isPathConnected_iff.mpr isPathConnected_iff.mpr ‚ü®isPathConnected_iff.mpr isPathConnected_iff.mpr isPathConnected_iff.mpr ‚ü®isPathConnected_iff.mpr isPathConnected_iff.mpr isPathConnected_iff.mpr ‚ü®isPathConnected_iff.mpr isPathConnected_iff.mpr isPathConnected_iff.mpr ‚ü®isPathConnected_iff.mpr isPathConnected_iff.mpr isPathConnected_iff.mpr ‚ü®isPathConnected_iff.mpr isPathConnected_iff.mpr isPathConnected_iff.mpr ‚ü®isPathConnected_iff.mpr isPathConnected_iff.mpr isPathConnected_iff.mpr ‚ü®isPathConnected_iff.mpr isPathConnected_iff.mpr isPathConnected_iff.mpr ‚ü®isPathConnected_iff.mpr isPathConnected_iff.mpr isPathConnected_iff.mpr ‚ü®isPathConnected_iff.mpr isPathConnected_iff.mpr isPathConnected_iff.mpr ‚ü®isPathConnected_iff.mpr isPathConnected_iff.mpr isPathConnected_iff.mpr isPathConnected_iff.mpr isPathConne
2026-01-11 17:18:06.328 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="<stdin>:2:839: unexpected end of input; expected '‚ü©'")
2026-01-11 17:18:06.328 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 2 steps and 529.93s.
2026-01-11 17:18:06.328 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="<stdin>:2:839: unexpected end of input; expected '‚ü©'")
2026-01-11 17:18:06.459 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:18:06.459 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:18:23.156 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: exact dvd_div_of_mul_dvd h
2026-01-11 17:18:23.229 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="kernel type check failed: (kernel) declaration has free variables '[anonymous]'")
2026-01-11 17:18:23.229 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 85.85s.
2026-01-11 17:18:23.230 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="kernel type check failed: (kernel) declaration has free variables '[anonymous]'")
2026-01-11 17:18:23.359 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:18:23.360 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:18:31.971 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: rexp_neg_image_aux
2026-01-11 17:18:36.666 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:18:41.754 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: MvPolynomial.IsSymmetric.smul
2026-01-11 17:18:46.220 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:19:09.793 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: simpa only [‚Üê mul_assoc] using hf.atBot_mul hC
2026-01-11 17:19:12.649 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simpa only [mul_comm] using hf.mul hg.contMDiffOn
2026-01-11 17:19:12.786 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="invalid field 'contMDiffOn', the environment does not contain 'ContMDiffOn.contMDiffOn'\n  hg\nhas type\n  ContMDiffOn I' I n g s\ninvalid field notation, type is not of the form (C ...) where C is a constant\n  hg\nhas type\n  ‚àÄ x ‚àà s, ContMDiffWithinAt I' I n g s x")
2026-01-11 17:19:12.786 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 321.44s.
2026-01-11 17:19:12.786 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="invalid field 'contMDiffOn', the environment does not contain 'ContMDiffOn.contMDiffOn'\n  hg\nhas type\n  ContMDiffOn I' I n g s\ninvalid field notation, type is not of the form (C ...) where C is a constant\n  hg\nhas type\n  ‚àÄ x ‚àà s, ContMDiffWithinAt I' I n g s x")
2026-01-11 17:19:12.916 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:19:12.916 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:19:21.562 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: List.formPerm_pow_apply_get
2026-01-11 17:19:25.896 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:19:43.547 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [Set.image_comp, Set.image_comp, Set.image_comp, Set.image_comp, Set.image_univ,
  Set.image_univ, Set.image_univ, Set.image_univ, Set.image_univ, Set.image_image]
2026-01-11 17:19:43.646 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  ?f ‚àò ?g '' ?a\nE : Type u_1\ninst‚úù¬π : NormedAddCommGroup E\ninst‚úù : NormedSpace ‚ÑÇ E\n‚ä¢ rexp '' (Neg.neg '' Set.univ) = Set.Ioi 0")
2026-01-11 17:19:43.646 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 71.67s.
2026-01-11 17:19:43.646 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  ?f ‚àò ?g '' ?a\nE : Type u_1\ninst‚úù¬π : NormedAddCommGroup E\ninst‚úù : NormedSpace ‚ÑÇ E\n‚ä¢ rexp '' (Neg.neg '' Set.univ) = Set.Ioi 0")
2026-01-11 17:19:43.776 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:19:43.777 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:19:55.797 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: CategoryTheory.unmop_rightUnitor
2026-01-11 17:20:00.283 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:20:09.904 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: simpa only [mul_comm] using hf.atBot_mul hg
2026-01-11 17:20:40.192 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp_rw [IsSymmetric, Algebra.algebraMap_eq_smul_one, Algebra.algebraMap_eq_smul_one,
  Algebra.algebraMap_eq_smul_one, Algebra.algebraMap_eq_smul_one, Algebra.algebraMap_eq_smul_one,
  Algebra.algebraMap_eq_smul_one, Algebra.algebraMap_eq_smul_one, Algebra.algebraMap_eq_smul_one,
  Algebra.algebraMap_eq_smul_one, Algebra.algebraMap_eq_smul_one, Algebra.algebraMap_eq_smul_one,
  Algebra.algebraMap_eq_smul_one, Algebra.algebraMap_eq_smul_one, Algebra.algebraMap_eq_smul_one,
  Algebra.algebraMap_eq_smul_one, Algebra.algebraMap_eq_smul_one, Algebra.algebraMap_eq_smul_one,
  Algebra.algebraMap_eq_smul_one, Algebra.algebraMap_eq_smul_one, Algebra.algebraMap_eq_smul_one,
  Algebra.algebraMap_eq_smul_one, Algebra.algebraMap_eq_smul_one, Algebra.algebraMap_eq_smul_one,
  Algebra.algebraMap_eq_smul_one, Algebra.algebraMap_eq_smul_one, Algebra.algebraMap_eq_smul_one,
  Algebra.algebraMap_eq_smul_one, Algebra.algebraMap_eq_smul_one, Algebra.algebraMap_eq_smul_one,
  Algebra.algebraMap_eq_smul_one, Algebra.algebraMap_eq
2026-01-11 17:20:40.261 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="<stdin>:11:55: unexpected end of input; expected ']'")
2026-01-11 17:20:40.261 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 118.51s.
2026-01-11 17:20:40.261 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="<stdin>:11:55: unexpected end of input; expected ']'")
2026-01-11 17:20:40.391 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:20:40.391 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:20:48.326 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: MvQPF.Cofix.bisim'
2026-01-11 17:20:52.676 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:21:10.015 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: simpa only [mul_comm] using hf.atTop_mul_const hC hf
2026-01-11 17:21:28.796 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp only [formPerm_apply_get _ h, Nat.mod_add_mod, Nat.mod_eq_of_lt (Nat.lt_succ_self _),
  Nat.mod_eq_of_lt (Nat.lt_succ_self _), Nat.mod_eq_of_lt (Nat.lt_succ_self _),
  Nat.mod_eq_of_lt (Nat.lt_succ_self _), Nat.mod_eq_of_lt (Nat.lt_succ_self _),
  Nat.mod_eq_of_lt (Nat.lt_succ_self _), Nat.mod_eq_of_lt (Nat.lt_succ_self _),
  Nat.mod_eq_of_lt (Nat.lt_succ_self _), Nat.mod_eq_of_lt (Nat.lt_succ_self _),
  Nat.mod_eq_of_lt (Nat.lt_succ_self _), Nat.mod_eq_of_lt (Nat.lt_succ_self _),
  Nat.mod_eq_of_lt (Nat.lt_succ_self _), Nat.mod_eq_of_lt (Nat.lt_succ_self _),
  Nat.mod_eq_of_lt (Nat.lt_succ_self _), Nat.mod_eq_of_lt (Nat.lt_succ_self _),
  Nat.mod_eq_of_lt (Nat.lt_succ_self _), Nat.mod_eq_of_lt (Nat.lt_succ_self _),
  Nat.mod_eq_of_lt (Nat.lt_succ_self _), Nat.mod_eq_of_lt (Nat.lt_succ_self _),
  Nat.mod_eq_of_lt (Nat.lt_succ_self _), Nat.mod_eq_of_lt (Nat.lt_succ_self _),
  Nat.mod_eq_of_lt (Nat.lt_succ_self _), Nat.mod_eq_of_lt (Nat.lt_succ_self _),
  Nat.mod_eq_of_lt (Nat.lt_succ_self _)]
2026-01-11 17:21:28.871 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='simp made no progress')
2026-01-11 17:21:28.871 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 127.31s.
2026-01-11 17:21:28.871 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='simp made no progress')
2026-01-11 17:21:29.001 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:21:29.001 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:21:56.526 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: UpperSet.coe_erase
2026-01-11 17:22:01.097 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:22:10.072 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: simpa only [‚Üê tendsto_neg_atTop_iff] using hf.atTop_mul_const hC hf
2026-01-11 17:22:43.280 | INFO     | lean_reinforcement.training.trainer:_collect_data:297 - Completed 80/128 proofs
2026-01-11 17:22:52.190 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [‚Üê unmop_comp, unmop_comp, unmop_comp, unmop_comp, ‚Üê unmop_comp, ‚Üê unmop_comp,
  ‚Üê unmop_comp, ‚Üê unmop_comp, ‚Üê unmop_comp, ‚Üê unmop_comp, ‚Üê unmop_comp, ‚Üê unmop_comp,
  ‚Üê unmop_comp, ‚Üê unmop_comp, ‚Üê unmop_comp, ‚Üê unmop_comp, ‚Üê unmop_comp, ‚Üê unmop_comp,
  ‚Üê unmop_comp, ‚Üê unmop_comp, ‚Üê unmop_comp, ‚Üê unmop_comp, ‚Üê unmop_comp, ‚Üê unmop_comp,
  ‚Üê unmop_comp, ‚Üê unmop_comp, ‚Üê unmop_comp, ‚Üê unmop_comp, ‚Üê unmop_comp, ‚Üê unmop_comp,
  ‚Üê unmop_comp, ‚Üê unmop_comp, ‚Üê unmop_comp, ‚Üê unmop_comp, ‚Üê unmop_comp, ‚Üê unmop_comp,
  ‚Üê unmop_comp, ‚Üê unmop_comp, ‚Üê unmop_comp, ‚Üê unmop_comp, ‚Üê unmop_comp, ‚Üê unmop_comp,
  ‚Üê unmop_comp, ‚Üê unmop_comp, ‚Üê unmop_comp, ‚Üê unmop_comp, ‚Üê unmop_comp, ‚Üê unmop_comp,
  ‚Üê unmop_comp, ‚Üê unmop_comp, ‚Üê unmop_comp, ‚Üê unmop_comp, ‚Üê unmop_comp, ‚Üê unmop_comp,
  ‚Üê unmop_comp, ‚Üê unmop_comp, ‚Üê unmop_comp, ‚Üê unmop_comp, ‚Üê unmop_comp, ‚Üê unmop_comp,
  ‚Üê unmop_comp, ‚Üê unmop_comp, ‚Üê unmop_comp, ‚Üê
2026-01-11 17:22:52.256 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='<stdin>:11:45: unexpected end of input')
2026-01-11 17:22:52.257 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 176.46s.
2026-01-11 17:22:52.257 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='<stdin>:11:45: unexpected end of input')
2026-01-11 17:22:52.387 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:22:52.387 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:23:02.230 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Fin.init_def
2026-01-11 17:23:07.128 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:23:31.650 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: simpa only [‚Üê mul_assoc] using hf.atBot_mul hC
2026-01-11 17:24:31.761 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: simpa only [mul_comm] using hf.atBot_mul hg
2026-01-11 17:24:50.098 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: refine ‚ü®fun h =>?_, fun h => Primcodable.of_uncurry_left‚ü©
2026-01-11 17:24:50.166 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="unknown constant 'Primcodable.of_uncurry_left'")
2026-01-11 17:24:50.166 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 2052.23s.
2026-01-11 17:24:50.166 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="unknown constant 'Primcodable.of_uncurry_left'")
2026-01-11 17:24:50.297 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:24:50.297 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:25:06.864 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Set.smul_neg
2026-01-11 17:25:11.356 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:25:31.872 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: simpa only [mul_comm] using hf.atTop_mul_const hC hf
2026-01-11 17:25:44.377 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [init_eq_castSucc_iff, init_eq_castSucc_iff]
2026-01-11 17:25:44.501 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.34539\nm n‚úù : ‚Ñï\nŒ±‚úù : Fin (n‚úù + 1) ‚Üí Type u\nx : Œ±‚úù (Fin.last n‚úù)\nq‚úù : (i : Fin (n‚úù + 1)) ‚Üí Œ±‚úù i\np : (i : Fin n‚úù) ‚Üí Œ±‚úù i.castSucc\ni : Fin n‚úù\ny : Œ±‚úù i.castSucc\nz : Œ±‚úù (Fin.last n‚úù)\nn : ‚Ñï\nŒ± : Fin (n + 1) ‚Üí Type u_1\nq : (i : Fin (n + 1)) ‚Üí Œ± i\n‚ä¢ (Fin.init fun k => q k) = fun k => q k.castSucc")
2026-01-11 17:25:44.501 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 162.27s.
2026-01-11 17:25:44.501 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.34539\nm n‚úù : ‚Ñï\nŒ±‚úù : Fin (n‚úù + 1) ‚Üí Type u\nx : Œ±‚úù (Fin.last n‚úù)\nq‚úù : (i : Fin (n‚úù + 1)) ‚Üí Œ±‚úù i\np : (i : Fin n‚úù) ‚Üí Œ±‚úù i.castSucc\ni : Fin n‚úù\ny : Œ±‚úù i.castSucc\nz : Œ±‚úù (Fin.last n‚úù)\nn : ‚Ñï\nŒ± : Fin (n + 1) ‚Üí Type u_1\nq : (i : Fin (n + 1)) ‚Üí Œ± i\n‚ä¢ (Fin.init fun k => q k) = fun k => q k.castSucc")
2026-01-11 17:25:44.632 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:25:44.632 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:26:14.631 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: ProbabilityTheory.kernel.swapLeft_apply'
2026-01-11 17:26:17.033 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 2: Applying best tactic: rw [‚Üê WithBot.coe_le_coe, WithBot.coe_le_coe]
2026-01-11 17:26:19.405 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:26:21.428 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 3: Running MCTS search for 200 iterations...
2026-01-11 17:26:31.984 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: simpa only [‚Üê tendsto_neg_atTop_iff] using hf.atTop_mul_const hC hf
2026-01-11 17:27:10.700 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp [smul_def]
2026-01-11 17:27:10.773 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='simp made no progress')
2026-01-11 17:27:10.773 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 123.91s.
2026-01-11 17:27:10.773 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='simp made no progress')
2026-01-11 17:27:10.904 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:27:10.904 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:27:32.501 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: ContinuousMap.setOfTop_eq_univ
2026-01-11 17:27:36.776 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:27:53.061 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: simpa only [‚Üê tendsto_neg_atTop_iff] using hf.atTop_mul_atBot hC hf
2026-01-11 17:28:14.740 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [swapLeft_apply]
2026-01-11 17:28:14.813 | SUCCESS  | lean_reinforcement.agent.runner:run:217 - Proof finished in 1 steps and 120.18s.
2026-01-11 17:28:14.943 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:28:14.943 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:28:19.181 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [nonempty_iff_ne_empty]
2026-01-11 17:28:21.951 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Set.Ioi_add_bij
2026-01-11 17:28:24.137 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 2: Running MCTS search for 200 iterations...
2026-01-11 17:28:26.606 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:28:53.156 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: simpa only [mul_comm] using hf.mul_const hC
2026-01-11 17:29:53.265 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: simpa only [mul_comm] using mul_left_cancel‚ÇÄ hC.ne' hf
2026-01-11 17:30:48.700 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp [hitting, if_pos h]
2026-01-11 17:30:53.376 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: simpa only [‚Üê tendsto_neg_atTop_iff] using hf.atBot_mul hC
2026-01-11 17:30:53.506 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 2: Running MCTS search for 200 iterations...
2026-01-11 17:31:01.283 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simpa only [add_comm] using bijOn_id (a + d)
2026-01-11 17:31:01.405 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='type mismatch\n  h‚úù\nhas type\n  Set.BijOn id (sorryAx (Set ?m.15040) true) (sorryAx (Set ?m.15040) true) : Prop\nbut is expected to have type\n  Set.BijOn (fun x => d + x) (Set.Ioi a) (Set.Ioi (a + d)) : Prop')
2026-01-11 17:31:01.405 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 159.45s.
2026-01-11 17:31:01.405 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='type mismatch\n  h‚úù\nhas type\n  Set.BijOn id (sorryAx (Set ?m.15040) true) (sorryAx (Set ?m.15040) true) : Prop\nbut is expected to have type\n  Set.BijOn (fun x => d + x) (Set.Ioi a) (Set.Ioi (a + d)) : Prop')
2026-01-11 17:31:01.535 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:31:01.535 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:31:26.287 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Filter.frequently_top
2026-01-11 17:31:31.097 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:32:14.917 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: simpa only [‚Üê tendsto_neg_atTop_iff] using hf.atTop_mul_atBot hC hf
2026-01-11 17:32:18.013 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: induction' s using Quotient.inductionOn with s
2026-01-11 17:32:22.698 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 2: Running MCTS search for 200 iterations...
2026-01-11 17:32:58.077 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: filter_upwards [hf.bddAbove_range_iff_bddBelow_range hbdd] with œâ hœâ htop using
  not_tendsto_atTop_atBot
2026-01-11 17:32:58.154 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="unknown identifier 'not_tendsto_atTop_atBot'")
2026-01-11 17:32:58.154 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 1507.47s.
2026-01-11 17:32:58.154 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="unknown identifier 'not_tendsto_atTop_atBot'")
2026-01-11 17:32:58.285 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:32:58.285 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:33:00.132 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 2: Applying best tactic: simp (config := { contextual := true }) only [Set.mem_inter_iff, Set.mem_setOf_eq, and_imp,
  forall_exists_index, and_imp, forall_apply_eq_imp_iff‚ÇÇ, and_imp, forall_exists_index,
  and_imp, forall_apply_eq_imp_iff‚ÇÇ, and_imp, forall_exists_index, and_imp, forall_apply_eq_imp_iff‚ÇÇ,
  and_imp, forall_exists_index, and_imp, forall_apply_eq_imp_iff‚ÇÇ, and_imp, forall_exists_index,
  and_imp, forall_apply_eq_imp_iff‚ÇÇ, and_imp, forall_exists_index, and_imp]
2026-01-11 17:33:00.207 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='simp made no progress')
2026-01-11 17:33:00.207 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 2 steps and 2177.29s.
2026-01-11 17:33:00.207 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='simp made no progress')
2026-01-11 17:33:00.339 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:33:00.339 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:33:07.322 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Filter.coe_pureOneHom
2026-01-11 17:33:10.046 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: AlgHom.toLinearMap_apply
2026-01-11 17:33:12.168 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:33:14.664 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:33:14.970 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: simpa only [mul_comm] using hf.mul_const hC
2026-01-11 17:34:15.039 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: simpa only [mul_comm] using mul_left_cancel‚ÇÄ hC.ne' hf
2026-01-11 17:34:45.563 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 2: Applying best tactic: simp only [quot_mk_to_coe, formPerm_coe]
2026-01-11 17:34:45.627 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='simp made no progress')
2026-01-11 17:34:45.627 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 2 steps and 1949.06s.
2026-01-11 17:34:45.627 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='simp made no progress')
2026-01-11 17:34:45.758 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:34:45.758 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:34:53.189 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Finset.measurableSet
2026-01-11 17:34:57.695 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:35:15.094 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: simpa only [‚Üê tendsto_neg_atTop_iff] using hf.atBot_mul hC
2026-01-11 17:35:45.202 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [AlgHom.toLinearMap_apply, AlgHom.toLinearMap_apply, AlgHom.toRingHom_eq_coe,
  AlgHom.coe_toRingHom, AlgHom.coe_toRingHom, AlgHom.coe_toRingHom, AlgHom.coe_toRingHom,
  AlgHom.coe_toRingHom, AlgHom.coe_toRingHom, AlgHom.coe_toRingHom, AlgHom.coe_toRingHom,
  AlgHom.coe_toRingHom, AlgHom.coe_toRingHom, AlgHom.coe_toRingHom, AlgHom.coe_toRingHom,
  AlgHom.coe_toRingHom, AlgHom.coe_toRingHom, AlgHom.coe_toRingHom, AlgHom.coe_toRingHom,
  AlgHom.coe_toRingHom, AlgHom.coe_toRingHom, AlgHom.coe_toRingHom, AlgHom.coe_toRingHom,
  AlgHom.coe_toRingHom, AlgHom.coe_toRingHom, AlgHom.coe_toRingHom, AlgHom.coe_toRingHom,
  AlgHom.coe_toRingHom, AlgHom.coe_toRingHom, AlgHom.coe_toRingHom, AlgHom.coe_toRingHom,
  AlgHom.coe_toRingHom, AlgHom.coe_toRingHom, AlgHom.coe_toRingHom, AlgHom.coe_toRingHom,
  AlgHom.coe_toRingHom, AlgHom.coe_toRingHom, AlgHom.coe_toRingHom, AlgHom.coe_toRingHom,
  AlgHom.coe_toRingHom, AlgHom.coe_toRingHom, AlgHom.coe_toRingHom, AlgHom.coe_toRingHom,
  AlgHom.coe_toRingHom, AlgHom.coe_toRingH
2026-01-11 17:35:45.270 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="<stdin>:12:42: unexpected end of input; expected ']'")
2026-01-11 17:35:45.270 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 155.22s.
2026-01-11 17:35:45.270 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="<stdin>:12:42: unexpected end of input; expected ']'")
2026-01-11 17:35:45.400 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:35:45.401 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:35:45.618 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [‚Üê principal_singleton, ‚Üê principal_singleton, ‚Üê principal_singleton, ‚Üê principal_singleton,
  ‚Üê principal_singleton, ‚Üê principal_singleton, ‚Üê principal_singleton, ‚Üê principal_singleton,
  ‚Üê principal_singleton, ‚Üê principal_singleton, ‚Üê principal_singleton]
2026-01-11 17:35:45.721 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  pure ?a\nF : Type u_1\nŒ± : Type u_2\nŒ≤ : Type u_3\nŒ≥ : Type u_4\nŒ¥ : Type u_5\nŒµ : Type u_6\ninst‚úù : One Œ±\nf : Filter Œ±\ns : Set Œ±\n‚ä¢ ‚áëFilter.pureOneHom = pure")
2026-01-11 17:35:45.721 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 158.40s.
2026-01-11 17:35:45.721 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  pure ?a\nF : Type u_1\nŒ± : Type u_2\nŒ≤ : Type u_3\nŒ≥ : Type u_4\nŒ¥ : Type u_5\nŒµ : Type u_6\ninst‚úù : One Œ±\nf : Filter Œ±\ns : Set Œ±\n‚ä¢ ‚áëFilter.pureOneHom = pure")
2026-01-11 17:35:45.853 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:35:45.853 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:35:54.649 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Filter.HasBasis.to_hasBasis'
2026-01-11 17:35:57.869 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: IsUnifLocDoublingMeasure.exists_measure_closedBall_le_mul
2026-01-11 17:35:59.272 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:36:02.707 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:36:35.790 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: simpa only [‚Üê mul_assoc] using hf.atBot_mul hC
2026-01-11 17:37:35.901 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: simpa only [mul_comm] using hf.atBot_mul hg
2026-01-11 17:37:37.593 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [Set.eq_univ_iff_forall, setOfIdeal_top]
2026-01-11 17:37:37.699 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.297364\nX : Type u_1\nR : Type u_2\ninst‚úù‚Å¥ : TopologicalSpace X\ninst‚úù¬≥ : Semiring R\ninst‚úù¬≤ : TopologicalSpace R\ninst‚úù¬π : TopologicalSemiring R\ninst‚úù : Nontrivial R\n‚ä¢ ‚àÄ (x : X), x ‚àà ContinuousMap.setOfIdeal ‚ä§")
2026-01-11 17:37:37.700 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 605.20s.
2026-01-11 17:37:37.700 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.297364\nX : Type u_1\nR : Type u_2\ninst‚úù‚Å¥ : TopologicalSpace X\ninst‚úù¬≥ : Semiring R\ninst‚úù¬≤ : TopologicalSpace R\ninst‚úù¬π : TopologicalSemiring R\ninst‚úù : Nontrivial R\n‚ä¢ ‚àÄ (x : X), x ‚àà ContinuousMap.setOfIdeal ‚ä§")
2026-01-11 17:37:37.830 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:37:37.831 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:37:45.499 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [hasBasis_iff_hasBasis, hasBasis_iff_hasBasis] at hl ‚ä¢
2026-01-11 17:37:45.623 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.15259\nŒ± : Type u_1\nŒ≤ : Type u_2\nŒ≥ : Type u_3\nŒπ : Sort u_4\nŒπ' : Sort u_5\nl l' : Filter Œ±\np : Œπ ‚Üí Prop\ns : Œπ ‚Üí Set Œ±\nt : Set Œ±\ni : Œπ\np' : Œπ' ‚Üí Prop\ns' : Œπ' ‚Üí Set Œ±\ni' : Œπ'\nhl : l.HasBasis p s\nh : ‚àÄ (i : Œπ), p i ‚Üí ‚àÉ i', p' i' ‚àß s' i' ‚äÜ s i\nh' : ‚àÄ (i' : Œπ'), p' i' ‚Üí s' i' ‚àà l\n‚ä¢ l.HasBasis p' s'")
2026-01-11 17:37:45.623 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 110.97s.
2026-01-11 17:37:45.623 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.15259\nŒ± : Type u_1\nŒ≤ : Type u_2\nŒ≥ : Type u_3\nŒπ : Sort u_4\nŒπ' : Sort u_5\nl l' : Filter Œ±\np : Œπ ‚Üí Prop\ns : Œπ ‚Üí Set Œ±\nt : Set Œ±\ni : Œπ\np' : Œπ' ‚Üí Prop\ns' : Œπ' ‚Üí Set Œ±\ni' : Œπ'\nhl : l.HasBasis p s\nh : ‚àÄ (i : Œπ), p i ‚Üí ‚àÉ i', p' i' ‚àß s' i' ‚äÜ s i\nh' : ‚àÄ (i' : Œπ'), p' i' ‚Üí s' i' ‚àà l\n‚ä¢ l.HasBasis p' s'")
2026-01-11 17:37:45.754 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:37:45.754 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:37:48.252 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: AlgEquiv.leftInverse_symm
2026-01-11 17:37:52.591 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:37:56.530 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: CategoryTheory.Limits.factorThruKernelSubobject_comp_kernelSubobjectIso
2026-01-11 17:38:01.277 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:38:10.797 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: constructor
2026-01-11 17:38:15.376 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 2: Running MCTS search for 200 iterations...
2026-01-11 17:38:16.089 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 2: Applying best tactic: rintro rfl
2026-01-11 17:38:20.820 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 3: Running MCTS search for 200 iterations...
2026-01-11 17:38:36.011 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: simpa only [mul_comm] using hf.atTop_mul_const hC hf
2026-01-11 17:39:28.753 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp [factorThruKernelSubobjectIso]
2026-01-11 17:39:28.822 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='simp made no progress')
2026-01-11 17:39:28.822 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 92.29s.
2026-01-11 17:39:28.823 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='simp made no progress')
2026-01-11 17:39:28.954 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:39:28.954 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:39:30.833 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp only [disjoint_iff_inf_le, h.mem_iff, compl_mem_comap]
2026-01-11 17:39:32.857 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp [Function.LeftInverse, Function.LeftInverse, Function.LeftInverse]
2026-01-11 17:39:32.927 | SUCCESS  | lean_reinforcement.agent.runner:run:217 - Proof finished in 1 steps and 104.68s.
2026-01-11 17:39:33.059 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:39:33.059 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:39:35.910 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 2: Running MCTS search for 200 iterations...
2026-01-11 17:39:36.122 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: simpa only [‚Üê tendsto_neg_atTop_iff] using hf.atTop_mul_const hC hf
2026-01-11 17:39:39.236 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Pi.card_Ioi
2026-01-11 17:39:41.065 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: IsMax.Ici_eq
2026-01-11 17:39:43.686 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:39:45.766 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:40:11.836 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 3: Applying best tactic: exact not_infinite_empty h
2026-01-11 17:40:11.902 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="unknown identifier 'not_infinite_empty'")
2026-01-11 17:40:11.902 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 3 steps and 1647.32s.
2026-01-11 17:40:11.902 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="unknown identifier 'not_infinite_empty'")
2026-01-11 17:40:12.032 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:40:12.033 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:40:17.812 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 2: Applying best tactic: exacts [isRightDescent_iff.mpr ‚ü®i, rfl‚ü©, isRightDescent_iff.mpr ‚ü®i, rfl‚ü©, isRightDescent_iff.mpr ‚ü®i, rfl‚ü©,
  isRightDescent_iff.mpr ‚ü®i, rfl‚ü©, isRightDescent_iff.mpr ‚ü®i, rfl‚ü©, isRightDescent_iff.mpr ‚ü®i, rfl‚ü©,
  isRightDescent_iff.mpr ‚ü®i, rfl‚ü©, isRightDescent_iff.mpr ‚ü®i, rfl‚ü©, isRightDescent_iff.mpr ‚ü®i, rfl‚ü©]
2026-01-11 17:40:17.924 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='type mismatch\n  isRightDescent_iff.mpr (sorryAx (cs.length (?m.159972 * cs.simple ?m.159973) + 1 = cs.length ?m.159972) true)\nhas type\n  cs.IsRightDescent ?m.159972 ?m.159973 : Prop\nbut is expected to have type\n  cs.IsRightDescent w i ‚Üí cs.length (w * cs.simple i) + 1 = cs.length w : Prop')
2026-01-11 17:40:17.924 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 2 steps and 1560.40s.
2026-01-11 17:40:17.924 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='type mismatch\n  isRightDescent_iff.mpr (sorryAx (cs.length (?m.159972 * cs.simple ?m.159973) + 1 = cs.length ?m.159972) true)\nhas type\n  cs.IsRightDescent ?m.159972 ?m.159973 : Prop\nbut is expected to have type\n  cs.IsRightDescent w i ‚Üí cs.length (w * cs.simple i) + 1 = cs.length w : Prop')
2026-01-11 17:40:18.054 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:40:18.054 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:40:27.850 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: SimpleGraph.Walk.mem_darts_reverse
2026-01-11 17:40:32.543 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:40:36.402 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: CategoryTheory.Functor.isEquivalence_of_iso
2026-01-11 17:40:40.889 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:40:58.073 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: simpa only [‚Üê mul_assoc] using hf.atBot_mul hC
2026-01-11 17:41:31.976 | INFO     | lean_reinforcement.training.trainer:_collect_data:297 - Completed 96/128 proofs
2026-01-11 17:41:46.811 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [card_eq_sum_ones, card_eq_sum_ones, card_eq_sum_ones, card_erase_of_mem (mem_univ _),
  card_erase_of_mem (mem_univ _), card_erase_of_mem (mem_univ _), card_erase_of_mem (mem_univ _),
  card_erase_of_mem (mem_univ _), card_erase_of_mem (mem_univ _), card_erase_of_mem (mem_univ _),
  card_erase_of_mem (mem_univ _), card_erase_of_mem (mem_univ _), card_erase_of_mem (mem_univ _),
  card_erase_of_mem (mem_univ _), card_erase_of_mem (mem_univ _), card_erase_of_mem (mem_univ _),
  card_erase_of_mem (mem_univ _), card_erase_of_mem (mem_univ _), card_erase_of_mem (mem_univ _),
  card_erase_of_mem (mem_univ _), card_erase_of_mem (mem_univ _), card_erase_of_mem (mem_univ _),
  card_erase_of_mem (mem_univ _), card_erase_of_mem (mem_univ _), card_erase_of_mem (mem_univ _),
  card_erase_of_mem (mem_univ _), card_erase_of_mem (mem_univ _), card_erase_of_mem (mem_univ _),
  card_erase_of_mem (mem_univ _), card_erase_of_mem (mem_univ _), card_erase_of_mem (mem_univ _),
  card_erase_of_mem (mem_univ _)]
2026-01-11 17:41:46.934 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.24753\nŒπ : Type u_1\nŒ± : Œπ ‚Üí Type u_2\ninst‚úù‚Å¥ : Fintype Œπ\ninst‚úù¬≥ : DecidableEq Œπ\ninst‚úù¬≤ : (i : Œπ) ‚Üí DecidableEq (Œ± i)\ninst‚úù¬π : (i : Œπ) ‚Üí PartialOrder (Œ± i)\ninst‚úù : (i : Œπ) ‚Üí LocallyFiniteOrderTop (Œ± i)\na : (i : Œπ) ‚Üí Œ± i\n‚ä¢ (Finset.Ioi a).card = ‚àè i : Œπ, (Finset.Ici (a i)).card - 1")
2026-01-11 17:41:46.934 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 127.70s.
2026-01-11 17:41:46.934 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.24753\nŒπ : Type u_1\nŒ± : Œπ ‚Üí Type u_2\ninst‚úù‚Å¥ : Fintype Œπ\ninst‚úù¬≥ : DecidableEq Œπ\ninst‚úù¬≤ : (i : Œπ) ‚Üí DecidableEq (Œ± i)\ninst‚úù¬π : (i : Œπ) ‚Üí PartialOrder (Œ± i)\ninst‚úù : (i : Œπ) ‚Üí LocallyFiniteOrderTop (Œ± i)\na : (i : Œπ) ‚Üí Œ± i\n‚ä¢ (Finset.Ioi a).card = ‚àè i : Œπ, (Finset.Ici (a i)).card - 1")
2026-01-11 17:41:47.065 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:41:47.065 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:41:53.365 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [Ici_eq_singleton_of_isMax h, Ici_eq_singleton_of_isMax h]
2026-01-11 17:41:53.451 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.53171\nŒ± : Type u_1\nŒ≤ : Type u_2\ninst‚úù : PartialOrder Œ±\na b c : Œ±\nh : IsMax a\n‚ä¢ Set.Ici a = {a}")
2026-01-11 17:41:53.452 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 132.39s.
2026-01-11 17:41:53.452 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.53171\nŒ± : Type u_1\nŒ≤ : Type u_2\ninst‚úù : PartialOrder Œ±\na b c : Œ±\nh : IsMax a\n‚ä¢ Set.Ici a = {a}")
2026-01-11 17:41:53.582 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:41:53.582 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:41:58.124 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: simpa only [mul_comm] using hf.atBot_mul hg
2026-01-11 17:42:02.252 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: dslope_sub_smul
2026-01-11 17:42:05.346 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: AffineEquiv.toAffineMap_injective
2026-01-11 17:42:06.683 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:42:09.918 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:42:44.554 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp only [mem_darts, List.mem_reverse, List.mem_append, List.mem_map, List.mem_map,
  forall_exists_index, and_imp, forall_apply_eq_imp_iff‚ÇÇ, and_imp, forall_exists_index,
  and_imp, forall_apply_eq_imp_iff‚ÇÇ, forall_exists_index, and_imp, forall_apply_eq_imp_iff‚ÇÇ,
  List.mem_map, forall_exists_index, and_imp, forall_apply_eq_imp_iff‚ÇÇ, List.mem_map,
  forall_exists_index, and_imp, forall_exists_index, and_imp, forall_apply_eq_imp_iff‚ÇÇ,
  forall_exists_index, and_imp, forall_exists_index, and_imp, forall_apply_eq_imp_iff‚ÇÇ,
  forall_exists_index, and_imp, forall_exists_index, and_imp, forall_apply_eq_imp_iff‚ÇÇ,
  forall_exists_index, and_imp, forall_exists_index, and_imp, forall_apply_eq_imp_iff‚ÇÇ,
  forall_exists_index, and_imp, forall_exists_index, and_imp, forall_apply_eq_imp_iff‚ÇÇ,
  forall_exists_index, and_imp, forall_exists_index, and_imp, forall_apply_eq_imp_iff‚ÇÇ,
  forall_exists_index, and_imp, forall_apply_eq_imp_iff‚ÇÇ]
2026-01-11 17:42:44.631 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='simp made no progress')
2026-01-11 17:42:44.631 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 136.78s.
2026-01-11 17:42:44.631 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='simp made no progress')
2026-01-11 17:42:44.761 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:42:44.761 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:42:45.950 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: exact IsEquivalence.of_arrow_iso e.symm
2026-01-11 17:42:46.034 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='invalid field notation, type is not of the form (C ...) where C is a constant\n  IsEquivalence\nhas type\n  ?m.120333 ‚•§ ?m.120353 ‚Üí Prop')
2026-01-11 17:42:46.034 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 129.63s.
2026-01-11 17:42:46.034 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='invalid field notation, type is not of the form (C ...) where C is a constant\n  IsEquivalence\nhas type\n  ?m.120333 ‚•§ ?m.120353 ‚Üí Prop')
2026-01-11 17:42:46.165 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:42:46.166 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:42:54.752 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: neg_smul
2026-01-11 17:42:58.235 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: simpa only [mul_comm] using hf.atTop_mul_const hC hf
2026-01-11 17:42:59.262 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:42:59.303 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: LieSubmodule.Quotient.range_mk'
2026-01-11 17:43:03.994 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:43:32.323 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp [Filter.Frequently]
2026-01-11 17:43:32.419 | SUCCESS  | lean_reinforcement.agent.runner:run:217 - Proof finished in 1 steps and 726.13s.
2026-01-11 17:43:32.549 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:43:32.549 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:43:40.365 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: PFun.preimage_union
2026-01-11 17:43:44.918 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:43:58.346 | WARNING  | lean_reinforcement.utilities.gym:run_tactic_stateless:81 - Tactic timed out: simpa only [‚Üê tendsto_neg_atTop_iff] using hf.atTop_mul_const hC hf
2026-01-11 17:43:58.347 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simpa only [mul_comm] using hf.mul hg
2026-01-11 17:44:18.804 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='type mismatch\n  h‚úù\nhas type\n  ?m.1587527 ‚àà Filter.map (fun x => f x * ?m.1449427 x) l : Prop\nbut is expected to have type\n  Filter.Tendsto (fun x => -(f x * g x)) l Filter.atTop : Prop')
2026-01-11 17:44:18.804 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 3052.54s.
2026-01-11 17:44:18.804 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='type mismatch\n  h‚úù\nhas type\n  ?m.1587527 ‚àà Filter.map (fun x => f x * ?m.1449427 x) l : Prop\nbut is expected to have type\n  Filter.Tendsto (fun x => -(f x * g x)) l Filter.atTop : Prop')
2026-01-11 17:44:18.834 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:44:23.346 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:44:28.179 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: coinduced_compose
2026-01-11 17:44:30.534 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: exact AffineMap.injective_of_injective_of_injective_of_injective_of_injective_of_injective
  AffineSubspace.injective_of_injective_of_injective_of_injective_of_injective
  AffineSpace.injective_of_injective_of_injective_of_injective_of_injective_of_injective
  AffineSpace.injective_of_injective_of_injective_of_injective_of_injective_of_injective
  AffineSpace.injective_of_injective_of_injective_of_injective_of_injective_of_injective
  AffineSpace.injective_of_injective_of_injective_of_injective_of_injective_of_injective
  AffineSpace.injective_of_injective_of_injective_of_injective_of_injective_of_injective
  AffineSpace.injective_of_injective_of_injective_of_injective_of_injective_of_injective
  AffineSpace.injective_of_injective_of_injective_of_injective_of_injective_of_injective
  AffineSpace.injective_of_injective_of_injective_of_injective_of_injective_of_injective
  AffineSpace.injective_of_injective_of_injective_of_injective_of_injective_of_injective
  AffineSpace.injective_of_injective_of_injective_of
2026-01-11 17:44:30.611 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="unknown constant 'AffineMap.injective_of_injective_of_injective_of_injective_of_injective_of_injective'")
2026-01-11 17:44:30.611 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 145.27s.
2026-01-11 17:44:30.611 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="unknown constant 'AffineMap.injective_of_injective_of_injective_of_injective_of_injective_of_injective'")
2026-01-11 17:44:30.743 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:44:30.743 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:44:32.934 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:44:45.129 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 3: Applying best tactic: rw [‚Üê WithBot.coe_le_coe, WithBot.coe_le_coe]
2026-01-11 17:44:49.465 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: ZeroAtInftyContinuousMap.isometry_toBCF
2026-01-11 17:44:49.627 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 4: Running MCTS search for 200 iterations...
2026-01-11 17:44:54.107 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:45:20.978 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [‚Üê image_union, image_union, image_union, image_union]
2026-01-11 17:45:21.085 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  ?f.image ?s ‚à™ ?f.image ?t\nŒ± : Type u_1\nŒ≤ : Type u_2\nŒ≥ : Type u_3\nŒ¥ : Type u_4\nŒµ : Type u_5\nŒπ : Type u_6\nf : Œ± ‚Üí. Œ≤\ns t : Set Œ≤\n‚ä¢ f.preimage (s ‚à™ t) = f.preimage s ‚à™ f.preimage t")
2026-01-11 17:45:21.085 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 100.72s.
2026-01-11 17:45:21.085 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  ?f.image ?s ‚à™ ?f.image ?t\nŒ± : Type u_1\nŒ≤ : Type u_2\nŒ≥ : Type u_3\nŒ¥ : Type u_4\nŒµ : Type u_5\nŒπ : Type u_6\nf : Œ± ‚Üí. Œ≤\ns t : Set Œ≤\n‚ä¢ f.preimage (s ‚à™ t) = f.preimage s ‚à™ f.preimage t")
2026-01-11 17:45:21.215 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:45:21.215 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:45:33.144 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: exists_pow_ne_one_of_isCyclic
2026-01-11 17:45:37.701 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:46:07.685 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: infer_instance
2026-01-11 17:46:07.752 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='type class instance expected\n  MeasurableSet ‚Üës')
2026-01-11 17:46:07.752 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 674.56s.
2026-01-11 17:46:07.753 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='type class instance expected\n  MeasurableSet ‚Üës')
2026-01-11 17:46:07.884 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:46:07.884 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:46:13.817 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [TopologicalSpace.coinduced, TopologicalSpace.topologicalSpace_coinduced,
  TopologicalSpace.topologicalSpace_coinduced, TopologicalSpace.topologicalSpace_coinduced,
  TopologicalSpace.topologicalSpace_coinduced, TopologicalSpace.topologicalSpace_coinduced,
  TopologicalSpace.topologicalSpace_coinduced, TopologicalSpace.topologicalSpace_coinduced,
  TopologicalSpace.topologicalSpace_coinduced, TopologicalSpace.topologicalSpace_coinduced,
  TopologicalSpace.topologicalSpace_coinduced, TopologicalSpace.topologicalSpace_coinduced,
  TopologicalSpace.topologicalSpace_coinduced, TopologicalSpace.topologicalSpace_coinduced,
  TopologicalSpace.topologicalSpace_coinduced, TopologicalSpace.topologicalSpace_coinduced,
  TopologicalSpace.topologicalSpace_coinduced, TopologicalSpace.topologicalSpace_coinduced,
  TopologicalSpace.topologicalSpace_coinduced, TopologicalSpace.topologicalSpace_coinduced,
  TopologicalSpace.topologicalSpace_coinduced, TopologicalSpace.topologicalSpace_coinduced]
2026-01-11 17:46:13.943 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.28138\nŒ± : Type u_1\nŒ≤ : Type u_2\nŒ≥ : Type u_3\nt t‚ÇÅ t‚ÇÇ : TopologicalSpace Œ±\nt' : TopologicalSpace Œ≤\nf‚úù : Œ± ‚Üí Œ≤\ng‚úù : Œ≤ ‚Üí Œ±\ntŒ± : TopologicalSpace Œ±\nf : Œ± ‚Üí Œ≤\ng : Œ≤ ‚Üí Œ≥\n‚ä¢ { IsOpen := fun s => IsOpen (g ‚Åª¬π' s), isOpen_univ := ‚ãØ, isOpen_inter := ‚ãØ, isOpen_sUnion := ‚ãØ } =\n    TopologicalSpace.coinduced (g ‚àò f) tŒ±")
2026-01-11 17:46:13.943 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 105.76s.
2026-01-11 17:46:13.944 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.28138\nŒ± : Type u_1\nŒ≤ : Type u_2\nŒ≥ : Type u_3\nt t‚ÇÅ t‚ÇÇ : TopologicalSpace Œ±\nt' : TopologicalSpace Œ≤\nf‚úù : Œ± ‚Üí Œ≤\ng‚úù : Œ≤ ‚Üí Œ±\ntŒ± : TopologicalSpace Œ±\nf : Œ± ‚Üí Œ≤\ng : Œ≤ ‚Üí Œ≥\n‚ä¢ { IsOpen := fun s => IsOpen (g ‚Åª¬π' s), isOpen_univ := ‚ãØ, isOpen_inter := ‚ãØ, isOpen_sUnion := ‚ãØ } =\n    TopologicalSpace.coinduced (g ‚àò f) tŒ±")
2026-01-11 17:46:14.074 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:46:14.074 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:46:15.204 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: commProb_eq_zero_of_infinite
2026-01-11 17:46:19.809 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:46:21.413 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Relation.cutExpand_pair_left
2026-01-11 17:46:25.924 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:47:05.734 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp only [Filter.Eventually, eventually_and]
2026-01-11 17:47:06.487 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp only [Isometry.toBCF_eq_closedBall, isometry_subtype_closedBall, closedBall_subset_closedBall,
  closedBall_subset_closedBall, closedBall_subset_closedBall, closedBall_subset_closedBall,
  closedBall_subset_closedBall, closedBall_subset_closedBall, closedBall_subset_closedBall,
  closedBall_subset_closedBall, closedBall_subset_closedBall, closedBall_subset_closedBall,
  closedBall_subset_closedBall, closedBall_subset_closedBall, closedBall_subset_closedBall,
  closedBall_subset_closedBall, closedBall_subset_closedBall, closedBall_subset_closedBall,
  closedBall_subset_closedBall, closedBall_subset_closedBall, closedBall_subset_closedBall,
  closedBall_subset_closedBall, closedBall_subset_closedBall, closedBall_subset_closedBall,
  closedBall_subset_closedBall, closedBall_subset_closedBall, closedBall_subset_closedBall,
  closedBall_subset_closedBall, closedBall_subset_closedBall, closedBall_subset_closedBall,
  closedBall_subset_closedBall, closedBall_subset_closedBall, closedBall_subset_closedBall,
  c
2026-01-11 17:47:06.556 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="<stdin>:12:3: unexpected end of input; expected ']'")
2026-01-11 17:47:06.557 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 137.09s.
2026-01-11 17:47:06.557 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="<stdin>:12:3: unexpected end of input; expected ']'")
2026-01-11 17:47:06.689 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:47:06.689 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:47:10.297 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 2: Running MCTS search for 200 iterations...
2026-01-11 17:47:19.707 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: LieSubalgebra.inf_coe
2026-01-11 17:47:24.312 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:47:56.535 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp [commProb_def]
2026-01-11 17:47:56.623 | SUCCESS  | lean_reinforcement.agent.runner:run:217 - Proof finished in 1 steps and 101.42s.
2026-01-11 17:47:56.754 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:47:56.754 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:48:06.440 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [‚Üê LieSubmodule.coe_toSubmodule_eq_iff, ‚Üê LieSubmodule.coe_toSubmodule_eq_iff,
  LieSubmodule.top_coeSubmodule]
2026-01-11 17:48:06.572 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  ?N = ?N'\nR : Type u\nL : Type v\nM : Type w\ninst‚úù‚Å∂ : CommRing R\ninst‚úù‚Åµ : LieRing L\ninst‚úù‚Å¥ : LieAlgebra R L\ninst‚úù¬≥ : AddCommGroup M\ninst‚úù¬≤ : Module R M\ninst‚úù¬π : LieRingModule L M\ninst‚úù : LieModule R L M\nN N' : LieSubmodule R L M\nI J : LieIdeal R L\n‚ä¢ ‚Üë(LieSubmodule.Quotient.mk' N).range = ‚Üë‚ä§")
2026-01-11 17:48:06.572 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 307.27s.
2026-01-11 17:48:06.572 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  ?N = ?N'\nR : Type u\nL : Type v\nM : Type w\ninst‚úù‚Å∂ : CommRing R\ninst‚úù‚Åµ : LieRing L\ninst‚úù‚Å¥ : LieAlgebra R L\ninst‚úù¬≥ : AddCommGroup M\ninst‚úù¬≤ : Module R M\ninst‚úù¬π : LieRingModule L M\ninst‚úù : LieModule R L M\nN N' : LieSubmodule R L M\nI J : LieIdeal R L\n‚ä¢ ‚Üë(LieSubmodule.Quotient.mk' N).range = ‚Üë‚ä§")
2026-01-11 17:48:06.702 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:48:06.703 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:48:14.837 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: MeasureTheory.FiniteMeasure.smul_apply
2026-01-11 17:48:17.965 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp [CutExpand, insert_subset_iff, insert_subset_iff, insert_subset_iff, insert_subset_iff,
  insert_subset_iff, insert_subset_iff, insert_subset_iff, insert_subset_iff, insert_subset_iff,
  insert_subset_iff, insert_subset_iff, insert_subset_iff, insert_subset_iff, insert_subset_iff,
  insert_subset_iff, insert_subset_iff, insert_subset_iff, insert_subset_iff, insert_subset_iff,
  insert_subset_iff, insert_subset_iff, insert_subset_iff, insert_subset_iff, insert_subset_iff,
  insert_subset_iff, insert_subset_iff, insert_subset_iff, insert_subset_iff, insert_subset_iff,
  insert_subset_iff, insert_subset_iff, insert_subset_iff, insert_subset_iff, insert_subset_iff,
  insert_subset_iff, insert_subset_iff, insert_subset_iff, insert_subset_iff, insert_subset_iff,
  insert_subset_iff, insert_subset_iff, insert_subset_iff, insert_subset_iff, insert_subset_iff,
  insert_subset_iff, insert_subset_iff, insert_subset_iff, insert_subset_iff, insert_subset_iff,
  insert_subset_iff, insert_subset_iff, insert_subset_iff
2026-01-11 17:48:18.034 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="<stdin>:11:57: unexpected end of input; expected ']'")
2026-01-11 17:48:18.035 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 116.62s.
2026-01-11 17:48:18.035 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="<stdin>:11:57: unexpected end of input; expected ']'")
2026-01-11 17:48:18.167 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:48:18.167 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:48:19.598 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:48:40.461 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Complex.hasSum_taylorSeries_log
2026-01-11 17:48:44.965 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:49:12.797 | ERROR    | lean_reinforcement.utilities.gym:reset:41 - Error during environment reset: Timeout during initialization
2026-01-11 17:49:12.797 | ERROR    | lean_reinforcement.training.worker:process_theorem:44 - Failed to initialize environment for theorem NonUnitalStarSubalgebra.mem_center_iff: Timeout during initialization
2026-01-11 17:49:13.086 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:49:26.551 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Finset.inv_eq_empty
2026-01-11 17:49:31.308 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2026-01-11 17:49:36.373 | INFO     | lean_reinforcement.training.trainer:_collect_data:297 - Completed 112/128 proofs
2026-01-11 17:49:45.595 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 2: Applying best tactic: simp only [or_and_right, exists_or, exists_eq_right', exists_eq_right', exists_eq_right',
  exists_eq_right', exists_eq_right', exists_eq_right', exists_eq_right', exists_eq_right',
  exists_eq_right', exists_eq_right', exists_eq_right', exists_eq_right', exists_eq_right',
  exists_eq_right', exists_eq_right', exists_eq_right', exists_eq_right', exists_eq_right',
  exists_eq_right', exists_eq_right', exists_eq_right', exists_eq_right', exists_eq_right',
  exists_eq_right', exists_eq_right', exists_eq_right', exists_eq_right', exists_eq_right',
  exists_eq_right', exists_eq_right', exists_eq_right', exists_eq_right', exists_eq_right',
  exists_eq_right', exists_eq_right', exists_eq_right', exists_eq_right', exists_eq_right',
  exists_eq_right', exists_eq_right', exists_eq_right', exists_eq_right', exists_eq_right',
  exists_eq_right', exists_eq_right', exists_eq_right', exists_eq_right', exists_eq_right',
  exists_eq_right', exists_eq_right', exists_eq_right', exists_eq_right', exists_eq_right',
  exists_eq_r
2026-01-11 17:49:45.664 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="<stdin>:12:13: unexpected end of input; expected ']'")
2026-01-11 17:49:45.664 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 2 steps and 2021.72s.
2026-01-11 17:49:45.664 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="<stdin>:12:13: unexpected end of input; expected ']'")
2026-01-11 17:49:45.795 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:49:45.795 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:49:48.335 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [LieSubalgebra.coe_inf, LieSubalgebra.coe_to_submodule, LieSubalgebra.coe_to_submodule,
  LieSubalgebra.coe_to_submodule, LieSubalgebra.coe_to_submodule, LieSubalgebra.coe_to_submodule,
  LieSubalgebra.coe_to_submodule, LieSubalgebra.coe_to_submodule, LieSubalgebra.coe_to_submodule,
  LieSubalgebra.coe_to_submodule, LieSubalgebra.coe_to_submodule, LieSubalgebra.coe_to_submodule,
  LieSubalgebra.coe_to_submodule, LieSubalgebra.coe_to_submodule, LieSubalgebra.coe_to_submodule,
  LieSubalgebra.coe_to_submodule, LieSubalgebra.coe_to_submodule, LieSubalgebra.coe_to_submodule,
  LieSubalgebra.coe_to_submodule, LieSubalgebra.coe_to_submodule, LieSubalgebra.coe_to_submodule,
  LieSubalgebra.coe_to_submodule, LieSubalgebra.coe_to_submodule, LieSubalgebra.coe_to_submodule,
  LieSubalgebra.coe_to_submodule, LieSubalgebra.coe_to_submodule, LieSubalgebra.coe_to_submodule,
  LieSubalgebra.coe_to_submodule, LieSubalgebra.coe_to_submodule, LieSubalgebra.coe_to_submodule,
  LieSubalgebra.coe_to_submodule, LieSubalgebra.co
2026-01-11 17:49:48.404 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="<stdin>:11:50: unexpected end of input; expected ']'")
2026-01-11 17:49:48.404 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 148.70s.
2026-01-11 17:49:48.404 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="<stdin>:11:50: unexpected end of input; expected ']'")
2026-01-11 17:49:48.535 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:49:48.536 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:50:38.230 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: have : HasSum (fun n : ‚Ñ§ ‚Ü¶ (-1 : ‚ÑÇ) ^ (n + 1) * z ^ n / ‚Üën) (log (1 + z)) := by
  rw [‚Üê hasSum_nat_add_iff' 1]
  exact ((hasSum_nat_add_iff' 1).mpr (hasSum_nat_add_iff' 1)).mpr (hasSum_nat_add_iff' 1)
    ((hasSum_nat_add_iff' 1).mpr (hasSum_nat_add_iff' 1).mpr (hasSum_nat_add_iff' 1).mpr
    (hasSum_nat_add_iff' 1).mpr (hasSum_nat_add_iff' 1).mpr (hasSum_nat_add_iff' 1).mpr
    (hasSum_nat_add_iff' 1).mpr (hasSum_nat_add_iff' 1).mpr (hasSum_nat_add_iff' 1).mpr
    (hasSum_nat_add_iff' 1).mpr (hasSum_nat_add_iff' 1).mpr (hasSum_nat_add_iff' 1).mpr
    (hasSum_nat_add_iff' 1).mpr (hasSum_nat_add_iff' 1).mpr (hasSum_nat_add_iff' 1).mpr
    (hasSum_nat_add_iff' 1).mpr (hasSum_nat_add_iff' 1).mpr (hasSum_nat_add_iff' 1).mpr
    (hasSum_nat_add_iff' 1).mpr (hasSum_nat_add_iff' 1).mpr (hasSum_nat_add_iff' 1).mpr
    (hasSum_nat_add_iff' 1).mpr (hasSum_nat_add_iff' 1).mpr (hasSum_nat_add_iff' 1).mpr
    (hasSum_nat_add_iff' 1).mpr (hasSum_nat_add_iff' 1).mpr (hasSum_nat_add_iff' 1).mpr (hasSum_nat_add_iff
2026-01-11 17:50:38.302 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="<stdin>:12:107: unexpected end of input; expected ')', ',' or ':'")
2026-01-11 17:50:38.302 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 117.84s.
2026-01-11 17:50:38.302 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="<stdin>:12:107: unexpected end of input; expected ')', ',' or ':'")
2026-01-11 17:50:38.433 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:50:38.433 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:51:14.383 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: obtain ‚ü®a, ha‚ü© := G_cyclic k k_pos k_lt_card_G
2026-01-11 17:51:14.454 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='rcases tactic failed: x‚úù : ?m.86077 is not an inductive datatype')
2026-01-11 17:51:14.454 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 341.31s.
2026-01-11 17:51:14.454 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='rcases tactic failed: x‚úù : ?m.86077 is not an inductive datatype')
2026-01-11 17:51:14.584 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:51:14.585 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:52:53.365 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp only [smul_apply, ENNReal.smul_def]
2026-01-11 17:52:53.455 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="kernel type check failed: (kernel) declaration has free variables '[anonymous]'")
2026-01-11 17:52:53.456 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 278.62s.
2026-01-11 17:52:53.456 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="kernel type check failed: (kernel) declaration has free variables '[anonymous]'")
2026-01-11 17:52:53.586 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:52:53.586 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:53:04.058 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: intro x hx
2026-01-11 17:53:07.186 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp only [neg_smul, smul_neg, neg_neg]
2026-01-11 17:53:07.266 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="kernel type check failed: (kernel) declaration has free variables '[anonymous]'")
2026-01-11 17:53:07.267 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 612.51s.
2026-01-11 17:53:07.267 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="kernel type check failed: (kernel) declaration has free variables '[anonymous]'")
2026-01-11 17:53:07.398 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:53:07.399 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:53:08.739 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 2: Running MCTS search for 200 iterations...
2026-01-11 17:54:02.393 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp [TendstoUniformlyOn, Tendsto]
2026-01-11 17:54:02.433 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 4: Applying best tactic: rw [‚Üê WithBot.coe_le_coe, WithBot.coe_le_coe]
2026-01-11 17:54:07.095 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 2: Running MCTS search for 200 iterations...
2026-01-11 17:54:07.328 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 5: Running MCTS search for 200 iterations...
2026-01-11 17:54:23.631 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 2: Applying best tactic: simp [UniformSpace.eventually_nhds_iff]
2026-01-11 17:54:23.713 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='simp made no progress')
2026-01-11 17:54:23.713 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 2 steps and 2603.40s.
2026-01-11 17:54:23.713 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='simp made no progress')
2026-01-11 17:54:23.843 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:54:23.843 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:58:06.344 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 5: Applying best tactic: rw [‚Üê WithBot.coe_le_coe, WithBot.coe_le_coe]
2026-01-11 17:58:06.487 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 2: Applying best tactic: simp only [le_bot_iff, exists_prop]
2026-01-11 17:58:10.096 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [inv_eq_empty_iff, eq_empty_iff_forall_not_mem]
2026-01-11 17:58:10.194 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.2201791\nF : Type u_1\nŒ± : Type u_2\nŒ≤ : Type u_3\nŒ≥ : Type u_4\ninst‚úù¬π : DecidableEq Œ±\ninst‚úù : Inv Œ±\ns s‚ÇÅ s‚ÇÇ t t‚ÇÅ t‚ÇÇ u : Finset Œ±\na b : Œ±\n‚ä¢ s‚Åª¬π = ‚àÖ ‚Üî s = ‚àÖ")
2026-01-11 17:58:10.194 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 523.64s.
2026-01-11 17:58:10.194 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.2201791\nF : Type u_1\nŒ± : Type u_2\nŒ≤ : Type u_3\nŒ≥ : Type u_4\ninst‚úù¬π : DecidableEq Œ±\ninst‚úù : Inv Œ±\ns s‚ÇÅ s‚ÇÇ t t‚ÇÅ t‚ÇÇ u : Finset Œ±\na b : Œ±\n‚ä¢ s‚Åª¬π = ‚àÖ ‚Üî s = ‚àÖ")
2026-01-11 17:58:10.327 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:58:10.327 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:58:10.987 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 6: Running MCTS search for 200 iterations...
2026-01-11 17:58:11.844 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 3: Running MCTS search for 200 iterations...
2026-01-11 17:59:12.283 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rcases exists_seq_strictAnti_tendsto (0 : ‚Ñù) with ‚ü®C, C_pos, hC‚ü©
2026-01-11 17:59:12.795 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 6: Applying best tactic: rw [‚Üê WithBot.coe_le_coe, WithBot.coe_le_coe]
2026-01-11 17:59:17.383 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 7: Running MCTS search for 200 iterations...
2026-01-11 17:59:17.417 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 2: Running MCTS search for 200 iterations...
2026-01-11 17:59:30.121 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 3: Applying best tactic: simp only [inf_eq_bot_iff, h.mem_inf_principal_inf_principal_inf_principal_inf_principal,
  h.mem_inf_principal_inf_principal_inf_principal_inf_principal, h.mem_inf_principal_inf_principal_inf_principal_inf_principal,
  h.mem_inf_principal_inf_principal_inf_principal_inf_principal, h.mem_inf_principal_inf_principal_inf_principal_inf_principal_inf_principal,
  h.mem_inf_principal_inf_principal_inf_principal_inf_principal_inf_principal_inf_principal_inf_principal_inf_principal,
  h.mem_inf_principal_inf_principal_inf_principal_inf_principal_inf_principal_inf_principal_inf_principal_inf_principal,
  h.mem_inf_principal_inf_principal_inf_principal_inf_principal, h.mem_inf_principal_inf_principal_inf_principal,
  h.mem_inf_principal_inf_principal_inf_principal_inf_principal_inf_principal_inf_principal,
  h.mem_inf_principal_inf_principal_inf_principal_inf_principal, h.mem_inf_principal_inf_principal_inf_principal,
  h.mem_inf_principal_inf_principal_inf_principal_inf_principal_inf_principal_inf_principal_inf_prin
2026-01-11 17:59:30.189 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="<stdin>:9:100: unexpected end of input; expected ']'")
2026-01-11 17:59:30.189 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 3 steps and 4262.21s.
2026-01-11 17:59:30.189 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="<stdin>:9:100: unexpected end of input; expected ']'")
2026-01-11 17:59:30.319 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:59:30.319 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:59:34.348 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 2: Applying best tactic: refine ‚ü®C, eventually_of_forall fun n =>?_‚ü©
2026-01-11 17:59:34.448 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='application type mismatch\n  Exists.intro C\nargument\n  C\nhas type\n  ‚Ñï ‚Üí ‚Ñù : Type\nbut is expected to have type\n  ‚Ñù‚â•0 : Type')
2026-01-11 17:59:34.449 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 2 steps and 1416.58s.
2026-01-11 17:59:34.449 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='application type mismatch\n  Exists.intro C\nargument\n  C\nhas type\n  ‚Ñï ‚Üí ‚Ñù : Type\nbut is expected to have type\n  ‚Ñù‚â•0 : Type')
2026-01-11 17:59:34.580 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 17:59:34.580 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2026-01-11 18:00:05.939 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 7: Applying best tactic: rw [‚Üê WithBot.coe_le_coe, WithBot.coe_le_coe]
2026-01-11 18:00:10.425 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 8: Running MCTS search for 200 iterations...
2026-01-11 18:01:28.421 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 8: Applying best tactic: rw [‚Üê WithBot.coe_le_coe, WithBot.coe_le_coe]
2026-01-11 18:01:32.853 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 9: Running MCTS search for 200 iterations...
2026-01-11 18:02:13.768 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 9: Applying best tactic: rw [‚Üê WithBot.coe_le_coe, WithBot.coe_le_coe]
2026-01-11 18:02:18.196 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 10: Running MCTS search for 200 iterations...
2026-01-11 18:02:25.899 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: push_cast
2026-01-11 18:02:30.402 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 2: Running MCTS search for 200 iterations...
2026-01-11 18:03:10.768 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 10: Applying best tactic: rw [‚Üê WithBot.coe_le_coe, WithBot.coe_le_coe]
2026-01-11 18:03:15.192 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 11: Running MCTS search for 200 iterations...
2026-01-11 18:03:27.822 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 2: Applying best tactic: rcases h x hx with ‚ü®a', f', f'_eq‚ü©
2026-01-11 18:03:32.586 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 3: Running MCTS search for 200 iterations...
2026-01-11 18:04:43.551 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 11: Applying best tactic: rw [‚Üê WithBot.coe_le_coe, WithBot.coe_le_coe]
2026-01-11 18:04:47.976 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 12: Running MCTS search for 200 iterations...
2026-01-11 18:06:02.983 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 12: Applying best tactic: rw [‚Üê WithBot.coe_le_coe, WithBot.coe_le_coe]
2026-01-11 18:06:07.454 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 13: Running MCTS search for 200 iterations...
2026-01-11 18:06:57.843 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 3: Applying best tactic: cases' f'_eq with f‚ÇÄ f‚ÇÅ
2026-01-11 18:07:02.385 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 4: Running MCTS search for 200 iterations...
2026-01-11 18:07:18.539 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 13: Applying best tactic: rw [‚Üê WithBot.coe_le_coe, WithBot.coe_le_coe]
2026-01-11 18:07:23.134 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 14: Running MCTS search for 200 iterations...
2026-01-11 18:08:31.069 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 14: Applying best tactic: rw [‚Üê WithBot.coe_le_coe, WithBot.coe_le_coe]
2026-01-11 18:08:35.652 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 15: Running MCTS search for 200 iterations...
2026-01-11 18:09:39.139 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 15: Applying best tactic: rw [‚Üê WithBot.coe_le_coe, WithBot.coe_le_coe]
2026-01-11 18:09:43.547 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 16: Running MCTS search for 200 iterations...
2026-01-11 18:09:54.408 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 4: Applying best tactic: rcases f‚ÇÅ with ‚ü®f‚ÇÅ, hf‚ÇÅ, hf‚ÇÅ, hf‚ÇÇ‚ü©
2026-01-11 18:09:59.119 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 5: Running MCTS search for 200 iterations...
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
[2026-01-11T18:10:08.785] error: *** JOB 18239904 ON gcn19 CANCELLED AT 2026-01-11T18:10:08 DUE to SIGNAL Terminated ***
[2026-01-11T18:10:08.785] error: *** STEP 18239904.0 ON gcn19 CANCELLED AT 2026-01-11T18:10:08 DUE to SIGNAL Terminated ***
