============================================================================================== 
Warning! Mixing Conda and module environments may lead to corruption of the
user environment. 
We do not recommend users mixing those two environments unless absolutely
necessary. Note that 
SURF does not provide any support for Conda environment.
For more information, please refer to our software policy page:
https://servicedesk.surf.nl/wiki/display/WIKI/Software+policy+Snellius#SoftwarepolicySnellius-UseofAnacondaandMinicondaenvironmentsonSnellius 

Remember that many packages have already been installed on the system and can
be loaded using 
the 'module load <package__name>' command. If you are uncertain if a package is
already available 
on the system, please use 'module avail' or 'module spider' to search for it.
============================================================================================== 
Building Cython extensions...
Compiling lean_reinforcement/agent/mcts/mcts_cy/base_mcts_cy.pyx because it changed.
Compiling lean_reinforcement/agent/mcts/mcts_cy/alphazero_cy.pyx because it changed.
Compiling lean_reinforcement/agent/mcts/mcts_cy/guidedrollout_cy.pyx because it changed.
Compiling ReProver/common_cy.pyx because it changed.
[1/4] Cythonizing ReProver/common_cy.pyx
[2/4] Cythonizing lean_reinforcement/agent/mcts/mcts_cy/alphazero_cy.pyx
[3/4] Cythonizing lean_reinforcement/agent/mcts/mcts_cy/base_mcts_cy.pyx
[4/4] Cythonizing lean_reinforcement/agent/mcts/mcts_cy/guidedrollout_cy.pyx
running build_ext
building 'lean_reinforcement.agent.mcts.mcts_cy.base_mcts_cy' extension
creating build/temp.linux-x86_64-cpython-310/lean_reinforcement/agent/mcts/mcts_cy
/home/gkoopman/.conda/envs/lean-reinforcement/bin/x86_64-conda-linux-gnu-cc -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/gkoopman/.conda/envs/lean-reinforcement/include -I/home/gkoopman/.conda/envs/lean-reinforcement/targets/x86_64-linux/include -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/gkoopman/.conda/envs/lean-reinforcement/include -I/home/gkoopman/.conda/envs/lean-reinforcement/targets/x86_64-linux/include -fPIC -I/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/numpy/_core/include -I/home/gkoopman/.conda/envs/lean-reinforcement/include/python3.10 -c lean_reinforcement/agent/mcts/mcts_cy/base_mcts_cy.c -o build/temp.linux-x86_64-cpython-310/lean_reinforcement/agent/mcts/mcts_cy/base_mcts_cy.o -O3
creating build/lib.linux-x86_64-cpython-310/lean_reinforcement/agent/mcts/mcts_cy
/home/gkoopman/.conda/envs/lean-reinforcement/bin/x86_64-conda-linux-gnu-cc -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/home/gkoopman/.conda/envs/lean-reinforcement/lib -Wl,-rpath-link,/home/gkoopman/.conda/envs/lean-reinforcement/lib -L/home/gkoopman/.conda/envs/lean-reinforcement/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/home/gkoopman/.conda/envs/lean-reinforcement/lib -Wl,-rpath-link,/home/gkoopman/.conda/envs/lean-reinforcement/lib -L/home/gkoopman/.conda/envs/lean-reinforcement/lib -Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,--disable-new-dtags -Wl,--gc-sections -Wl,--allow-shlib-undefined -Wl,-rpath,/home/gkoopman/.conda/envs/lean-reinforcement/lib -Wl,-rpath-link,/home/gkoopman/.conda/envs/lean-reinforcement/lib -L/home/gkoopman/.conda/envs/lean-reinforcement/lib -L/home/gkoopman/.conda/envs/lean-reinforcement/targets/x86_64-linux/lib -L/home/gkoopman/.conda/envs/lean-reinforcement/targets/x86_64-linux/lib/stubs -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/gkoopman/.conda/envs/lean-reinforcement/include -I/home/gkoopman/.conda/envs/lean-reinforcement/targets/x86_64-linux/include -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/gkoopman/.conda/envs/lean-reinforcement/include -I/home/gkoopman/.conda/envs/lean-reinforcement/targets/x86_64-linux/include build/temp.linux-x86_64-cpython-310/lean_reinforcement/agent/mcts/mcts_cy/base_mcts_cy.o -o build/lib.linux-x86_64-cpython-310/lean_reinforcement/agent/mcts/mcts_cy/base_mcts_cy.cpython-310-x86_64-linux-gnu.so
building 'lean_reinforcement.agent.mcts.mcts_cy.alphazero_cy' extension
/home/gkoopman/.conda/envs/lean-reinforcement/bin/x86_64-conda-linux-gnu-cc -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/gkoopman/.conda/envs/lean-reinforcement/include -I/home/gkoopman/.conda/envs/lean-reinforcement/targets/x86_64-linux/include -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/gkoopman/.conda/envs/lean-reinforcement/include -I/home/gkoopman/.conda/envs/lean-reinforcement/targets/x86_64-linux/include -fPIC -I/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/numpy/_core/include -I/home/gkoopman/.conda/envs/lean-reinforcement/include/python3.10 -c lean_reinforcement/agent/mcts/mcts_cy/alphazero_cy.c -o build/temp.linux-x86_64-cpython-310/lean_reinforcement/agent/mcts/mcts_cy/alphazero_cy.o -O3
/home/gkoopman/.conda/envs/lean-reinforcement/bin/x86_64-conda-linux-gnu-cc -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/home/gkoopman/.conda/envs/lean-reinforcement/lib -Wl,-rpath-link,/home/gkoopman/.conda/envs/lean-reinforcement/lib -L/home/gkoopman/.conda/envs/lean-reinforcement/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/home/gkoopman/.conda/envs/lean-reinforcement/lib -Wl,-rpath-link,/home/gkoopman/.conda/envs/lean-reinforcement/lib -L/home/gkoopman/.conda/envs/lean-reinforcement/lib -Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,--disable-new-dtags -Wl,--gc-sections -Wl,--allow-shlib-undefined -Wl,-rpath,/home/gkoopman/.conda/envs/lean-reinforcement/lib -Wl,-rpath-link,/home/gkoopman/.conda/envs/lean-reinforcement/lib -L/home/gkoopman/.conda/envs/lean-reinforcement/lib -L/home/gkoopman/.conda/envs/lean-reinforcement/targets/x86_64-linux/lib -L/home/gkoopman/.conda/envs/lean-reinforcement/targets/x86_64-linux/lib/stubs -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/gkoopman/.conda/envs/lean-reinforcement/include -I/home/gkoopman/.conda/envs/lean-reinforcement/targets/x86_64-linux/include -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/gkoopman/.conda/envs/lean-reinforcement/include -I/home/gkoopman/.conda/envs/lean-reinforcement/targets/x86_64-linux/include build/temp.linux-x86_64-cpython-310/lean_reinforcement/agent/mcts/mcts_cy/alphazero_cy.o -o build/lib.linux-x86_64-cpython-310/lean_reinforcement/agent/mcts/mcts_cy/alphazero_cy.cpython-310-x86_64-linux-gnu.so
building 'lean_reinforcement.agent.mcts.mcts_cy.guidedrollout_cy' extension
/home/gkoopman/.conda/envs/lean-reinforcement/bin/x86_64-conda-linux-gnu-cc -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/gkoopman/.conda/envs/lean-reinforcement/include -I/home/gkoopman/.conda/envs/lean-reinforcement/targets/x86_64-linux/include -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/gkoopman/.conda/envs/lean-reinforcement/include -I/home/gkoopman/.conda/envs/lean-reinforcement/targets/x86_64-linux/include -fPIC -I/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/numpy/_core/include -I/home/gkoopman/.conda/envs/lean-reinforcement/include/python3.10 -c lean_reinforcement/agent/mcts/mcts_cy/guidedrollout_cy.c -o build/temp.linux-x86_64-cpython-310/lean_reinforcement/agent/mcts/mcts_cy/guidedrollout_cy.o -O3
/home/gkoopman/.conda/envs/lean-reinforcement/bin/x86_64-conda-linux-gnu-cc -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/home/gkoopman/.conda/envs/lean-reinforcement/lib -Wl,-rpath-link,/home/gkoopman/.conda/envs/lean-reinforcement/lib -L/home/gkoopman/.conda/envs/lean-reinforcement/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/home/gkoopman/.conda/envs/lean-reinforcement/lib -Wl,-rpath-link,/home/gkoopman/.conda/envs/lean-reinforcement/lib -L/home/gkoopman/.conda/envs/lean-reinforcement/lib -Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,--disable-new-dtags -Wl,--gc-sections -Wl,--allow-shlib-undefined -Wl,-rpath,/home/gkoopman/.conda/envs/lean-reinforcement/lib -Wl,-rpath-link,/home/gkoopman/.conda/envs/lean-reinforcement/lib -L/home/gkoopman/.conda/envs/lean-reinforcement/lib -L/home/gkoopman/.conda/envs/lean-reinforcement/targets/x86_64-linux/lib -L/home/gkoopman/.conda/envs/lean-reinforcement/targets/x86_64-linux/lib/stubs -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/gkoopman/.conda/envs/lean-reinforcement/include -I/home/gkoopman/.conda/envs/lean-reinforcement/targets/x86_64-linux/include -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/gkoopman/.conda/envs/lean-reinforcement/include -I/home/gkoopman/.conda/envs/lean-reinforcement/targets/x86_64-linux/include build/temp.linux-x86_64-cpython-310/lean_reinforcement/agent/mcts/mcts_cy/guidedrollout_cy.o -o build/lib.linux-x86_64-cpython-310/lean_reinforcement/agent/mcts/mcts_cy/guidedrollout_cy.cpython-310-x86_64-linux-gnu.so
building 'ReProver.common_cy' extension
creating build/temp.linux-x86_64-cpython-310/ReProver
/home/gkoopman/.conda/envs/lean-reinforcement/bin/x86_64-conda-linux-gnu-cc -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/gkoopman/.conda/envs/lean-reinforcement/include -I/home/gkoopman/.conda/envs/lean-reinforcement/targets/x86_64-linux/include -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/gkoopman/.conda/envs/lean-reinforcement/include -I/home/gkoopman/.conda/envs/lean-reinforcement/targets/x86_64-linux/include -fPIC -I/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/numpy/_core/include -I/home/gkoopman/.conda/envs/lean-reinforcement/include/python3.10 -c ReProver/common_cy.c -o build/temp.linux-x86_64-cpython-310/ReProver/common_cy.o -O3
creating build/lib.linux-x86_64-cpython-310/ReProver
/home/gkoopman/.conda/envs/lean-reinforcement/bin/x86_64-conda-linux-gnu-cc -shared -Wl,--allow-shlib-undefined -Wl,-rpath,/home/gkoopman/.conda/envs/lean-reinforcement/lib -Wl,-rpath-link,/home/gkoopman/.conda/envs/lean-reinforcement/lib -L/home/gkoopman/.conda/envs/lean-reinforcement/lib -Wl,--allow-shlib-undefined -Wl,-rpath,/home/gkoopman/.conda/envs/lean-reinforcement/lib -Wl,-rpath-link,/home/gkoopman/.conda/envs/lean-reinforcement/lib -L/home/gkoopman/.conda/envs/lean-reinforcement/lib -Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,--disable-new-dtags -Wl,--gc-sections -Wl,--allow-shlib-undefined -Wl,-rpath,/home/gkoopman/.conda/envs/lean-reinforcement/lib -Wl,-rpath-link,/home/gkoopman/.conda/envs/lean-reinforcement/lib -L/home/gkoopman/.conda/envs/lean-reinforcement/lib -L/home/gkoopman/.conda/envs/lean-reinforcement/targets/x86_64-linux/lib -L/home/gkoopman/.conda/envs/lean-reinforcement/targets/x86_64-linux/lib/stubs -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/gkoopman/.conda/envs/lean-reinforcement/include -I/home/gkoopman/.conda/envs/lean-reinforcement/targets/x86_64-linux/include -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/gkoopman/.conda/envs/lean-reinforcement/include -I/home/gkoopman/.conda/envs/lean-reinforcement/targets/x86_64-linux/include build/temp.linux-x86_64-cpython-310/ReProver/common_cy.o -o build/lib.linux-x86_64-cpython-310/ReProver/common_cy.cpython-310-x86_64-linux-gnu.so
copying build/lib.linux-x86_64-cpython-310/lean_reinforcement/agent/mcts/mcts_cy/base_mcts_cy.cpython-310-x86_64-linux-gnu.so -> lean_reinforcement/agent/mcts/mcts_cy
copying build/lib.linux-x86_64-cpython-310/lean_reinforcement/agent/mcts/mcts_cy/alphazero_cy.cpython-310-x86_64-linux-gnu.so -> lean_reinforcement/agent/mcts/mcts_cy
copying build/lib.linux-x86_64-cpython-310/lean_reinforcement/agent/mcts/mcts_cy/guidedrollout_cy.cpython-310-x86_64-linux-gnu.so -> lean_reinforcement/agent/mcts/mcts_cy
copying build/lib.linux-x86_64-cpython-310/ReProver/common_cy.cpython-310-x86_64-linux-gnu.so -> ReProver
Starting training run with distributed environment...
wandb: Currently logged in as: gerbennkoopman to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: setting up run qtlcndf6
wandb: Tracking run with wandb version 0.23.1
wandb: Run data is saved locally in /gpfs/home1/gkoopman/lean_reinforcement/wandb/run-20251216_150129-qtlcndf6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run light-wind-31
wandb: ‚≠êÔ∏è View project at https://wandb.ai/gerbennkoopman-university-of-amsterdam/lean-reinforcement
wandb: üöÄ View run at https://wandb.ai/gerbennkoopman-university-of-amsterdam/lean-reinforcement/runs/qtlcndf6
2025-12-16 15:01:31.763 | INFO     | lean_reinforcement.training.trainer:_setup_models:56 - Using checkpoint directory: /gpfs/scratch1/shared/lean-reinforcement/checkpoints
2025-12-16 15:01:34.769 | INFO     | lean_reinforcement.agent.value_head:load_checkpoint:192 - Checkpoint loaded from /gpfs/scratch1/shared/lean-reinforcement/checkpoints/value_head_latest.pth
2025-12-16 15:01:34.770 | INFO     | lean_reinforcement.training.trainer:_setup_models:67 - Resuming training from epoch 4
2025-12-16 15:01:34.770 | INFO     | lean_reinforcement.training.trainer:_log_gpu_memory:108 - After model initialization - GPU Memory: 1.12GB allocated, 1.23GB reserved
2025-12-16 15:01:34.771 | INFO     | lean_reinforcement.training.trainer:_setup_data:72 - Loading data from 'leandojo_benchmark_4/novel_premises'
2025-12-16 15:01:34.772 | INFO     | lean_reinforcement.training.trainer:_setup_data:77 - Loading indexed corpus from /gpfs/scratch1/shared/lean-reinforcement/indexed_corpus/indexed_corpus.pkl
2025-12-16 15:02:11.498 | INFO     | lean_dojo.data_extraction.trace:trace:248 - Loading the traced repo from /gpfs/scratch1/shared/lean-reinforcement/datasets/lean_dojo_cache/leanprover-community-mathlib4-29dcec074de168ac2bf835a77ef68bbe069194c5/mathlib4
2025-12-16 15:02:39,342	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
/home/gkoopman/.conda/envs/lean-reinforcement/lib/python3.10/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
  0%|          | 0/5674 [00:00<?, ?it/s]  0%|          | 1/5674 [00:01<2:40:49,  1.70s/it]  0%|          | 5/5674 [00:01<26:37,  3.55it/s]    0%|          | 9/5674 [00:01<13:35,  6.95it/s]  0%|          | 12/5674 [00:02<09:48,  9.61it/s]  0%|          | 18/5674 [00:02<05:39, 16.68it/s]  0%|          | 22/5674 [00:02<04:37, 20.36it/s]  0%|          | 26/5674 [00:06<38:24,  2.45it/s]  1%|          | 32/5674 [00:07<23:28,  4.01it/s]  1%|          | 37/5674 [00:07<16:43,  5.62it/s]  1%|          | 41/5674 [00:07<13:03,  7.19it/s]  1%|          | 45/5674 [00:07<10:39,  8.80it/s]  1%|          | 49/5674 [00:07<08:19, 11.26it/s]  1%|          | 53/5674 [00:12<40:40,  2.30it/s]  1%|          | 56/5674 [00:12<31:54,  2.93it/s]  1%|          | 59/5674 [00:13<25:07,  3.72it/s]  1%|          | 65/5674 [00:13<15:14,  6.13it/s]  1%|          | 69/5674 [00:13<11:43,  7.97it/s]  1%|‚ñè         | 76/5674 [00:13<07:24, 12.58it/s]  1%|‚ñè         | 81/5674 [00:19<37:06,  2.51it/s]  1%|‚ñè         | 85/5674 [00:19<29:00,  3.21it/s]  2%|‚ñè         | 88/5674 [00:19<24:32,  3.79it/s]  2%|‚ñè         | 91/5674 [00:19<19:33,  4.76it/s]  2%|‚ñè         | 96/5674 [00:19<13:18,  6.99it/s]  2%|‚ñè         | 100/5674 [00:20<10:21,  8.97it/s]  2%|‚ñè         | 103/5674 [00:20<08:55, 10.41it/s]  2%|‚ñè         | 106/5674 [00:26<56:22,  1.65it/s]  2%|‚ñè         | 108/5674 [00:26<47:03,  1.97it/s]  2%|‚ñè         | 112/5674 [00:26<31:51,  2.91it/s]  2%|‚ñè         | 116/5674 [00:26<21:56,  4.22it/s]  2%|‚ñè         | 119/5674 [00:27<17:36,  5.26it/s]  2%|‚ñè         | 122/5674 [00:27<14:01,  6.59it/s]  2%|‚ñè         | 129/5674 [00:27<08:10, 11.32it/s]  2%|‚ñè         | 133/5674 [00:27<06:47, 13.58it/s]  2%|‚ñè         | 136/5674 [00:27<06:01, 15.31it/s]  2%|‚ñè         | 139/5674 [00:34<58:51,  1.57it/s]  3%|‚ñé         | 142/5674 [00:34<44:15,  2.08it/s]  3%|‚ñé         | 145/5674 [00:35<33:45,  2.73it/s]  3%|‚ñé         | 148/5674 [00:35<25:12,  3.65it/s]  3%|‚ñé         | 151/5674 [00:35<18:54,  4.87it/s]  3%|‚ñé         | 158/5674 [00:35<10:22,  8.86it/s]  3%|‚ñé         | 162/5674 [00:35<08:25, 10.90it/s]  3%|‚ñé         | 170/5674 [00:35<05:10, 17.75it/s]  3%|‚ñé         | 175/5674 [00:35<04:26, 20.62it/s]  3%|‚ñé         | 180/5674 [00:35<04:01, 22.75it/s]  3%|‚ñé         | 184/5674 [00:36<03:37, 25.27it/s]  3%|‚ñé         | 188/5674 [00:36<03:33, 25.68it/s]  3%|‚ñé         | 192/5674 [00:44<54:21,  1.68it/s]  3%|‚ñé         | 195/5674 [00:44<42:51,  2.13it/s]  4%|‚ñé         | 200/5674 [00:44<29:26,  3.10it/s]  4%|‚ñé         | 205/5674 [00:45<20:21,  4.48it/s]  4%|‚ñé         | 209/5674 [00:45<15:30,  5.87it/s]  4%|‚ñç         | 218/5674 [00:45<08:41, 10.47it/s]  4%|‚ñç         | 228/5674 [00:45<05:21, 16.95it/s]  4%|‚ñç         | 238/5674 [00:45<03:44, 24.27it/s]  4%|‚ñç         | 245/5674 [00:45<03:14, 27.92it/s]  4%|‚ñç         | 252/5674 [00:45<02:55, 30.86it/s]  5%|‚ñç         | 258/5674 [00:45<02:37, 34.31it/s]  5%|‚ñç         | 264/5674 [00:46<02:35, 34.71it/s]  5%|‚ñç         | 270/5674 [00:46<02:30, 35.87it/s]  5%|‚ñç         | 278/5674 [00:55<37:46,  2.38it/s]  5%|‚ñç         | 283/5674 [00:55<29:27,  3.05it/s]  5%|‚ñå         | 287/5674 [00:55<23:41,  3.79it/s]  5%|‚ñå         | 291/5674 [00:55<19:04,  4.70it/s]  5%|‚ñå         | 295/5674 [00:56<15:04,  5.95it/s]  5%|‚ñå         | 299/5674 [00:56<12:00,  7.47it/s]  5%|‚ñå         | 302/5674 [00:56<10:12,  8.76it/s]  5%|‚ñå         | 307/5674 [00:56<07:25, 12.06it/s]  6%|‚ñå         | 314/5674 [00:56<05:03, 17.67it/s]  6%|‚ñå         | 322/5674 [00:56<03:29, 25.52it/s]  6%|‚ñå         | 329/5674 [00:56<02:46, 32.11it/s]  6%|‚ñå         | 335/5674 [00:56<02:30, 35.48it/s]  6%|‚ñå         | 342/5674 [00:57<02:07, 41.75it/s]  6%|‚ñå         | 348/5674 [00:57<02:05, 42.36it/s]  6%|‚ñã         | 357/5674 [00:57<01:40, 52.83it/s]  6%|‚ñã         | 366/5674 [00:57<01:28, 59.65it/s]  7%|‚ñã         | 375/5674 [00:57<01:19, 67.01it/s]  7%|‚ñã         | 383/5674 [00:57<01:34, 56.20it/s]  7%|‚ñã         | 391/5674 [00:57<01:26, 61.37it/s]  7%|‚ñã         | 391/5674 [01:08<01:26, 61.37it/s]  7%|‚ñã         | 397/5674 [01:08<40:35,  2.17it/s]  7%|‚ñã         | 408/5674 [01:09<25:08,  3.49it/s]  7%|‚ñã         | 425/5674 [01:09<13:44,  6.36it/s]  8%|‚ñä         | 448/5674 [01:09<07:25, 11.74it/s]  8%|‚ñä         | 462/5674 [01:09<05:30, 15.79it/s]  8%|‚ñä         | 475/5674 [01:09<04:15, 20.32it/s]  9%|‚ñä         | 487/5674 [01:09<03:25, 25.22it/s]  9%|‚ñâ         | 498/5674 [01:09<02:55, 29.55it/s]  9%|‚ñâ         | 507/5674 [01:10<02:47, 30.84it/s]  9%|‚ñâ         | 515/5674 [01:10<02:39, 32.32it/s]  9%|‚ñâ         | 522/5674 [01:10<02:34, 33.38it/s]  9%|‚ñâ         | 528/5674 [01:10<02:37, 32.63it/s]  9%|‚ñâ         | 536/5674 [01:10<02:16, 37.70it/s] 10%|‚ñâ         | 542/5674 [01:11<02:23, 35.87it/s] 10%|‚ñâ         | 550/5674 [01:11<02:07, 40.21it/s] 10%|‚ñâ         | 559/5674 [01:11<01:48, 47.31it/s] 10%|‚ñâ         | 567/5674 [01:11<01:55, 44.31it/s] 10%|‚ñà         | 576/5674 [01:11<01:40, 50.97it/s] 10%|‚ñà         | 586/5674 [01:11<01:24, 60.54it/s] 10%|‚ñà         | 586/5674 [01:24<01:24, 60.54it/s] 10%|‚ñà         | 588/5674 [01:24<49:49,  1.70it/s] 10%|‚ñà         | 594/5674 [01:24<36:34,  2.31it/s] 11%|‚ñà         | 601/5674 [01:25<25:28,  3.32it/s] 11%|‚ñà         | 608/5674 [01:25<18:08,  4.65it/s] 11%|‚ñà         | 614/5674 [01:25<13:40,  6.17it/s] 11%|‚ñà         | 623/5674 [01:25<08:58,  9.37it/s] 11%|‚ñà         | 631/5674 [01:25<06:28, 12.99it/s] 11%|‚ñà         | 638/5674 [01:25<05:05, 16.48it/s] 11%|‚ñà‚ñè        | 645/5674 [01:25<04:12, 19.89it/s] 12%|‚ñà‚ñè        | 653/5674 [01:25<03:12, 26.12it/s] 12%|‚ñà‚ñè        | 660/5674 [01:26<02:41, 31.12it/s] 12%|‚ñà‚ñè        | 667/5674 [01:26<02:19, 35.97it/s] 12%|‚ñà‚ñè        | 673/5674 [01:26<02:08, 38.84it/s] 12%|‚ñà‚ñè        | 679/5674 [01:26<02:16, 36.62it/s] 12%|‚ñà‚ñè        | 688/5674 [01:26<01:47, 46.54it/s] 12%|‚ñà‚ñè        | 695/5674 [01:26<01:37, 50.95it/s] 12%|‚ñà‚ñè        | 702/5674 [01:26<01:32, 54.04it/s] 12%|‚ñà‚ñè        | 709/5674 [01:26<01:40, 49.23it/s] 13%|‚ñà‚ñé        | 720/5674 [01:27<01:23, 59.65it/s] 13%|‚ñà‚ñé        | 727/5674 [01:27<01:31, 54.11it/s] 13%|‚ñà‚ñé        | 733/5674 [01:27<01:51, 44.15it/s] 13%|‚ñà‚ñé        | 739/5674 [01:27<01:50, 44.75it/s] 13%|‚ñà‚ñé        | 744/5674 [01:27<01:52, 43.72it/s] 13%|‚ñà‚ñé        | 751/5674 [01:27<01:47, 45.94it/s] 13%|‚ñà‚ñé        | 759/5674 [01:27<01:32, 53.42it/s] 13%|‚ñà‚ñé        | 765/5674 [01:28<01:55, 42.55it/s] 13%|‚ñà‚ñé        | 765/5674 [01:44<01:55, 42.55it/s] 14%|‚ñà‚ñé        | 768/5674 [01:44<1:11:22,  1.15it/s] 14%|‚ñà‚ñé        | 777/5674 [01:44<42:32,  1.92it/s]   14%|‚ñà‚ñç        | 784/5674 [01:44<29:50,  2.73it/s] 14%|‚ñà‚ñç        | 791/5674 [01:44<21:16,  3.82it/s] 14%|‚ñà‚ñç        | 796/5674 [01:44<16:48,  4.84it/s] 14%|‚ñà‚ñç        | 801/5674 [01:44<13:04,  6.21it/s] 14%|‚ñà‚ñç        | 806/5674 [01:45<10:39,  7.61it/s] 14%|‚ñà‚ñç        | 812/5674 [01:45<07:44, 10.47it/s] 14%|‚ñà‚ñç        | 817/5674 [01:45<06:25, 12.60it/s] 14%|‚ñà‚ñç        | 821/5674 [01:45<05:37, 14.36it/s] 15%|‚ñà‚ñç        | 827/5674 [01:45<04:15, 18.99it/s] 15%|‚ñà‚ñç        | 833/5674 [01:45<03:22, 23.94it/s] 15%|‚ñà‚ñç        | 838/5674 [01:45<03:17, 24.47it/s] 15%|‚ñà‚ñç        | 843/5674 [01:46<02:51, 28.11it/s] 15%|‚ñà‚ñç        | 848/5674 [01:46<02:46, 29.03it/s] 15%|‚ñà‚ñå        | 852/5674 [01:46<02:38, 30.51it/s] 15%|‚ñà‚ñå        | 856/5674 [01:46<02:54, 27.64it/s] 15%|‚ñà‚ñå        | 862/5674 [01:46<02:40, 30.06it/s] 15%|‚ñà‚ñå        | 866/5674 [01:46<02:45, 29.01it/s] 15%|‚ñà‚ñå        | 873/5674 [01:46<02:09, 37.12it/s] 15%|‚ñà‚ñå        | 879/5674 [01:47<02:11, 36.56it/s] 16%|‚ñà‚ñå        | 885/5674 [01:47<02:01, 39.42it/s] 16%|‚ñà‚ñå        | 892/5674 [01:47<01:46, 44.94it/s] 16%|‚ñà‚ñå        | 897/5674 [01:47<02:09, 36.87it/s] 16%|‚ñà‚ñå        | 905/5674 [01:47<01:53, 42.03it/s] 16%|‚ñà‚ñå        | 911/5674 [01:47<01:48, 43.97it/s] 16%|‚ñà‚ñå        | 916/5674 [01:47<01:55, 41.37it/s] 16%|‚ñà‚ñã        | 926/5674 [01:48<01:26, 54.85it/s] 16%|‚ñà‚ñã        | 933/5674 [01:48<01:25, 55.37it/s] 16%|‚ñà‚ñã        | 933/5674 [02:06<01:25, 55.37it/s] 16%|‚ñà‚ñã        | 934/5674 [02:06<1:23:10,  1.05s/it] 17%|‚ñà‚ñã        | 940/5674 [02:06<56:16,  1.40it/s]   17%|‚ñà‚ñã        | 946/5674 [02:06<38:56,  2.02it/s] 17%|‚ñà‚ñã        | 952/5674 [02:06<27:21,  2.88it/s] 17%|‚ñà‚ñã        | 959/5674 [02:06<18:21,  4.28it/s] 17%|‚ñà‚ñã        | 965/5674 [02:07<13:18,  5.89it/s] 17%|‚ñà‚ñã        | 971/5674 [02:07<09:44,  8.05it/s] 17%|‚ñà‚ñã        | 977/5674 [02:07<07:27, 10.50it/s] 17%|‚ñà‚ñã        | 983/5674 [02:07<06:16, 12.46it/s] 17%|‚ñà‚ñã        | 988/5674 [02:07<05:10, 15.10it/s] 18%|‚ñà‚ñä        | 994/5674 [02:07<04:08, 18.82it/s] 18%|‚ñà‚ñä        | 999/5674 [02:07<03:34, 21.84it/s] 18%|‚ñà‚ñä        | 1005/5674 [02:08<03:14, 23.99it/s] 18%|‚ñà‚ñä        | 1012/5674 [02:08<02:31, 30.81it/s] 18%|‚ñà‚ñä        | 1017/5674 [02:08<02:38, 29.33it/s] 18%|‚ñà‚ñä        | 1022/5674 [02:08<02:42, 28.66it/s] 18%|‚ñà‚ñä        | 1027/5674 [02:08<02:27, 31.50it/s] 18%|‚ñà‚ñä        | 1031/5674 [02:08<02:42, 28.58it/s] 18%|‚ñà‚ñä        | 1035/5674 [02:09<02:35, 29.83it/s] 18%|‚ñà‚ñä        | 1042/5674 [02:09<02:00, 38.33it/s] 18%|‚ñà‚ñä        | 1047/5674 [02:09<01:56, 39.73it/s] 19%|‚ñà‚ñä        | 1055/5674 [02:09<01:38, 46.66it/s] 19%|‚ñà‚ñä        | 1062/5674 [02:09<01:37, 47.50it/s] 19%|‚ñà‚ñâ        | 1070/5674 [02:09<01:23, 55.07it/s] 19%|‚ñà‚ñâ        | 1076/5674 [02:09<01:24, 54.57it/s] 19%|‚ñà‚ñâ        | 1082/5674 [02:09<01:33, 49.06it/s] 19%|‚ñà‚ñâ        | 1089/5674 [02:10<01:26, 52.88it/s] 19%|‚ñà‚ñâ        | 1095/5674 [02:10<01:33, 48.77it/s] 19%|‚ñà‚ñâ        | 1101/5674 [02:10<01:38, 46.45it/s] 19%|‚ñà‚ñâ        | 1106/5674 [02:10<01:47, 42.41it/s] 20%|‚ñà‚ñâ        | 1112/5674 [02:10<01:41, 45.00it/s] 20%|‚ñà‚ñâ        | 1121/5674 [02:10<01:23, 54.79it/s] 20%|‚ñà‚ñâ        | 1133/5674 [02:10<01:10, 64.80it/s] 20%|‚ñà‚ñà        | 1140/5674 [02:11<01:36, 46.87it/s] 20%|‚ñà‚ñà        | 1149/5674 [02:11<01:28, 51.03it/s] 20%|‚ñà‚ñà        | 1163/5674 [02:11<01:05, 69.18it/s] 21%|‚ñà‚ñà        | 1174/5674 [02:11<00:57, 78.00it/s] 21%|‚ñà‚ñà        | 1174/5674 [02:33<00:57, 78.00it/s] 21%|‚ñà‚ñà        | 1187/5674 [02:33<46:07,  1.62it/s] 21%|‚ñà‚ñà        | 1203/5674 [02:34<28:35,  2.61it/s] 21%|‚ñà‚ñà‚ñè       | 1214/5674 [02:34<21:00,  3.54it/s] 22%|‚ñà‚ñà‚ñè       | 1237/5674 [02:34<11:41,  6.33it/s] 22%|‚ñà‚ñà‚ñè       | 1253/5674 [02:34<08:12,  8.97it/s] 22%|‚ñà‚ñà‚ñè       | 1270/5674 [02:34<05:42, 12.84it/s] 23%|‚ñà‚ñà‚ñé       | 1285/5674 [02:34<04:15, 17.15it/s] 23%|‚ñà‚ñà‚ñé       | 1299/5674 [02:34<03:14, 22.52it/s] 23%|‚ñà‚ñà‚ñé       | 1315/5674 [02:34<02:22, 30.69it/s] 23%|‚ñà‚ñà‚ñé       | 1329/5674 [02:35<01:59, 36.32it/s] 24%|‚ñà‚ñà‚ñé       | 1341/5674 [02:35<01:40, 42.95it/s] 24%|‚ñà‚ñà‚ñç       | 1352/5674 [02:35<01:25, 50.53it/s] 24%|‚ñà‚ñà‚ñç       | 1363/5674 [02:35<01:23, 51.37it/s] 24%|‚ñà‚ñà‚ñç       | 1373/5674 [02:35<01:23, 51.69it/s] 24%|‚ñà‚ñà‚ñç       | 1382/5674 [02:35<01:26, 49.69it/s] 24%|‚ñà‚ñà‚ñç       | 1389/5674 [02:36<01:24, 50.79it/s] 25%|‚ñà‚ñà‚ñç       | 1396/5674 [02:36<01:20, 53.00it/s] 25%|‚ñà‚ñà‚ñç       | 1403/5674 [02:36<01:33, 45.46it/s] 25%|‚ñà‚ñà‚ñç       | 1409/5674 [02:36<01:34, 45.18it/s] 25%|‚ñà‚ñà‚ñç       | 1415/5674 [02:36<01:31, 46.37it/s] 25%|‚ñà‚ñà‚ñå       | 1421/5674 [02:36<01:33, 45.44it/s] 25%|‚ñà‚ñà‚ñå       | 1426/5674 [02:37<02:00, 35.12it/s] 25%|‚ñà‚ñà‚ñå       | 1434/5674 [02:37<01:44, 40.49it/s] 25%|‚ñà‚ñà‚ñå       | 1439/5674 [02:37<01:41, 41.90it/s] 26%|‚ñà‚ñà‚ñå       | 1447/5674 [02:37<01:36, 43.96it/s] 26%|‚ñà‚ñà‚ñå       | 1455/5674 [02:37<01:21, 51.53it/s] 26%|‚ñà‚ñà‚ñå       | 1461/5674 [02:37<01:20, 52.01it/s] 26%|‚ñà‚ñà‚ñå       | 1473/5674 [02:37<01:01, 68.49it/s] 26%|‚ñà‚ñà‚ñå       | 1481/5674 [02:37<01:07, 62.04it/s] 26%|‚ñà‚ñà‚ñå       | 1488/5674 [02:38<01:23, 50.13it/s] 26%|‚ñà‚ñà‚ñã       | 1495/5674 [02:38<01:17, 53.72it/s] 26%|‚ñà‚ñà‚ñã       | 1501/5674 [02:38<01:43, 40.24it/s] 27%|‚ñà‚ñà‚ñã       | 1506/5674 [02:38<01:44, 39.93it/s] 27%|‚ñà‚ñà‚ñã       | 1514/5674 [02:38<01:42, 40.72it/s] 27%|‚ñà‚ñà‚ñã       | 1519/5674 [02:39<01:58, 35.05it/s] 27%|‚ñà‚ñà‚ñã       | 1523/5674 [02:39<01:59, 34.60it/s] 27%|‚ñà‚ñà‚ñã       | 1527/5674 [02:39<02:17, 30.11it/s] 27%|‚ñà‚ñà‚ñã       | 1534/5674 [02:39<02:07, 32.57it/s] 27%|‚ñà‚ñà‚ñã       | 1542/5674 [02:39<01:48, 37.92it/s] 27%|‚ñà‚ñà‚ñã       | 1548/5674 [02:39<01:42, 40.40it/s] 27%|‚ñà‚ñà‚ñã       | 1553/5674 [02:40<01:59, 34.57it/s] 27%|‚ñà‚ñà‚ñã       | 1558/5674 [02:40<01:51, 37.04it/s] 27%|‚ñà‚ñà‚ñã       | 1558/5674 [03:06<01:51, 37.04it/s] 27%|‚ñà‚ñà‚ñã       | 1560/5674 [03:06<2:03:24,  1.80s/it] 28%|‚ñà‚ñà‚ñä       | 1565/5674 [03:07<1:24:19,  1.23s/it] 28%|‚ñà‚ñà‚ñä       | 1569/5674 [03:07<1:02:45,  1.09it/s] 28%|‚ñà‚ñà‚ñä       | 1575/5674 [03:07<40:26,  1.69it/s]   28%|‚ñà‚ñà‚ñä       | 1582/5674 [03:07<25:35,  2.66it/s] 28%|‚ñà‚ñà‚ñä       | 1586/5674 [03:07<19:59,  3.41it/s] 28%|‚ñà‚ñà‚ñä       | 1591/5674 [03:07<14:29,  4.70it/s] 28%|‚ñà‚ñà‚ñä       | 1596/5674 [03:08<11:28,  5.93it/s] 28%|‚ñà‚ñà‚ñä       | 1600/5674 [03:08<09:19,  7.28it/s] 28%|‚ñà‚ñà‚ñä       | 1603/5674 [03:08<07:54,  8.59it/s] 28%|‚ñà‚ñà‚ñä       | 1608/5674 [03:08<06:01, 11.26it/s] 28%|‚ñà‚ñà‚ñä       | 1613/5674 [03:08<04:37, 14.65it/s] 28%|‚ñà‚ñà‚ñä       | 1617/5674 [03:08<04:12, 16.09it/s] 29%|‚ñà‚ñà‚ñä       | 1621/5674 [03:09<03:42, 18.20it/s] 29%|‚ñà‚ñà‚ñä       | 1627/5674 [03:09<02:58, 22.69it/s] 29%|‚ñà‚ñà‚ñâ       | 1634/5674 [03:09<02:12, 30.41it/s] 29%|‚ñà‚ñà‚ñâ       | 1639/5674 [03:09<02:12, 30.38it/s] 29%|‚ñà‚ñà‚ñâ       | 1645/5674 [03:09<01:52, 35.87it/s] 29%|‚ñà‚ñà‚ñâ       | 1650/5674 [03:09<01:48, 37.10it/s] 29%|‚ñà‚ñà‚ñâ       | 1655/5674 [03:09<01:50, 36.37it/s] 29%|‚ñà‚ñà‚ñâ       | 1660/5674 [03:10<01:50, 36.18it/s] 29%|‚ñà‚ñà‚ñâ       | 1666/5674 [03:10<01:39, 40.43it/s] 29%|‚ñà‚ñà‚ñâ       | 1671/5674 [03:10<01:38, 40.73it/s] 30%|‚ñà‚ñà‚ñâ       | 1676/5674 [03:10<01:40, 39.88it/s] 30%|‚ñà‚ñà‚ñâ       | 1681/5674 [03:10<01:44, 38.26it/s] 30%|‚ñà‚ñà‚ñâ       | 1690/5674 [03:10<01:21, 49.02it/s] 30%|‚ñà‚ñà‚ñâ       | 1696/5674 [03:10<01:34, 42.13it/s] 30%|‚ñà‚ñà‚ñâ       | 1701/5674 [03:11<01:46, 37.40it/s] 30%|‚ñà‚ñà‚ñà       | 1708/5674 [03:11<01:35, 41.60it/s] 30%|‚ñà‚ñà‚ñà       | 1715/5674 [03:11<01:24, 46.92it/s] 30%|‚ñà‚ñà‚ñà       | 1722/5674 [03:11<01:42, 38.59it/s] 30%|‚ñà‚ñà‚ñà       | 1729/5674 [03:11<01:28, 44.81it/s] 31%|‚ñà‚ñà‚ñà       | 1735/5674 [03:11<01:29, 43.87it/s] 31%|‚ñà‚ñà‚ñà       | 1747/5674 [03:11<01:15, 52.30it/s] 31%|‚ñà‚ñà‚ñà       | 1756/5674 [03:12<01:06, 58.83it/s] 31%|‚ñà‚ñà‚ñà       | 1763/5674 [03:12<01:19, 48.99it/s] 31%|‚ñà‚ñà‚ñà       | 1772/5674 [03:12<01:08, 57.30it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 1780/5674 [03:12<01:05, 59.02it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1792/5674 [03:12<00:54, 70.65it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1800/5674 [03:12<00:59, 65.23it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1807/5674 [03:12<01:03, 61.26it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1815/5674 [03:13<00:59, 65.11it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1822/5674 [03:13<01:00, 63.99it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1834/5674 [03:13<00:49, 76.81it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 1842/5674 [03:13<00:51, 73.82it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1850/5674 [03:13<00:55, 68.57it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1859/5674 [03:13<00:52, 73.06it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1869/5674 [03:13<00:49, 76.78it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1880/5674 [03:13<00:44, 85.01it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1890/5674 [03:13<00:49, 76.73it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 1898/5674 [03:14<01:03, 59.44it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1905/5674 [03:14<01:14, 50.31it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1905/5674 [03:47<01:14, 50.31it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 1913/5674 [03:47<1:15:46,  1.21s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 1919/5674 [03:47<58:10,  1.08it/s]   34%|‚ñà‚ñà‚ñà‚ñç      | 1925/5674 [03:48<43:51,  1.42it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1932/5674 [03:48<31:09,  2.00it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1941/5674 [03:48<20:25,  3.05it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 1952/5674 [03:48<12:51,  4.82it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1961/5674 [03:48<09:06,  6.80it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1970/5674 [03:48<06:32,  9.43it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 1980/5674 [03:48<04:39, 13.23it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1990/5674 [03:48<03:22, 18.16it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 1999/5674 [03:48<02:36, 23.46it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 2008/5674 [03:49<02:06, 29.00it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 2017/5674 [03:49<01:41, 36.05it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 2026/5674 [03:49<01:28, 40.99it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 2035/5674 [03:49<01:14, 48.73it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 2043/5674 [03:49<01:14, 48.55it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 2052/5674 [03:49<01:11, 50.80it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 2064/5674 [03:49<00:59, 60.61it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 2072/5674 [03:50<01:02, 57.76it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 2079/5674 [03:50<01:05, 55.14it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 2086/5674 [03:50<01:04, 55.53it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 2092/5674 [03:50<01:14, 48.26it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 2098/5674 [03:50<01:27, 40.87it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 2103/5674 [03:50<01:38, 36.38it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 2108/5674 [03:51<01:31, 38.98it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 2116/5674 [03:51<01:50, 32.30it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 2122/5674 [03:51<01:36, 36.69it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 2127/5674 [03:51<01:30, 39.05it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 2135/5674 [03:51<01:16, 46.42it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 2143/5674 [03:51<01:05, 53.67it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 2153/5674 [03:51<00:54, 64.72it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 2161/5674 [03:52<00:56, 62.06it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 2169/5674 [03:52<00:53, 65.67it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 2176/5674 [03:52<00:54, 64.61it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 2184/5674 [03:52<00:51, 67.90it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 2193/5674 [03:52<00:47, 73.04it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 2201/5674 [03:52<00:52, 65.87it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 2208/5674 [03:52<00:55, 62.14it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 2215/5674 [03:52<00:57, 60.34it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 2222/5674 [03:53<01:03, 54.05it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 2229/5674 [03:53<01:00, 57.11it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 2237/5674 [03:53<00:55, 62.16it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 2244/5674 [03:53<01:02, 54.78it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 2250/5674 [03:53<01:12, 47.20it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 2256/5674 [03:53<01:30, 37.95it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 2261/5674 [03:53<01:32, 36.76it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 2266/5674 [03:54<01:30, 37.56it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 2271/5674 [03:54<02:08, 26.51it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 2276/5674 [03:54<01:58, 28.68it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 2280/5674 [03:54<02:05, 27.12it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 2284/5674 [03:54<02:09, 26.11it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 2290/5674 [03:55<01:54, 29.48it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 2295/5674 [03:55<02:01, 27.83it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 2306/5674 [03:55<01:20, 42.08it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 2311/5674 [03:55<01:17, 43.54it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 2320/5674 [03:55<01:02, 53.98it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 2327/5674 [03:55<00:59, 56.39it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 2334/5674 [03:55<00:59, 55.90it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 2340/5674 [03:55<01:07, 49.18it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2350/5674 [03:56<00:55, 59.82it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2357/5674 [03:56<00:59, 55.62it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2363/5674 [03:56<01:05, 50.60it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2369/5674 [03:56<01:05, 50.13it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2375/5674 [03:56<01:07, 49.23it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2381/5674 [03:56<01:19, 41.29it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2389/5674 [03:56<01:08, 47.66it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2389/5674 [04:36<01:08, 47.66it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2390/5674 [04:36<2:09:20,  2.36s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2397/5674 [04:36<1:21:47,  1.50s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2402/5674 [04:37<59:34,  1.09s/it]   42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2407/5674 [04:37<43:25,  1.25it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 2411/5674 [04:37<33:17,  1.63it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2416/5674 [04:37<23:39,  2.30it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2425/5674 [04:37<13:33,  4.00it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2434/5674 [04:37<08:34,  6.30it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2440/5674 [04:37<06:41,  8.06it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2446/5674 [04:38<05:13, 10.29it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2452/5674 [04:38<04:03, 13.21it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2458/5674 [04:38<03:10, 16.90it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2471/5674 [04:38<01:53, 28.16it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2480/5674 [04:38<01:28, 36.02it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2488/5674 [04:38<01:19, 40.28it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2495/5674 [04:38<01:12, 43.60it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2502/5674 [04:38<01:07, 47.01it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2509/5674 [04:39<01:08, 46.49it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2515/5674 [04:39<01:23, 37.86it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2520/5674 [04:39<01:30, 34.69it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2526/5674 [04:39<01:20, 38.87it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2531/5674 [04:39<01:18, 39.99it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2538/5674 [04:39<01:13, 42.95it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2544/5674 [04:40<01:07, 46.40it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 2550/5674 [04:40<01:05, 47.40it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2557/5674 [04:40<01:09, 45.07it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2564/5674 [04:40<01:04, 48.47it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2570/5674 [04:40<01:15, 41.37it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2577/5674 [04:40<01:08, 45.28it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2582/5674 [04:40<01:08, 45.08it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2587/5674 [04:41<01:34, 32.57it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2591/5674 [04:41<01:44, 29.62it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2595/5674 [04:41<01:42, 29.93it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2600/5674 [04:41<01:35, 32.31it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2607/5674 [04:41<01:16, 40.04it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2613/5674 [04:41<01:11, 43.10it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 2619/5674 [04:41<01:05, 46.70it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2625/5674 [04:42<01:01, 49.90it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2631/5674 [04:42<01:30, 33.69it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2636/5674 [04:42<01:31, 33.11it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2640/5674 [04:42<01:32, 32.83it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2646/5674 [04:42<01:19, 38.11it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2655/5674 [04:42<01:00, 50.00it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2661/5674 [04:42<00:59, 50.75it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2671/5674 [04:43<00:48, 61.33it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2678/5674 [04:43<00:53, 56.15it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2684/5674 [04:43<00:52, 56.85it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 2694/5674 [04:43<00:46, 63.65it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2701/5674 [04:43<00:53, 55.71it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2709/5674 [04:43<00:48, 61.48it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2719/5674 [04:43<00:44, 66.91it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2726/5674 [04:43<00:43, 67.59it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2733/5674 [04:44<01:13, 40.02it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2739/5674 [04:44<01:39, 29.55it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2745/5674 [04:44<01:29, 32.83it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2750/5674 [04:44<01:32, 31.48it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2755/5674 [04:45<01:24, 34.56it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2760/5674 [04:45<01:26, 33.84it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2766/5674 [04:45<01:15, 38.37it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2771/5674 [04:45<01:11, 40.52it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2778/5674 [04:45<01:05, 44.40it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2786/5674 [04:45<00:54, 52.99it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2792/5674 [04:45<00:53, 54.20it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2799/5674 [04:45<00:49, 57.86it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2807/5674 [04:46<00:48, 59.16it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2815/5674 [04:46<00:51, 55.37it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2821/5674 [04:46<00:55, 51.10it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2827/5674 [04:46<00:58, 48.36it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 2832/5674 [04:46<01:04, 43.85it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2837/5674 [04:46<01:04, 44.30it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2847/5674 [04:46<00:50, 55.87it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2853/5674 [04:46<00:49, 56.80it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2859/5674 [04:47<00:51, 54.36it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2867/5674 [04:47<00:46, 60.70it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2874/5674 [04:47<00:44, 62.51it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2882/5674 [04:47<00:44, 63.40it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2889/5674 [04:47<00:46, 59.32it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2896/5674 [04:47<00:46, 59.85it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2904/5674 [04:47<00:43, 63.95it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2911/5674 [04:47<00:47, 58.01it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2911/5674 [05:37<00:47, 58.01it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2912/5674 [05:37<2:06:54,  2.76s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2917/5674 [05:37<1:30:55,  1.98s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2923/5674 [05:37<1:01:25,  1.34s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2930/5674 [05:37<39:54,  1.15it/s]   52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2936/5674 [05:37<28:10,  1.62it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2941/5674 [05:37<20:56,  2.18it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2946/5674 [05:37<15:35,  2.92it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2952/5674 [05:38<10:53,  4.17it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2958/5674 [05:38<07:42,  5.88it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2963/5674 [05:38<05:58,  7.56it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2968/5674 [05:38<04:42,  9.59it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 2975/5674 [05:38<03:21, 13.37it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2983/5674 [05:38<02:29, 18.03it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2988/5674 [05:39<02:09, 20.69it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2993/5674 [05:39<01:51, 24.00it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 2998/5674 [05:39<01:36, 27.77it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3003/5674 [05:39<01:32, 28.97it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3008/5674 [05:39<01:27, 30.44it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3012/5674 [05:39<01:28, 30.24it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3017/5674 [05:39<01:23, 31.74it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3022/5674 [05:39<01:20, 33.00it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3028/5674 [05:40<01:08, 38.80it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3033/5674 [05:40<01:04, 40.69it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3040/5674 [05:40<00:56, 46.84it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3045/5674 [05:40<00:57, 45.94it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3051/5674 [05:40<00:54, 48.04it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3059/5674 [05:40<00:52, 50.00it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3067/5674 [05:40<00:46, 55.55it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3073/5674 [05:40<00:47, 54.84it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3079/5674 [05:41<00:51, 50.03it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3085/5674 [05:41<00:55, 46.61it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3091/5674 [05:41<00:56, 45.33it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3096/5674 [05:41<00:59, 43.53it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3103/5674 [05:41<00:52, 49.06it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3109/5674 [05:41<00:52, 49.11it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3116/5674 [05:41<00:49, 51.64it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3122/5674 [05:41<00:58, 43.80it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3127/5674 [05:42<00:59, 42.65it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3132/5674 [05:42<01:00, 42.12it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3137/5674 [05:42<01:00, 41.71it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3143/5674 [05:42<01:00, 41.91it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3148/5674 [05:42<01:00, 41.54it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3153/5674 [05:42<01:00, 41.95it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3161/5674 [05:42<00:50, 50.03it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3167/5674 [05:42<00:48, 51.28it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3173/5674 [05:43<00:59, 41.97it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3178/5674 [05:43<00:58, 42.51it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3183/5674 [05:43<00:56, 43.74it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 3188/5674 [05:43<00:58, 42.77it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3200/5674 [05:43<00:41, 59.81it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3207/5674 [05:43<00:40, 60.62it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3216/5674 [05:43<00:36, 67.38it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3227/5674 [05:43<00:31, 77.41it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3237/5674 [05:44<00:29, 82.98it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3246/5674 [05:44<00:38, 62.62it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3255/5674 [05:44<00:35, 68.00it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3266/5674 [05:44<00:31, 77.19it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3275/5674 [05:44<00:39, 60.09it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3283/5674 [05:44<00:38, 61.75it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3290/5674 [05:44<00:38, 61.77it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3302/5674 [05:45<00:31, 74.68it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3311/5674 [05:45<00:32, 73.27it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3319/5674 [05:45<00:38, 61.33it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3326/5674 [05:45<00:41, 56.53it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 3333/5674 [05:45<00:45, 52.00it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3339/5674 [05:45<00:55, 42.02it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3344/5674 [05:46<00:55, 41.74it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3349/5674 [05:46<01:10, 33.09it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3353/5674 [05:46<01:18, 29.61it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3358/5674 [05:46<01:16, 30.24it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3362/5674 [05:46<01:12, 31.71it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3367/5674 [05:46<01:15, 30.61it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3371/5674 [05:47<01:12, 31.62it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3378/5674 [05:47<00:58, 39.05it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3383/5674 [05:47<00:58, 39.42it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3390/5674 [05:47<00:49, 45.71it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3395/5674 [05:47<01:20, 28.44it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3399/5674 [05:47<01:27, 26.10it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3406/5674 [05:48<01:10, 32.16it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3414/5674 [05:48<00:55, 40.48it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3419/5674 [05:48<00:58, 38.25it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3424/5674 [05:48<01:01, 36.74it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3429/5674 [05:48<01:01, 36.38it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3434/5674 [05:48<00:57, 39.17it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3439/5674 [05:48<00:55, 40.13it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3446/5674 [05:48<00:50, 44.04it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3453/5674 [05:49<00:51, 43.31it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3461/5674 [05:49<00:42, 51.72it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3468/5674 [05:49<00:39, 56.05it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3482/5674 [05:49<00:37, 58.60it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3489/5674 [05:49<00:36, 59.16it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3496/5674 [05:49<00:40, 53.78it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3504/5674 [05:49<00:38, 56.29it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3510/5674 [05:50<00:50, 42.79it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3517/5674 [05:50<00:48, 44.77it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3517/5674 [06:49<00:48, 44.77it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3519/5674 [06:49<1:52:52,  3.14s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3526/5674 [06:49<1:14:05,  2.07s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3531/5674 [06:49<54:59,  1.54s/it]   62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3535/5674 [06:50<42:30,  1.19s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3541/5674 [06:50<28:38,  1.24it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3549/5674 [06:50<17:41,  2.00it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3555/5674 [06:50<12:41,  2.78it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3562/5674 [06:50<08:49,  3.99it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3573/5674 [06:50<05:15,  6.65it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3579/5674 [06:51<04:20,  8.05it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3591/5674 [06:51<02:39, 13.07it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3599/5674 [06:51<02:01, 17.09it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3609/5674 [06:51<01:27, 23.47it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3622/5674 [06:51<01:00, 34.05it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3631/5674 [06:51<00:51, 39.47it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3640/5674 [06:51<00:57, 35.35it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3647/5674 [06:52<00:52, 38.49it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3654/5674 [06:52<00:53, 37.48it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3661/5674 [06:52<00:47, 42.43it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3667/5674 [06:52<00:52, 38.04it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3673/5674 [06:52<00:49, 40.71it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3678/5674 [06:52<00:50, 39.66it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3683/5674 [06:52<00:58, 33.98it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3688/5674 [06:53<00:54, 36.73it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3693/5674 [06:53<00:53, 37.21it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3698/5674 [06:53<00:53, 36.62it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3707/5674 [06:53<00:44, 43.92it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3712/5674 [06:53<00:45, 42.98it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3717/5674 [06:53<00:46, 41.68it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3724/5674 [06:53<00:42, 45.79it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3736/5674 [06:54<00:30, 63.76it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3743/5674 [06:54<00:35, 53.82it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 3749/5674 [06:54<00:42, 45.29it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3760/5674 [06:54<00:34, 55.71it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3768/5674 [06:54<00:31, 60.36it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3778/5674 [06:54<00:27, 67.75it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3786/5674 [06:54<00:31, 60.63it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3797/5674 [06:55<00:26, 70.79it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3805/5674 [06:55<00:26, 70.61it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3818/5674 [06:55<00:22, 84.13it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3827/5674 [06:55<00:25, 73.18it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3839/5674 [06:55<00:22, 83.08it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3851/5674 [06:55<00:19, 92.35it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3861/5674 [06:55<00:19, 91.50it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3871/5674 [06:55<00:21, 84.16it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3880/5674 [06:56<00:25, 71.26it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3888/5674 [06:56<00:25, 69.39it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3896/5674 [06:56<00:26, 68.14it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3904/5674 [06:56<00:25, 70.47it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3912/5674 [06:56<00:24, 72.19it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3920/5674 [06:56<00:27, 63.16it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3927/5674 [06:56<00:28, 60.42it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3935/5674 [06:56<00:27, 64.39it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3942/5674 [06:57<00:28, 61.36it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3949/5674 [06:57<00:33, 50.99it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3955/5674 [06:57<00:37, 45.64it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3960/5674 [06:57<00:38, 44.14it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 3966/5674 [06:57<00:35, 47.62it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 3977/5674 [06:57<00:27, 62.54it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 3986/5674 [06:57<00:27, 60.53it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 3993/5674 [06:57<00:26, 62.58it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 4000/5674 [06:58<00:29, 57.16it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 4006/5674 [06:58<00:33, 49.53it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 4012/5674 [06:58<00:32, 51.85it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 4022/5674 [06:58<00:26, 61.75it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 4031/5674 [06:58<00:23, 68.82it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 4039/5674 [06:58<00:25, 63.02it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4046/5674 [06:58<00:32, 49.38it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4059/5674 [06:59<00:25, 62.19it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4066/5674 [06:59<00:25, 62.91it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4073/5674 [06:59<00:30, 52.87it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4079/5674 [06:59<00:30, 51.82it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4086/5674 [06:59<00:39, 40.32it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4093/5674 [06:59<00:34, 45.93it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4099/5674 [07:00<00:36, 43.45it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 4106/5674 [07:00<00:34, 46.00it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4117/5674 [07:00<00:27, 57.61it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4124/5674 [07:00<00:30, 50.79it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4135/5674 [07:00<00:25, 61.26it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4142/5674 [07:00<00:26, 58.19it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4149/5674 [07:00<00:30, 50.30it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4158/5674 [07:01<00:25, 58.40it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4165/5674 [07:01<00:25, 58.09it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4172/5674 [07:01<00:25, 58.43it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4179/5674 [07:01<00:29, 50.52it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4187/5674 [07:01<00:26, 56.48it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4194/5674 [07:01<00:25, 59.11it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4204/5674 [07:01<00:21, 68.86it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4212/5674 [07:01<00:21, 68.78it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4220/5674 [07:02<00:23, 61.29it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4228/5674 [07:02<00:24, 60.18it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4239/5674 [07:02<00:19, 72.24it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4247/5674 [07:02<00:24, 58.72it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 4254/5674 [07:02<00:30, 46.92it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4260/5674 [07:02<00:32, 43.33it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4265/5674 [07:03<00:33, 42.08it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4272/5674 [07:03<00:29, 47.05it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4278/5674 [07:03<00:34, 40.77it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4283/5674 [07:03<00:33, 41.68it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4288/5674 [07:03<00:36, 38.17it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4293/5674 [07:03<00:34, 40.55it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4302/5674 [07:03<00:28, 47.56it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4309/5674 [07:04<00:27, 49.88it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4315/5674 [07:04<00:30, 45.20it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 4322/5674 [07:04<00:26, 50.18it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4328/5674 [07:04<00:26, 50.18it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4336/5674 [07:04<00:23, 56.95it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4346/5674 [07:04<00:20, 64.93it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4354/5674 [07:04<00:20, 65.33it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4363/5674 [07:04<00:18, 70.85it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4379/5674 [07:04<00:13, 94.45it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4389/5674 [07:05<00:14, 89.17it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4399/5674 [07:05<00:15, 82.37it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4399/5674 [08:19<00:15, 82.37it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4407/5674 [08:19<49:05,  2.32s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4410/5674 [08:19<43:17,  2.05s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4417/5674 [08:19<30:59,  1.48s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4424/5674 [08:19<22:05,  1.06s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4432/5674 [08:19<15:01,  1.38it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4449/5674 [08:19<07:36,  2.68it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 4463/5674 [08:20<04:48,  4.19it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4473/5674 [08:20<03:32,  5.65it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4487/5674 [08:20<02:19,  8.51it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4508/5674 [08:20<01:20, 14.47it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4523/5674 [08:20<00:57, 19.95it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 4539/5674 [08:20<00:41, 27.62it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4560/5674 [08:20<00:27, 40.76it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4577/5674 [08:20<00:21, 50.65it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4595/5674 [08:20<00:16, 65.17it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4613/5674 [08:21<00:13, 80.89it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4630/5674 [08:21<00:11, 91.25it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4646/5674 [08:21<00:09, 103.47it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4664/5674 [08:21<00:08, 118.54it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 4680/5674 [08:21<00:09, 107.76it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4694/5674 [08:21<00:10, 97.33it/s]  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4706/5674 [08:21<00:10, 89.93it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4717/5674 [08:22<00:11, 84.54it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4727/5674 [08:22<00:11, 79.71it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4736/5674 [08:22<00:13, 69.35it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 4744/5674 [08:22<00:13, 67.93it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4753/5674 [08:22<00:13, 67.76it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4761/5674 [08:22<00:14, 62.77it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4768/5674 [08:22<00:14, 61.17it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4777/5674 [08:23<00:15, 56.46it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4793/5674 [08:23<00:11, 78.40it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4802/5674 [08:23<00:16, 52.48it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4812/5674 [08:23<00:17, 48.30it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 4820/5674 [08:23<00:16, 51.50it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4827/5674 [08:24<00:16, 52.34it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4839/5674 [08:24<00:12, 65.89it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4850/5674 [08:24<00:10, 75.70it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4866/5674 [08:24<00:08, 95.87it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 4887/5674 [08:24<00:06, 124.54it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 4901/5674 [08:24<00:06, 127.27it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 4920/5674 [08:24<00:05, 143.96it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 4939/5674 [08:24<00:04, 153.95it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 4955/5674 [08:24<00:05, 137.03it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 4970/5674 [08:25<00:05, 125.23it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 4984/5674 [08:25<00:05, 125.73it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 4998/5674 [08:25<00:06, 107.91it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 5013/5674 [08:25<00:05, 116.02it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 5026/5674 [08:25<00:05, 108.79it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5038/5674 [08:25<00:05, 106.72it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5050/5674 [08:25<00:05, 104.94it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5061/5674 [08:25<00:06, 97.25it/s]  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5072/5674 [08:26<00:06, 98.02it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5083/5674 [08:26<00:05, 100.22it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 5097/5674 [08:26<00:05, 103.12it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 5108/5674 [08:26<00:05, 101.91it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 5119/5674 [08:26<00:06, 82.02it/s]  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 5133/5674 [08:26<00:05, 95.16it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 5144/5674 [08:26<00:05, 95.79it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 5162/5674 [08:26<00:04, 115.44it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 5175/5674 [08:27<00:04, 107.42it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5187/5674 [08:27<00:04, 99.13it/s]  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5198/5674 [08:27<00:04, 96.16it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5210/5674 [08:27<00:04, 97.38it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5220/5674 [08:27<00:05, 88.04it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5231/5674 [08:27<00:04, 90.87it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 5241/5674 [08:27<00:05, 73.23it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5249/5674 [08:28<00:05, 73.16it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5261/5674 [08:28<00:04, 84.22it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5271/5674 [08:28<00:05, 69.45it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5285/5674 [08:28<00:04, 84.78it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5296/5674 [08:28<00:04, 90.73it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5306/5674 [08:28<00:04, 91.21it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5319/5674 [08:28<00:03, 93.63it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5329/5674 [08:29<00:05, 60.88it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5345/5674 [08:29<00:04, 76.32it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5355/5674 [08:29<00:04, 72.10it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5364/5674 [08:29<00:04, 72.99it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 5374/5674 [08:29<00:03, 76.53it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5391/5674 [08:29<00:02, 97.66it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5412/5674 [08:29<00:02, 125.14it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5426/5674 [08:29<00:02, 123.63it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5440/5674 [08:30<00:02, 101.08it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 5452/5674 [08:30<00:02, 104.00it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5466/5674 [08:30<00:01, 111.74it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5481/5674 [08:30<00:01, 121.51it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5494/5674 [08:30<00:01, 100.95it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5511/5674 [08:30<00:01, 116.34it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 5532/5674 [08:30<00:01, 139.46it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5553/5674 [08:30<00:00, 157.50it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5570/5674 [08:31<00:00, 153.50it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5587/5674 [08:31<00:00, 115.37it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 5601/5674 [08:31<00:00, 107.84it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5614/5674 [08:31<00:00, 106.12it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5628/5674 [08:31<00:00, 113.06it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5643/5674 [08:31<00:00, 119.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5656/5674 [08:32<00:00, 79.12it/s] 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 5667/5674 [08:32<00:00, 59.66it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5674/5674 [08:32<00:00, 11.07it/s]
2025-12-16 15:12:15.225 | INFO     | lean_reinforcement.training.trainer:_start_workers:182 - Starting 16 workers
2025-12-16 15:21:52.804 | INFO     | lean_reinforcement.training.trainer:_run_epoch:137 - Starting Epoch 5/10
2025-12-16 15:21:52.892 | INFO     | lean_reinforcement.training.trainer:_run_epoch:148 - Processing 128 theorems with 16 workers.
2025-12-16 15:22:06.467 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: CategoryTheory.id_of_comp_left_id
2025-12-16 15:22:06.993 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: biInf_congr'
2025-12-16 15:22:10.390 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Ordinal.nat_nadd
2025-12-16 15:22:11.871 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:22:12.239 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:22:13.237 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: UpperHalfPlane.coe_im
2025-12-16 15:22:14.314 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Filter.mono_bliminf
2025-12-16 15:22:14.373 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: dense_iff_exists_between
2025-12-16 15:22:16.452 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:22:18.830 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp only [eq_iff_true_of_subsingleton]
2025-12-16 15:22:18.896 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='simp made no progress')
2025-12-16 15:22:18.896 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 12.43s.
2025-12-16 15:22:18.896 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='simp made no progress')
2025-12-16 15:22:19.029 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:22:19.029 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:22:19.152 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:22:19.599 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: NormedAddGroupHom.NormNoninc.neg_iff
2025-12-16 15:22:19.661 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:22:19.766 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:22:21.064 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: LowerSet.mem_iInf‚ÇÇ_iff
2025-12-16 15:22:22.339 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Complex.abs_deriv_le_div_of_mapsTo_ball
2025-12-16 15:22:23.333 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [nadd_comm, nadd_nat]
2025-12-16 15:22:23.398 | SUCCESS  | lean_reinforcement.agent.runner:run:217 - Proof finished in 1 steps and 13.01s.
2025-12-16 15:22:23.532 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:22:23.533 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:22:24.079 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Matrix.PosDef.posSemidef_add
2025-12-16 15:22:24.483 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: SimpleGraph.Coloring.not_adj_of_mem_colorClass
2025-12-16 15:22:25.360 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:22:25.743 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Real.sin_pi_div_sixteen
2025-12-16 15:22:27.567 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: bound
2025-12-16 15:22:27.690 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:22:29.437 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:22:30.995 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:22:31.237 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: rank_span_le
2025-12-16 15:22:31.275 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:22:31.718 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:22:32.936 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:22:35.450 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: CoheytingHom.cancel_right
2025-12-16 15:22:35.589 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: FractionalIdeal.den_mem_inv
2025-12-16 15:22:35.744 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:22:37.512 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: LinearMap.closedEmbedding_of_injective
2025-12-16 15:22:40.573 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:22:40.649 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:22:42.140 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:22:43.360 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [ofReal_im, ofReal_re, ofReal_re, ofReal_re, ofReal_re, ofReal_re, ofReal_re,
  ofReal_re, ofReal_re, ofReal_re, ofReal_re, ofReal_re, ofReal_re, ofReal_re,
  ofReal_re, ofReal_re, ofReal_re, ofReal_re, ofReal_re, ofReal_re, ofReal_re, ofReal_re,
  ofReal_re, ofReal_re, ofReal_re, ofReal_re, ofReal_re, ofReal_re, ofReal_re, ofReal_re,
  ofReal_re, ofReal_re, ofReal_re, ofReal_re, ofReal_re, ofReal_re, ofReal_re,
  ofReal_re, ofReal_re, ofReal_re, ofReal_re, ofReal_re, ofReal_re, ofReal_re,
  ofReal_re, ofReal_re, ofReal_re, ofReal_re, ofReal_re, ofReal_re, ofReal_re,
  ofReal_re, ofReal_re, ofReal_re, ofReal_re, ofReal_re, ofReal_re, ofReal_re,
  ofReal_re, ofReal_re, ofReal_re, ofReal_re, ofReal_re, ofReal_re, ofReal_re,
  ofReal_re, ofReal_re, ofReal_re, ofReal_re, ofReal_re, ofReal_re, ofReal_re,
  ofReal_re, ofReal_re, ofReal_re, ofReal_re, ofReal_re, ofReal_re, ofReal_re,
  ofReal_re, ofReal_re, ofReal_re, ofReal_re, ofReal_re, ofReal_re, ofReal_re,
  ofReal_re, ofReal_re, ofReal_re, ofReal_re, ofRea
2025-12-16 15:22:43.429 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="<stdin>:13:51: unexpected end of input; expected ']'")
2025-12-16 15:22:43.429 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 30.19s.
2025-12-16 15:22:43.429 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="<stdin>:13:51: unexpected end of input; expected ']'")
2025-12-16 15:22:43.559 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:22:43.559 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:22:52.773 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Topology.WithLowerSet.ofLowerSet_le_ofLowerSet
2025-12-16 15:22:54.847 | ERROR    | lean_reinforcement.utilities.gym:reset:41 - Error during environment reset: Timeout during initialization
2025-12-16 15:22:54.847 | ERROR    | lean_reinforcement.training.worker:process_theorem:44 - Failed to initialize environment for theorem HasStrictFDerivAt.mul: Timeout during initialization
2025-12-16 15:22:55.070 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:22:57.419 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:23:02.071 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: FirstOrder.Language.LHom.mem_onTheory
2025-12-16 15:23:06.347 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:24:09.286 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: have : DifferentiableOn ‚ÑÇ f (ball c R‚ÇÅ) (ball c R‚ÇÅ) := differentiableOn_compact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigma
  (differentiableOn_compact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaC
2025-12-16 15:24:09.318 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp only [dense_iff_closure_subset, dense_iff_closure_subset]
2025-12-16 15:24:09.346 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simpa only [bliminf_def] using bliminf_le_bliminf_of_le h
2025-12-16 15:24:09.356 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="<stdin>:2:879: unexpected end of input; expected ')', ',' or ':'")
2025-12-16 15:24:09.356 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 107.02s.
2025-12-16 15:24:09.356 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="<stdin>:2:879: unexpected end of input; expected ')', ',' or ':'")
2025-12-16 15:24:09.383 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='simp made no progress')
2025-12-16 15:24:09.383 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 115.01s.
2025-12-16 15:24:09.383 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='simp made no progress')
2025-12-16 15:24:09.419 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="unknown identifier 'bliminf_def'\nunknown identifier 'bliminf_le_bliminf_of_le'")
2025-12-16 15:24:09.420 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 115.11s.
2025-12-16 15:24:09.420 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="unknown identifier 'bliminf_def'\nunknown identifier 'bliminf_le_bliminf_of_le'")
2025-12-16 15:24:09.486 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:24:09.486 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:24:09.487 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp only [mem_iInf_iff]
2025-12-16 15:24:09.510 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:24:09.510 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:24:09.547 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:24:09.547 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:24:09.559 | SUCCESS  | lean_reinforcement.agent.runner:run:217 - Proof finished in 1 steps and 108.49s.
2025-12-16 15:24:09.691 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:24:09.691 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:24:17.987 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Pi.mulSupport_mulSingle_of_ne
2025-12-16 15:24:22.411 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:24:27.727 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: ONote.exists_lt_add
2025-12-16 15:24:28.304 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: FiniteField.trace_to_zmod_nondegenerate
2025-12-16 15:24:32.561 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:24:33.025 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:24:35.105 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Turing.TM2to1.supports_run
2025-12-16 15:24:39.486 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:25:31.252 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simpa using C.colorClass_ne_nil_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_o
2025-12-16 15:25:32.643 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="invalid field 'colorClass_ne_nil_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_o', the environment does not contain 'SimpleGraph.Coloring.colorClass_ne_nil_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_o'\n  C\nhas type\n  G.Coloring Œ±\ninvalid field 'colorClass_ne_nil_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_o', the environment does not contain 'SimpleGraph.Hom.colorClass_ne_nil_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_o'\n  C\nhas type\n  G ‚Üíg ‚ä§\ninvalid field 'colorClass_ne_nil_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_o', the environment does not contain 'RelHom.colorClass_ne_nil_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_o'\n  C\nhas type\n  G.Adj ‚Üír ‚ä§.Adj")
2025-12-16 15:25:32.643 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 188.16s.
2025-12-16 15:25:32.643 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="invalid field 'colorClass_ne_nil_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_o', the environment does not contain 'SimpleGraph.Coloring.colorClass_ne_nil_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_o'\n  C\nhas type\n  G.Coloring Œ±\ninvalid field 'colorClass_ne_nil_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_o', the environment does not contain 'SimpleGraph.Hom.colorClass_ne_nil_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_o'\n  C\nhas type\n  G ‚Üíg ‚ä§\ninvalid field 'colorClass_ne_nil_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_o', the environment does not contain 'RelHom.colorClass_ne_nil_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_of_mem_colorClass_o'\n  C\nhas type\n  G.Adj ‚Üír ‚ä§.Adj")
2025-12-16 15:25:32.773 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:25:32.774 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:25:36.950 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: exact mem_inv_of_mem_nonZeroDivisors_of_noZeroDivisors hI
2025-12-16 15:25:37.021 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="unknown identifier 'mem_inv_of_mem_nonZeroDivisors_of_noZeroDivisors'")
2025-12-16 15:25:37.021 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 181.43s.
2025-12-16 15:25:37.021 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="unknown identifier 'mem_inv_of_mem_nonZeroDivisors_of_noZeroDivisors'")
2025-12-16 15:25:37.151 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:25:37.151 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:25:37.388 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simpa only [Cardinal.lift_id] using lift_rank_span_set_le_rank s
2025-12-16 15:25:37.457 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="unknown identifier 'lift_rank_span_set_le_rank'")
2025-12-16 15:25:37.457 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 186.22s.
2025-12-16 15:25:37.457 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="unknown identifier 'lift_rank_span_set_le_rank'")
2025-12-16 15:25:37.588 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:25:37.588 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:25:38.018 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [‚Üê sin_pi_div_two_sub, ‚Üê sin_pi_div_two_add_sin_pi_div_two_add_sin_pi_div_two,
  sin_pi_div_two_add_sin_pi_div_two_add_sin_pi_div_two_add_sin_pi_div_two_add_sin_pi_div_two,
  sin_pi_div_two_add_sin_pi_div_two_add_sin_pi_div_two, sin_pi_div_two_add_sin_pi_div_two]
2025-12-16 15:25:38.105 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  Real.cos ?x\nx : ‚Ñù\n‚ä¢ Real.sin (œÄ / 16) = ‚àö(2 - ‚àö(2 + ‚àö2)) / 2")
2025-12-16 15:25:38.105 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 192.36s.
2025-12-16 15:25:38.106 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  Real.cos ?x\nx : ‚Ñù\n‚ä¢ Real.sin (œÄ / 16) = ‚àö(2 - ‚àö(2 + ‚àö2)) / 2")
2025-12-16 15:25:38.237 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:25:38.238 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:25:39.036 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [‚Üê CoheytingHom.comp_assoc, ‚Üê CoheytingHom.comp_assoc, CoheytingHom.comp_assoc,
  CoheytingHom.comp_assoc, CoheytingHom.comp_assoc, CoheytingHom.comp_assoc,
  CoheytingHom.comp_assoc, CoheytingHom.comp_assoc, CoheytingHom.comp_assoc, CoheytingHom.comp_assoc,
  CoheytingHom.comp_assoc, CoheytingHom.comp_assoc, CoheytingHom.comp_assoc, CoheytingHom.comp_assoc,
  CoheytingHom.comp_assoc, CoheytingHom.comp_assoc, CoheytingHom.comp_assoc, CoheytingHom.comp_assoc,
  CoheytingHom.comp_assoc, CoheytingHom.comp_assoc, CoheytingHom.comp_assoc, CoheytingHom.comp_assoc,
  CoheytingHom.comp_assoc, CoheytingHom.comp_assoc, CoheytingHom.comp_assoc, CoheytingHom.comp_assoc,
  CoheytingHom.comp_assoc, CoheytingHom.comp_assoc, CoheytingHom.comp_assoc, CoheytingHom.comp_assoc,
  CoheytingHom.comp_assoc, CoheytingHom.comp_assoc, CoheytingHom.comp_assoc, CoheytingHom.comp_assoc,
  CoheytingHom.comp_assoc, CoheytingHom.comp_assoc, CoheytingHom.comp_assoc, CoheytingHom.comp_assoc,
  CoheytingHom.comp_assoc, CoheytingHom.com
2025-12-16 15:25:39.105 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="<stdin>:11:43: unexpected end of input; expected ']'")
2025-12-16 15:25:39.105 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 183.66s.
2025-12-16 15:25:39.105 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="<stdin>:11:43: unexpected end of input; expected ']'")
2025-12-16 15:25:39.237 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:25:39.238 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:25:40.074 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Int.natCast_sub
2025-12-16 15:25:41.321 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp only [onTheory, Sentence.Realize, Sentence.Realize, Sentence.Realize, Sentence.Realize,
  Sentence.Realize, Sentence.Realize, Sentence.Realize, Sentence.Realize, Sentence.Realize,
  Sentence.Realize, Sentence.Realize, Sentence.Realize, Sentence.Realize, Sentence.Realize,
  Sentence.Realize, Sentence.Realize, Sentence.Realize, Sentence.Realize, Sentence.Realize,
  Sentence.Realize, Sentence.Realize, Sentence.Realize, Sentence.Realize, Sentence.Realize,
  Sentence.Realize, Sentence.Realize, Sentence.Realize, Sentence.Realize, Sentence.Realize,
  Sentence.Realize, Sentence.Realize, Sentence.Realize, Sentence.Realize, Sentence.Realize,
  Sentence.Realize, Sentence.Realize, Sentence.Realize, Sentence.Realize, Sentence.Realize,
  Sentence.Realize, Sentence.Realize, Sentence.Realize, Sentence.Realize, Sentence.Realize,
  Sentence.Realize, Sentence.Realize, Sentence.Realize, Sentence.Realize, Sentence.Realize,
  Sentence.Realize, Sentence.Realize, Sentence.Realize, Sentence.Realize, Sentence.Realize,
  Sentence
2025-12-16 15:25:41.391 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="<stdin>:12:10: unexpected end of input; expected ']'")
2025-12-16 15:25:41.391 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 159.32s.
2025-12-16 15:25:41.391 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="<stdin>:12:10: unexpected end of input; expected ']'")
2025-12-16 15:25:41.527 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:25:41.528 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:25:42.818 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [closedEmbedding_iff_closedEmbedding_of_finiteDimensional ùïú]
2025-12-16 15:25:42.981 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.605757\nùïú : Type u_1\nE : Type u_2\nF : Type u_3\ninst‚úù¬π‚Å¥ : NontriviallyNormedField ùïú\ninst‚úù¬π¬≥ : CompleteSpace ùïú\ninst‚úù¬π¬≤ : AddCommGroup E\ninst‚úù¬π¬π : TopologicalSpace E\ninst‚úù¬π‚Å∞ : T2Space E\ninst‚úù‚Åπ : TopologicalAddGroup E\ninst‚úù‚Å∏ : Module ùïú E\ninst‚úù‚Å∑ : ContinuousSMul ùïú E\ninst‚úù‚Å∂ : AddCommGroup F\ninst‚úù‚Åµ : TopologicalSpace F\ninst‚úù‚Å¥ : T2Space F\ninst‚úù¬≥ : TopologicalAddGroup F\ninst‚úù¬≤ : Module ùïú F\ninst‚úù¬π : ContinuousSMul ùïú F\ninst‚úù : FiniteDimensional ùïú E\nf : E ‚Üí‚Çó[ùïú] F\nhf : LinearMap.ker f = ‚ä•\n‚ä¢ ClosedEmbedding ‚áëf")
2025-12-16 15:25:42.981 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 185.47s.
2025-12-16 15:25:42.981 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.605757\nùïú : Type u_1\nE : Type u_2\nF : Type u_3\ninst‚úù¬π‚Å¥ : NontriviallyNormedField ùïú\ninst‚úù¬π¬≥ : CompleteSpace ùïú\ninst‚úù¬π¬≤ : AddCommGroup E\ninst‚úù¬π¬π : TopologicalSpace E\ninst‚úù¬π‚Å∞ : T2Space E\ninst‚úù‚Åπ : TopologicalAddGroup E\ninst‚úù‚Å∏ : Module ùïú E\ninst‚úù‚Å∑ : ContinuousSMul ùïú E\ninst‚úù‚Å∂ : AddCommGroup F\ninst‚úù‚Åµ : TopologicalSpace F\ninst‚úù‚Å¥ : T2Space F\ninst‚úù¬≥ : TopologicalAddGroup F\ninst‚úù¬≤ : Module ùïú F\ninst‚úù¬π : ContinuousSMul ùïú F\ninst‚úù : FiniteDimensional ùïú E\nf : E ‚Üí‚Çó[ùïú] F\nhf : LinearMap.ker f = ‚ä•\n‚ä¢ ClosedEmbedding ‚áëf")
2025-12-16 15:25:43.115 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:25:43.116 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:25:45.000 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: nonempty_fun
2025-12-16 15:25:45.447 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rcases lt_or_eq_of_le h with (‚ü®i, hi‚ü© | ‚ü®i, hi‚ü©)
2025-12-16 15:25:45.536 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='rcases tactic failed: h‚úù : Preorder.toLT.1 ?m.267689 ?m.267690 is not an inductive datatype')
2025-12-16 15:25:45.536 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 77.81s.
2025-12-16 15:25:45.536 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='rcases tactic failed: h‚úù : Preorder.toLT.1 ?m.267689 ?m.267690 is not an inductive datatype')
2025-12-16 15:25:45.669 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:25:45.669 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:25:46.185 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:25:47.611 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp [NormNoninc, NormNoninc]
2025-12-16 15:25:47.709 | SUCCESS  | lean_reinforcement.agent.runner:run:217 - Proof finished in 1 steps and 208.11s.
2025-12-16 15:25:47.841 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:25:47.842 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:25:49.304 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Set.Ico.coe_lt_one
2025-12-16 15:25:50.353 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:25:51.672 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: refine iInf_congr fun i => iInf_congr fun i =>?_
2025-12-16 15:25:53.037 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Matrix.map_map
2025-12-16 15:25:54.347 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:25:54.671 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Nat.factorizationEquiv_apply
2025-12-16 15:25:56.886 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 2: Running MCTS search for 200 iterations...
2025-12-16 15:25:56.886 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 2: Applying best tactic: exact h _ i
2025-12-16 15:25:56.955 | SUCCESS  | lean_reinforcement.agent.runner:run:217 - Proof finished in 2 steps and 229.96s.
2025-12-16 15:25:57.087 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:25:57.088 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:25:57.793 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:25:58.236 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Polynomial.natDegree_C_add
2025-12-16 15:25:59.849 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:26:02.699 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:26:10.012 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: tendsto_inverse_atTop_nhds_zero_nat
2025-12-16 15:26:12.085 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: differentiableWithinAt_inter'
2025-12-16 15:26:13.882 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Finset.sdiff_eq_empty_iff_subset
2025-12-16 15:26:14.568 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:26:16.805 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:26:16.979 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: HasStrictFDerivAt.isBigO_sub_rev
2025-12-16 15:26:18.691 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:26:18.716 | INFO     | lean_reinforcement.training.trainer:_collect_data:277 - Completed 16/128 proofs
2025-12-16 15:26:21.359 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:26:22.980 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp [mulSupport_mulSingle, h]
2025-12-16 15:26:23.045 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='simp made no progress')
2025-12-16 15:26:23.045 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 125.06s.
2025-12-16 15:26:23.045 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='simp made no progress')
2025-12-16 15:26:23.158 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: induction m with
| zero => simp
| succ n ih => simp only [Int.cast_sub, Int.cast_natCast, Int.cast_sub, Int.cast_sub, Int.cast_sub,
  Int.cast_natCast, Int.cast_sub, Int.cast_natCast, Int.cast_natCast, Int.cast_natCast,
  Int.cast_sub, Int.cast_sub, Int.cast_sub, Int.cast_sub, Int.cast_natCast, Int.cast_natCast,
  Int.cast_sub, Int.cast_sub, Int.cast_sub, Int.cast_sub, Int.cast_natCast, Int.cast_natCast,
  Int.cast_sub, Int.cast_sub, Int.cast_sub, Int.cast_sub, Int.cast_natCast, Int.cast_natCast,
  Int.cast_sub, Int.cast_sub, Int.cast_sub, Int.cast_sub, Int.cast_natCast, Int.cast_natCast,
  Int.cast_sub, Int.cast_sub, Int.cast_sub, Int.cast_sub, Int.cast_sub, Int.cast_natCast,
  Int.cast_sub, Int.cast_sub, Int.cast_sub, Int.cast_sub, Int.cast_natCast, Int.cast_natCast,
  Int.cast_sub, Int.cast_sub, Int.cast_sub, Int.cast_sub, Int.cast_sub, Int.cast_natCast,
  Int.cast_sub, Int.cast_sub, Int.cast_sub, Int.cast_sub, Int.cast_sub, Int.cast_natCast,
  Int.cast_sub, Int.cast_sub, Int.cast_sub, Int.cast_sub, Int.c
2025-12-16 15:26:23.175 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:26:23.175 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:26:23.228 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="<stdin>:13:63: unexpected end of input; expected ']'")
2025-12-16 15:26:23.228 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 43.15s.
2025-12-16 15:26:23.228 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="<stdin>:13:63: unexpected end of input; expected ']'")
2025-12-16 15:26:23.359 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:26:23.359 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:26:23.761 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [TM2.SupportsStmt, TM2.SupportsStmt]
2025-12-16 15:26:23.836 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="failed to rewrite using equation theorems for 'Turing.TM2.SupportsStmt'")
2025-12-16 15:26:23.836 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 108.73s.
2025-12-16 15:26:23.836 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="failed to rewrite using equation theorems for 'Turing.TM2.SupportsStmt'")
2025-12-16 15:26:23.969 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:26:23.969 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:26:31.837 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: WType.infinite_of_nonempty_of_isEmpty
2025-12-16 15:26:32.820 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: TopologicalSpace.Opens.coe_top
2025-12-16 15:26:36.418 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:26:36.857 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Set.Ioc_union_Ioi_eq_Ioi
2025-12-16 15:26:37.635 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:26:41.352 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:27:02.257 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simpa using x.2.2
2025-12-16 15:27:02.322 | SUCCESS  | lean_reinforcement.agent.runner:run:217 - Proof finished in 1 steps and 73.02s.
2025-12-16 15:27:02.452 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:27:02.452 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:27:10.336 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: ENat.toENNReal_sub
2025-12-16 15:27:14.988 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:27:19.332 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [DifferentiableWithinAt, DifferentiableWithinAt, DifferentiableWithinAt, DifferentiableWithinAt,
  DifferentiableWithinAt, DifferentiableWithinAt, DifferentiableWithinAt]
2025-12-16 15:27:19.407 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="failed to rewrite using equation theorems for 'DifferentiableWithinAt'")
2025-12-16 15:27:19.407 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 67.32s.
2025-12-16 15:27:19.408 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="failed to rewrite using equation theorems for 'DifferentiableWithinAt'")
2025-12-16 15:27:19.538 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:27:19.538 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:27:20.038 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp only [natDegree_C, natDegree_zero, zero_add]
2025-12-16 15:27:20.103 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='simp made no progress')
2025-12-16 15:27:20.103 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 81.87s.
2025-12-16 15:27:20.103 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='simp made no progress')
2025-12-16 15:27:20.235 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:27:20.235 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:27:20.283 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [‚Üê coe_sdiff, coe_eq_empty, coe_eq_empty]
2025-12-16 15:27:20.381 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  ‚Üë?s‚ÇÅ \\ ‚Üë?s‚ÇÇ\nŒ± : Type u_1\nŒ≤ : Type u_2\nŒ≥ : Type u_3\ninst‚úù : DecidableEq Œ±\ns t u v : Finset Œ±\na b : Œ±\n‚ä¢ s \\ t = ‚àÖ ‚Üî s ‚äÜ t")
2025-12-16 15:27:20.382 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 66.50s.
2025-12-16 15:27:20.382 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  ‚Üë?s‚ÇÅ \\ ‚Üë?s‚ÇÇ\nŒ± : Type u_1\nŒ≤ : Type u_2\nŒ≥ : Type u_3\ninst‚úù : DecidableEq Œ±\ns t u v : Finset Œ±\na b : Œ±\n‚ä¢ s \\ t = ‚àÖ ‚Üî s ‚äÜ t")
2025-12-16 15:27:20.513 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:27:20.513 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:27:21.087 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: exact tendsto_inv_atTop_zero.inv_tendsto_atTop
2025-12-16 15:27:21.303 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='type mismatch\n  Filter.Tendsto.inv_tendsto_atTop (sorryAx (Filter.Tendsto (fun r => r‚Åª¬π) Filter.atTop Filter.atTop) true)\nhas type\n  Filter.Tendsto (fun r => r‚Åª¬π)‚Åª¬π Filter.atTop (ùìù 0) : Prop\nbut is expected to have type\n  Filter.Tendsto (fun n => (‚Üën)‚Åª¬π) Filter.atTop (ùìù 0) : Prop')
2025-12-16 15:27:21.303 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 71.29s.
2025-12-16 15:27:21.303 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='type mismatch\n  Filter.Tendsto.inv_tendsto_atTop (sorryAx (Filter.Tendsto (fun r => r‚Åª¬π) Filter.atTop Filter.atTop) true)\nhas type\n  Filter.Tendsto (fun r => r‚Åª¬π)‚Åª¬π Filter.atTop (ùìù 0) : Prop\nbut is expected to have type\n  Filter.Tendsto (fun n => (‚Üën)‚Åª¬π) Filter.atTop (ùìù 0) : Prop')
2025-12-16 15:27:21.437 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:27:21.437 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:27:23.672 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: infer_instance
2025-12-16 15:27:23.750 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='failed to synthesize\n  Infinite (WType Œ≤)\nuse `set_option diagnostics true` to get diagnostic information')
2025-12-16 15:27:23.750 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 51.91s.
2025-12-16 15:27:23.750 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='failed to synthesize\n  Infinite (WType Œ≤)\nuse `set_option diagnostics true` to get diagnostic information')
2025-12-16 15:27:23.884 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:27:23.884 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:27:26.154 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [union_comm, Ioc_union_Ioi' h]
2025-12-16 15:27:26.191 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: List.getD_eq_default
2025-12-16 15:27:26.248 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.89696\nŒ± : Type u_1\nŒ≤ : Type u_2\ninst‚úù : LinearOrder Œ±\na a‚ÇÅ a‚ÇÇ b b‚ÇÅ b‚ÇÇ c d : Œ±\nh : a ‚â§ b\n‚ä¢ Set.Ioi b ‚à™ Set.Ioc a b = Set.Ioi a")
2025-12-16 15:27:26.248 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 49.39s.
2025-12-16 15:27:26.248 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.89696\nŒ± : Type u_1\nŒ≤ : Type u_2\ninst‚úù : LinearOrder Œ±\na a‚ÇÅ a‚ÇÇ b b‚ÇÅ b‚ÇÇ c d : Œ±\nh : a ‚â§ b\n‚ä¢ Set.Ioi b ‚à™ Set.Ioc a b = Set.Ioi a")
2025-12-16 15:27:26.379 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:27:26.379 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:27:26.680 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [coe_sub, coe_sub, coe_sub, coe_natCast, coe_natCast, coe_natCast]
2025-12-16 15:27:26.764 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  ‚Üë(?m - ?n)\nm‚úù n‚úù m n : ‚Ñï‚àû\n‚ä¢ ‚Üë(m - n) = ‚Üëm - ‚Üën")
2025-12-16 15:27:26.764 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 16.43s.
2025-12-16 15:27:26.765 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  ‚Üë(?m - ?n)\nm‚úù n‚úù m n : ‚Ñï‚àû\n‚ä¢ ‚Üë(m - n) = ‚Üëm - ‚Üën")
2025-12-16 15:27:26.898 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:27:26.898 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:27:27.055 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Int.succ_dvd_or_succ_dvd_of_succ_sum_dvd_mul
2025-12-16 15:27:28.538 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: intro Œµ hŒµ
2025-12-16 15:27:29.416 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp only [specializes_iff_closure_subset, specializes_iff_closure_subset]
2025-12-16 15:27:30.942 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: cases nonempty_fintype F
2025-12-16 15:27:32.588 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:27:33.421 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: CategoryTheory.PresheafOfGroups.Cochain‚ÇÄ.one_apply
2025-12-16 15:27:33.570 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:27:34.340 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: map_bind
2025-12-16 15:27:34.647 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 2: Running MCTS search for 200 iterations...
2025-12-16 15:27:35.450 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 2: Running MCTS search for 200 iterations...
2025-12-16 15:27:36.098 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Filter.liminf_eq_sSup_sInf
2025-12-16 15:27:36.844 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 2: Running MCTS search for 200 iterations...
2025-12-16 15:27:38.310 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:27:39.273 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:27:40.215 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: LinearMap.restrict_comp
2025-12-16 15:27:41.134 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:27:44.923 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:27:48.909 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: AEMeasurable.singularPart
2025-12-16 15:27:53.683 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:28:03.836 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp [factorizationEquiv]
2025-12-16 15:28:08.413 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 2: Running MCTS search for 200 iterations...
2025-12-16 15:28:44.693 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: induction l generalizing l with
| nil => simp
| cons x _ ih =>
  rw [getD_cons_of_length_lt _ hn, getD_cons_of_length_lt _ hn, getD_cons_of_length_lt _ hn,
    getD_cons_of_length_lt _ hn]
| cons x _ ih =>
  rw [getD_cons_of_length_lt _ hn, getD_cons_of_length_lt _ hn, getD_cons_of_length_lt _ hn,
    getD_cons_of_length_lt _ hn, getD_cons_of_length_lt _ hn]
| cons x _ ih =>
  rw [getD_cons_of_length_lt _ hn, getD_cons_of_length_lt _ hn, getD_cons_of_length_lt _ hn,
    getD_cons_of_length_lt _ hn, getD_cons_of_length_lt _ hn, getD_cons_of_length_lt _ hn]
2025-12-16 15:28:44.763 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='variable cannot be generalized because target depends on it\n  l')
2025-12-16 15:28:44.763 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 78.57s.
2025-12-16 15:28:44.764 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='variable cannot be generalized because target depends on it\n  l')
2025-12-16 15:28:44.894 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:28:44.894 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:28:45.022 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 2: Applying best tactic: obtain ‚ü®b, hb‚ü© := Algebra.trace_eq_zero_iff.mp ha
2025-12-16 15:28:45.092 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 2: Applying best tactic: obtain ‚ü®N, hN‚ü© := exists_pow_neg_lt_of_lt_of_le hnorm hŒµ
2025-12-16 15:28:45.098 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='rcases tactic failed: x‚úù : ?m.19455 is not an inductive datatype')
2025-12-16 15:28:45.098 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 2 steps and 256.79s.
2025-12-16 15:28:45.098 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='rcases tactic failed: x‚úù : ?m.19455 is not an inductive datatype')
2025-12-16 15:28:45.163 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='rcases tactic failed: x‚úù : ?m.209581 is not an inductive datatype')
2025-12-16 15:28:45.163 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 2 steps and 377.60s.
2025-12-16 15:28:45.164 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='rcases tactic failed: x‚úù : ?m.209581 is not an inductive datatype')
2025-12-16 15:28:45.228 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:28:45.228 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:28:45.293 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:28:45.293 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:28:47.108 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [‚Üê Int.natCast_dvd_natCast, ‚Üê Int.natCast_dvd_natCast, ‚Üê Int.natCast_dvd_natCast, ‚Üê
  Int.natCast_dvd_natCast, ‚Üê Int.natCast_dvd_natCast, ‚Üê Int.natCast_dvd_natCast, ‚Üê
  Int.natCast_dvd_natCast, ‚Üê Int.natCast_dvd_natCast, ‚Üê Int.natCast_dvd_natCast, ‚Üê
  Int.natCast_dvd_natCast, ‚Üê Int.natCast_dvd_natCast, ‚Üê Int.natCast_dvd_natCast, ‚Üê
  Int.natCast_dvd_natCast, ‚Üê Int.natCast_dvd_natCast, ‚Üê Int.natCast_dvd_natCast, ‚Üê
  Int.natCast_dvd_natCast, ‚Üê Int.natCast_dvd_natCast, ‚Üê Int.natCast_dvd_natCast, ‚Üê
  Int.natCast_dvd_natCast, ‚Üê Int.natCast_dvd_natCast, ‚Üê Int.natCast_dvd_natCast, ‚Üê
  Int.natCast_dvd_natCast, ‚Üê Int.natCast_dvd_natCast, ‚Üê Int.natCast_dvd_natCast, ‚Üê
  Int.natCast_dvd_natCast]
2025-12-16 15:28:47.217 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  ?m.908 ‚à£ ?m.909\np : ‚Ñï\np_prime : Nat.Prime p\nm n : ‚Ñ§\nk l : ‚Ñï\nhpm : ‚Üë(p ^ k) ‚à£ m\nhpn : ‚Üë(p ^ l) ‚à£ n\nhpmn : ‚Üë(p ^ (k + l + 1)) ‚à£ m * n\n‚ä¢ ‚Üë(p ^ (k + 1)) ‚à£ m ‚à® ‚Üë(p ^ (l + 1)) ‚à£ n")
2025-12-16 15:28:47.217 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 80.16s.
2025-12-16 15:28:47.217 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  ?m.908 ‚à£ ?m.909\np : ‚Ñï\np_prime : Nat.Prime p\nm n : ‚Ñ§\nk l : ‚Ñï\nhpm : ‚Üë(p ^ k) ‚à£ m\nhpn : ‚Üë(p ^ l) ‚à£ n\nhpmn : ‚Üë(p ^ (k + l + 1)) ‚à£ m * n\n‚ä¢ ‚Üë(p ^ (k + 1)) ‚à£ m ‚à® ‚Üë(p ^ (l + 1)) ‚à£ n")
2025-12-16 15:28:47.349 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:28:47.349 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:28:53.160 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Nat.recDiag_succ_zero
2025-12-16 15:28:55.284 | INFO     | lean_reinforcement.training.trainer:_collect_data:277 - Completed 32/128 proofs
2025-12-16 15:28:57.683 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:28:59.414 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp only [Category.comp_id, Category.assoc, Category.comp_id, Category.id_comp]
2025-12-16 15:28:59.478 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='simp made no progress')
2025-12-16 15:28:59.478 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 86.06s.
2025-12-16 15:28:59.478 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='simp made no progress')
2025-12-16 15:28:59.608 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:28:59.608 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:28:59.902 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: exact aemeasurable_singularPart hf
2025-12-16 15:28:59.969 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="unknown identifier 'aemeasurable_singularPart'")
2025-12-16 15:28:59.969 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 71.06s.
2025-12-16 15:28:59.969 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="unknown identifier 'aemeasurable_singularPart'")
2025-12-16 15:29:00.101 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:29:00.101 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:29:00.910 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: exact optPara_le_of_mapsTo_of_mapsTo_of_mapsTo_of_mapsTo_of_mapsTo_of_mapsTo_of_mapsTo_of_mapsTo_of_mapsTo_of_mapsTo_optPara hf hg hfg
2025-12-16 15:29:00.993 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="unknown identifier 'optPara_le_of_mapsTo_of_mapsTo_of_mapsTo_of_mapsTo_of_mapsTo_of_mapsTo_of_mapsTo_of_mapsTo_of_mapsTo_of_mapsTo_optPara'")
2025-12-16 15:29:00.993 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 80.78s.
2025-12-16 15:29:00.993 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="unknown identifier 'optPara_le_of_mapsTo_of_mapsTo_of_mapsTo_of_mapsTo_of_mapsTo_of_mapsTo_of_mapsTo_of_mapsTo_of_mapsTo_of_mapsTo_optPara'")
2025-12-16 15:29:01.126 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:29:01.126 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:29:01.465 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [liminf_eq_sSup_image, liminf_eq_sSup_image]
2025-12-16 15:29:01.580 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.144398\nŒ± : Type u_1\nŒ≤ : Type u_2\nŒ≥ : Type u_3\nŒπ‚úù : Type u_4\nŒπ' : Type u_5\ninst‚úù¬π : CompleteLattice Œ±\nŒπ : Type u_6\nR : Type u_7\nF : Filter Œπ\ninst‚úù : CompleteLattice R\na : Œπ ‚Üí R\n‚ä¢ Filter.liminf a F = sSup ((fun I => sInf (a '' I)) '' F.sets)")
2025-12-16 15:29:01.580 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 85.48s.
2025-12-16 15:29:01.580 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.144398\nŒ± : Type u_1\nŒ≤ : Type u_2\nŒ≥ : Type u_3\nŒπ‚úù : Type u_4\nŒπ' : Type u_5\ninst‚úù¬π : CompleteLattice Œ±\nŒπ : Type u_6\nR : Type u_7\nF : Filter Œπ\ninst‚úù : CompleteLattice R\na : Œπ ‚Üí R\n‚ä¢ Filter.liminf a F = sSup ((fun I => sInf (a '' I)) '' F.sets)")
2025-12-16 15:29:01.713 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:29:01.714 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:29:04.361 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: RCLike.I_re
2025-12-16 15:29:06.461 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Polynomial.eval_one_map
2025-12-16 15:29:09.531 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:29:10.885 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:29:11.720 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: CategoryTheory.dcongr_arg
2025-12-16 15:29:12.187 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: PNat.modDivAux_spec
2025-12-16 15:29:16.418 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:29:17.049 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:29:23.564 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: LieIdeal.map_eq_bot_iff
2025-12-16 15:29:24.943 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 2: Applying best tactic: rw [factorization_eq_factors_map, factorization_eq_factors_map, factorization_eq_factors_map,
  factorization_eq_factors_map, factorization_eq_factors_map, factorization_eq_factors_map,
  factorization_eq_factors_map, factorization_eq_factors_map, factorization_eq_factors_map,
  factorization_eq_factors_map, factorization_eq_factors_map, factorization_eq_factors_map,
  factorization_eq_factors_map, factorization_eq_factors_map, factorization_eq_factors_map,
  factorization_eq_factors_map, factorization_eq_factors_map, factorization_eq_factors_map,
  factorization_eq_factors_map, factorization_eq_factors_map, factorization_eq_factors_map,
  factorization_eq_factors_map, factorization_eq_factors_map, factorization_eq_factors_map,
  factorization_eq_factors_map, factorization_eq_factors_map, factorization_eq_factors_map,
  factorization_eq_factors_map, factorization_eq_factors_map, factorization_eq_factors_map,
  factorization_eq_factors_map, factorization_eq_factors_map, factorization_eq_factors_map]
2025-12-16 15:29:25.036 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.59347\na b m n‚úù p : ‚Ñï\nn : ‚Ñï+\n‚ä¢ ‚Üë(match n with\n      | ‚ü®n, property‚ü© => ‚ü®n.factorization, ‚ãØ‚ü©) =\n    (‚Üën).factorization")
2025-12-16 15:29:25.036 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 2 steps and 210.37s.
2025-12-16 15:29:25.036 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.59347\na b m n‚úù p : ‚Ñï\nn : ‚Ñï+\n‚ä¢ ‚Üë(match n with\n      | ‚ü®n, property‚ü© => ‚ü®n.factorization, ‚ãØ‚ü©) =\n    (‚Üën).factorization")
2025-12-16 15:29:25.168 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:29:25.168 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:29:27.294 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Convex.norm_image_sub_le_of_norm_derivWithin_le
2025-12-16 15:29:28.085 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:29:31.804 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:29:32.154 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: tendsto_setIntegral_pow_smul_of_unique_maximum_of_isCompact_of_integrableOn
2025-12-16 15:29:36.583 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:29:53.987 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: induction m with
| zero => rfl
| succ_zero zero_zero zero_succ zero_succ zero_succ zero_succ zero_succ zero_succ zero_succ
| succ_zero zero_succ zero_succ zero_succ zero_succ zero_succ zero_succ zero_succ zero_succ
| succ_zero zero_succ zero_succ zero_succ zero_succ zero_succ zero_succ zero_succ zero_succ
| succ_zero zero_succ zero_succ zero_succ zero_succ zero_succ zero_succ zero_succ zero_succ
| succ_zero zero_succ zero_succ zero_succ zero_succ zero_succ zero_succ zero_succ zero_succ
| succ_zero zero_succ zero_succ zero_succ zero_succ zero_succ zero_succ zero_succ zero_succ
| succ_zero zero_succ zero_succ zero_succ zero_succ zero_succ zero_succ zero_succ zero_succ
| succ_zero zero_succ zero_succ zero_succ zero_succ zero_succ zero_succ zero_succ zero_succ
| succ_zero zero_succ zero_succ zero_succ zero_succ zero_succ zero_succ zero_succ zero_succ
| succ_zero zero_succ zero_succ zero_succ zero_succ zero_succ zero_succ zero_succ zero_succ
| succ_zero zero_succ zero_succ zero_succ zero_succ zero_succ zero_succ 
2025-12-16 15:29:54.055 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="<stdin>:13:72: unexpected end of input; expected '=>'")
2025-12-16 15:29:54.056 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 60.90s.
2025-12-16 15:29:54.056 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="<stdin>:13:72: unexpected end of input; expected '=>'")
2025-12-16 15:29:54.186 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:29:54.186 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:29:55.165 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [‚Üê ofReal_re, ofReal_re, ofReal_re, ofReal_re, ofReal_re, ofReal_re, ofReal_re]
2025-12-16 15:29:55.253 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, pattern is a metavariable\n  ?r\nfrom equation\n  ?r = RCLike.re ‚Üë?r\nK : Type u_1\nE : Type u_2\ninst‚úù : RCLike K\n‚ä¢ RCLike.re RCLike.I = 0")
2025-12-16 15:29:55.253 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 50.89s.
2025-12-16 15:29:55.253 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, pattern is a metavariable\n  ?r\nfrom equation\n  ?r = RCLike.re ‚Üë?r\nK : Type u_1\nE : Type u_2\ninst‚úù : RCLike K\n‚ä¢ RCLike.re RCLike.I = 0")
2025-12-16 15:29:55.384 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:29:55.384 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:30:04.084 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Matrix.conjTranspose_eq_one
2025-12-16 15:30:07.363 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Set.empty_union
2025-12-16 15:30:08.961 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:30:11.969 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:30:15.948 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Finset.mem_inter_of_mem
2025-12-16 15:30:20.726 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:30:28.040 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp [h]
2025-12-16 15:30:28.114 | SUCCESS  | lean_reinforcement.agent.runner:run:217 - Proof finished in 1 steps and 76.39s.
2025-12-16 15:30:28.233 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: induction p using Polynomial.induction_on' with
| h_add p q hp hq =>
  simp only [hp, hq, Polynomial.map_add]
| h_monomial n b =>
  simp only [hp, hq, Polynomial.map_add]
| h_monomial n b =>
  simp only [hp, hq, Polynomial.map_add]
| h_monomial n b =>
  simp only [hp, hq, Polynomial.map_add]
| h_monomial n b =>
  simp only [hp, hq, Polynomial.map_add]
| h_monomial n b =>
  simp only [hp, hq, Polynomial.map_add]
| h_monomial n b =>
  simp only [hp, hq, Polynomial.map_add]
| h_monomial n b =>
  simp only [hp, hq, Polynomial.map_add]
| h_monomial n b =>
  simp only [hp, hq, Polynomial.map_add]
| h_monomial n b =>
  simp only [hp, hq, Polynomial.map_add]
| h_monomial n b =>
  simp only [hp, hq, Polynomial.map_add]
| h_monomial n b =>
  simp only [hp, hq, Polynomial.map_add]
| h_monomial n b =>
  simp only [hp, hq, Polynomial.map_add]
| h_monomial n b =>
  simp only [hp, hq, Polynomial.map_add]
| h_monomial n b =>
  simp only [hp, hq, Polynomial.map_add]
| h_monomial n b =>
  simp only [hp, hq, Polynomial.map_add
2025-12-16 15:30:28.245 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:30:28.245 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:30:28.303 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="<stdin>:33:39: unexpected end of input; expected ']'")
2025-12-16 15:30:28.303 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 81.84s.
2025-12-16 15:30:28.303 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="<stdin>:33:39: unexpected end of input; expected ']'")
2025-12-16 15:30:28.434 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:30:28.434 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:30:47.370 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: LieHom.map_smul
2025-12-16 15:30:51.167 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: MeasureTheory.Integrable.ae_eq_of_withDensity·µ•_eq
2025-12-16 15:30:51.942 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:30:55.463 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:31:14.539 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [‚Üê bind_pure_comp, bind_assoc]
2025-12-16 15:31:14.888 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: have : ‚Äñf y - f x‚Äñ ‚â§ C * ‚Äñy - x‚Äñ :=
  calc
    ‚ÄñderivWithin f s x‚Äñ ‚â§ C * ‚Äñy - x‚Äñ := norm_sub_le _ _
   _ ‚â§ C * ‚Äñy - x‚Äñ := norm_sub_le _ _
   _ ‚â§ C * ‚Äñy - x‚Äñ := norm_sub_le _ _
   _ ‚â§ C * ‚Äñy - x‚Äñ := norm_sub_le _ _
   _ ‚â§ C * ‚Äñy - x‚Äñ := norm_sub_le _ _
   _ ‚â§ C * ‚Äñy - x‚Äñ := norm_sub_le _ _
   _ ‚â§ C * ‚Äñy - x‚Äñ := norm_sub_le _ _
   _ ‚â§ C * ‚Äñy - x‚Äñ := norm_sub_le _ _
   _ ‚â§ C * ‚Äñy - x‚Äñ := norm_sub_le _ _
   _ ‚â§ C * ‚Äñy - x‚Äñ := norm_sub_le _ _
   _ ‚â§ C * ‚Äñy - x‚Äñ := norm_sub_le _ _
   _ ‚â§ C * ‚Äñy - x‚Äñ := norm_sub_le _ _
   _ ‚â§ C * ‚Äñy - x‚Äñ := norm_sub_le _ _
   _ ‚â§ C * ‚Äñy - x‚Äñ := norm_sub_le _ _
   _ ‚â§ C * ‚Äñy - x‚Äñ := norm_sub_le _ _
   _ ‚â§ C * ‚Äñy - x‚Äñ := norm_sub_le _ _
   _ ‚â§ C * ‚Äñy - x‚Äñ := norm_sub_le _ _
   _ ‚â§ C * ‚Äñy - x‚Äñ := norm_sub_le _ _
   _ ‚â§ C * ‚Äñy - x‚Äñ := norm_sub_le _ _
   _ ‚â§ C * ‚Äñy - x‚Äñ := norm_sub_le _ _
   _ ‚â§ C * ‚Äñy - x‚Äñ := norm_sub_le _ _
   _ ‚â§ C * ‚Äñy - x
2025-12-16 15:31:14.960 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="<stdin>:24:17: unexpected end of input; expected '‚Äñ' or '‚Äñ‚Çä'")
2025-12-16 15:31:14.961 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 107.67s.
2025-12-16 15:31:14.961 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="<stdin>:24:17: unexpected end of input; expected '‚Äñ' or '‚Äñ‚Çä'")
2025-12-16 15:31:15.091 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:31:15.091 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:31:18.205 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [union_empty, empty_union]
2025-12-16 15:31:18.298 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  ?a ‚à™ ‚àÖ\nŒ± : Type u\nŒ≤ : Type v\nŒ≥ : Type w\nŒπ : Sort x\na‚úù b : Œ±\ns s‚ÇÅ s‚ÇÇ t t‚ÇÅ t‚ÇÇ u a : Set Œ±\n‚ä¢ ‚àÖ ‚à™ a = a")
2025-12-16 15:31:18.298 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 70.94s.
2025-12-16 15:31:18.298 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  ?a ‚à™ ‚àÖ\nŒ± : Type u\nŒ≤ : Type v\nŒ≥ : Type w\nŒπ : Sort x\na‚úù b : Œ±\ns s‚ÇÅ s‚ÇÇ t t‚ÇÅ t‚ÇÇ u a : Set Œ±\n‚ä¢ ‚àÖ ‚à™ a = a")
2025-12-16 15:31:18.431 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:31:18.431 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:31:19.009 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 2: Running MCTS search for 200 iterations...
2025-12-16 15:31:19.009 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 2: Applying best tactic: simp [bind_pure_comp]
2025-12-16 15:31:19.082 | SUCCESS  | lean_reinforcement.agent.runner:run:217 - Proof finished in 2 steps and 224.74s.
2025-12-16 15:31:19.213 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:31:19.213 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:31:19.570 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [conjTranspose_eq_conjTranspose, conjTranspose_conjTranspose]
2025-12-16 15:31:19.686 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.609252\nl : Type u_1\nm : Type u_2\nn : Type u_3\no : Type u_4\nm' : o ‚Üí Type u_5\nn' : o ‚Üí Type u_6\nR : Type u_7\nS : Type u_8\nŒ± : Type v\nŒ≤ : Type w\nŒ≥ : Type u_9\ninst‚úù¬≤ : DecidableEq n\ninst‚úù¬π : Semiring Œ±\ninst‚úù : StarRing Œ±\nM : Matrix n n Œ±\n‚ä¢ M·¥¥ = 1 ‚Üî M = 1")
2025-12-16 15:31:19.687 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 75.60s.
2025-12-16 15:31:19.687 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.609252\nl : Type u_1\nm : Type u_2\nn : Type u_3\no : Type u_4\nm' : o ‚Üí Type u_5\nn' : o ‚Üí Type u_6\nR : Type u_7\nS : Type u_8\nŒ± : Type v\nŒ≤ : Type w\nŒ≥ : Type u_9\ninst‚úù¬≤ : DecidableEq n\ninst‚úù¬π : Semiring Œ±\ninst‚úù : StarRing Œ±\nM : Matrix n n Œ±\n‚ä¢ M·¥¥ = 1 ‚Üî M = 1")
2025-12-16 15:31:19.819 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:31:19.819 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:31:27.765 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: BiheytingHom.coe_id
2025-12-16 15:31:28.938 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: CategoryTheory.SingleObj.mapHom_comp
2025-12-16 15:31:32.091 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: SimpleGraph.deleteEdges_le
2025-12-16 15:31:32.290 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:31:33.426 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:31:34.993 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp only [LinearMap.map_smul‚Çõ‚Çó, LinearMap.map_smul‚Çõ‚Çó, LinearMap.map_smul‚Çõ‚Çó,
  LinearMap.map_smul‚Çõ‚Çó, LinearMap.map_smul‚Çõ‚Çó, LinearMap.map_smul‚Çõ‚Çó, LinearMap.map_smul‚Çõ‚Çó,
  LinearMap.map_smul‚Çõ‚Çó, LinearMap.map_smul‚Çõ‚Çó, LinearMap.map_smul‚Çõ‚Çó, LinearMap.map_smul‚Çõ‚Çó,
  LinearMap.map_smul‚Çõ‚Çó, LinearMap.map_smul‚Çõ‚Çó, LinearMap.map_smul‚Çõ‚Çó, LinearMap.map_smul‚Çõ‚Çó,
  LinearMap.map_smul‚Çõ‚Çó, LinearMap.map_smul‚Çõ‚Çó, LinearMap.map_smul‚Çõ‚Çó, LinearMap.map_smul‚Çõ‚Çó,
  LinearMap.map_smul‚Çõ‚Çó, LinearMap.map_smul‚Çõ‚Çó, LinearMap.map_smul‚Çõ‚Çó]
2025-12-16 15:31:35.063 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='simp made no progress')
2025-12-16 15:31:35.064 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 47.69s.
2025-12-16 15:31:35.064 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='simp made no progress')
2025-12-16 15:31:35.195 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:31:35.195 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:31:36.842 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:31:37.271 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [‚Üê withDensity·µ•_symmDiff_eq_withDensity·µ•_symmDiff_eq_withDensity·µ•_symmDiff_eq_withDensity·µ•_symmDiff_eq_withDensity·µ•_symmDiff_eq_withDensity·µ•_symmDiff
  hf hg hfg]
2025-12-16 15:31:37.398 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.54060\nŒ± : Type u_1\nŒ≤ : Type u_2\nm : MeasurableSpace Œ±\nŒº ŒΩ : MeasureTheory.Measure Œ±\nE : Type u_3\ninst‚úù¬≤ : NormedAddCommGroup E\ninst‚úù¬π : NormedSpace ‚Ñù E\ninst‚úù : CompleteSpace E\nf‚úù g‚úù f g : Œ± ‚Üí E\nhf : MeasureTheory.Integrable f Œº\nhg : MeasureTheory.Integrable g Œº\nhfg : Œº.withDensity·µ• f = Œº.withDensity·µ• g\n‚ä¢ f =·µê[Œº] g")
2025-12-16 15:31:37.398 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 46.23s.
2025-12-16 15:31:37.398 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.54060\nŒ± : Type u_1\nŒ≤ : Type u_2\nm : MeasurableSpace Œ±\nŒº ŒΩ : MeasureTheory.Measure Œ±\nE : Type u_3\ninst‚úù¬≤ : NormedAddCommGroup E\ninst‚úù¬π : NormedSpace ‚Ñù E\ninst‚úù : CompleteSpace E\nf‚úù g‚úù f g : Œ± ‚Üí E\nhf : MeasureTheory.Integrable f Œº\nhg : MeasureTheory.Integrable g Œº\nhfg : Œº.withDensity·µ• f = Œº.withDensity·µ• g\n‚ä¢ f =·µê[Œº] g")
2025-12-16 15:31:37.529 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:31:37.529 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:31:41.505 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: LinearMap.IsSymmetric.restrictScalars
2025-12-16 15:31:42.779 | INFO     | lean_reinforcement.training.trainer:_collect_data:277 - Completed 48/128 proofs
2025-12-16 15:31:44.349 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: ext
2025-12-16 15:31:46.073 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:31:47.063 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp [mapHom, mapHomAux, mapHomAux, mapHomAux, mapHomAux]
2025-12-16 15:31:47.197 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="unknown identifier 'mapHomAux'\nunknown identifier 'mapHomAux'\nunknown identifier 'mapHomAux'\nunknown identifier 'mapHomAux'")
2025-12-16 15:31:47.197 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 18.26s.
2025-12-16 15:31:47.197 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="unknown identifier 'mapHomAux'\nunknown identifier 'mapHomAux'\nunknown identifier 'mapHomAux'\nunknown identifier 'mapHomAux'")
2025-12-16 15:31:47.256 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [BiheytingHom.id, id_coe, BiheytingAlgebra.coe_id]
2025-12-16 15:31:47.329 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:31:47.329 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:31:47.393 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.65931\nF : Type u_1\nŒ± : Type u_2\nŒ≤ : Type u_3\nŒ≥ : Type u_4\nŒ¥ : Type u_5\ninst‚úù‚Å¥ : FunLike F Œ± Œ≤\ninst‚úù¬≥ : BiheytingAlgebra Œ±\ninst‚úù¬≤ : BiheytingAlgebra Œ≤\ninst‚úù¬π : BiheytingAlgebra Œ≥\ninst‚úù : BiheytingAlgebra Œ¥\n‚ä¢ ‚áë(let __src := HeytingHom.id Œ±;\n      let __src := CoheytingHom.id Œ±;\n      { toLatticeHom := LatticeHom.id Œ±, map_himp' := ‚ãØ, map_sdiff' := ‚ãØ }) =\n    id")
2025-12-16 15:31:47.393 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 19.63s.
2025-12-16 15:31:47.393 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.65931\nF : Type u_1\nŒ± : Type u_2\nŒ≤ : Type u_3\nŒ≥ : Type u_4\nŒ¥ : Type u_5\ninst‚úù‚Å¥ : FunLike F Œ± Œ≤\ninst‚úù¬≥ : BiheytingAlgebra Œ±\ninst‚úù¬≤ : BiheytingAlgebra Œ≤\ninst‚úù¬π : BiheytingAlgebra Œ≥\ninst‚úù : BiheytingAlgebra Œ¥\n‚ä¢ ‚áë(let __src := HeytingHom.id Œ±;\n      let __src := CoheytingHom.id Œ±;\n      { toLatticeHom := LatticeHom.id Œ±, map_himp' := ‚ãØ, map_sdiff' := ‚ãØ }) =\n    id")
2025-12-16 15:31:47.525 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:31:47.525 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:31:49.109 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 2: Running MCTS search for 200 iterations...
2025-12-16 15:31:49.293 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 2: Applying best tactic: refine ‚ü®fun h =>?_, fun h =>?_‚ü©
2025-12-16 15:31:54.081 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 3: Running MCTS search for 200 iterations...
2025-12-16 15:31:55.277 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: CategoryTheory.NatIso.naturality_2
2025-12-16 15:31:56.162 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: MeasureTheory.leastGE_eq_min
2025-12-16 15:31:56.290 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: NonUnitalSubalgebra.coe_toNonUnitalStarSubalgebra
2025-12-16 15:31:56.442 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [eq_univ_iff_forall, eq_univ_iff_forall]
2025-12-16 15:31:56.550 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  ?m.66122 = Set.univ\nŒπ : Type u_1\nŒ± : Type u_2\nŒ≤ : Type u_3\nŒ≥ : Type u_4\ninst‚úù¬≤ : TopologicalSpace Œ±\ninst‚úù¬π : TopologicalSpace Œ≤\ninst‚úù : TopologicalSpace Œ≥\n‚ä¢ ‚àÄ (x : Œ±), x ‚àà ‚Üë‚ä§")
2025-12-16 15:31:56.550 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 323.73s.
2025-12-16 15:31:56.550 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  ?m.66122 = Set.univ\nŒπ : Type u_1\nŒ± : Type u_2\nŒ≤ : Type u_3\nŒ≥ : Type u_4\ninst‚úù¬≤ : TopologicalSpace Œ±\ninst‚úù¬π : TopologicalSpace Œ≤\ninst‚úù : TopologicalSpace Œ≥\n‚ä¢ ‚àÄ (x : Œ±), x ‚àà ‚Üë‚ä§")
2025-12-16 15:31:56.683 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:31:56.683 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:31:57.653 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [‚Üê LieSubmodule.map_le_iff_le_comap, LieSubmodule.map_le_iff_le_comap]
2025-12-16 15:31:57.828 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  ?m.891835 ‚â§ LieSubmodule.comap ?m.891834 ?m.891836\nR : Type u\nL : Type v\nL' : Type w‚ÇÇ\nM : Type w\nM' : Type w‚ÇÅ\ninst‚úù¬π¬≤ : CommRing R\ninst‚úù¬π¬π : LieRing L\ninst‚úù¬π‚Å∞ : LieAlgebra R L\ninst‚úù‚Åπ : LieRing L'\ninst‚úù‚Å∏ : LieAlgebra R L'\ninst‚úù‚Å∑ : AddCommGroup M\ninst‚úù‚Å∂ : Module R M\ninst‚úù‚Åµ : LieRingModule L M\ninst‚úù‚Å¥ : LieModule R L M\ninst‚úù¬≥ : AddCommGroup M'\ninst‚úù¬≤ : Module R M'\ninst‚úù¬π : LieRingModule L M'\ninst‚úù : LieModule R L M'\nf : L ‚Üí‚Çó‚ÅÖR‚ÅÜ L'\nI : LieIdeal R L\nJ : LieIdeal R L'\n‚ä¢ LieIdeal.map f I = ‚ä• ‚Üî I ‚â§ f.ker")
2025-12-16 15:31:57.828 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 154.26s.
2025-12-16 15:31:57.828 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  ?m.891835 ‚â§ LieSubmodule.comap ?m.891834 ?m.891836\nR : Type u\nL : Type v\nL' : Type w‚ÇÇ\nM : Type w\nM' : Type w‚ÇÅ\ninst‚úù¬π¬≤ : CommRing R\ninst‚úù¬π¬π : LieRing L\ninst‚úù¬π‚Å∞ : LieAlgebra R L\ninst‚úù‚Åπ : LieRing L'\ninst‚úù‚Å∏ : LieAlgebra R L'\ninst‚úù‚Å∑ : AddCommGroup M\ninst‚úù‚Å∂ : Module R M\ninst‚úù‚Åµ : LieRingModule L M\ninst‚úù‚Å¥ : LieModule R L M\ninst‚úù¬≥ : AddCommGroup M'\ninst‚úù¬≤ : Module R M'\ninst‚úù¬π : LieRingModule L M'\ninst‚úù : LieModule R L M'\nf : L ‚Üí‚Çó‚ÅÖR‚ÅÜ L'\nI : LieIdeal R L\nJ : LieIdeal R L'\n‚ä¢ LieIdeal.map f I = ‚ä• ‚Üî I ‚â§ f.ker")
2025-12-16 15:31:57.962 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:31:57.963 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:31:58.228 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [isSymmetric_iff_isSymmetric] at hT ‚ä¢
2025-12-16 15:31:58.371 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.29611\nùïú : Type u_1\nE : Type u_2\nE' : Type u_3\nF : Type u_4\nG : Type u_5\ninst‚úù‚Å∏ : RCLike ùïú\ninst‚úù‚Å∑ : NormedAddCommGroup E\ninst‚úù‚Å∂ : InnerProductSpace ùïú E\ninst‚úù‚Åµ : NormedAddCommGroup F\ninst‚úù‚Å¥ : InnerProductSpace ùïú F\ninst‚úù¬≥ : NormedAddCommGroup G\ninst‚úù¬≤ : InnerProductSpace ùïú G\ninst‚úù¬π : NormedAddCommGroup E'\ninst‚úù : InnerProductSpace ‚Ñù E'\nT : E ‚Üí‚Çó[ùïú] E\nhT : T.IsSymmetric\n‚ä¢ (‚Üë‚Ñù T).IsSymmetric")
2025-12-16 15:31:58.371 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 16.87s.
2025-12-16 15:31:58.371 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.29611\nùïú : Type u_1\nE : Type u_2\nE' : Type u_3\nF : Type u_4\nG : Type u_5\ninst‚úù‚Å∏ : RCLike ùïú\ninst‚úù‚Å∑ : NormedAddCommGroup E\ninst‚úù‚Å∂ : InnerProductSpace ùïú E\ninst‚úù‚Åµ : NormedAddCommGroup F\ninst‚úù‚Å¥ : InnerProductSpace ùïú F\ninst‚úù¬≥ : NormedAddCommGroup G\ninst‚úù¬≤ : InnerProductSpace ùïú G\ninst‚úù¬π : NormedAddCommGroup E'\ninst‚úù : InnerProductSpace ‚Ñù E'\nT : E ‚Üí‚Çó[ùïú] E\nhT : T.IsSymmetric\n‚ä¢ (‚Üë‚Ñù T).IsSymmetric")
2025-12-16 15:31:58.504 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:31:58.505 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:32:01.109 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:32:01.731 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Submodule.rank_add_le_rank_add_rank
2025-12-16 15:32:02.208 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:32:02.690 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:32:03.334 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: suffices Tendsto (fun n => (‚à´ x in s, c x ^ n ‚àÇŒº)‚Åª¬π ‚Ä¢ ‚à´ x in s, c x ^ n ‚àÇŒº) atTop (ùìù (g x‚ÇÄ)) from
  tendsto_const_nhds.smul_const _
2025-12-16 15:32:05.077 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 3: Applying best tactic: exacts [Set.Subset.trans h h, Set.singleton_subset_iff.mpr h]
2025-12-16 15:32:05.193 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='application type mismatch\n  Set.Subset.trans (sorryAx (closure {b} ‚äÜ ?m.45044) true) h\nargument\n  h\nhas type\n  Topology.WithLowerSet.ofLowerSet a ‚â§ Topology.WithLowerSet.ofLowerSet b : Prop\nbut is expected to have type\n  ?m.45044 ‚äÜ closure {a} : Prop')
2025-12-16 15:32:05.194 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 3 steps and 552.42s.
2025-12-16 15:32:05.194 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='application type mismatch\n  Set.Subset.trans (sorryAx (closure {b} ‚äÜ ?m.45044) true) h\nargument\n  h\nhas type\n  Topology.WithLowerSet.ofLowerSet a ‚â§ Topology.WithLowerSet.ofLowerSet b : Prop\nbut is expected to have type\n  ?m.45044 ‚äÜ closure {a} : Prop')
2025-12-16 15:32:05.325 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:32:05.326 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:32:06.346 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:32:06.509 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='type mismatch\n  Filter.Tendsto.smul_const tendsto_const_nhds ?m.3058332\nhas type\n  Filter.Tendsto (fun x => ?m.3058319 ‚Ä¢ ?m.3058332) ?m.3058318 (ùìù (?m.3058319 ‚Ä¢ ?m.3058332)) : Prop\nbut is expected to have type\n  Filter.Tendsto (fun n => (‚à´ (x : Œ±) in s, c x ^ n ‚àÇŒº)‚Åª¬π ‚Ä¢ ‚à´ (x : Œ±) in s, c x ^ n ‚Ä¢ g x ‚àÇŒº) Filter.atTop\n    (ùìù (g x‚ÇÄ)) : Prop')
2025-12-16 15:32:06.509 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 154.36s.
2025-12-16 15:32:06.509 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='type mismatch\n  Filter.Tendsto.smul_const tendsto_const_nhds ?m.3058332\nhas type\n  Filter.Tendsto (fun x => ?m.3058319 ‚Ä¢ ?m.3058332) ?m.3058318 (ùìù (?m.3058319 ‚Ä¢ ?m.3058332)) : Prop\nbut is expected to have type\n  Filter.Tendsto (fun n => (‚à´ (x : Œ±) in s, c x ^ n ‚àÇŒº)‚Åª¬π ‚Ä¢ ‚à´ (x : Œ±) in s, c x ^ n ‚Ä¢ g x ‚àÇŒº) Filter.atTop\n    (ùìù (g x‚ÇÄ)) : Prop')
2025-12-16 15:32:06.640 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:32:06.640 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:32:11.203 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 2: Applying best tactic: simp only [map_apply, Function.comp_apply]
2025-12-16 15:32:11.269 | SUCCESS  | lean_reinforcement.agent.runner:run:217 - Proof finished in 2 steps and 378.23s.
2025-12-16 15:32:11.399 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:32:11.399 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:32:16.691 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: CategoryTheory.Adjunction.rightAdjointUniq_trans_app
2025-12-16 15:32:18.448 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: CategoryTheory.Idempotents.app_p_comm
2025-12-16 15:32:19.395 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: MeasureTheory.NullMeasurableSet.iInter
2025-12-16 15:32:21.317 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:32:22.996 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Matrix.fromColumns_fromRows_eq_fromBlocks
2025-12-16 15:32:23.112 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:32:24.241 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:32:27.453 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:32:29.012 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Real.sin_pi
2025-12-16 15:32:33.447 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:32:50.010 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: unfold deleteEdges
2025-12-16 15:32:54.633 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 2: Running MCTS search for 200 iterations...
2025-12-16 15:32:54.633 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 2: Applying best tactic: exact sdiff_le
2025-12-16 15:32:54.697 | SUCCESS  | lean_reinforcement.agent.runner:run:217 - Proof finished in 2 steps and 82.61s.
2025-12-16 15:32:54.827 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:32:54.827 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:32:55.133 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [‚Üê cancel_mono Œ±.hom.naturality, ‚Üê Œ±.hom.naturality, ‚Üê Œ±.hom.naturality,
  ‚Üê Œ±.hom.naturality, ‚Üê Œ±.hom.naturality, ‚Üê Œ±.hom.naturality, ‚Üê Œ±.hom.naturality,
  ‚Üê Œ±.hom.naturality, ‚Üê Œ±.hom.naturality, ‚Üê Œ±.hom.naturality, ‚Üê Œ±.hom.naturality,
  ‚Üê Œ±.hom.naturality, ‚Üê Œ±.hom.naturality, ‚Üê Œ±.hom.naturality, ‚Üê Œ±.hom.naturality,
  ‚Üê Œ±.hom.naturality, ‚Üê Œ±.hom.naturality, ‚Üê Œ±.hom.naturality, ‚Üê Œ±.hom.naturality,
  ‚Üê Œ±.hom.naturality, ‚Üê Œ±.hom.naturality, ‚Üê Œ±.hom.naturality, ‚Üê Œ±.hom.naturality,
  ‚Üê Œ±.hom.naturality, ‚Üê Œ±.hom.naturality, ‚Üê Œ±.hom.naturality, ‚Üê Œ±.hom.naturality,
  ‚Üê Œ±.hom.naturality, ‚Üê Œ±.hom.naturality, ‚Üê Œ±.hom.naturality, ‚Üê Œ±.hom.naturality,
  ‚Üê Œ±.hom.naturality, ‚Üê Œ±.hom.naturality, ‚Üê Œ±.hom.naturality, ‚Üê Œ±.hom.naturality,
  ‚Üê Œ±.hom.naturality, ‚Üê Œ±.hom.naturality, ‚Üê Œ±.hom.naturality, ‚Üê Œ±.hom.naturality,
  ‚Üê Œ±.hom.naturality, ‚Üê Œ±.hom.naturality, ‚Üê Œ±.hom.naturality, ‚Üê Œ±.hom.naturality
2025-12-16 15:32:55.202 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="<stdin>:11:80: unexpected end of input; expected ']'")
2025-12-16 15:32:55.202 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 59.92s.
2025-12-16 15:32:55.202 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="<stdin>:11:80: unexpected end of input; expected ']'")
2025-12-16 15:32:55.333 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:32:55.333 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:32:59.753 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp (config := { contextual := true })
2025-12-16 15:32:59.822 | SUCCESS  | lean_reinforcement.agent.runner:run:217 - Proof finished in 1 steps and 163.87s.
2025-12-16 15:32:59.954 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:32:59.954 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:33:02.937 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: exact MeasurableSet.iInter h
2025-12-16 15:33:03.002 | SUCCESS  | lean_reinforcement.agent.runner:run:217 - Proof finished in 1 steps and 43.61s.
2025-12-16 15:33:03.134 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:33:03.135 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:33:05.944 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [‚Üê f.p.naturality_assoc, f.f.naturality_assoc, ‚Üê f.f.naturality_assoc,
  f.f.naturality_assoc, f.f.naturality_assoc, f.naturality_assoc]
2025-12-16 15:33:06.058 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.3481\nJ : Type u_1\nC : Type u_2\ninst‚úù¬π : CategoryTheory.Category.{u_4, u_1} J\ninst‚úù : CategoryTheory.Category.{u_3, u_2} C\nP Q : CategoryTheory.Idempotents.Karoubi (J ‚•§ C)\nf : P ‚ü∂ Q\nX : J\n‚ä¢ P.p.app X ‚â´ f.f.app X = f.f.app X ‚â´ Q.p.app X")
2025-12-16 15:33:06.058 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 47.61s.
2025-12-16 15:33:06.058 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.3481\nJ : Type u_1\nC : Type u_2\ninst‚úù¬π : CategoryTheory.Category.{u_4, u_1} J\ninst‚úù : CategoryTheory.Category.{u_3, u_2} C\nP Q : CategoryTheory.Idempotents.Karoubi (J ‚•§ C)\nf : P ‚ü∂ Q\nX : J\n‚ä¢ P.p.app X ‚â´ f.f.app X = f.f.app X ‚â´ Q.p.app X")
2025-12-16 15:33:06.190 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:33:06.190 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:33:06.679 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Sym.mem_cons_of_mem
2025-12-16 15:33:06.988 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [‚Üê rightAdjointUniq_comp_rightAdjointUniq adj1 adj3, rightAdjointUniq_comp_rightAdjointUniq adj3,
  rightAdjointUniq_comp_rightAdjointUniq adj3, rightAdjointUniq_comp_rightAdjointUniq adj3]
2025-12-16 15:33:07.119 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.44898\nC : Type u_1\nD : Type u_2\ninst‚úù¬π : CategoryTheory.Category.{u_3, u_1} C\ninst‚úù : CategoryTheory.Category.{u_4, u_2} D\nF : C ‚•§ D\nG G' G'' : D ‚•§ C\nadj1 : F ‚ä£ G\nadj2 : F ‚ä£ G'\nadj3 : F ‚ä£ G''\nx : D\n‚ä¢ (adj1.rightAdjointUniq adj2).hom.app x ‚â´ (adj2.rightAdjointUniq adj3).hom.app x =\n    (adj1.rightAdjointUniq adj3).hom.app x")
2025-12-16 15:33:07.119 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 50.43s.
2025-12-16 15:33:07.119 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.44898\nC : Type u_1\nD : Type u_2\ninst‚úù¬π : CategoryTheory.Category.{u_3, u_1} C\ninst‚úù : CategoryTheory.Category.{u_4, u_2} D\nF : C ‚•§ D\nG G' G'' : D ‚•§ C\nadj1 : F ‚ä£ G\nadj2 : F ‚ä£ G'\nadj3 : F ‚ä£ G''\nx : D\n‚ä¢ (adj1.rightAdjointUniq adj2).hom.app x ‚â´ (adj2.rightAdjointUniq adj3).hom.app x =\n    (adj1.rightAdjointUniq adj3).hom.app x")
2025-12-16 15:33:07.253 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:33:07.253 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:33:07.986 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [‚Üê rank_sup_eq_rank, ‚Üê rank_sup_eq_rank, ‚Üê rank_sup_eq_rank, ‚Üê rank_sup_eq_rank]
2025-12-16 15:33:08.133 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.131859\nR : Type u_1\nM M‚ÇÅ M‚ÇÇ M‚ÇÉ : Type u\nM' : Type v\ninst‚úù¬π¬π : Ring R\ninst‚úù¬π‚Å∞ : AddCommGroup M\ninst‚úù‚Åπ : AddCommGroup M‚ÇÅ\ninst‚úù‚Å∏ : AddCommGroup M‚ÇÇ\ninst‚úù‚Å∑ : AddCommGroup M‚ÇÉ\ninst‚úù‚Å∂ : AddCommGroup M'\ninst‚úù‚Åµ : Module R M\ninst‚úù‚Å¥ : Module R M‚ÇÅ\ninst‚úù¬≥ : Module R M‚ÇÇ\ninst‚úù¬≤ : Module R M‚ÇÉ\ninst‚úù¬π : Module R M'\ninst‚úù : HasRankNullity.{u, u_1} R\ns t : Submodule R M\n‚ä¢ Module.rank R ‚Ü•(s ‚äî t) ‚â§ Module.rank R ‚Ü•s + Module.rank R ‚Ü•t")
2025-12-16 15:33:08.133 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 66.40s.
2025-12-16 15:33:08.133 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.131859\nR : Type u_1\nM M‚ÇÅ M‚ÇÇ M‚ÇÉ : Type u\nM' : Type v\ninst‚úù¬π¬π : Ring R\ninst‚úù¬π‚Å∞ : AddCommGroup M\ninst‚úù‚Åπ : AddCommGroup M‚ÇÅ\ninst‚úù‚Å∏ : AddCommGroup M‚ÇÇ\ninst‚úù‚Å∑ : AddCommGroup M‚ÇÉ\ninst‚úù‚Å∂ : AddCommGroup M'\ninst‚úù‚Åµ : Module R M\ninst‚úù‚Å¥ : Module R M‚ÇÅ\ninst‚úù¬≥ : Module R M‚ÇÇ\ninst‚úù¬≤ : Module R M‚ÇÉ\ninst‚úù¬π : Module R M'\ninst‚úù : HasRankNullity.{u, u_1} R\ns t : Submodule R M\n‚ä¢ Module.rank R ‚Ü•(s ‚äî t) ‚â§ Module.rank R ‚Ü•s + Module.rank R ‚Ü•t")
2025-12-16 15:33:08.266 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:33:08.266 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:33:08.920 | ERROR    | lean_reinforcement.utilities.gym:reset:41 - Error during environment reset: Timeout during initialization
2025-12-16 15:33:08.920 | ERROR    | lean_reinforcement.training.worker:process_theorem:44 - Failed to initialize environment for theorem MeasureTheory.norm_setToFun_le_mul_norm': Timeout during initialization
2025-12-16 15:33:09.009 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp only [coe_toNonUnitalStarSubalgebra, coe_toNonUnitalStarAlgebra, coe_toNonUnitalStarAlgebra,
  coe_toNonUnitalStarAlgebra, coe_toNonUnitalStarAlgebra, coe_toNonUnitalStarAlgebra,
  coe_toNonUnitalStarAlgebra, coe_toNonUnitalStarAlgebra, coe_toNonUnitalStarAlgebra,
  coe_toNonUnitalStarAlgebra, coe_toNonUnitalStarAlgebra, coe_toNonUnitalStarAlgebra,
  coe_toNonUnitalStarAlgebra, coe_toNonUnitalStarAlgebra, coe_toNonUnitalStarAlgebra,
  coe_toNonUnitalStarAlgebra, coe_toNonUnitalStarAlgebra, coe_toNonUnitalStarAlgebra,
  coe_toNonUnitalStarAlgebra, coe_toNonUnitalStarAlgebra, coe_toNonUnitalStarAlgebra,
  coe_toNonUnitalStarAlgebra, coe_toNonUnitalStarAlgebra, coe_toNonUnitalStarAlgebra,
  coe_toNonUnitalStarAlgebra, coe_toNonUnitalStarAlgebra, coe_toNonUnitalStarAlgebra,
  coe_toNonUnitalStarAlgebra, coe_toNonUnitalStarAlgebra, coe_toNonUnitalStarAlgebra,
  coe_toNonUnitalStarAlgebra, coe_toNonUnitalStarAlgebra, coe_toNonUnitalStarAlgebra,
  coe_toNonUnitalStarAlgebra, coe_toNonUnitalStarAlgebra]
2025-12-16 15:33:09.151 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:33:09.367 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="unknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'")
2025-12-16 15:33:09.367 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 73.08s.
2025-12-16 15:33:09.367 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="unknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'\nunknown identifier 'coe_toNonUnitalStarAlgebra'")
2025-12-16 15:33:09.501 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:33:09.501 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:33:09.678 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: ContextFreeRule.rewrites_of_exists_parts
2025-12-16 15:33:10.448 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: midpoint_vadd_midpoint
2025-12-16 15:33:12.979 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: ext (_ | _) (_ | _) <;> simp
2025-12-16 15:33:13.063 | SUCCESS  | lean_reinforcement.agent.runner:run:217 - Proof finished in 1 steps and 50.07s.
2025-12-16 15:33:13.198 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:33:13.198 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:33:13.504 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: PMF.toOuterMeasure_apply
2025-12-16 15:33:13.533 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:33:14.704 | INFO     | lean_reinforcement.training.trainer:_collect_data:277 - Completed 64/128 proofs
2025-12-16 15:33:14.881 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: SetTheory.PGame.ofLists_moveRight'
2025-12-16 15:33:15.492 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: disjoint_iSup‚ÇÇ_iff
2025-12-16 15:33:16.571 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:33:17.330 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Finset.image_add_right_Ico
2025-12-16 15:33:17.828 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:33:19.260 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: List.length_sym2
2025-12-16 15:33:19.692 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:33:20.654 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp [h]
2025-12-16 15:33:20.719 | SUCCESS  | lean_reinforcement.agent.runner:run:217 - Proof finished in 1 steps and 14.04s.
2025-12-16 15:33:20.788 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:33:20.852 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:33:20.853 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:33:21.210 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:33:21.705 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Bornology.isBounded_prod_of_nonempty
2025-12-16 15:33:22.499 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:33:23.509 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp [sin_antiperiodic œÄ]
2025-12-16 15:33:23.574 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='simp made no progress')
2025-12-16 15:33:23.574 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 54.56s.
2025-12-16 15:33:23.574 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='simp made no progress')
2025-12-16 15:33:23.707 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:33:23.708 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:33:24.474 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:33:26.840 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:33:37.703 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: LucasLehmer.order_œâ
2025-12-16 15:33:38.689 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Set.injOn_empty
2025-12-16 15:33:42.437 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:33:43.324 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:33:50.827 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp only [‚Üê not_nonempty_iff, nonempty_pi]
2025-12-16 15:33:50.893 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="unknown identifier 'nonempty_pi'")
2025-12-16 15:33:50.893 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 485.89s.
2025-12-16 15:33:50.893 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="unknown identifier 'nonempty_pi'")
2025-12-16 15:33:51.022 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:33:51.023 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:33:55.986 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [midpoint_comm, midpoint_vadd_midpoint_left]
2025-12-16 15:33:56.122 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.51277\nR : Type u_1\nV : Type u_2\nV' : Type u_3\nP : Type u_4\nP' : Type u_5\ninst‚úù‚Å∑ : Ring R\ninst‚úù‚Å∂ : Invertible 2\ninst‚úù‚Åµ : AddCommGroup V\ninst‚úù‚Å¥ : Module R V\ninst‚úù¬≥ : AddTorsor V P\ninst‚úù¬≤ : AddCommGroup V'\ninst‚úù¬π : Module R V'\ninst‚úù : AddTorsor V' P'\nx y z : P\nv v' : V\np p' : P\n‚ä¢ midpoint R v' v +·µ• midpoint R p p' = midpoint R (v +·µ• p) (v' +·µ• p')")
2025-12-16 15:33:56.122 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 45.67s.
2025-12-16 15:33:56.122 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.51277\nR : Type u_1\nV : Type u_2\nV' : Type u_3\nP : Type u_4\nP' : Type u_5\ninst‚úù‚Å∑ : Ring R\ninst‚úù‚Å∂ : Invertible 2\ninst‚úù‚Åµ : AddCommGroup V\ninst‚úù‚Å¥ : Module R V\ninst‚úù¬≥ : AddTorsor V P\ninst‚úù¬≤ : AddCommGroup V'\ninst‚úù¬π : Module R V'\ninst‚úù : AddTorsor V' P'\nx y z : P\nv v' : V\np p' : P\n‚ä¢ midpoint R v' v +·µ• midpoint R p p' = midpoint R (v +·µ• p) (v' +·µ• p')")
2025-12-16 15:33:56.252 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:33:56.252 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:33:57.331 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Profinite.NobelingProof.GoodProducts.sum_equiv_comp_eval_eq_elim
2025-12-16 15:34:00.276 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: induction p generalizing q with
| nil => simp
| cons x _ ih =>
  simp only [ContextFreeRule.nil_append, cons_append, cons_append, cons_append, cons_append,
    cons_append, cons_append, cons_append, cons_append, cons_append, cons_append, cons_append,
    cons_append, cons_append, cons_append, cons_append, cons_append, cons_append, cons_append,
    cons_append, cons_append, cons_append, cons_append, cons_append, cons_append, cons_append,
    cons_append, cons_append, cons_append, cons_append, cons_append, cons_append, cons_append,
    cons_append, cons_append, cons_append, cons_append, cons_append, cons_append, cons_append,
    cons_append, cons_append, cons_append, cons_append, cons_append, cons_append, cons_append,
    cons_append, cons_append, cons_append, cons_append, cons_append, cons_append, cons_append,
    cons_append, cons_append, cons_append, cons_append, cons_append, cons_append, cons_append,
    cons_append, cons_append, cons_append, cons_append, cons_append, cons_append, cons_append,
    cons_app
2025-12-16 15:34:00.346 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="<stdin>:14:12: unexpected end of input; expected ']'")
2025-12-16 15:34:00.346 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 50.67s.
2025-12-16 15:34:00.346 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="<stdin>:14:12: unexpected end of input; expected ']'")
2025-12-16 15:34:00.479 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:34:00.479 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:34:01.928 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:34:04.540 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: induction xs generalizing xs <;> simp [*]
2025-12-16 15:34:04.611 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='variable cannot be generalized because target depends on it\n  xs')
2025-12-16 15:34:04.611 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 45.35s.
2025-12-16 15:34:04.611 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='variable cannot be generalized because target depends on it\n  xs')
2025-12-16 15:34:04.717 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp [add_comm]
2025-12-16 15:34:04.743 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:34:04.743 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:34:04.791 | SUCCESS  | lean_reinforcement.agent.runner:run:217 - Proof finished in 1 steps and 47.46s.
2025-12-16 15:34:04.923 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:34:04.923 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:34:05.795 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp [toOuterMeasure_apply]
2025-12-16 15:34:05.882 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="kernel type check failed: (kernel) declaration has free variables '[anonymous]'")
2025-12-16 15:34:05.882 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 52.38s.
2025-12-16 15:34:05.882 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="kernel type check failed: (kernel) declaration has free variables '[anonymous]'")
2025-12-16 15:34:06.015 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:34:06.015 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:34:16.765 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Bundle.contMDiff_proj
2025-12-16 15:34:16.837 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Sym.map_zero
2025-12-16 15:34:20.420 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Padic.valuation_map_add
2025-12-16 15:34:21.761 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:34:21.866 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:34:23.320 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: extChartAt_self_apply
2025-12-16 15:34:25.036 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:34:27.793 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:34:37.434 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Matrix.transpose_add
2025-12-16 15:34:41.822 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:34:41.851 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Asymptotics.IsBigO.natCast_atTop
2025-12-16 15:34:43.891 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp [InjOn]
2025-12-16 15:34:43.964 | SUCCESS  | lean_reinforcement.agent.runner:run:217 - Proof finished in 1 steps and 65.28s.
2025-12-16 15:34:44.094 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:34:44.095 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:34:45.297 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [‚Üê isBounded_compl_iff, ‚Üê isBounded_compl_iff, ‚Üê isBounded_compl_iff, ‚Üê isBounded_compl_iff,
  isBounded_compl_iff, ‚Üê isBounded_compl_iff, ‚Üê isBounded_compl_iff, ‚Üê isBounded_compl_iff,
  isBounded_compl_iff, ‚Üê isBounded_compl_iff, ‚Üê isBounded_compl_iff, ‚Üê isBounded_compl_iff,
  isBounded_compl_iff, ‚Üê isBounded_compl_iff, ‚Üê isBounded_compl_iff, ‚Üê isBounded_compl_iff,
  isBounded_compl_iff, ‚Üê isBounded_compl_iff, ‚Üê isBounded_compl_iff, ‚Üê isBounded_compl_iff,
  isBounded_compl_iff, ‚Üê isBounded_compl_iff, ‚Üê isBounded_compl_iff, ‚Üê isBounded_compl_iff,
  isBounded_compl_iff, ‚Üê isBounded_compl_iff, ‚Üê isBounded_compl_iff, ‚Üê isBounded_compl_iff,
  isBounded_compl_iff, ‚Üê isBounded_compl_iff, ‚Üê isBounded_compl_iff, ‚Üê isBounded_compl_iff,
  isBounded_compl_iff, ‚Üê isBounded_compl_iff, ‚Üê isBounded_compl_iff, ‚Üê isBounded_compl_iff,
  isBounded_compl_iff, ‚Üê isBounded_compl_iff, ‚Üê isBounded_compl_iff, isBounded_compl_iff,
  isBounded_compl_iff, isBounded_compl_if
2025-12-16 15:34:45.366 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="<stdin>:11:41: unexpected end of input; expected ']'")
2025-12-16 15:34:45.366 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 83.66s.
2025-12-16 15:34:45.366 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="<stdin>:11:41: unexpected end of input; expected ']'")
2025-12-16 15:34:45.499 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:34:45.499 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:34:46.448 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:34:53.371 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Prod.map_bijective
2025-12-16 15:34:57.209 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: SetTheory.PGame.mul_moveLeft_inl
2025-12-16 15:34:58.055 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:35:01.883 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:35:28.426 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [map, Function.Embedding.coe_map, Function.Embedding.coe_zero]
2025-12-16 15:35:28.517 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.19427\nŒ± : Type u_1\nŒ≤ : Type u_2\nn n' m : ‚Ñï\ns : Sym Œ± n\na b : Œ±\nf : Œ± ‚Üí Œ≤\n‚ä¢ ‚ü®Multiset.map f ‚Üë0, ‚ãØ‚ü© = 0")
2025-12-16 15:35:28.517 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 71.68s.
2025-12-16 15:35:28.517 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.19427\nŒ± : Type u_1\nŒ≤ : Type u_2\nn n' m : ‚Ñï\ns : Sym Œ± n\na b : Œ±\nf : Œ± ‚Üí Œ≤\n‚ä¢ ‚ü®Multiset.map f ‚Üë0, ‚ãØ‚ü© = 0")
2025-12-16 15:35:28.647 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:35:28.647 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:35:43.466 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: MeasureTheory.Measure.toPMF_toMeasure
2025-12-16 15:35:48.158 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:36:14.386 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [valuation_eq_matrix_valuation, valuation_eq_matrix_valuation, valuation_eq_matrix_valuation,
  valuation_eq_matrix_valuation, valuation_eq_matrix_valuation, valuation_eq_matrix_valuation,
  valuation_eq_matrix_valuation, valuation_eq_matrix_valuation, valuation_eq_matrix_valuation,
  valuation_eq_matrix_valuation, valuation_eq_matrix_valuation, valuation_eq_matrix_valuation,
  valuation_eq_matrix_valuation, valuation_eq_matrix_valuation, valuation_eq_matrix_valuation,
  valuation_eq_matrix_valuation, valuation_eq_matrix_valuation, valuation_eq_matrix_valuation,
  valuation_eq_matrix_valuation, valuation_eq_matrix_valuation, valuation_eq_matrix_valuation,
  valuation_eq_matrix_valuation, valuation_eq_matrix_valuation, valuation_eq_matrix_valuation,
  valuation_eq_matrix_valuation, valuation_eq_matrix_valuation, valuation_eq_matrix_valuation,
  valuation_eq_matrix_valuation, valuation_eq_matrix_valuation, valuation_eq_matrix_valuation,
  valuation_eq_matrix_valuation, valuation_eq_matrix_valuation, valuati
2025-12-16 15:36:14.454 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="<stdin>:11:71: unexpected end of input; expected ']'")
2025-12-16 15:36:14.454 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 114.03s.
2025-12-16 15:36:14.454 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="<stdin>:11:71: unexpected end of input; expected ']'")
2025-12-16 15:36:14.585 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:36:14.585 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:36:14.748 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simpa only [Nat.cast_injective.eq_iff] using h.isBigO
2025-12-16 15:36:14.830 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="invalid field 'isBigO', the environment does not contain 'Asymptotics.IsBigO.isBigO'\n  h\nhas type\n  f =O[atTop] g")
2025-12-16 15:36:14.830 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 92.98s.
2025-12-16 15:36:14.831 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="invalid field 'isBigO', the environment does not contain 'Asymptotics.IsBigO.isBigO'\n  h\nhas type\n  f =O[atTop] g")
2025-12-16 15:36:14.961 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:36:14.961 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:36:17.303 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp only [Bijective, map_injective_iff, and_congr_right_iff, and_congr_right_iff]
2025-12-16 15:36:17.372 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="unknown identifier 'map_injective_iff'")
2025-12-16 15:36:17.372 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 84.00s.
2025-12-16 15:36:17.372 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="unknown identifier 'map_injective_iff'")
2025-12-16 15:36:17.505 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:36:17.505 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:36:21.689 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: isMin_ofDual_iff
2025-12-16 15:36:26.373 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:36:29.101 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: lcm_eq_one_iff
2025-12-16 15:36:33.425 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Set.infinite_image2
2025-12-16 15:36:33.803 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:36:36.004 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: cases x <;> cases y <;> rfl
2025-12-16 15:36:36.079 | SUCCESS  | lean_reinforcement.agent.runner:run:217 - Proof finished in 1 steps and 98.87s.
2025-12-16 15:36:36.210 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:36:36.210 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:36:38.124 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:36:45.593 | INFO     | lean_reinforcement.training.trainer:_collect_data:277 - Completed 80/128 proofs
2025-12-16 15:36:51.272 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [lucasLehmerResidue, lucasLehmerResidue_eq_zero_iff] at h
2025-12-16 15:36:51.366 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.192944\np' : ‚Ñï\nh : LucasLehmer.sZMod (p' + 2) (p' + 2 - 2) = 0\n‚ä¢ orderOf (LucasLehmer.œâUnit (p' + 2)) = 2 ^ (p' + 2)")
2025-12-16 15:36:51.366 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 193.66s.
2025-12-16 15:36:51.366 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.192944\np' : ‚Ñï\nh : LucasLehmer.sZMod (p' + 2) (p' + 2 - 2) = 0\n‚ä¢ orderOf (LucasLehmer.œâUnit (p' + 2)) = 2 ^ (p' + 2)")
2025-12-16 15:36:51.495 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:36:51.495 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:36:52.670 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [‚Üê toMeasure_toMeasure, toMeasure_toMeasure, toMeasure_toMeasure]
2025-12-16 15:36:52.780 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.48591\nŒ± : Type u_1\nŒ≤ : Type u_2\nŒ≥ : Type u_3\ninst‚úù¬≥ : Countable Œ±\ninst‚úù¬≤ : MeasurableSpace Œ±\ninst‚úù¬π : MeasurableSingletonClass Œ±\nŒº : MeasureTheory.Measure Œ±\ninst‚úù : MeasureTheory.IsProbabilityMeasure Œº\n‚ä¢ Œº.toPMF.toMeasure = Œº")
2025-12-16 15:36:52.780 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 69.31s.
2025-12-16 15:36:52.780 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.48591\nŒ± : Type u_1\nŒ≤ : Type u_2\nŒ≥ : Type u_3\ninst‚úù¬≥ : Countable Œ±\ninst‚úù¬≤ : MeasurableSpace Œ±\ninst‚úù¬π : MeasurableSingletonClass Œ±\nŒº : MeasureTheory.Measure Œ±\ninst‚úù : MeasureTheory.IsProbabilityMeasure Œº\n‚ä¢ Œº.toPMF.toMeasure = Œº")
2025-12-16 15:36:52.912 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:36:52.912 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:37:02.027 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [infinite_image2_iff_of_injOn hfs hft, infinite_image2_iff_of_injOn hft, infinite_image2_iff_of_injOn hft,
  infinite_image2_iff_of_injOn hfs hft, infinite_image2_iff_of_injOn hft]
2025-12-16 15:37:02.147 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.158711\nŒ± : Type u\nŒ≤ : Type v\nŒπ : Sort w\nŒ≥ : Type x\ns‚úù t‚úù : Set Œ±\nf : Œ± ‚Üí Œ≤ ‚Üí Œ≥\ns : Set Œ±\nt : Set Œ≤\na : Œ±\nb : Œ≤\nhfs : ‚àÄ b ‚àà t, Set.InjOn (fun a => f a b) s\nhft : ‚àÄ a ‚àà s, Set.InjOn (f a) t\n‚ä¢ (Set.image2 f s t).Infinite ‚Üî s.Infinite ‚àß t.Nonempty ‚à® t.Infinite ‚àß s.Nonempty")
2025-12-16 15:37:02.147 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 28.72s.
2025-12-16 15:37:02.147 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.158711\nŒ± : Type u\nŒ≤ : Type v\nŒπ : Sort w\nŒ≥ : Type x\ns‚úù t‚úù : Set Œ±\nf : Œ± ‚Üí Œ≤ ‚Üí Œ≥\ns : Set Œ±\nt : Set Œ≤\na : Œ±\nb : Œ≤\nhfs : ‚àÄ b ‚àà t, Set.InjOn (fun a => f a b) s\nhft : ‚àÄ a ‚àà s, Set.InjOn (f a) t\n‚ä¢ (Set.image2 f s t).Infinite ‚Üî s.Infinite ‚àß t.Nonempty ‚à® t.Infinite ‚àß s.Nonempty")
2025-12-16 15:37:02.278 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:37:02.278 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:37:04.094 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Set.ssubset_iff_of_subset
2025-12-16 15:37:08.747 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:37:12.034 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Polynomial.expand_mul
2025-12-16 15:37:16.789 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:37:18.000 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: ContDiff.comp
2025-12-16 15:37:19.922 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp [ofLists, toOfListsRightMoves, toOfListsRightMoves]
2025-12-16 15:37:20.005 | SUCCESS  | lean_reinforcement.agent.runner:run:217 - Proof finished in 1 steps and 245.12s.
2025-12-16 15:37:20.135 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:37:20.135 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:37:20.494 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp only [mfld_simps]
2025-12-16 15:37:20.566 | SUCCESS  | lean_reinforcement.agent.runner:run:217 - Proof finished in 1 steps and 177.25s.
2025-12-16 15:37:20.698 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:37:20.698 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:37:22.997 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:37:26.097 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: induction' f using Nat.strong_induction_on with f g
2025-12-16 15:37:26.170 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='target\n  f\nhas type\n  R[X] : Type u\nbut is expected to have type\n  ‚Ñï : Type')
2025-12-16 15:37:26.171 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 14.14s.
2025-12-16 15:37:26.171 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='target\n  f\nhas type\n  R[X] : Type u\nbut is expected to have type\n  ‚Ñï : Type')
2025-12-16 15:37:26.302 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:37:26.302 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:37:27.004 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: DifferentiableWithinAt.dist
2025-12-16 15:37:28.960 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Nat.pred_eq_pred
2025-12-16 15:37:30.641 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: ContinuousWithinAt.inf'
2025-12-16 15:37:31.955 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:37:33.659 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:37:34.455 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Nat.ModEq.eq_of_abs_lt
2025-12-16 15:37:35.199 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:37:39.198 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:38:06.499 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [‚Üê Int.natCast_modEq_iff, ‚Üê Int.natCast_modEq_iff, ‚Üê Int.natCast_modEq_iff,
  Int.natCast_modEq_iff] at h2
2025-12-16 15:38:06.582 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.16582\nm n a b c d : ‚Ñï\nh : a ‚â° b [MOD m]\nh2 : |‚Üëb - ‚Üëa| < ‚Üëm\n‚ä¢ a = b")
2025-12-16 15:38:06.582 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 32.13s.
2025-12-16 15:38:06.582 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.16582\nm n a b c d : ‚Ñï\nh : a ‚â° b [MOD m]\nh2 : |‚Üëb - ‚Üëa| < ‚Üëm\n‚ä¢ a = b")
2025-12-16 15:38:06.713 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:38:06.713 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:38:08.618 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [continuousWithinAt_iff_continuousWithinAt] at *
2025-12-16 15:38:08.735 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the current goal\nL : Type u_1\nX : Type u_2\ninst‚úù¬≥ : TopologicalSpace L\ninst‚úù¬≤ : TopologicalSpace X\ninst‚úù¬π : Inf L\ninst‚úù : ContinuousInf L\nf g : X ‚Üí L\ns : Set X\nx : X\nhf : ContinuousWithinAt f s x\nhg : ContinuousWithinAt g s x\n‚ä¢ ContinuousWithinAt (f ‚äì g) s x")
2025-12-16 15:38:08.736 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 38.09s.
2025-12-16 15:38:08.736 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the current goal\nL : Type u_1\nX : Type u_2\ninst‚úù¬≥ : TopologicalSpace L\ninst‚úù¬≤ : TopologicalSpace X\ninst‚úù¬π : Inf L\ninst‚úù : ContinuousInf L\nf g : X ‚Üí L\ns : Set X\nx : X\nhf : ContinuousWithinAt f s x\nhg : ContinuousWithinAt g s x\n‚ä¢ ContinuousWithinAt (f ‚äì g) s x")
2025-12-16 15:38:08.866 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:38:08.866 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:38:09.022 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: exact hf.differentiableWithinAt.differentiableWithinAt x hg.differentiableWithinAt hne
2025-12-16 15:38:09.139 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="invalid field 'differentiableWithinAt', the environment does not contain 'DifferentiableWithinAt.differentiableWithinAt'\n  hf\nhas type\n  DifferentiableWithinAt ‚Ñù f s x\ninvalid field 'differentiableWithinAt', the environment does not contain 'Exists.differentiableWithinAt'\n  hf\nhas type\n  ‚àÉ f', HasFDerivWithinAt f f' s x")
2025-12-16 15:38:09.139 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 42.13s.
2025-12-16 15:38:09.139 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="invalid field 'differentiableWithinAt', the environment does not contain 'DifferentiableWithinAt.differentiableWithinAt'\n  hf\nhas type\n  DifferentiableWithinAt ‚Ñù f s x\ninvalid field 'differentiableWithinAt', the environment does not contain 'Exists.differentiableWithinAt'\n  hf\nhas type\n  ‚àÉ f', HasFDerivWithinAt f f' s x")
2025-12-16 15:38:09.271 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:38:09.271 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:38:17.290 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Bimon_.comp_hom'
2025-12-16 15:38:20.589 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Real.lipschitzWith_toNNReal
2025-12-16 15:38:21.734 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:38:21.954 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Turing.ListBlank.tail_map
2025-12-16 15:38:25.146 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:38:26.736 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:38:36.237 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp only [ssubset_def, mem_ssubset_iff, exists_prop]
2025-12-16 15:38:36.305 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="unknown identifier 'mem_ssubset_iff'")
2025-12-16 15:38:36.305 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 92.21s.
2025-12-16 15:38:36.305 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="unknown identifier 'mem_ssubset_iff'")
2025-12-16 15:38:36.435 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:38:36.435 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:38:59.861 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp only [Category.assoc, Category.comp_id, Category.assoc]
2025-12-16 15:38:59.926 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='simp made no progress')
2025-12-16 15:38:59.926 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 42.64s.
2025-12-16 15:38:59.927 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='simp made no progress')
2025-12-16 15:39:00.027 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: induction l with
| nil => rfl
| cons hd tl ih =>
  simp only [List.tail_cons, List.tail_cons, List.tail_cons, List.tail_cons, List.tail_cons,
    List.tail_cons, List.tail_cons, List.tail_cons, List.tail_cons, List.tail_cons,
    List.tail_cons, List.tail_cons, List.tail_cons, List.tail_cons, List.tail_cons, List.tail_cons,
    List.tail_cons, List.tail_cons, List.tail_cons, List.tail_cons, List.tail_cons,
    List.tail_cons, List.tail_cons, List.tail_cons, List.tail_cons, List.tail_cons, List.tail_cons,
    List.tail_cons, List.tail_cons, List.tail_cons, List.tail_cons, List.tail_cons]
2025-12-16 15:39:00.056 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:39:00.056 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:39:00.136 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'induction' failed, major premise type is not an inductive type \n  Quot Setoid.r\nŒì : Type u_1\nŒì' : Type u_2\ninst‚úù¬π : Inhabited Œì\ninst‚úù : Inhabited Œì'\nf : Turing.PointedMap Œì Œì'\nl : Turing.ListBlank Œì\n‚ä¢ (Turing.ListBlank.map f l).tail = Turing.ListBlank.map f l.tail")
2025-12-16 15:39:00.136 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 38.18s.
2025-12-16 15:39:00.136 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'induction' failed, major premise type is not an inductive type \n  Quot Setoid.r\nŒì : Type u_1\nŒì' : Type u_2\ninst‚úù¬π : Inhabited Œì\ninst‚úù : Inhabited Œì'\nf : Turing.PointedMap Œì Œì'\nl : Turing.ListBlank Œì\n‚ä¢ (Turing.ListBlank.map f l).tail = Turing.ListBlank.map f l.tail")
2025-12-16 15:39:00.266 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:39:00.267 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:39:11.275 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: FirstOrder.Language.Substructure.cg_closure
2025-12-16 15:39:11.829 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Polynomial.eraseLead_natDegree_le_aux
2025-12-16 15:39:15.954 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:39:16.560 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:39:18.712 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Submodule.orthogonal_eq_bot_iff
2025-12-16 15:39:23.440 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:39:28.760 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: ext
2025-12-16 15:39:33.096 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 2: Running MCTS search for 200 iterations...
2025-12-16 15:39:33.096 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 2: Applying best tactic: simp [add_apply, transpose_apply]
2025-12-16 15:39:33.167 | SUCCESS  | lean_reinforcement.agent.runner:run:217 - Proof finished in 2 steps and 295.73s.
2025-12-16 15:39:33.296 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:39:33.296 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:39:48.259 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [closure_eq_preimage_closure_image]
2025-12-16 15:39:48.355 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.7671\nL : FirstOrder.Language\nM : Type u_1\ninst‚úù : L.Structure M\ns : Set M\nhs : s.Countable\n‚ä¢ ((FirstOrder.Language.Substructure.closure L).toFun s).CG")
2025-12-16 15:39:48.355 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 37.08s.
2025-12-16 15:39:48.355 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.7671\nL : FirstOrder.Language\nM : Type u_1\ninst‚úù : L.Structure M\ns : Set M\nhs : s.Countable\n‚ä¢ ((FirstOrder.Language.Substructure.closure L).toFun s).CG")
2025-12-16 15:39:48.485 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:39:48.485 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:39:48.497 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: refine ‚ü®fun h ‚Ü¶?_, fun h ‚Ü¶?_‚ü©
2025-12-16 15:39:50.651 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [‚Üê orthogonalProjection_eq_bot_iff, orthogonalProjection_eq_bot, orthogonalProjection_eq_bot]
2025-12-16 15:39:50.768 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.661389\nùïú : Type u_1\nE : Type u_2\nF : Type u_3\ninst‚úù‚Åµ : RCLike ùïú\ninst‚úù‚Å¥ : NormedAddCommGroup E\ninst‚úù¬≥ : NormedAddCommGroup F\ninst‚úù¬≤ : InnerProductSpace ùïú E\ninst‚úù¬π : InnerProductSpace ‚Ñù F\nK : Submodule ùïú E\ninst‚úù : HasOrthogonalProjection K\n‚ä¢ K·óÆ = ‚ä• ‚Üî K = ‚ä§")
2025-12-16 15:39:50.768 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 32.06s.
2025-12-16 15:39:50.768 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.661389\nùïú : Type u_1\nE : Type u_2\nF : Type u_3\ninst‚úù‚Åµ : RCLike ùïú\ninst‚úù‚Å¥ : NormedAddCommGroup E\ninst‚úù¬≥ : NormedAddCommGroup F\ninst‚úù¬≤ : InnerProductSpace ùïú E\ninst‚úù¬π : InnerProductSpace ‚Ñù F\nK : Submodule ùïú E\ninst‚úù : HasOrthogonalProjection K\n‚ä¢ K·óÆ = ‚ä• ‚Üî K = ‚ä§")
2025-12-16 15:39:50.900 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:39:50.900 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:39:52.490 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: UpperHalfPlane.ModularGroup.det_coe'
2025-12-16 15:39:53.773 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 2: Running MCTS search for 200 iterations...
2025-12-16 15:39:56.966 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:40:04.310 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: cauchy_iff
2025-12-16 15:40:08.812 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:40:10.887 | INFO     | lean_reinforcement.training.trainer:_collect_data:277 - Completed 96/128 proofs
2025-12-16 15:40:27.967 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: MeasurableEquiv.map_symm_map
2025-12-16 15:40:29.395 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [‚Üê Int.cast_det, ‚Üê Int.cast_det, ‚Üê Int.cast_det, ‚Üê Int.cast_det, ‚Üê Int.cast_det, ‚Üê
  Int.cast_det, Int.cast_det, Int.cast_det]
2025-12-16 15:40:29.477 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.92119\nŒì : Subgroup SL(2, ‚Ñ§)\ng : SL(2, ‚Ñ§)\n‚ä¢ (‚Üë‚Üë‚Üëg).det = 1")
2025-12-16 15:40:29.477 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 36.99s.
2025-12-16 15:40:29.477 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.92119\nŒì : Subgroup SL(2, ‚Ñ§)\ng : SL(2, ‚Ñ§)\n‚ä¢ (‚Üë‚Üë‚Üëg).det = 1")
2025-12-16 15:40:29.608 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:40:29.608 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:40:30.195 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 2: Applying best tactic: exacts [isMin_ofDual_left_ofDual.2 h, isMax_ofDual_left_ofDual_left_ofDual_left_ofDual_left_ofDual_left_ofDual_left_ofDual_left_ofDual_left_ofDual_left h]
2025-12-16 15:40:30.285 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="unknown identifier 'isMin_ofDual_left_ofDual'\nunknown identifier 'isMax_ofDual_left_ofDual_left_ofDual_left_ofDual_left_ofDual_left_ofDual_left_ofDual_left_ofDual_left_ofDual_left'")
2025-12-16 15:40:30.285 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 2 steps and 248.60s.
2025-12-16 15:40:30.285 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="unknown identifier 'isMin_ofDual_left_ofDual'\nunknown identifier 'isMax_ofDual_left_ofDual_left_ofDual_left_ofDual_left_ofDual_left_ofDual_left_ofDual_left_ofDual_left_ofDual_left'")
2025-12-16 15:40:30.417 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:40:30.417 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:40:33.252 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:40:38.628 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Int.shiftLeft_neg
2025-12-16 15:40:42.879 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:40:51.967 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: AlgebraicGeometry.LocallyRingedSpace.Œì_map
2025-12-16 15:40:56.381 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:41:07.947 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: refine ‚ü®fun h ‚Ü¶?_, fun h ‚Ü¶?_‚ü©
2025-12-16 15:41:12.220 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 2: Running MCTS search for 200 iterations...
2025-12-16 15:41:44.993 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [shiftRight_neg, shiftRight_neg, shiftRight_neg, shiftRight_neg, shiftRight_neg,
  shiftRight_neg, shiftRight_neg, shiftRight_neg, shiftRight_neg, shiftRight_neg,
  shiftRight_neg, shiftRight_neg, shiftRight_neg, shiftRight_neg, shiftRight_neg, shiftRight_neg,
  shiftRight_neg, shiftRight_neg, shiftRight_neg, shiftRight_neg, shiftRight_neg, shiftRight_neg,
  shiftRight_neg, shiftRight_neg, shiftRight_neg, shiftRight_neg, shiftRight_neg, shiftRight_neg,
  shiftRight_neg, shiftRight_neg, shiftRight_neg, shiftRight_neg, shiftRight_neg, shiftRight_neg,
  shiftRight_neg, shiftRight_neg, shiftRight_neg, shiftRight_neg, shiftRight_neg, shiftRight_neg,
  shiftRight_neg, shiftRight_neg, shiftRight_neg, shiftRight_neg, shiftRight_neg, shiftRight_neg,
  shiftRight_neg, shiftRight_neg, shiftRight_neg, shiftRight_neg, shiftRight_neg, shiftRight_neg,
  shiftRight_neg, shiftRight_neg, shiftRight_neg, shiftRight_neg, shiftRight_neg, shiftRight_neg,
  shiftRight_neg, shiftRight_neg, shiftRight_neg, shiftRight_neg, shiftRi
2025-12-16 15:41:45.061 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="<stdin>:11:73: unexpected end of input; expected ']'")
2025-12-16 15:41:45.061 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 66.43s.
2025-12-16 15:41:45.061 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="<stdin>:11:73: unexpected end of input; expected ']'")
2025-12-16 15:41:45.191 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:41:45.191 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:41:46.238 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [‚Üê cancel_mono (f.unop.val.c.app (Opposite.op ‚ä§)), ‚Üê cancel_mono (f.unop.val.c.app (Opposite.op ‚ä§)),
  ‚Üê cancel_mono (f.unop.val.c.app (Opposite.op ‚ä§)), ‚Üê cancel_mono (f.unop.val.c.app (Opposite.op ‚ä§)),
  CategoryTheory.Functor.map_comp, CategoryTheory.Functor.map_comp, CategoryTheory.Functor.map_id,
  CategoryTheory.Functor.map_id, CategoryTheory.Functor.map_id, CategoryTheory.Functor.map_id,
  CategoryTheory.Functor.map_id, CategoryTheory.Functor.map_id, CategoryTheory.Functor.map_id,
  CategoryTheory.Functor.map_id, CategoryTheory.Functor.map_id, CategoryTheory.Functor.map_id,
  CategoryTheory.Functor.map_id, CategoryTheory.Functor.map_id, CategoryTheory.Functor.map_id,
  CategoryTheory.Functor.map_id, CategoryTheory.Functor.map_id, CategoryTheory.Functor.map_id,
  CategoryTheory.Functor.map_id, CategoryTheory.Functor.map_id, CategoryTheory.Functor.map_id,
  CategoryTheory.Functor.map_id, CategoryTheory.Functor.map_id, CategoryTheory.Functor.map_id,
  CategoryTheory.Functor.map_id]
2025-12-16 15:41:46.348 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.24145\nX‚úù : AlgebraicGeometry.LocallyRingedSpace\nX Y : AlgebraicGeometry.LocallyRingedSpace·µí·µñ\nf : X ‚ü∂ Y\n‚ä¢ AlgebraicGeometry.LocallyRingedSpace.Œì.map f = f.unop.val.c.app { unop := ‚ä§ }")
2025-12-16 15:41:46.348 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 54.38s.
2025-12-16 15:41:46.348 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.24145\nX‚úù : AlgebraicGeometry.LocallyRingedSpace\nX Y : AlgebraicGeometry.LocallyRingedSpace·µí·µñ\nf : X ‚ü∂ Y\n‚ä¢ AlgebraicGeometry.LocallyRingedSpace.Œì.map f = f.unop.val.c.app { unop := ‚ä§ }")
2025-12-16 15:41:46.479 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:41:46.480 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:41:48.045 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [‚Üê Measure.map_map_map e.symm.measurable e.symm.measurable, ‚Üê Measure.map_map e.symm.measurable,
  Measure.map_map e.symm.measurable e.symm.measurable]
2025-12-16 15:41:48.169 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.568606\nŒ± : Type u_1\nŒ≤ : Type u_2\nŒ≥ : Type u_3\nŒ¥ : Type u_4\nŒπ : Type u_5\nR : Type u_6\nR' : Type u_7\ninst‚úù¬π : MeasurableSpace Œ±\ninst‚úù : MeasurableSpace Œ≤\nŒº : MeasureTheory.Measure Œ±\nŒΩ : MeasureTheory.Measure Œ≤\ne : Œ± ‚âÉ·µê Œ≤\n‚ä¢ MeasureTheory.Measure.map (‚áëe.symm) (MeasureTheory.Measure.map (‚áëe) Œº) = Œº")
2025-12-16 15:41:48.169 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 80.20s.
2025-12-16 15:41:48.169 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.568606\nŒ± : Type u_1\nŒ≤ : Type u_2\nŒ≥ : Type u_3\nŒ¥ : Type u_4\nŒπ : Type u_5\nR : Type u_6\nR' : Type u_7\ninst‚úù¬π : MeasurableSpace Œ±\ninst‚úù : MeasurableSpace Œ≤\nŒº : MeasureTheory.Measure Œ±\nŒΩ : MeasureTheory.Measure Œ≤\ne : Œ± ‚âÉ·µê Œ≤\n‚ä¢ MeasureTheory.Measure.map (‚áëe.symm) (MeasureTheory.Measure.map (‚áëe) Œº) = Œº")
2025-12-16 15:41:48.301 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:41:48.302 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:42:04.061 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: FreeGroup.norm_eq_zero
2025-12-16 15:42:08.324 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:42:09.261 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Nat.exists_prime_gt_modEq_one
2025-12-16 15:42:13.452 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: ContinuousMap.toLp_denseRange
2025-12-16 15:42:13.975 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:42:18.001 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:42:26.122 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp only [ContMDiff, ContMDiff, contMDiffWithinAt_iff_target, contMDiffWithinAt_iff_target,
  contMDiffWithinAt_iff_target, contMDiffWithinAt_iff_target, contMDiffWithinAt_iff_target,
  contMDiffWithinAt_iff_target, contMDiffWithinAt_iff_target, contMDiffWithinAt_iff_target,
  contMDiffWithinAt_iff_target, contMDiffWithinAt_iff_target, contMDiffWithinAt_iff_target,
  contMDiffWithinAt_iff_target, contMDiffWithinAt_iff_target, contMDiffWithinAt_iff_target,
  contMDiffWithinAt_iff_target, contMDiffWithinAt_iff_target, contMDiffWithinAt_iff_target,
  contMDiffWithinAt_iff_target, contMDiffWithinAt_iff_target, contMDiffWithinAt_iff_target,
  contMDiffWithinAt_iff_target, contMDiffWithinAt_iff_target, contMDiffWithinAt_iff_target,
  contMDiffWithinAt_iff_target, contMDiffWithinAt_iff_target, contMDiffWithinAt_iff_target,
  contMDiffWithinAt_iff_target, contMDiffWithinAt_iff_target, contMDiffWithinAt_iff_target,
  contMDiffWithinAt_iff_target, contMDiffWithinAt_iff_target, contMDiffWithinAt_iff_target,
  contMDif
2025-12-16 15:42:26.190 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="<stdin>:12:10: unexpected end of input; expected ']'")
2025-12-16 15:42:26.190 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 489.43s.
2025-12-16 15:42:26.190 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="<stdin>:12:10: unexpected end of input; expected ']'")
2025-12-16 15:42:26.320 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:42:26.320 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:42:28.156 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 2: Applying best tactic: exacts [‚ü®h.1, h.2.trans h.1‚ü©, ‚ü®h.2.trans h.1, h.2.trans h.2‚ü©]
2025-12-16 15:42:28.261 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="invalid projection, structure expected\n  h\nhas type\n  lcm a b = 1\ninvalid projection, structure expected\n  h\nhas type\n  lcm a b = 1\ninvalid constructor ‚ü®...‚ü©, insufficient number of arguments, constructs 'Eq.refl' does not have explicit fields, but #2 provided")
2025-12-16 15:42:28.261 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 2 steps and 359.16s.
2025-12-16 15:42:28.261 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="invalid projection, structure expected\n  h\nhas type\n  lcm a b = 1\ninvalid projection, structure expected\n  h\nhas type\n  lcm a b = 1\ninvalid constructor ‚ü®...‚ü©, insufficient number of arguments, constructs 'Eq.refl' does not have explicit fields, but #2 provided")
2025-12-16 15:42:28.393 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:42:28.393 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:42:28.860 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp only [sum_equiv, Function.comp_apply]
2025-12-16 15:42:33.560 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 2: Running MCTS search for 200 iterations...
2025-12-16 15:42:40.819 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: OrderRingIso.symm_symm
2025-12-16 15:42:45.168 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:42:46.288 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: obtain ‚ü®p, hp‚ÇÅ, hp‚ÇÇ‚ü© := exists_prime_and_dvd hk0
2025-12-16 15:42:46.374 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='application type mismatch\n  Nat.exists_prime_and_dvd hk0\nargument\n  hk0\nhas type\n  k ‚â† 0 : Prop\nbut is expected to have type\n  k ‚â† 1 : Prop')
2025-12-16 15:42:46.374 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 37.11s.
2025-12-16 15:42:46.374 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='application type mismatch\n  Nat.exists_prime_and_dvd hk0\nargument\n  hk0\nhas type\n  k ‚â† 0 : Prop\nbut is expected to have type\n  k ‚â† 1 : Prop')
2025-12-16 15:42:46.504 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:42:46.504 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:42:48.917 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp [Order.pred]
2025-12-16 15:42:50.616 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: MeasureTheory.ProbabilityMeasure.mk_apply
2025-12-16 15:42:52.263 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simpa only [‚Üê contDiffOn_univ] using hg.comp_contDiffOn hf.contDiffOn
2025-12-16 15:42:52.332 | SUCCESS  | lean_reinforcement.agent.runner:run:217 - Proof finished in 1 steps and 334.33s.
2025-12-16 15:42:52.465 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:42:52.465 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:42:53.421 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 2: Running MCTS search for 200 iterations...
2025-12-16 15:42:55.716 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: have : DenseRange (toLp p Œº ùïú) := denseRange_compact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact_sigmaCompact
2025-12-16 15:42:55.733 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:42:55.945 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='internal exception #4')
2025-12-16 15:42:55.946 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 42.49s.
2025-12-16 15:42:55.946 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='internal exception #4')
2025-12-16 15:42:56.077 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:42:56.077 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:43:01.966 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: TrivSqZeroExt.uniformContinuous_inl
2025-12-16 15:43:02.617 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Filter.tendsto_nhds
2025-12-16 15:43:02.816 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Path.extend_extends
2025-12-16 15:43:06.959 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:43:07.566 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:43:07.760 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:43:08.901 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp (config := { contextual := true })
2025-12-16 15:43:12.687 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 2: Applying best tactic: simp only [Equiv.ofInjective_apply, Equiv.ofInjective_apply]
2025-12-16 15:43:12.759 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='simp made no progress')
2025-12-16 15:43:12.759 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 2 steps and 555.43s.
2025-12-16 15:43:12.759 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='simp made no progress')
2025-12-16 15:43:12.891 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:43:12.891 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:43:13.440 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 2: Applying best tactic: rw [PredOrder.pred]
2025-12-16 15:43:13.504 | SUCCESS  | lean_reinforcement.agent.runner:run:217 - Proof finished in 2 steps and 344.54s.
2025-12-16 15:43:13.636 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:43:13.636 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:43:13.764 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 2: Running MCTS search for 200 iterations...
2025-12-16 15:43:20.378 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Con.refl
2025-12-16 15:43:23.354 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: PowerSeries.smul_eq_C_mul
2025-12-16 15:43:24.814 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:43:27.622 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:43:51.555 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [Subtype.val_injective.eq_iff, Subtype.val_injective.eq_iff, Subtype.val_injective.eq_iff,
  Subtype.val_injective.eq_iff]
2025-12-16 15:43:51.660 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  ‚Üë?m.10402 = ‚Üë?m.10403\nŒ© : Type u_1\ninst‚úù : MeasurableSpace Œ©\nŒº : MeasureTheory.Measure Œ©\nhŒº : MeasureTheory.IsProbabilityMeasure Œº\ns : Set Œ©\n‚ä¢ ‚ü®Œº, hŒº‚ü© s = (Œº s).toNNReal")
2025-12-16 15:43:51.660 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 61.04s.
2025-12-16 15:43:51.660 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  ‚Üë?m.10402 = ‚Üë?m.10403\nŒ© : Type u_1\ninst‚úù : MeasurableSpace Œ©\nŒº : MeasureTheory.Measure Œ©\nhŒº : MeasureTheory.IsProbabilityMeasure Œº\ns : Set Œ©\n‚ä¢ ‚ü®Œº, hŒº‚ü© s = (Œº s).toNNReal")
2025-12-16 15:43:51.791 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:43:51.791 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:43:59.079 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Submonoid.unop_inf
2025-12-16 15:44:03.575 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [‚Üê Œ≥.extend_apply t, Œ≥.extend_apply t, Œ≥.extend_apply t, ‚Üê Œ≥.extend_apply t,
  ‚Üê Œ≥.extend_apply t, Œ≥.extend_apply t, Œ≥.extend_apply t, Œ≥.extend_apply t, Œ≥.extend_apply t,
  Œ≥.extend_apply t, Œ≥.extend_apply t, Œ≥.extend_apply t, Œ≥.extend_apply t, Œ≥.extend_apply t,
  Œ≥.extend_apply t, Œ≥.extend_apply t, Œ≥.extend_apply t, Œ≥.extend_apply t, Œ≥.extend_apply t,
  Œ≥.extend_apply t, Œ≥.extend_apply t, Œ≥.extend_apply t, Œ≥.extend_apply t]
2025-12-16 15:44:03.681 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.52235\nX : Type u_1\nY : Type u_2\ninst‚úù¬π : TopologicalSpace X\ninst‚úù : TopologicalSpace Y\nx y z : X\nŒπ : Type u_3\nŒ≥‚úù : Path x y\na b : X\nŒ≥ : Path a b\nt : ‚Ñù\nht : t ‚àà Set.Icc 0 1\n‚ä¢ Œ≥.extend t = Œ≥ ‚ü®t, ht‚ü©")
2025-12-16 15:44:03.681 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 60.87s.
2025-12-16 15:44:03.681 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.52235\nX : Type u_1\nY : Type u_2\ninst‚úù¬π : TopologicalSpace X\ninst‚úù : TopologicalSpace Y\nx y z : X\nŒπ : Type u_3\nŒ≥‚úù : Path x y\na b : X\nŒ≥ : Path a b\nt : ‚Ñù\nht : t ‚àà Set.Icc 0 1\n‚ä¢ Œ≥.extend t = Œ≥ ‚ü®t, ht‚ü©")
2025-12-16 15:44:03.813 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:44:03.813 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:44:03.987 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:44:07.884 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [‚Üê C_mul_X_pow_eq_monomial, smul_eq_mul]
2025-12-16 15:44:07.971 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.36767\nR : Type u_1\ninst‚úù : Semiring R\nf : R‚ü¶X‚üß\na : R\n‚ä¢ a ‚Ä¢ f = (PowerSeries.C R) a * f")
2025-12-16 15:44:07.971 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 44.62s.
2025-12-16 15:44:07.971 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.36767\nR : Type u_1\ninst‚úù : Semiring R\nf : R‚ü¶X‚üß\na : R\n‚ä¢ a ‚Ä¢ f = (PowerSeries.C R) a * f")
2025-12-16 15:44:08.101 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:44:08.101 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:44:15.547 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [unop_inf_def, unop_inf_def, unop_inf_def, unop_inf_def, unop_inf_def]
2025-12-16 15:44:15.637 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.5635\nŒπ : Sort u_1\nM : Type u_2\ninst‚úù : MulOneClass M\nS‚ÇÅ S‚ÇÇ : Submonoid M·µê·µí·µñ\n‚ä¢ (S‚ÇÅ ‚äì S‚ÇÇ).unop = S‚ÇÅ.unop ‚äì S‚ÇÇ.unop")
2025-12-16 15:44:15.637 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 16.56s.
2025-12-16 15:44:15.638 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.5635\nŒπ : Sort u_1\nM : Type u_2\ninst‚úù : MulOneClass M\nS‚ÇÅ S‚ÇÇ : Submonoid M·µê·µí·µñ\n‚ä¢ (S‚ÇÅ ‚äì S‚ÇÇ).unop = S‚ÇÅ.unop ‚äì S‚ÇÇ.unop")
2025-12-16 15:44:15.767 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:44:15.767 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:44:23.082 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Equiv.Perm.extendDomain_refl
2025-12-16 15:44:23.953 | INFO     | lean_reinforcement.training.trainer:_collect_data:277 - Completed 112/128 proofs
2025-12-16 15:44:25.232 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp [norm]
2025-12-16 15:44:25.298 | SUCCESS  | lean_reinforcement.agent.runner:run:217 - Proof finished in 1 steps and 141.24s.
2025-12-16 15:44:25.429 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:44:25.429 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:44:25.610 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp_rw [disjoint_iff_inf_le, iSup_le_iff]
2025-12-16 15:44:25.690 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='simp made no progress')
2025-12-16 15:44:25.690 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 670.20s.
2025-12-16 15:44:25.690 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='simp made no progress')
2025-12-16 15:44:25.822 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:44:25.822 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:44:27.886 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:44:32.256 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: LinearPMap.IsClosable.leIsClosable
2025-12-16 15:44:36.920 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:44:47.215 | INFO     | lean_reinforcement.agent.runner:run:81 - Starting proof search for: Profinite.NobelingProof.GoodProducts.span_sum
2025-12-16 15:44:51.831 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 1: Running MCTS search for 200 iterations...
2025-12-16 15:44:55.968 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [Equiv.extendDomain_apply, Equiv.extendDomain_apply]
2025-12-16 15:44:56.068 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.79468\nŒ±' : Type u_1\nŒ≤' : Type u_2\ne : Equiv.Perm Œ±'\np : Œ≤' ‚Üí Prop\ninst‚úù : DecidablePred p\nf : Œ±' ‚âÉ Subtype p\n‚ä¢ Equiv.Perm.extendDomain (Equiv.refl Œ±') f = Equiv.refl Œ≤'")
2025-12-16 15:44:56.068 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 32.99s.
2025-12-16 15:44:56.068 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.79468\nŒ±' : Type u_1\nŒ≤' : Type u_2\ne : Equiv.Perm Œ±'\np : Œ≤' ‚Üí Prop\ninst‚úù : DecidablePred p\nf : Œ±' ‚âÉ Subtype p\n‚ä¢ Equiv.Perm.extendDomain (Equiv.refl Œ±') f = Equiv.refl Œ≤'")
2025-12-16 15:44:56.198 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:44:56.198 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:45:00.909 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [isClosable_iff_isClosed] at hf ‚ä¢
2025-12-16 15:45:01.052 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.25927\nR : Type u_1\nE : Type u_2\nF : Type u_3\ninst‚úù¬π¬π : CommRing R\ninst‚úù¬π‚Å∞ : AddCommGroup E\ninst‚úù‚Åπ : AddCommGroup F\ninst‚úù‚Å∏ : Module R E\ninst‚úù‚Å∑ : Module R F\ninst‚úù‚Å∂ : TopologicalSpace E\ninst‚úù‚Åµ : TopologicalSpace F\ninst‚úù‚Å¥ : ContinuousAdd E\ninst‚úù¬≥ : ContinuousAdd F\ninst‚úù¬≤ : TopologicalSpace R\ninst‚úù¬π : ContinuousSMul R E\ninst‚úù : ContinuousSMul R F\nf g : E ‚Üí‚Çó.[R] F\nhf : f.IsClosable\nhfg : g ‚â§ f\n‚ä¢ g.IsClosable")
2025-12-16 15:45:01.053 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 28.80s.
2025-12-16 15:45:01.053 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, equality or iff proof expected\n  ?m.25927\nR : Type u_1\nE : Type u_2\nF : Type u_3\ninst‚úù¬π¬π : CommRing R\ninst‚úù¬π‚Å∞ : AddCommGroup E\ninst‚úù‚Åπ : AddCommGroup F\ninst‚úù‚Å∏ : Module R E\ninst‚úù‚Å∑ : Module R F\ninst‚úù‚Å∂ : TopologicalSpace E\ninst‚úù‚Åµ : TopologicalSpace F\ninst‚úù‚Å¥ : ContinuousAdd E\ninst‚úù¬≥ : ContinuousAdd F\ninst‚úù¬≤ : TopologicalSpace R\ninst‚úù¬π : ContinuousSMul R E\ninst‚úù : ContinuousSMul R F\nf g : E ‚Üí‚Çó.[R] F\nhf : f.IsClosable\nhfg : g ‚â§ f\n‚ä¢ g.IsClosable")
2025-12-16 15:45:01.182 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:45:01.183 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:46:01.420 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: ext
2025-12-16 15:46:05.746 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 2: Running MCTS search for 200 iterations...
2025-12-16 15:46:05.746 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 2: Applying best tactic: rfl
2025-12-16 15:46:05.812 | SUCCESS  | lean_reinforcement.agent.runner:run:217 - Proof finished in 2 steps and 204.99s.
2025-12-16 15:46:05.942 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:46:05.942 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:46:21.168 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rcases c with ‚ü®m, rfl‚ü©
2025-12-16 15:46:21.298 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'subst' failed, invalid equality proof, it is not of the form (x = t) or (t = x)\n  ‚àÄ {w x y z : M}, Setoid.r w x ‚Üí Setoid.r y z ‚Üí Setoid.r (w * y) (x * z)\ncase mk\nM : Type u_1\nN : Type u_2\nP : Type u_3\ninst‚úù¬≤ : Mul M\ninst‚úù¬π : Mul N\ninst‚úù : Mul P\nx : M\nm : Setoid M\nmul'‚úù : ‚àÄ {w x y z : M}, Setoid.r w x ‚Üí Setoid.r y z ‚Üí Setoid.r (w * y) (x * z)\n‚ä¢ { toSetoid := m, mul' := mul'‚úù } x x")
2025-12-16 15:46:21.298 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 180.92s.
2025-12-16 15:46:21.298 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'subst' failed, invalid equality proof, it is not of the form (x = t) or (t = x)\n  ‚àÄ {w x y z : M}, Setoid.r w x ‚Üí Setoid.r y z ‚Üí Setoid.r (w * y) (x * z)\ncase mk\nM : Type u_1\nN : Type u_2\nP : Type u_3\ninst‚úù¬≤ : Mul M\ninst‚úù¬π : Mul N\ninst‚úù : Mul P\nx : M\nm : Setoid M\nmul'‚úù : ‚àÄ {w x y z : M}, Setoid.r w x ‚Üí Setoid.r y z ‚Üí Setoid.r (w * y) (x * z)\n‚ä¢ { toSetoid := m, mul' := mul'‚úù } x x")
2025-12-16 15:46:21.428 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:46:21.428 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:46:43.541 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rw [uniformContinuous_def]
2025-12-16 15:46:48.260 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 2: Running MCTS search for 200 iterations...
2025-12-16 15:46:48.287 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 2: Applying best tactic: simp (config := { contextual := true })
2025-12-16 15:46:48.424 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='simp made no progress')
2025-12-16 15:46:48.424 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 2 steps and 1056.24s.
2025-12-16 15:46:48.424 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='simp made no progress')
2025-12-16 15:46:48.553 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:46:48.554 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:47:19.351 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 2: Applying best tactic: simp only [mem_uniformity_distrib_left, mem_uniformity_distrib]
2025-12-16 15:47:19.416 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='simp made no progress')
2025-12-16 15:47:19.416 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 2 steps and 257.45s.
2025-12-16 15:47:19.417 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='simp made no progress')
2025-12-16 15:47:19.546 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:47:19.546 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:48:11.210 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: refine le_antisymm?_?_
2025-12-16 15:48:11.275 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="unknown identifier 'le_antisymm?_?_'")
2025-12-16 15:48:11.275 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 204.06s.
2025-12-16 15:48:11.276 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="unknown identifier 'le_antisymm?_?_'")
2025-12-16 15:48:11.405 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:48:11.405 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:48:51.187 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp [LipschitzWith]
2025-12-16 15:48:55.872 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 2: Running MCTS search for 200 iterations...
2025-12-16 15:49:03.547 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 2: Applying best tactic: simp
2025-12-16 15:49:03.623 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error='simp made no progress')
2025-12-16 15:49:03.623 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 2 steps and 643.03s.
2025-12-16 15:49:03.623 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error='simp made no progress')
2025-12-16 15:49:03.753 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:49:03.753 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:50:36.581 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp only [Tendsto, mem_max_iff, eventually_max_iff]
2025-12-16 15:50:36.654 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="unknown identifier 'mem_max_iff'\nunknown identifier 'eventually_max_iff'")
2025-12-16 15:50:36.654 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 1 steps and 454.04s.
2025-12-16 15:50:36.654 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="unknown identifier 'mem_max_iff'\nunknown identifier 'eventually_max_iff'")
2025-12-16 15:50:36.783 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:50:36.783 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:56:25.591 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: simp only [Cauchy, cauchy_iff, exists_prop]
2025-12-16 15:56:30.299 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 2: Running MCTS search for 200 iterations...
2025-12-16 15:59:13.030 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: refine ‚ü®hA.1.add hB.1, fun x hx =>?_‚ü©
2025-12-16 15:59:17.927 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 2: Running MCTS search for 200 iterations...
2025-12-16 15:59:27.531 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 2: Applying best tactic: rw [add_mulVec, dotProduct_add]
2025-12-16 15:59:32.302 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 3: Running MCTS search for 200 iterations...
2025-12-16 15:59:32.303 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 3: Applying best tactic: rw [dotProduct_mulVec, dotProduct_mulVec, dotProduct_mulVec, dotProduct_mulVec,
  dotProduct_add_dotProduct_add_dotProduct_add_dotProduct_add_dotProduct_add_dotProduct_add_dotProduct_add_dotProduct_add_dotProduct_add_dotProduct_add_dotProduct_add_dotProduct_add_dotProduct_add_dotProduct_add_dotProduct_add_dotProduct_add_dotProduct_add_dotProduct_add_dotProduct_add_dotProduct_add_dotProduct_add_dotProduct_add_dotProduct_add_dotProduct_add_dotProduct_add_dotProduct_add_dotProduct_add_dotProduct_add_dotProduct_add_dotProduct_add_dotProduct_add_dotProduct_add_dotProduct_add_dotProduct_add_dotProduct_add_dotProduct]
2025-12-16 15:59:32.448 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  ?v ‚¨ù·µ• ?A *·µ• ?w\nm : Type u_1\nn : Type u_2\nR : Type u_3\nùïú : Type u_4\ninst‚úù‚Å∂ : Fintype m\ninst‚úù‚Åµ : Fintype n\ninst‚úù‚Å¥ : CommRing R\ninst‚úù¬≥ : PartialOrder R\ninst‚úù¬≤ : StarRing R\ninst‚úù¬π : StarOrderedRing R\ninst‚úù : RCLike ùïú\nA B : Matrix m m R\nhA : A.PosSemidef\nhB : B.PosDef\nx : m ‚Üí R\nhx : x ‚â† 0\n‚ä¢ 0 < star x ·µ•* A ‚¨ù·µ• x + star x ·µ•* B ‚¨ù·µ• x")
2025-12-16 15:59:32.448 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 3 steps and 2228.37s.
2025-12-16 15:59:32.448 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="tactic 'rewrite' failed, did not find instance of the pattern in the target expression\n  ?v ‚¨ù·µ• ?A *·µ• ?w\nm : Type u_1\nn : Type u_2\nR : Type u_3\nùïú : Type u_4\ninst‚úù‚Å∂ : Fintype m\ninst‚úù‚Åµ : Fintype n\ninst‚úù‚Å¥ : CommRing R\ninst‚úù¬≥ : PartialOrder R\ninst‚úù¬≤ : StarRing R\ninst‚úù¬π : StarOrderedRing R\ninst‚úù : RCLike ùïú\nA B : Matrix m m R\nhA : A.PosSemidef\nhB : B.PosDef\nx : m ‚Üí R\nhx : x ‚â† 0\n‚ä¢ 0 < star x ·µ•* A ‚¨ù·µ• x + star x ·µ•* B ‚¨ù·µ• x")
2025-12-16 15:59:32.578 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:59:32.578 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 15:59:34.101 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rcases eq_or_lt_of_le (hœÄn œâ) with (h | h)
2025-12-16 15:59:38.808 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 2: Running MCTS search for 200 iterations...
2025-12-16 15:59:50.440 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: by_cases h : f = 0
2025-12-16 15:59:54.916 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 2: Running MCTS search for 200 iterations...
2025-12-16 16:03:44.982 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 2: Applying best tactic: simp only [le_def, prod_subset_prod_iff]
2025-12-16 16:03:49.439 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 3: Running MCTS search for 200 iterations...
2025-12-16 16:04:47.142 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 1: Applying best tactic: rcases eq_or_ne x 0 with (rfl | h'x)
2025-12-16 16:04:52.118 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 2: Running MCTS search for 200 iterations...
2025-12-16 16:07:14.712 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 3: Applying best tactic: constructor
2025-12-16 16:07:19.149 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 4: Running MCTS search for 200 iterations...
2025-12-16 16:07:19.149 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 4: Applying best tactic: exacts [fun s hs ‚Ü¶ ‚ü®t, t_mem_uniformity hs, fun s hs ‚Ü¶ ‚ü®t, t_mem_uniformity hs, hs‚ü©,
  fun s hs ‚Ü¶ ‚ü®t, t_mem_uniformity hs, fun s hs ‚Ü¶ ‚ü®t, t_mem_uniformity hs, fun s hs ‚Ü¶ ‚ü®t, t_mem_uniformity hs‚ü©]
2025-12-16 16:07:19.213 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="<stdin>:2:109: expected '‚ü©'")
2025-12-16 16:07:19.213 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 4 steps and 1634.90s.
2025-12-16 16:07:19.214 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="<stdin>:2:109: expected '‚ü©'")
2025-12-16 16:07:19.342 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 16:07:19.342 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 16:07:48.584 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 2: Applying best tactic: swap
2025-12-16 16:07:53.081 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 3: Running MCTS search for 200 iterations...
2025-12-16 16:08:47.122 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 2: Applying best tactic: swap
2025-12-16 16:08:51.818 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 3: Running MCTS search for 200 iterations...
2025-12-16 16:08:51.818 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 3: Applying best tactic: exacts [isBigO_sub (isBigO_refl _ _) (isBigO_sub (isBigO_refl _ _) (isBigO_sub (isBigO_refl _ _) _),
  isBigO_sub (isBigO_refl _ _) (isBigO_sub (isBigO_refl _ _) (isBigO_sub (isBigO_refl _ _) _),
  isBigO_sub (isBigO_refl _ _) (isBigO_sub (isBigO_refl _ _) (isBigO_sub (isBigO_refl _ _) _),
  isBigO_sub (isBigO_refl _ _) (isBigO_sub (isBigO_refl _ _) (isBigO_sub (isBigO_refl _ _) _),
  isBigO_sub (isBigO_refl _ _) (isBigO_sub (isBigO_refl _ _) (isBigO_refl _ _),
  isBigO_sub (isBigO_refl _ _), isBigO_sub (isBigO_refl _ _), isBigO_sub (isBigO_refl _ _),
  isBigO_sub (isBigO_refl _ _), isBigO_sub (isBigO_refl _ _), isBigO_sub (isBigO_refl _ _),
  isBigO_sub (isBigO_refl _ _), isBigO_sub (isBigO_refl _ _), isBigO_sub (isBigO_refl _ _),
  isBigO_sub (isBigO_refl _ _), isBigO_sub (isBigO_refl _ _), isBigO_sub (isBigO_refl _ _)]
2025-12-16 16:08:51.884 | WARNING  | lean_reinforcement.agent.runner:run:184 - Tactic resulted in error: LeanError(error="<stdin>:9:90: expected ')'")
2025-12-16 16:08:51.884 | ERROR    | lean_reinforcement.agent.runner:run:221 - Proof failed after 3 steps and 2554.91s.
2025-12-16 16:08:51.885 | WARNING  | lean_reinforcement.agent.runner:run:225 - Final state: LeanError(error="<stdin>:9:90: expected ')'")
2025-12-16 16:08:52.013 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 16:08:52.013 | INFO     | lean_reinforcement.utilities.gym:close:99 - Environment closed.
2025-12-16 16:09:43.136 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 2: Applying best tactic: swap
2025-12-16 16:09:47.761 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 3: Running MCTS search for 200 iterations...
2025-12-16 16:10:38.230 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 3: Applying best tactic: swap
2025-12-16 16:10:42.680 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 4: Running MCTS search for 200 iterations...
2025-12-16 16:12:31.530 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 3: Applying best tactic: swap
2025-12-16 16:12:35.991 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 4: Running MCTS search for 200 iterations...
2025-12-16 16:16:07.029 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 4: Applying best tactic: swap
2025-12-16 16:16:11.124 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 4: Applying best tactic: swap
2025-12-16 16:16:11.576 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 5: Running MCTS search for 200 iterations...
2025-12-16 16:16:15.613 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 5: Running MCTS search for 200 iterations...
2025-12-16 16:21:16.093 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 5: Applying best tactic: swap
2025-12-16 16:21:20.624 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 6: Running MCTS search for 200 iterations...
2025-12-16 16:23:38.700 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 6: Applying best tactic: swap
2025-12-16 16:23:43.122 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 7: Running MCTS search for 200 iterations...
2025-12-16 16:23:44.490 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 5: Applying best tactic: swap
2025-12-16 16:23:49.078 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 6: Running MCTS search for 200 iterations...
2025-12-16 16:24:23.238 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 6: Applying best tactic: swap
2025-12-16 16:24:27.898 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 7: Running MCTS search for 200 iterations...
2025-12-16 16:24:37.980 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 7: Applying best tactic: swap
2025-12-16 16:24:42.637 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 8: Running MCTS search for 200 iterations...
2025-12-16 16:25:15.264 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 8: Applying best tactic: swap
2025-12-16 16:25:19.924 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 9: Running MCTS search for 200 iterations...
2025-12-16 16:28:27.907 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 7: Applying best tactic: swap
2025-12-16 16:28:32.379 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 8: Running MCTS search for 200 iterations...
2025-12-16 16:28:52.802 | INFO     | lean_reinforcement.agent.runner:run:175 - Step 9: Applying best tactic: swap
2025-12-16 16:28:57.350 | INFO     | lean_reinforcement.agent.runner:run:112 - Step 10: Running MCTS search for 200 iterations...
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
[2025-12-16T16:28:58.867] error: *** JOB 17642759 ON gcn43 CANCELLED AT 2025-12-16T16:28:58 DUE to SIGNAL Terminated ***
[2025-12-16T16:28:58.867] error: *** STEP 17642759.0 ON gcn43 CANCELLED AT 2025-12-16T16:28:58 DUE to SIGNAL Terminated ***
